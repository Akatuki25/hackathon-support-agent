2025-09-07 13:23:20,893 | INFO | hackson_support_agent | Loaded environment variables from /workspaces/hackson_support_agent/back/.env.local
2025-09-07 13:23:36,022 | INFO | hackson_support_agent | Loaded environment variables from /workspaces/hackson_support_agent/back/.env.local
2025-09-07 13:23:37,119 | INFO | hackson_support_agent | Loaded environment variables from /workspaces/hackson_support_agent/back/.env.local
2025-09-07 13:24:44,800 | INFO | hackson_support_agent | Loaded environment variables from /workspaces/hackson_support_agent/back/.env.local
2025-09-07 13:26:25,715 | INFO | hackson_support_agent | Loaded environment variables from /workspaces/hackson_support_agent/back/.env.local
2025-09-07 13:28:08,921 | DEBUG | hackson_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-07 13:28:08,922 | INFO | hackson_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-07 13:28:08,922 | DEBUG | hackson_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-07 13:28:08,946 | INFO | hackson_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-07 13:28:08,946 | DEBUG | hackson_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-07 13:28:08,947 | INFO | hackson_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-07 13:28:08,948 | DEBUG | hackson_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-07 13:28:08,948 | INFO | hackson_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-07 13:28:08,948 | DEBUG | hackson_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-07 13:28:08,949 | INFO | hackson_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-07 13:28:08,949 | DEBUG | hackson_support_agent.QuestionService | LLMs initialized
2025-09-07 13:28:08,950 | DEBUG | hackson_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-09-07 13:30:43,710 | INFO | hackson_support_agent | Loaded environment variables from /workspaces/hackson_support_agent/back/.env.local
2025-09-07 13:30:47,568 | INFO | hackson_support_agent | Loaded environment variables from /workspaces/hackson_support_agent/back/.env.local
2025-09-07 13:30:49,798 | INFO | hackson_support_agent | Loaded environment variables from /workspaces/hackson_support_agent/back/.env.local
2025-09-07 13:30:55,499 | INFO | hackson_support_agent | Loaded environment variables from /workspaces/hackson_support_agent/back/.env.local
2025-09-07 13:30:58,698 | INFO | hackson_support_agent | Loaded environment variables from /workspaces/hackson_support_agent/back/.env.local
2025-09-07 13:31:01,177 | INFO | hackson_support_agent | Loaded environment variables from /workspaces/hackson_support_agent/back/.env.local
2025-09-07 13:31:14,735 | INFO | hackson_support_agent | Loaded environment variables from /workspaces/hackson_support_agent/back/.env.local
2025-09-07 13:31:19,680 | INFO | hackson_support_agent | Loaded environment variables from /workspaces/hackson_support_agent/back/.env.local
2025-09-07 13:31:23,048 | INFO | hackson_support_agent | Loaded environment variables from /workspaces/hackson_support_agent/back/.env.local
2025-09-07 13:31:30,236 | INFO | hackson_support_agent | Loaded environment variables from /workspaces/hackson_support_agent/back/.env.local
2025-09-07 13:32:32,727 | INFO | hackson_support_agent | Loaded environment variables from /workspaces/hackson_support_agent/back/.env.local
2025-09-07 13:37:09,655 | INFO | hackson_support_agent | Loaded environment variables from /workspaces/hackson_support_agent/back/.env.local
2025-09-07 13:37:12,858 | INFO | hackson_support_agent | Loaded environment variables from /workspaces/hackson_support_agent/back/.env.local
2025-09-07 13:38:14,435 | INFO | hackson_support_agent | Loaded environment variables from /workspaces/hackson_support_agent/back/.env.local
2025-09-07 13:40:57,147 | DEBUG | hackson_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-07 13:40:57,149 | INFO | hackson_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-07 13:40:57,149 | DEBUG | hackson_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-07 13:40:57,159 | INFO | hackson_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-07 13:40:57,159 | DEBUG | hackson_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-07 13:40:57,160 | INFO | hackson_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-07 13:40:57,160 | DEBUG | hackson_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-07 13:40:57,161 | INFO | hackson_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-07 13:40:57,161 | DEBUG | hackson_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-07 13:40:57,162 | INFO | hackson_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-07 13:40:57,162 | DEBUG | hackson_support_agent.QuestionService | LLMs initialized
2025-09-07 13:40:57,162 | DEBUG | hackson_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-09-07 13:42:30,765 | DEBUG | hackson_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-07 13:42:30,766 | INFO | hackson_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-07 13:42:30,766 | DEBUG | hackson_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-07 13:42:30,767 | INFO | hackson_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-07 13:42:30,767 | DEBUG | hackson_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-07 13:42:30,768 | INFO | hackson_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-07 13:42:30,768 | DEBUG | hackson_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-07 13:42:30,769 | INFO | hackson_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-07 13:42:30,769 | DEBUG | hackson_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-07 13:42:30,770 | INFO | hackson_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-07 13:42:30,770 | DEBUG | hackson_support_agent.QuestionService | LLMs initialized
2025-09-07 13:42:30,770 | DEBUG | hackson_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-09-07 13:44:03,467 | INFO | hackson_support_agent | Loaded environment variables from /workspaces/hackson_support_agent/back/.env.local
2025-09-07 13:44:04,507 | INFO | hackson_support_agent | Loaded environment variables from /workspaces/hackson_support_agent/back/.env.local
2025-09-07 13:44:12,556 | DEBUG | hackson_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-07 13:44:12,557 | INFO | hackson_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-07 13:44:12,557 | DEBUG | hackson_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-07 13:44:12,567 | INFO | hackson_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-07 13:44:12,567 | DEBUG | hackson_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-07 13:44:12,568 | INFO | hackson_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-07 13:44:12,568 | DEBUG | hackson_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-07 13:44:12,569 | INFO | hackson_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-07 13:44:12,569 | DEBUG | hackson_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-07 13:44:12,570 | INFO | hackson_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-07 13:44:12,570 | DEBUG | hackson_support_agent.QuestionService | LLMs initialized
2025-09-07 13:44:12,570 | DEBUG | hackson_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-09-07 13:48:23,328 | INFO | hackson_support_agent | Loaded environment variables from /workspaces/hackson_support_agent/back/.env.local
2025-09-07 13:48:24,427 | INFO | hackson_support_agent | Loaded environment variables from /workspaces/hackson_support_agent/back/.env.local
2025-09-07 13:48:54,741 | INFO | hackson_support_agent | Loaded environment variables from /workspaces/hackson_support_agent/back/.env.local
2025-09-07 13:48:55,799 | INFO | hackson_support_agent | Loaded environment variables from /workspaces/hackson_support_agent/back/.env.local
2025-09-07 13:51:24,296 | DEBUG | hackson_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-07 13:51:24,297 | INFO | hackson_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-07 13:51:24,297 | DEBUG | hackson_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-07 13:51:24,307 | INFO | hackson_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-07 13:51:24,307 | DEBUG | hackson_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-07 13:51:24,308 | INFO | hackson_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-07 13:51:24,309 | DEBUG | hackson_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-07 13:51:24,310 | INFO | hackson_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-07 13:51:24,310 | DEBUG | hackson_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-07 13:51:24,311 | INFO | hackson_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-07 13:51:24,311 | DEBUG | hackson_support_agent.QuestionService | LLMs initialized
2025-09-07 13:51:24,312 | DEBUG | hackson_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-09-07 13:52:58,376 | INFO | hackt_support_agent | Loaded environment variables from /workspaces/hackson_support_agent/back/.env.local
2025-09-07 13:53:00,439 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackson_support_agent/back/.env.local
2025-09-07 13:53:05,052 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-07 13:53:45,888 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-07 13:53:45,890 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-07 13:53:45,890 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-07 13:53:45,901 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-07 13:53:45,901 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-07 13:53:45,902 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-07 13:53:45,902 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-07 13:53:45,903 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-07 13:53:45,903 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-07 13:53:45,904 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-07 13:53:45,904 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-07 13:53:45,904 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-09-07 14:08:41,549 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-07 14:08:42,643 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-07 14:09:36,865 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-07 14:09:36,866 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-07 14:09:36,866 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-07 14:09:36,889 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-07 14:09:36,889 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-07 14:09:36,890 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-07 14:09:36,890 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-07 14:09:36,891 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-07 14:09:36,891 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-07 14:09:36,892 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-07 14:09:36,892 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-07 14:09:36,892 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-09-07 14:10:54,138 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-07 14:10:55,267 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-07 14:10:59,253 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-07 14:10:59,254 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-07 14:10:59,254 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-07 14:10:59,264 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-07 14:10:59,264 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-07 14:10:59,265 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-07 14:10:59,265 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-07 14:10:59,266 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-07 14:10:59,266 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-07 14:10:59,267 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-07 14:10:59,267 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-07 14:10:59,267 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-09-07 14:12:43,135 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-07 14:12:44,785 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-07 14:12:51,984 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-07 14:12:54,746 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-07 14:13:01,859 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-07 14:13:03,136 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-07 14:13:06,537 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-07 14:13:06,537 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-07 14:13:06,538 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-07 14:13:06,548 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-07 14:13:06,549 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-07 14:13:06,550 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-07 14:13:06,550 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-07 14:13:06,551 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-07 14:13:06,551 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-07 14:13:06,552 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-07 14:13:06,552 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-07 14:13:06,552 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-09-07 14:13:10,164 | INFO | hackthon_support_agent.QuestionService | Questions saved successfully
2025-09-07 14:19:27,789 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-07 14:21:01,633 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-07 14:21:01,634 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-07 14:21:01,634 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-07 14:21:01,643 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-07 14:21:01,644 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-07 14:21:01,645 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-07 14:21:01,645 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-07 14:21:01,646 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-07 14:21:01,646 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-07 14:21:01,647 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-07 14:21:01,647 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-07 14:21:01,647 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-09-07 14:21:05,634 | INFO | hackthon_support_agent.QuestionService | Questions saved successfully
2025-09-07 14:21:59,017 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-07 14:22:29,047 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-07 14:22:29,047 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-07 14:22:29,048 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-07 14:22:29,057 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-07 14:22:29,058 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-07 14:22:29,059 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-07 14:22:29,059 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-07 14:22:29,060 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-07 14:22:29,060 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-07 14:22:29,061 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-07 14:22:29,061 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-07 14:22:29,061 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-09-07 14:22:33,036 | ERROR | hackthon_support_agent.QuestionService | Failed to save questions
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2114, in _exec_insertmany_context
    dialect.do_execute(
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 943, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.ForeignKeyViolation: insert or update on table "qa" violates foreign key constraint "qa_project_id_fkey"
DETAIL:  Key (project_id)=(7db0a417-9717-44c2-aa7f-28a308740f33) is not present in table "projectBase".


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/question_service.py", line 112, in save_question
    self.db.commit()
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2032, in commit
    trans.commit(_to_root=True)
  File "<string>", line 2, in commit
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
    ret_value = fn(self, *arg, **kw)
                ^^^^^^^^^^^^^^^^^^^^
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1313, in commit
    self._prepare_impl()
  File "<string>", line 2, in _prepare_impl
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
    ret_value = fn(self, *arg, **kw)
                ^^^^^^^^^^^^^^^^^^^^
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1288, in _prepare_impl
    self.session.flush()
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4345, in flush
    self._flush(objects)
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4480, in _flush
    with util.safe_reraise():
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 224, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4441, in _flush
    flush_context.execute()
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 466, in execute
    rec.execute(self)
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 642, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 93, in save_obj
    _emit_insert_statements(
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 1143, in _emit_insert_statements
    result = connection.execute(
             ^^^^^^^^^^^^^^^^^^^
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1415, in execute
    return meth(
           ^^^^^
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 523, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1637, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1840, in _execute_context
    return self._exec_insertmany_context(dialect, context)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2122, in _exec_insertmany_context
    self._handle_dbapi_exception(
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2351, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2114, in _exec_insertmany_context
    dialect.do_execute(
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 943, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.ForeignKeyViolation) insert or update on table "qa" violates foreign key constraint "qa_project_id_fkey"
DETAIL:  Key (project_id)=(7db0a417-9717-44c2-aa7f-28a308740f33) is not present in table "projectBase".

[SQL: INSERT INTO qa (qa_id, project_id, question, answer, is_ai, source_doc_id, follows_qa_id, importance) VALUES (%(qa_id__0)s::UUID, %(project_id__0)s::UUID, %(question__0)s, %(answer__0)s, %(is_ai__0)s, %(source_doc_id__0)s::UUID, %(follows_qa_id__0)s: ... 967 characters truncated ... _doc_id__6)s::UUID, %(follows_qa_id__6)s::UUID, %(importance__6)s) RETURNING qa.created_at, qa.qa_id]
[parameters: {'importance__0': 5, 'project_id__0': UUID('7db0a417-9717-44c2-aa7f-28a308740f33'), 'follows_qa_id__0': None, 'question__0': '「面白いアプリ」とは、具体的にどのような面白さを指しますか？例えば、ゲームのようなエンターテイメント性、日常を便利にするような実用性、あるいは新しい発見や学びを提供するような知的好奇心を刺激するものなど、どのような方向性の面白さをイメージされていますか？', 'qa_id__0': UUID('ad5183a5-e682-411d-88dc-12a9577f6639'), 'source_doc_id__0': None, 'answer__0': 'まだ具体的には決まっていませんが、友達とワイワイ楽しめるような、ちょっと変わったゲーム要素のあるアプリが面白そうだと考えています。あるいは、普段の生活で「こんなアプリがあったら便利なのに」と思うような、ニッチだけど役立つものも良いですね。', 'is_ai__0': True, 'importance__1': 5, 'project_id__1': UUID('7db0a417-9717-44c2-aa7f-28a308740f33'), 'follows_qa_id__1': None, 'question__1': 'ハッカソン期間はどのくらいを想定されていますか？また、参加される人数は何名くらいでしょうか？この情報があると、実現可能な機能の範囲や、チームでの役割分担などを具体的に検討しやすくなります。', 'qa_id__1': UUID('d4169449-265e-4533-aea2-3df3f95deeac'), 'source_doc_id__1': None, 'answer__1': '期間は2日間、人数は3〜4名で参加する予定です。短期間なので、あまり複雑すぎないものが良いかもしれません。', 'is_ai__1': True, 'importance__2': 4, 'project_id__2': UUID('7db0a417-9717-44c2-aa7f-28a308740f33'), 'follows_qa_id__2': None, 'question__2': 'ターゲットユーザーはどのような層を想定していますか？例えば、学生、社会人、特定の趣味を持つ人々など、誰に使ってもらいたいかによって、アプリの機能やデザインの方向性が大きく変わってきます。', 'qa_id__2': UUID('f1c558c4-dcb3-4a36-93b4-323442714cdd'), 'source_doc_id__2': None, 'answer__2': '主に同世代の学生や、気軽に遊べるアプリを探している若年層を想定しています。友達同士で盛り上がれるようなものが良いですね。', 'is_ai__2': True, 'importance__3': 4, 'project_id__3': UUID('7db0a417-9717-44c2-aa7f-28a308740f33'), 'follows_qa_id__3': None, 'question__3': 'もし、アイデアがまだ漠然としている場合、どのようなテーマやジャンルに興味がありますか？例えば、コミュニケーション、学習、エンターテイメント、ライフログ、クリエイティブツールなど、いくつか候補を挙げていただくと、そこから具体的なアイデアを膨らませることができます。', 'qa_id__3': UUID('8f93729d-fc66-4419-894b-3ccd882ac0d7'), 'source_doc_id__3': None, 'answer__3': 'コミュニケーション系は面白そうですね。あとは、ちょっとしたゲーム要素があるものや、写真・動画を加工するようなクリエイティブなものにも興味があります。', 'is_ai__3': True, 'importance__4': 3, 'project_id__4': UUID('7db0a417-9717-44c2-aa7f-28a308740f33'), 'follows_qa_id__4': None, 'question__4': '現在、どのようなプログラミング言語や技術に触れた経験がありますか？例えば、Web開発（HTML, CSS, JavaScript）、モバイルアプリ開発（Swift, Kotlin, React Native）、バックエンド開発（Python, Ruby, Node.js）など、得意な分野や学習したい分野があれば教えてください。', 'qa_id__4': UUID('0cf3d149-2758-48cd-84ad-9f5d684f83ec'), 'source_doc_id__4': None, 'answer__4': '私はHTMLとCSS、JavaScriptの基本的な知識があります。Pythonも少し触ったことがあります。他のメンバーは、SwiftやJavaを少し勉強したことがあるようです。', 'is_ai__4': True, 'importance__5': 4, 'project_id__5': UUID('7db0a417-9717-44c2-aa7f-28a308740f33'), 'follows_qa_id__5': None, 'question__5': 'アプリを通じて、ユーザーにどのような体験を提供したいですか？例えば、驚き、感動、共感、達成感など、ユーザーがアプリを使った後にどのような気持ちになってほしいかを想像してみてください。', 'qa_id__5': UUID('b463005f-274c-4e6c-8ceb-e7f20f287ca1'), 'source_doc_id__5': None, 'answer__5': '友達と遊んでいる時に「これ面白いね！」と盛り上がったり、思わず笑ってしまうような体験を提供したいです。', 'is_ai__5': True, 'importance__6': 3, 'project_id__6': UUID('7db0a417-9717-44c2-aa7f-28a308740f33'), 'follows_qa_id__6': None, 'question__6': '既存のアプリで「こんな機能があったらもっと良いのに」と感じたことはありますか？あるいは、「このアプリのこの部分が面白い」と感じた点はありますか？参考にしたい既存のアプリがあれば教えてください。', 'qa_id__6': UUID('4330ec05-4496-411f-bb54-00b474f69d4b'), 'source_doc_id__6': None, 'answer__6': 'SNSで友達と共有する際に、もっとユニークなスタンプやエフェクトがあったら楽しいのに、と思います。あと、簡単なミニゲームを友達とすぐに遊べるようなアプリも良いですね。', 'is_ai__6': True}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
2025-09-07 14:22:33,041 | ERROR | hackthon_support_agent.QuestionService | Error details: (psycopg2.errors.ForeignKeyViolation) insert or update on table "qa" violates foreign key constraint "qa_project_id_fkey"
DETAIL:  Key (project_id)=(7db0a417-9717-44c2-aa7f-28a308740f33) is not present in table "projectBase".

[SQL: INSERT INTO qa (qa_id, project_id, question, answer, is_ai, source_doc_id, follows_qa_id, importance) VALUES (%(qa_id__0)s::UUID, %(project_id__0)s::UUID, %(question__0)s, %(answer__0)s, %(is_ai__0)s, %(source_doc_id__0)s::UUID, %(follows_qa_id__0)s: ... 967 characters truncated ... _doc_id__6)s::UUID, %(follows_qa_id__6)s::UUID, %(importance__6)s) RETURNING qa.created_at, qa.qa_id]
[parameters: {'importance__0': 5, 'project_id__0': UUID('7db0a417-9717-44c2-aa7f-28a308740f33'), 'follows_qa_id__0': None, 'question__0': '「面白いアプリ」とは、具体的にどのような面白さを指しますか？例えば、ゲームのようなエンターテイメント性、日常を便利にするような実用性、あるいは新しい発見や学びを提供するような知的好奇心を刺激するものなど、どのような方向性の面白さをイメージされていますか？', 'qa_id__0': UUID('ad5183a5-e682-411d-88dc-12a9577f6639'), 'source_doc_id__0': None, 'answer__0': 'まだ具体的には決まっていませんが、友達とワイワイ楽しめるような、ちょっと変わったゲーム要素のあるアプリが面白そうだと考えています。あるいは、普段の生活で「こんなアプリがあったら便利なのに」と思うような、ニッチだけど役立つものも良いですね。', 'is_ai__0': True, 'importance__1': 5, 'project_id__1': UUID('7db0a417-9717-44c2-aa7f-28a308740f33'), 'follows_qa_id__1': None, 'question__1': 'ハッカソン期間はどのくらいを想定されていますか？また、参加される人数は何名くらいでしょうか？この情報があると、実現可能な機能の範囲や、チームでの役割分担などを具体的に検討しやすくなります。', 'qa_id__1': UUID('d4169449-265e-4533-aea2-3df3f95deeac'), 'source_doc_id__1': None, 'answer__1': '期間は2日間、人数は3〜4名で参加する予定です。短期間なので、あまり複雑すぎないものが良いかもしれません。', 'is_ai__1': True, 'importance__2': 4, 'project_id__2': UUID('7db0a417-9717-44c2-aa7f-28a308740f33'), 'follows_qa_id__2': None, 'question__2': 'ターゲットユーザーはどのような層を想定していますか？例えば、学生、社会人、特定の趣味を持つ人々など、誰に使ってもらいたいかによって、アプリの機能やデザインの方向性が大きく変わってきます。', 'qa_id__2': UUID('f1c558c4-dcb3-4a36-93b4-323442714cdd'), 'source_doc_id__2': None, 'answer__2': '主に同世代の学生や、気軽に遊べるアプリを探している若年層を想定しています。友達同士で盛り上がれるようなものが良いですね。', 'is_ai__2': True, 'importance__3': 4, 'project_id__3': UUID('7db0a417-9717-44c2-aa7f-28a308740f33'), 'follows_qa_id__3': None, 'question__3': 'もし、アイデアがまだ漠然としている場合、どのようなテーマやジャンルに興味がありますか？例えば、コミュニケーション、学習、エンターテイメント、ライフログ、クリエイティブツールなど、いくつか候補を挙げていただくと、そこから具体的なアイデアを膨らませることができます。', 'qa_id__3': UUID('8f93729d-fc66-4419-894b-3ccd882ac0d7'), 'source_doc_id__3': None, 'answer__3': 'コミュニケーション系は面白そうですね。あとは、ちょっとしたゲーム要素があるものや、写真・動画を加工するようなクリエイティブなものにも興味があります。', 'is_ai__3': True, 'importance__4': 3, 'project_id__4': UUID('7db0a417-9717-44c2-aa7f-28a308740f33'), 'follows_qa_id__4': None, 'question__4': '現在、どのようなプログラミング言語や技術に触れた経験がありますか？例えば、Web開発（HTML, CSS, JavaScript）、モバイルアプリ開発（Swift, Kotlin, React Native）、バックエンド開発（Python, Ruby, Node.js）など、得意な分野や学習したい分野があれば教えてください。', 'qa_id__4': UUID('0cf3d149-2758-48cd-84ad-9f5d684f83ec'), 'source_doc_id__4': None, 'answer__4': '私はHTMLとCSS、JavaScriptの基本的な知識があります。Pythonも少し触ったことがあります。他のメンバーは、SwiftやJavaを少し勉強したことがあるようです。', 'is_ai__4': True, 'importance__5': 4, 'project_id__5': UUID('7db0a417-9717-44c2-aa7f-28a308740f33'), 'follows_qa_id__5': None, 'question__5': 'アプリを通じて、ユーザーにどのような体験を提供したいですか？例えば、驚き、感動、共感、達成感など、ユーザーがアプリを使った後にどのような気持ちになってほしいかを想像してみてください。', 'qa_id__5': UUID('b463005f-274c-4e6c-8ceb-e7f20f287ca1'), 'source_doc_id__5': None, 'answer__5': '友達と遊んでいる時に「これ面白いね！」と盛り上がったり、思わず笑ってしまうような体験を提供したいです。', 'is_ai__5': True, 'importance__6': 3, 'project_id__6': UUID('7db0a417-9717-44c2-aa7f-28a308740f33'), 'follows_qa_id__6': None, 'question__6': '既存のアプリで「こんな機能があったらもっと良いのに」と感じたことはありますか？あるいは、「このアプリのこの部分が面白い」と感じた点はありますか？参考にしたい既存のアプリがあれば教えてください。', 'qa_id__6': UUID('4330ec05-4496-411f-bb54-00b474f69d4b'), 'source_doc_id__6': None, 'answer__6': 'SNSで友達と共有する際に、もっとユニークなスタンプやエフェクトがあったら楽しいのに、と思います。あと、簡単なミニゲームを友達とすぐに遊べるようなアプリも良いですね。', 'is_ai__6': True}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
2025-09-07 14:25:09,614 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-07 14:25:13,302 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-07 14:25:33,988 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-07 14:25:33,988 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-07 14:25:33,988 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-07 14:25:34,000 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-07 14:25:34,000 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-07 14:25:34,002 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-07 14:25:34,002 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-07 14:25:34,003 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-07 14:25:34,003 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-07 14:25:34,004 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-07 14:25:34,004 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-07 14:25:34,004 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-09-07 14:25:37,678 | ERROR | hackthon_support_agent.QuestionService | Failed to save questions
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/question_service.py", line 100, in save_question
    project_uuid = uuid.UUID(project_uuid)
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/uuid.py", line 178, in __init__
    raise ValueError('badly formed hexadecimal UUID string')
ValueError: badly formed hexadecimal UUID string
2025-09-07 14:25:37,678 | ERROR | hackthon_support_agent.QuestionService | Error details: badly formed hexadecimal UUID string
2025-09-07 14:26:14,023 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-07 14:27:07,456 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-07 14:27:30,319 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-07 14:27:30,320 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-07 14:27:30,320 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-07 14:27:30,332 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-07 14:27:30,332 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-07 14:27:30,333 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-07 14:27:30,333 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-07 14:27:30,334 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-07 14:27:30,334 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-07 14:27:30,335 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-07 14:27:30,335 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-07 14:27:30,335 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-09-07 14:27:35,032 | INFO | hackthon_support_agent.QuestionService | Questions saved successfully
2025-09-07 14:28:34,692 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-07 14:29:10,380 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-07 14:29:10,381 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-07 14:29:10,381 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-07 14:29:10,391 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-07 14:29:10,392 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-07 14:29:10,393 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-07 14:29:10,393 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-07 14:29:10,394 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-07 14:29:10,394 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-07 14:29:10,395 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-07 14:29:10,395 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-07 14:29:10,395 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-09-07 14:29:13,986 | INFO | hackthon_support_agent.QuestionService | Questions saved successfully
2025-09-08 04:38:07,081 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-08 04:51:48,584 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-08 04:52:02,236 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-08 04:52:03,474 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-08 04:53:25,024 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-08 04:53:49,752 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-08 04:53:51,949 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-08 06:03:12,101 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-08 06:03:13,940 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-08 06:03:16,205 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-08 06:03:18,989 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-08 06:03:41,329 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-08 06:03:44,526 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-08 06:04:59,789 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-08 06:05:18,059 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 02:28:26,734 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 02:28:46,678 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 02:28:48,840 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 02:29:05,914 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 02:29:08,760 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 02:29:15,866 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 02:29:18,993 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 02:29:21,456 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 02:30:01,077 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 05:30:44,538 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-10 05:30:44,540 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-10 05:30:44,540 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 05:30:44,575 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 05:30:44,575 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 05:30:44,577 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 05:30:44,577 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 05:30:44,578 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 05:30:44,578 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 05:30:44,578 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 05:30:44,578 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-10 05:30:44,579 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-09-10 05:30:47,971 | INFO | hackthon_support_agent.QuestionService | Questions saved successfully
2025-09-10 05:56:13,085 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-10 05:56:13,086 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-10 05:56:13,086 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 05:56:13,090 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 05:56:13,090 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 05:56:13,091 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 05:56:13,091 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 05:56:13,092 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 05:56:13,092 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 05:56:13,093 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 05:56:13,093 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-10 05:56:13,093 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-09-10 05:56:17,178 | INFO | hackthon_support_agent.QuestionService | Questions saved successfully
2025-09-10 06:02:20,656 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 06:02:27,641 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 06:02:29,693 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 06:02:33,481 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 06:02:37,989 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 06:11:12,002 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 06:11:21,781 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 06:11:31,525 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 06:11:35,271 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 06:11:39,399 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 06:11:41,990 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 06:12:20,147 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 06:12:22,183 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 06:12:48,495 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 06:12:56,833 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 06:13:02,256 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 06:13:12,477 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 06:13:15,153 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 06:13:18,489 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 06:13:23,391 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 06:13:25,206 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 06:13:26,928 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 06:13:28,103 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 06:13:33,796 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 07:14:50,790 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 07:14:57,215 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 07:24:13,477 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 07:24:34,023 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 07:59:04,635 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 08:00:04,557 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 10:26:27,921 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 10:26:29,111 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 10:29:35,049 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 10:29:36,164 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 10:36:28,803 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 10:36:29,939 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 10:41:14,718 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 10:41:24,849 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 10:41:30,542 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 10:41:50,344 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 10:42:03,093 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 10:42:04,198 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 10:44:31,519 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 10:44:59,779 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 10:45:00,876 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 10:51:39,243 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 10:51:40,334 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 10:58:17,787 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 10:59:03,529 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 10:59:04,626 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 10:59:57,531 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 11:10:53,502 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 11:10:54,636 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 11:17:15,569 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 11:17:41,449 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 11:17:42,596 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 11:19:16,030 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 11:21:36,156 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-10 11:21:36,157 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-10 11:21:36,157 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 11:21:36,184 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 11:21:36,184 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 11:21:36,185 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 11:21:36,185 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 11:21:36,186 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 11:21:36,186 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 11:21:36,187 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 11:21:36,187 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-10 11:21:36,187 | DEBUG | hackthon_support_agent.QuestionService | Generating questions for project_id: 27987788-e0be-421f-a63b-c55af3761b89 with idea_prompt: こんにちは
2025-09-10 11:21:36,187 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-09-10 11:31:25,834 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 11:51:35,810 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 11:51:36,963 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 11:51:53,078 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-10 11:51:53,079 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-10 11:51:53,079 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 11:51:53,104 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 11:51:53,105 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 11:51:53,106 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 11:51:53,106 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 11:51:53,107 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 11:51:53,107 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 11:51:53,108 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 11:51:53,108 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-10 11:51:53,108 | DEBUG | hackthon_support_agent.QuestionService | Generating questions for project_id: dd9674d2-53e9-4235-b076-f8ccefa41e08 with idea_prompt: プロジェクトタイトル: AIプロジェクト
プロジェクトアイディア: AIを活用したアイディア
期間: 2025-09-10 〜 2025-09-10 20:51
人数: 2
2025-09-10 11:51:53,108 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-09-10 11:52:59,486 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 11:53:38,985 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 11:54:55,727 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-10 11:54:55,727 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-10 11:54:55,728 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 11:54:55,738 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 11:54:55,738 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 11:54:55,739 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 11:54:55,739 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 11:54:55,740 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 11:54:55,740 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 11:54:55,741 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 11:54:55,741 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-10 11:54:55,741 | DEBUG | hackthon_support_agent.QuestionService | Generating questions for project_id: 68c75ca7-ce7e-4d01-adc3-3cd7bbc7635a with idea_prompt: プロジェクトタイトル: AIプロジェクト
プロジェクトアイディア: AIを活用したアイディア
期間: 2025-09-10 〜 2025-09-10 20:51
人数: 2
2025-09-10 11:54:55,741 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-09-10 11:57:06,075 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 11:57:12,434 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 11:57:32,332 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 11:57:34,793 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-10 11:57:34,793 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-10 11:57:34,794 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 11:57:34,804 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 11:57:34,805 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 11:57:34,806 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 11:57:34,806 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 11:57:34,807 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 11:57:34,807 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 11:57:34,808 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 11:57:34,808 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-10 11:57:34,808 | DEBUG | hackthon_support_agent.QuestionService | Generating questions for project_id: 248e9ea5-2257-4688-8705-9419a57e69bf with idea_prompt: プロジェクトタイトル: AIプロジェクト
プロジェクトアイディア: AIを活用したアイディア
期間: 2025-09-10 〜 2025-09-10 20:51
人数: 2
2025-09-10 11:57:34,808 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-09-10 12:01:47,259 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 12:01:48,385 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 12:01:52,537 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-10 12:01:52,538 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-10 12:01:52,538 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:01:52,548 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:01:52,549 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:01:52,550 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:01:52,550 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:01:52,551 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:01:52,551 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:01:52,552 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:01:52,552 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-10 12:01:52,552 | DEBUG | hackthon_support_agent.QuestionService | Generating questions for project_id: ccd1580d-fb90-4384-b886-2cf93442067a with idea_prompt: プロジェクトタイトル: AIプロジェクト
プロジェクトアイディア: AIを活用したアイディア
期間: 2025-09-10 〜 2025-09-10 20:51
人数: 2
2025-09-10 12:01:52,552 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-09-10 12:02:24,240 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 12:02:25,485 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-10 12:02:25,486 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-10 12:02:25,486 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:02:25,496 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:02:25,496 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:02:25,497 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:02:25,497 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:02:25,498 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:02:25,498 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:02:25,499 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:02:25,499 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-10 12:02:25,499 | DEBUG | hackthon_support_agent.QuestionService | Generating questions for project_id: 5889e324-6dce-4593-973a-a59e552a4170 with idea_prompt: プロジェクトタイトル: AIプロジェクト
プロジェクトアイディア: AIを活用したアイディア
期間: 2025-09-10 〜 2025-09-10 20:51
人数: 2
2025-09-10 12:02:25,499 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-09-10 12:03:48,425 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 12:03:49,779 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 12:03:53,971 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-10 12:03:53,972 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-10 12:03:53,972 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:03:53,982 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:03:53,982 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:03:53,983 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:03:53,983 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:03:53,984 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:03:53,984 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:03:53,985 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:03:53,985 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-10 12:03:53,985 | DEBUG | hackthon_support_agent.QuestionService | Generating questions for project_id: 39d178fa-5483-4d51-8a49-4f55e99c10d4 with idea_prompt: プロジェクトタイトル: AIプロジェクト
プロジェクトアイディア: AIを活用したアイディア
期間: 2025-09-10 〜 2025-09-10 20:51
人数: 2
2025-09-10 12:03:53,985 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-09-10 12:04:12,598 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 12:04:12,811 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-10 12:04:12,812 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-10 12:04:12,812 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:04:12,821 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:04:12,821 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:04:12,822 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:04:12,822 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:04:12,823 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:04:12,823 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:04:12,824 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:04:12,824 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-10 12:04:12,824 | DEBUG | hackthon_support_agent.QuestionService | Generating questions for project_id: 18e34469-a5ca-40c7-96ab-23bb788315ee with idea_prompt: プロジェクトタイトル: AIプロジェクト
プロジェクトアイディア: AIを活用したアイディア
期間: 2025-09-10 〜 2025-09-10 20:51
人数: 2
2025-09-10 12:04:12,824 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-09-10 12:08:35,507 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 12:08:46,885 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 12:08:52,671 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 12:08:54,120 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 12:09:18,861 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-10 12:09:18,862 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-10 12:09:18,862 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:09:18,872 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:09:18,873 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:09:18,874 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:09:18,874 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:09:18,875 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:09:18,875 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:09:18,876 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:09:18,876 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-10 12:09:18,876 | DEBUG | hackthon_support_agent.QuestionService | Generating questions for project_id: 992cd451-db2b-42cf-ba45-8267d87bb85b with idea_prompt: プロジェクトタイトル: AIプロジェクト
プロジェクトアイディア: AIを活用したアイディア
期間: 2025-09-10 〜 2025-09-10 20:51
人数: 2
2025-09-10 12:09:18,876 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-09-10 12:09:55,045 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-10 12:09:55,046 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-10 12:09:55,046 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:09:55,047 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:09:55,047 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:09:55,048 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:09:55,048 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:09:55,049 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:09:55,049 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:09:55,050 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:09:55,050 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-10 12:09:55,050 | DEBUG | hackthon_support_agent.QuestionService | Generating questions for project_id: 6dc67f91-a358-4604-9941-52294b58c791 with idea_prompt: プロジェクトタイトル: IAプロジェクト
プロジェクトアイディア: IAをつかうプロジェクト
期間: 2025-09-10 〜 2025-09-10 21:09
人数: 3
2025-09-10 12:09:55,050 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-09-10 12:11:43,858 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 12:11:54,854 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 12:12:00,452 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 12:12:01,937 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 12:13:52,600 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-10 12:13:52,601 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-10 12:13:52,601 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:13:52,611 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:13:52,611 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:13:52,612 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:13:52,612 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:13:52,613 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:13:52,613 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:13:52,614 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:13:52,614 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-10 12:13:52,614 | DEBUG | hackthon_support_agent.QuestionService | Generating questions for project_id: 25601076-ed62-4f17-bc24-95cfcd382b2d with idea_prompt: プロジェクトタイトル: IAプロジェクト
プロジェクトアイディア: IAをつかうプロジェクト
期間: 2025-09-10 〜 2025-09-10 21:09
人数: 3
2025-09-10 12:13:52,615 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-09-10 12:15:26,561 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-10 12:15:26,562 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-10 12:15:26,562 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:15:26,563 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:15:26,563 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:15:26,564 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:15:26,564 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:15:26,565 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:15:26,565 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:15:26,566 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:15:26,566 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-10 12:15:26,566 | DEBUG | hackthon_support_agent.QuestionService | Generating questions for project_id: 256000f6-9c8b-4855-a7e7-0912ef0861cc with idea_prompt: プロジェクトタイトル: IAプロジェクト
プロジェクトアイディア: IAをつかうプロジェクト
期間: 2025-09-10 〜 2025-09-10 21:09
人数: 3
2025-09-10 12:15:26,566 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-09-10 12:17:27,463 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 12:17:40,942 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-10 12:17:40,943 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-10 12:17:40,943 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:17:40,953 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:17:40,953 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:17:40,954 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:17:40,954 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:17:40,955 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:17:40,956 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:17:40,957 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:17:40,957 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-10 12:17:40,957 | DEBUG | hackthon_support_agent.QuestionService | Generating questions for project_id: 2c7fb00f-9a81-4edd-8989-89522e42378a with idea_prompt: プロジェクトタイトル: IAプロジェクト
プロジェクトアイディア: IAをつかうプロジェクト
期間: 2025-09-10 〜 2025-09-10 21:09
人数: 3
2025-09-10 12:17:40,957 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-09-10 12:18:02,625 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 12:18:05,314 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-10 12:18:05,315 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-10 12:18:05,315 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:18:05,325 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:18:05,325 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:18:05,326 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:18:05,326 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:18:05,327 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:18:05,328 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:18:05,329 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:18:05,329 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-10 12:18:05,329 | DEBUG | hackthon_support_agent.QuestionService | Generating questions for project_id: 8d0ccfe1-d1e2-493d-940e-5cb261131be2 with idea_prompt: プロジェクトタイトル: IAプロジェクト
プロジェクトアイディア: IAをつかうプロジェクト
期間: 2025-09-10 〜 2025-09-10 21:09
人数: 3
2025-09-10 12:18:05,329 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-09-10 12:18:33,771 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 12:18:34,880 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 12:18:38,399 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-10 12:18:38,400 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-10 12:18:38,400 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:18:38,411 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:18:38,411 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:18:38,413 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:18:38,413 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:18:38,414 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:18:38,414 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:18:38,415 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:18:38,415 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-10 12:18:38,415 | DEBUG | hackthon_support_agent.QuestionService | Generating questions for project_id: 4df72b6e-d54c-4568-8f4a-781e814dea44 with idea_prompt: プロジェクトタイトル: IAプロジェクト
プロジェクトアイディア: IAをつかうプロジェクト
期間: 2025-09-10 〜 2025-09-10 21:09
人数: 3
2025-09-10 12:18:38,415 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-09-10 12:22:12,033 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 12:22:13,803 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 12:22:26,851 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 12:22:46,125 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 12:22:52,356 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 12:22:55,450 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 12:23:00,128 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 12:23:03,233 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 12:23:07,851 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 12:23:15,091 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 12:23:19,865 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 12:23:21,409 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 12:23:28,744 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 12:23:37,903 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 12:25:15,531 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 12:26:42,307 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 12:27:39,427 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 12:28:57,783 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 12:28:58,907 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 12:31:12,175 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-10 12:31:12,176 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-10 12:31:12,176 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:31:12,186 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:31:12,186 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:31:12,187 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:31:12,187 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:31:12,188 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:31:12,188 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:31:12,189 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:31:12,189 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-10 12:32:12,705 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 12:32:16,333 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-10 12:32:16,334 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-10 12:32:16,334 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:32:16,344 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:32:16,344 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:32:16,345 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:32:16,345 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:32:16,346 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:32:16,346 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:32:16,347 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:32:16,347 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-10 12:32:25,459 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 12:32:29,052 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-10 12:32:29,053 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-10 12:32:29,053 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:32:29,063 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:32:29,063 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:32:29,064 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:32:29,064 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:32:29,065 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:32:29,065 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:32:29,066 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:32:29,066 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-10 12:32:29,066 | DEBUG | hackthon_support_agent.QuestionService | Generating questions for project_id: badf0ee8-5655-476e-a6fc-26b226760fcf with idea_prompt: プロジェクトタイトル: IAプロジェクト
プロジェクトアイディア: IAをつかうプロジェクト
期間: 2025-09-10 〜 2025-09-10 21:09
人数: 3
2025-09-10 12:32:29,066 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-09-10 12:34:24,733 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 12:34:25,860 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 12:34:28,961 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-10 12:34:28,962 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-10 12:34:28,962 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:34:28,972 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:34:28,972 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:34:28,973 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:34:28,973 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:34:28,974 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:34:28,974 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:34:28,975 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:34:28,975 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-10 12:34:28,975 | DEBUG | hackthon_support_agent.QuestionService | Generating questions for project_id: 0920de8c-6c98-4bd2-a528-20cd4a5b9d7f with idea_prompt: プロジェクトタイトル: IAプロジェクト
プロジェクトアイディア: IAをつかうプロジェクト
期間: 2025-09-10 〜 2025-09-10 21:09
人数: 3
2025-09-10 12:34:28,975 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-09-10 12:37:51,490 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 12:37:52,662 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 12:37:59,226 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-10 12:37:59,227 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-10 12:37:59,227 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:37:59,237 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:37:59,237 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:37:59,239 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:37:59,239 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:37:59,240 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:37:59,240 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:37:59,241 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:37:59,241 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-10 12:37:59,241 | DEBUG | hackthon_support_agent.QuestionService | Generating questions for project_id: 50193780-d5f2-4426-ac56-4727ee15cfb5 with idea_prompt: プロジェクトタイトル: IAプロジェクト
プロジェクトアイディア: IAをつかうプロジェクト
期間: 2025-09-10 〜 2025-09-10 21:09
人数: 3
2025-09-10 12:37:59,241 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-09-10 12:39:50,066 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 12:39:54,936 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 12:41:16,474 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-10 12:41:16,475 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-10 12:41:16,475 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:41:16,485 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:41:16,485 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:41:16,486 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:41:16,486 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:41:16,487 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:41:16,487 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:41:16,488 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:41:16,488 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-10 12:41:16,488 | DEBUG | hackthon_support_agent.QuestionService | Generating questions for project_id: b3054a92-589b-45bf-86a8-39c8c773a9f7 with idea_prompt: プロジェクトタイトル: IAプロジェクト
プロジェクトアイディア: IAをつかうプロジェクト
期間: 2025-09-10 〜 2025-09-10 21:09
人数: 3
2025-09-10 12:41:16,488 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-09-10 12:41:22,185 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-10 12:41:22,186 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-10 12:41:22,186 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:41:22,187 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:41:22,188 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:41:22,188 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:41:22,188 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:41:22,189 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:41:22,189 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:41:22,190 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:41:22,190 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-10 12:42:30,000 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 12:42:31,147 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 12:44:01,454 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-10 12:44:01,455 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-10 12:44:01,455 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:44:01,465 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:44:01,465 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:44:01,466 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:44:01,466 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:44:01,467 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:44:01,467 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:44:01,468 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:44:01,468 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-10 12:44:01,468 | DEBUG | hackthon_support_agent.QuestionService | Generating questions for project_id: 725564ed-bb9b-499e-a724-3d9be62dc2d2 with idea_prompt: プロジェクトタイトル:  AIプロジェクト
プロジェクトアイディア: AIプロジェクト
期間: 2025-09-10 〜 2025-09-10 21:43
人数: 2
2025-09-10 12:44:01,468 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-09-10 12:44:08,997 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-10 12:44:08,998 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-10 12:44:08,998 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:44:08,999 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:44:08,999 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:44:09,000 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:44:09,000 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:44:09,001 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:44:09,001 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:44:09,002 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:44:09,002 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-10 12:44:58,220 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-10 12:44:58,221 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-10 12:44:58,221 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:44:58,223 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:44:58,223 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:44:58,224 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:44:58,224 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:44:58,225 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:44:58,225 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:44:58,225 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:44:58,225 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-10 12:44:58,225 | DEBUG | hackthon_support_agent.QuestionService | Generating questions for project_id: 91cfde10-d755-4a5b-a921-902c2dc77fa4 with idea_prompt: プロジェクトタイトル: A
プロジェクトアイディア: a
期間: 2025-09-10 〜 2025-09-10 21:44
人数: 1
2025-09-10 12:44:58,226 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-09-10 12:45:04,134 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-10 12:45:04,135 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-10 12:45:04,135 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:45:04,136 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:45:04,137 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:45:04,138 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:45:04,138 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:45:04,139 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:45:04,140 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:45:04,140 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:45:04,140 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-10 12:47:23,042 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-10 12:47:23,043 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-10 12:47:23,043 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:47:23,045 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:47:23,046 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:47:23,047 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:47:23,047 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:47:23,047 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:47:23,048 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:47:23,048 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:47:23,048 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-10 12:47:23,049 | DEBUG | hackthon_support_agent.QuestionService | Generating questions for project_id: 25b6dbe2-1c24-41b2-a97d-e654af5b1bd5 with idea_prompt: プロジェクトタイトル: AI
プロジェクトアイディア: AI
期間: 2025-09-10 〜 2025-09-10 21:47
人数: 3
2025-09-10 12:47:23,049 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-09-10 12:47:28,536 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-10 12:47:28,537 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-10 12:47:28,537 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:47:28,538 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:47:28,538 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:47:28,539 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:47:28,539 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:47:28,540 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:47:28,540 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:47:28,541 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:47:28,541 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-10 12:48:56,572 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 12:49:25,507 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 12:49:35,531 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 12:49:37,769 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 12:51:57,377 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 12:52:06,441 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-10 12:52:06,442 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-10 12:52:06,442 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:52:06,451 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:52:06,452 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:52:06,453 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:52:06,453 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:52:06,454 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:52:06,454 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:52:06,455 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:52:06,455 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-10 12:52:06,455 | DEBUG | hackthon_support_agent.QuestionService | Generating questions for project_id: ccc206ae-e149-46db-b736-90831e2156c7 with idea_prompt: プロジェクトタイトル: AI
プロジェクトアイディア: aa
期間: 2025-09-10 〜 2025-09-10 21:51
人数: 1
2025-09-10 12:52:06,455 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-09-10 12:52:12,236 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-10 12:52:12,237 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-10 12:52:12,237 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:52:12,238 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:52:12,238 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:52:12,239 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:52:12,239 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:52:12,240 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:52:12,240 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:52:12,241 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:52:12,241 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-10 12:52:12,241 | ERROR | hackthon_support_agent.QuestionService | Failed to save questions
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/question_service.py", line 104, in save_question
    for qa_data in question.get("QA", []):
                   ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'get'
2025-09-10 12:52:12,242 | ERROR | hackthon_support_agent.QuestionService | Error details: 'list' object has no attribute 'get'
2025-09-10 12:52:46,288 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 12:52:51,931 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 12:52:55,789 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 12:52:58,119 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 12:53:00,467 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 12:53:02,576 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-10 12:53:02,577 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-10 12:53:02,577 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:53:02,588 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:53:02,588 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:53:02,589 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:53:02,589 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:53:02,590 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:53:02,590 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:53:02,591 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:53:02,591 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-10 12:53:02,591 | DEBUG | hackthon_support_agent.QuestionService | Generating questions for project_id: 1936233c-18bd-4a96-8ab1-fc7331ba83e7 with idea_prompt: プロジェクトタイトル: AI
プロジェクトアイディア: aa
期間: 2025-09-10 〜 2025-09-10 21:51
人数: 1
2025-09-10 12:53:02,591 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-09-10 12:53:07,447 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-10 12:53:07,448 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-10 12:53:07,448 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:53:07,449 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:53:07,449 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:53:07,450 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:53:07,450 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:53:07,451 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:53:07,451 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:53:07,452 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:53:07,452 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-10 12:53:07,452 | ERROR | hackthon_support_agent.QuestionService | Failed to save questions
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/question_service.py", line 106, in save_question
    project_uuid = qa_data["project_id"]
                   ~~~~~~~^^^^^^^^^^^^^^
TypeError: 'QABase' object is not subscriptable
2025-09-10 12:53:07,453 | ERROR | hackthon_support_agent.QuestionService | Error details: 'QABase' object is not subscriptable
2025-09-10 12:53:23,565 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 12:53:43,184 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 12:53:58,068 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 12:54:00,405 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-10 12:54:00,406 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-10 12:54:00,407 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:54:00,417 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:54:00,417 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:54:00,418 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:54:00,418 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:54:00,419 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:54:00,420 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:54:00,420 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:54:00,421 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-10 12:54:00,421 | DEBUG | hackthon_support_agent.QuestionService | Generating questions for project_id: 0be536a7-0db0-4f1a-8d2c-3ed0e9228e9a with idea_prompt: プロジェクトタイトル: AI
プロジェクトアイディア: aa
期間: 2025-09-10 〜 2025-09-10 21:51
人数: 1
2025-09-10 12:54:00,421 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-09-10 12:54:13,800 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-10 12:54:13,801 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-10 12:54:13,801 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:54:13,802 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:54:13,802 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:54:13,803 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:54:13,803 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:54:13,804 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:54:13,804 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:54:13,805 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:54:13,805 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-10 12:54:13,805 | ERROR | hackthon_support_agent.QuestionService | Failed to save questions
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/question_service.py", line 104, in save_question
    for qa_data in question.get("QA", []):
                   ^^^^^^^^^^^^
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/pydantic/main.py", line 991, in __getattr__
    raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}')
AttributeError: 'QAResult' object has no attribute 'get'
2025-09-10 12:54:13,808 | ERROR | hackthon_support_agent.QuestionService | Error details: 'QAResult' object has no attribute 'get'
2025-09-10 12:54:30,191 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 12:56:58,446 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 12:57:14,440 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 12:57:16,045 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 12:57:22,769 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 12:57:31,065 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-10 12:57:31,065 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-10 12:57:31,066 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:57:31,075 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:57:31,076 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:57:31,077 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:57:31,077 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:57:31,077 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:57:31,078 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:57:31,078 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:57:31,078 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-10 12:57:31,079 | DEBUG | hackthon_support_agent.QuestionService | Generating questions for project_id: b3fd56b0-2ec7-47ea-ada1-7ee3431c2b76 with idea_prompt: プロジェクトタイトル: AI
プロジェクトアイディア: aa
期間: 2025-09-10 〜 2025-09-10 21:51
人数: 1
2025-09-10 12:57:31,079 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-09-10 12:57:36,790 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-10 12:57:36,791 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-10 12:57:36,791 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:57:36,792 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:57:36,792 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:57:36,793 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:57:36,793 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:57:36,794 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:57:36,794 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:57:36,795 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:57:36,795 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-10 12:57:36,795 | ERROR | hackthon_support_agent.QuestionService | Failed to save questions
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/question_service.py", line 104, in save_question
    for qa_data in question.get("QA", []):
                   ^^^^^^^^^^^^
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/pydantic/main.py", line 991, in __getattr__
    raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}')
AttributeError: 'QAResult' object has no attribute 'get'
2025-09-10 12:57:36,796 | ERROR | hackthon_support_agent.QuestionService | Error details: 'QAResult' object has no attribute 'get'
2025-09-10 12:58:15,028 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 12:58:17,391 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 12:58:29,218 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 12:58:37,226 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 12:58:38,329 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 12:58:50,852 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 12:59:19,489 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 12:59:22,328 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 12:59:26,158 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 12:59:30,941 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-10 12:59:30,941 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-10 12:59:30,942 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:59:30,952 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:59:30,952 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:59:30,954 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:59:30,954 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:59:30,955 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:59:30,955 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:59:30,956 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:59:30,956 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-10 12:59:30,956 | DEBUG | hackthon_support_agent.QuestionService | Generating questions for project_id: f72bc78b-ff64-4a21-89b9-f6ab72d3d465 with idea_prompt: プロジェクトタイトル: AI
プロジェクトアイディア: aa
期間: 2025-09-10 〜 2025-09-10 21:51
人数: 1
2025-09-10 12:59:30,956 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-09-10 12:59:37,564 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-10 12:59:37,565 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-10 12:59:37,565 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:59:37,566 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:59:37,566 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:59:37,567 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:59:37,567 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:59:37,568 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:59:37,568 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 12:59:37,569 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 12:59:37,569 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-10 12:59:37,575 | ERROR | hackthon_support_agent.QuestionService | Failed to save questions
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2114, in _exec_insertmany_context
    dialect.do_execute(
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 943, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.ForeignKeyViolation: insert or update on table "qa" violates foreign key constraint "qa_follows_qa_id_fkey"
DETAIL:  Key (follows_qa_id)=(226f8b22-1c6b-4069-a80c-3eacd85d4edd) is not present in table "qa".


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/question_service.py", line 126, in save_question
    self.db.commit()
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2032, in commit
    trans.commit(_to_root=True)
  File "<string>", line 2, in commit
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
    ret_value = fn(self, *arg, **kw)
                ^^^^^^^^^^^^^^^^^^^^
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1313, in commit
    self._prepare_impl()
  File "<string>", line 2, in _prepare_impl
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
    ret_value = fn(self, *arg, **kw)
                ^^^^^^^^^^^^^^^^^^^^
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1288, in _prepare_impl
    self.session.flush()
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4345, in flush
    self._flush(objects)
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4480, in _flush
    with util.safe_reraise():
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 224, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4441, in _flush
    flush_context.execute()
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 466, in execute
    rec.execute(self)
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 642, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 93, in save_obj
    _emit_insert_statements(
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 1143, in _emit_insert_statements
    result = connection.execute(
             ^^^^^^^^^^^^^^^^^^^
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1415, in execute
    return meth(
           ^^^^^
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 523, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1637, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1840, in _execute_context
    return self._exec_insertmany_context(dialect, context)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2122, in _exec_insertmany_context
    self._handle_dbapi_exception(
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2351, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2114, in _exec_insertmany_context
    dialect.do_execute(
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 943, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.ForeignKeyViolation) insert or update on table "qa" violates foreign key constraint "qa_follows_qa_id_fkey"
DETAIL:  Key (follows_qa_id)=(226f8b22-1c6b-4069-a80c-3eacd85d4edd) is not present in table "qa".

[SQL: INSERT INTO qa (qa_id, project_id, question, answer, is_ai, source_doc_id, follows_qa_id, importance) VALUES (%(qa_id__0)s::UUID, %(project_id__0)s::UUID, %(question__0)s, %(answer__0)s, %(is_ai__0)s, %(source_doc_id__0)s::UUID, %(follows_qa_id__0)s: ... 1135 characters truncated ... _doc_id__7)s::UUID, %(follows_qa_id__7)s::UUID, %(importance__7)s) RETURNING qa.created_at, qa.qa_id]
[parameters: {'follows_qa_id__0': None, 'importance__0': 5, 'question__0': '「AI」というプロジェクトタイトルですが、具体的にどのようなAI技術を活用したいと考えていますか？例えば、自然言語処理、画像認識、機械学習のどの分野に興味がありますか？', 'qa_id__0': UUID('164eb17f-f7de-4e3a-b5b1-7816f42dfcd9'), 'project_id__0': UUID('f72bc78b-ff64-4a21-89b9-f6ab72d3d465'), 'source_doc_id__0': None, 'is_ai__0': True, 'answer__0': 'まだ具体的に決まっていませんが、例えばユーザーの質問に答えるチャットボットのようなものや、画像から何かを認識するようなものに興味があります。', 'follows_qa_id__1': UUID('226f8b22-1c6b-4069-a80c-3eacd85d4edd'), 'importance__1': 5, 'question__1': '「aa」というプロジェクトアイディアについて、もう少し詳しく教えていただけますか？どのような課題を解決したいのか、あるいはどのような新しい体験を提供したいのか、具体的なイメージを教えてください。', 'qa_id__1': UUID('6c99df65-29d1-434a-9254-19b6643cb67e'), 'project_id__1': UUID('f72bc78b-ff64-4a21-89b9-f6ab72d3d465'), 'source_doc_id__1': None, 'is_ai__1': True, 'answer__1': 'まだ漠然としていますが、例えば、日々の生活でちょっとした疑問や困りごとがあったときに、すぐにAIに相談できて解決策が見つかるような、そんなツールがあったら便利かなと考えています。', 'follows_qa_id__2': UUID('28ba26b8-ede3-4386-bde4-3bbeea02a263'), 'importance__2': 5, 'question__2': 'このプロジェクトで解決したい「誰かの課題」は何でしょうか？その課題を抱えているのは、どのようなユーザー層ですか？（例：学生、社会人、特定の趣味を持つ人など）', 'qa_id__2': UUID('c66e4e59-3350-47a0-ac06-e3dd20d0f966'), 'project_id__2': UUID('f72bc78b-ff64-4a21-89b9-f6ab72d3d465'), 'source_doc_id__2': None, 'is_ai__2': True, 'answer__2': '例えば、プログラミング学習中の人が、エラーコードの意味が分からなかったり、次に何を学べば良いか迷ったりする課題を解決できたら良いなと思っています。対象ユーザーは、プログラミング初学者です。', 'follows_qa_id__3': UUID('371705e1-f400-4466-ab79-4641a6361959'), 'importance__3': 4, 'question__3': 'その「プログラミング初学者が抱える課題」について、どのような裏付けがありますか？例えば、ご自身の経験や、周りの人の話、インターネット上の情報など、課題が存在することをどのように認識していますか？', 'qa_id__3': UUID('56867af0-6afa-40df-b79e-9e9b1dab7937'), 'project_id__3': UUID('f72bc78b-ff64-4a21-89b9-f6ab72d3d465'), 'source_doc_id__3': None, 'is_ai__3': True, 'answer__3': '私自身がプログラミング学習を始めたばかりで、よく分からないエラーに遭遇したり、学習の進め方に迷ったりすることが多いです。また、オンラインコミュニティでも同様の悩みを抱えている人を多く見かけます。', 'follows_qa_id__4': UUID('7cb71a03-cc69-4aed-b56c-f3db68066811'), 'importance__4': 4, 'question__4': '「プログラミング初学者がAIに相談して課題を解決する」というシナリオについて、具体的なイメージを教えてください。例えば、ユーザーはどのようにAIに質問し、AIはどのような形式で回答するのでしょうか？', 'qa_id__4': UUID('33c4258c-995a-4304-9a71-5f78041da4dc'), 'project_id__4': UUID('f72bc78b-ff64-4a21-89b9-f6ab72d3d465'), 'source_doc_id__4': None, 'is_ai__4': True, 'answer__4': '例えば、ユーザーが「Pythonでリストの要素を削除する方法が分からない」と質問すると、AIがコード例を提示したり、簡単な解説を返してくれるようなイメージです。チャット形式でやり取りできると嬉しいです。', 'follows_qa_id__5': UUID('cf2d8cc8-8a26-4240-a28c-8fba23601a6d'), 'importance__5': 4, 'question__5': 'このプロジェクトで、どのような「仮説」を検証したいですか？例えば、「AIがプログラミング初学者の学習効率を向上させる」といった仮説があれば教えてください。', 'qa_id__5': UUID('2dd0f061-775b-4946-907e-6ec0dbbfe95d'), 'project_id__5': UUID('f72bc78b-ff64-4a21-89b9-f6ab72d3d465'), 'source_doc_id__5': None, 'is_ai__5': True, 'answer__5': '「AIがプログラミング初学者の学習における疑問解決をサポートすることで、学習の挫折率を低下させ、学習意欲を維持できる」という仮説を検証したいです。', 'follows_qa_id__6': UUID('b5152daf-4f02-41d7-bb11-d0c259237aec'), 'importance__6': 3, 'question__6': 'もし、このAIが「エラーコードの意味を解説する」機能を持つとしたら、どのようなエラーコードを対象にしますか？また、解説はどの程度の詳細さが必要だと考えますか？', 'qa_id__6': UUID('32773def-b0a5-48b0-af7a-84ad4679f69b'), 'project_id__6': UUID('f72bc78b-ff64-4a21-89b9-f6ab72d3d465'), 'source_doc_id__6': None, 'is_ai__6': True, 'answer__6': 'まずはPythonでよく遭遇するエラーコード（SyntaxError, TypeError, NameErrorなど）を対象にしたいです。解説は、エラーの原因と、それを修正するための具体的なコードの書き方や考え方を簡潔に示してほしいです。', 'follows_qa_id__7': UUID('4cfbcb2f-f32f-4a07-8527-b62c029aed89'), 'importance__7': 3, 'question__7': 'AIが「次に何を学べば良いか」を提案する機能を持つ場合、どのような基準で提案しますか？例えば、ユーザーの現在のスキルレベルや、興味のある分野などを考慮しますか？', 'qa_id__7': UUID('150cfad1-b3a7-4a90-95f9-3c02e5b18d50'), 'project_id__7': UUID('f72bc78b-ff64-4a21-89b9-f6ab72d3d465'), 'source_doc_id__7': None, 'is_ai__7': True, 'answer__7': 'ユーザーが現在学んでいる言語や、過去にどのような質問をしたか、といった情報を元に、次に学習すると役立ちそうな概念やライブラリを提案できると良いですね。例えば、Pythonの基礎を学んでいる人には、オブジェクト指向の概念や、よく使われるライブラリ（NumPy, Pandasなど）を段階的に提案するイメージです。'}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
2025-09-10 13:00:14,420 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 13:00:15,553 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 13:03:57,435 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 13:04:09,841 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 13:04:13,588 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 13:04:19,316 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 13:04:41,274 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 13:04:50,422 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 13:04:55,535 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 13:05:27,791 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 13:05:41,964 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-10 13:05:41,965 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-10 13:05:41,965 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 13:05:41,974 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 13:05:41,974 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 13:05:41,975 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 13:05:41,975 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 13:05:41,976 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 13:05:41,977 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 13:05:41,977 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 13:05:41,977 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-10 13:05:41,977 | DEBUG | hackthon_support_agent.QuestionService | Generating questions for project_id: 56f0491d-2baa-4e53-a72d-f7ba2df806e1 with idea_prompt: プロジェクトタイトル: apple
プロジェクトアイディア: A
期間: 2025-09-10 〜 2025-09-10 22:00
人数: 1
2025-09-10 13:05:41,978 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-09-10 13:05:46,937 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-10 13:05:46,938 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-10 13:05:46,938 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 13:05:46,939 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 13:05:46,939 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 13:05:46,939 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 13:05:46,940 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 13:05:46,941 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 13:05:46,941 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 13:05:46,941 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 13:05:46,941 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-10 13:06:20,779 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-10 13:06:24,951 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-10 13:06:24,952 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-10 13:06:24,952 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 13:06:24,962 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 13:06:24,962 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 13:06:24,964 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 13:06:24,964 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 13:06:24,965 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 13:06:24,965 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 13:06:24,966 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 13:06:24,966 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-10 13:06:24,966 | DEBUG | hackthon_support_agent.QuestionService | Generating questions for project_id: 0a83e9d8-95bf-49f5-9729-930ee9ee19da with idea_prompt: プロジェクトタイトル: apple
プロジェクトアイディア: A
期間: 2025-09-10 〜 2025-09-10 22:00
人数: 1
2025-09-10 13:06:24,966 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-09-10 13:06:29,346 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-10 13:06:29,347 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-10 13:06:29,347 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 13:06:29,348 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 13:06:29,348 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 13:06:29,349 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 13:06:29,349 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 13:06:29,350 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 13:06:29,350 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-10 13:06:29,351 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-10 13:06:29,351 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-11 01:32:09,373 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 01:32:10,578 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 01:33:23,309 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-11 01:33:23,310 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 01:33:23,310 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 01:33:23,333 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 01:33:23,333 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 01:33:23,335 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 01:33:23,335 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 01:33:23,336 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 01:33:23,336 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 01:33:23,337 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 01:33:23,337 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-11 01:33:23,337 | DEBUG | hackthon_support_agent.QuestionService | Generating questions for project_id: 86b5ef53-ee81-44c7-941f-c87b0cdc1dfa with idea_prompt: プロジェクトタイトル: AI
プロジェクトアイディア: AI1
期間: 2025-09-11 〜 2025-09-11 10:33
人数: 12
2025-09-11 01:33:23,337 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-09-11 01:33:26,627 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-11 01:33:26,628 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 01:33:26,628 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 01:33:26,629 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 01:33:26,629 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 01:33:26,630 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 01:33:26,630 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 01:33:26,631 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 01:33:26,631 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 01:33:26,632 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 01:33:26,632 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-11 01:41:13,564 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 01:41:19,816 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 01:41:25,560 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 01:41:49,457 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 01:41:53,766 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 01:41:58,059 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 01:50:59,026 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-11 01:50:59,027 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 01:50:59,027 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 01:50:59,038 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 01:50:59,038 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 01:50:59,039 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 01:50:59,039 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 01:50:59,040 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 01:50:59,041 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 01:50:59,041 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 01:50:59,042 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-11 01:50:59,042 | DEBUG | hackthon_support_agent.QuestionService | Generating questions for project_id: 8175d52f-b8c3-4ac9-aebe-73f65da96d88 with idea_prompt: プロジェクトタイトル: AI
プロジェクトアイディア: AI
期間: 2025-09-11 〜 2025-09-11 10:50
人数: 3
2025-09-11 01:50:59,042 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-09-11 01:51:02,233 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-11 01:51:02,234 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 01:51:02,234 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 01:51:02,235 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 01:51:02,235 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 01:51:02,236 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 01:51:02,236 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 01:51:02,237 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 01:51:02,237 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 01:51:02,238 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 01:51:02,238 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-11 01:54:38,829 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 01:55:07,714 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 01:55:30,514 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 01:55:45,265 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 01:56:03,932 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 02:03:21,135 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 02:03:24,897 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 02:03:33,471 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 02:03:42,735 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 04:28:36,129 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-11 04:28:36,130 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-11 04:28:36,131 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 04:28:36,132 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 04:28:36,132 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:28:36,132 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:28:36,160 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:28:36,160 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:28:36,160 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:28:36,160 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:28:36,162 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:28:36,163 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:28:36,163 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:28:36,163 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:28:36,165 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:28:36,165 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:28:36,165 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:28:36,165 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:28:36,167 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:28:36,167 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:28:36,168 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-11 04:28:36,168 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-11 04:28:36,204 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.generate_summary_document'
2025-09-11 04:28:36,204 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.generate_summary_document'
2025-09-11 04:28:39,357 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-11 04:28:39,358 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 04:28:39,359 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:28:39,360 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:28:39,360 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:28:39,361 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:28:39,361 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:28:39,362 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:28:39,362 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:28:39,363 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:28:39,363 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-11 04:28:39,365 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-11 04:28:39,365 | ERROR | hackthon_support_agent.MVPJudgeService | Prompt 'judge_mvp' not found under service 'mvp_service' in prompts.toml
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/base_service.py", line 148, in get_prompt
    prompt = self.prompts[service_name][prompt_name]
             ~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^
KeyError: 'judge_mvp'
2025-09-11 04:28:40,930 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-11 04:28:40,931 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 04:28:40,931 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:28:40,933 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:28:40,933 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:28:40,934 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:28:40,934 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:28:40,935 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:28:40,935 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:28:40,936 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:28:40,936 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-11 04:28:40,937 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-11 04:28:40,937 | ERROR | hackthon_support_agent.MVPJudgeService | Prompt 'judge_mvp' not found under service 'mvp_service' in prompts.toml
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/base_service.py", line 148, in get_prompt
    prompt = self.prompts[service_name][prompt_name]
             ~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^
KeyError: 'judge_mvp'
2025-09-11 04:37:45,245 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-11 04:37:45,245 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-11 04:37:45,246 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 04:37:45,247 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 04:37:45,247 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:37:45,247 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:37:45,250 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:37:45,250 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:37:45,250 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:37:45,251 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:37:45,252 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:37:45,252 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:37:45,253 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:37:45,253 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:37:45,255 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:37:45,255 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:37:45,255 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:37:45,255 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:37:45,256 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:37:45,257 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-11 04:37:45,258 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:37:45,258 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-11 04:37:45,258 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.generate_summary_document'
2025-09-11 04:37:45,261 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.generate_summary_document'
2025-09-11 04:37:49,262 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-11 04:37:49,263 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 04:37:49,263 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:37:49,264 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:37:49,264 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:37:49,265 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:37:49,265 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:37:49,266 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:37:49,266 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:37:49,267 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:37:49,267 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-11 04:37:49,268 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-11 04:37:50,101 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-11 04:37:50,102 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 04:37:50,102 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:37:50,103 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:37:50,103 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:37:50,104 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:37:50,104 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:37:50,104 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:37:50,105 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:37:50,105 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:37:50,105 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-11 04:37:50,106 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-11 04:47:47,637 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-11 04:47:47,637 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-11 04:47:47,639 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 04:47:47,640 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 04:47:47,640 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:47:47,640 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:47:47,642 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:47:47,643 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:47:47,643 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:47:47,644 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:47:47,646 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:47:47,647 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:47:47,647 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:47:47,647 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:47:47,649 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:47:47,649 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:47:47,649 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:47:47,649 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:47:47,651 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:47:47,652 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:47:47,652 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-11 04:47:47,652 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-11 04:47:47,653 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.generate_summary_document'
2025-09-11 04:47:47,654 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.generate_summary_document'
2025-09-11 04:47:50,533 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-11 04:47:50,534 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 04:47:50,534 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:47:50,535 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:47:50,535 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:47:50,536 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:47:50,536 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:47:50,537 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:47:50,537 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:47:50,537 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:47:50,538 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-11 04:47:50,539 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-11 04:47:50,658 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-11 04:47:50,659 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 04:47:50,659 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:47:50,661 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:47:50,661 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:47:50,662 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:47:50,662 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:47:50,663 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:47:50,663 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:47:50,664 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:47:50,664 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-11 04:47:50,665 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-11 04:48:05,593 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-11 04:48:05,594 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 04:48:05,594 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:48:05,596 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:48:05,596 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:48:05,597 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:48:05,597 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:48:05,598 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:48:05,598 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:48:05,599 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:48:05,599 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-11 04:48:05,599 | DEBUG | hackthon_support_agent.QuestionService | Generating questions for project_id: 553545a1-05da-4a07-a295-a36401daedc9 with idea_prompt: プロジェクトタイトル: A
プロジェクトアイディア: A
期間: 2025-09-11 〜 2025-09-11 13:47
人数: 1
2025-09-11 04:48:05,599 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-09-11 04:48:09,340 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-11 04:48:09,340 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 04:48:09,340 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:48:09,341 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:48:09,342 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:48:09,342 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:48:09,342 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:48:09,343 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:48:09,343 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:48:09,344 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:48:09,344 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-11 04:48:11,650 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-11 04:48:11,650 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-11 04:48:11,651 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 04:48:11,652 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 04:48:11,652 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:48:11,652 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:48:11,655 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:48:11,655 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:48:11,656 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:48:11,656 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:48:11,659 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:48:11,659 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:48:11,659 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:48:11,659 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:48:11,661 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:48:11,661 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:48:11,662 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:48:11,662 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:48:11,663 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:48:11,664 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:48:11,664 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-11 04:48:11,664 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-11 04:48:11,665 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.generate_summary_document'
2025-09-11 04:48:11,665 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.generate_summary_document'
2025-09-11 04:48:15,971 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-11 04:48:15,972 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 04:48:15,972 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:48:15,973 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:48:15,973 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:48:15,974 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:48:15,974 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:48:15,975 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:48:15,975 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:48:15,976 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:48:15,976 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-11 04:48:15,977 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-11 04:48:16,379 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-11 04:48:16,380 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 04:48:16,380 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:48:16,381 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:48:16,381 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:48:16,382 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:48:16,382 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:48:16,383 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:48:16,383 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:48:16,384 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:48:16,384 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-11 04:48:16,385 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-11 04:49:46,916 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 04:49:48,092 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 04:50:02,515 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-11 04:50:02,516 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 04:50:02,516 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:50:02,529 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:50:02,529 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:50:02,530 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:50:02,531 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:50:02,532 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:50:02,532 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:50:02,533 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:50:02,533 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-11 04:50:02,558 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.generate_summary_document'
2025-09-11 04:50:06,693 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-11 04:50:06,693 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 04:50:06,694 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:50:06,695 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:50:06,695 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:50:06,696 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:50:06,696 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:50:06,697 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:50:06,697 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:50:06,698 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:50:06,698 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-11 04:50:06,699 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-11 04:50:45,830 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 04:50:52,648 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-11 04:50:52,649 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 04:50:52,649 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:50:52,660 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:50:52,660 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:50:52,661 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:50:52,661 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:50:52,662 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:50:52,662 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:50:52,663 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:50:52,663 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-11 04:50:52,689 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.generate_summary_document'
2025-09-11 04:50:56,932 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-11 04:50:56,933 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 04:50:56,933 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:50:56,934 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:50:56,934 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:50:56,935 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:50:56,935 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:50:56,936 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:50:56,936 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:50:56,937 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:50:56,937 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-11 04:50:56,939 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-11 04:53:07,164 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 04:53:14,230 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-11 04:53:14,231 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 04:53:14,231 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:53:14,242 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:53:14,242 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:53:14,243 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:53:14,243 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:53:14,244 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:53:14,245 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:53:14,245 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:53:14,245 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-11 04:53:14,273 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.generate_summary_document'
2025-09-11 04:53:17,912 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-11 04:53:17,913 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 04:53:17,913 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:53:17,914 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:53:17,914 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:53:17,915 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:53:17,915 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:53:17,916 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:53:17,916 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:53:17,918 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:53:17,918 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-11 04:53:17,920 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-11 04:53:37,995 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-11 04:53:37,996 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 04:53:37,996 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:53:37,998 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:53:37,998 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:53:37,999 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:53:37,999 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:53:37,999 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:53:38,000 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 04:53:38,000 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 04:53:38,000 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-11 04:53:38,000 | DEBUG | hackthon_support_agent.QuestionService | Generating questions for project_id: 8175d52f-b8c3-4ac9-aebe-73f65da96d88 with idea_prompt: Test project idea for hackathon
2025-09-11 04:53:38,000 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-09-11 06:38:07,071 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 06:38:08,277 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 06:38:36,070 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-11 06:38:36,071 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 06:38:36,071 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 06:38:36,083 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 06:38:36,083 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 06:38:36,084 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 06:38:36,084 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 06:38:36,085 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 06:38:36,085 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 06:38:36,086 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 06:38:36,086 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-11 06:38:36,086 | DEBUG | hackthon_support_agent.QuestionService | Generating questions for project_id: 8e83c0d4-5989-436a-9c59-e77dea57be92 with idea_prompt: プロジェクトタイトル: AIプロジェクト
プロジェクトアイディア: AIを活用した
期間: 2025-09-11 〜 2025-09-11 15:38
人数: 2
2025-09-11 06:38:36,086 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-09-11 06:38:39,558 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-11 06:38:39,559 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 06:38:39,559 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 06:38:39,560 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 06:38:39,560 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 06:38:39,560 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 06:38:39,561 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 06:38:39,562 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 06:38:39,562 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 06:38:39,563 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 06:38:39,563 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-11 06:38:42,943 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-11 06:38:42,944 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 06:38:42,944 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 06:38:42,948 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 06:38:42,948 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 06:38:42,949 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 06:38:42,949 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 06:38:42,950 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 06:38:42,950 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 06:38:42,951 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 06:38:42,951 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-11 06:38:42,952 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.generate_summary_document'
2025-09-11 06:38:46,987 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-11 06:38:46,988 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 06:38:46,988 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 06:38:46,990 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 06:38:46,990 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 06:38:46,991 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 06:38:46,991 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 06:38:46,992 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 06:38:46,992 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 06:38:46,993 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 06:38:46,993 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-11 06:40:11,172 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 06:40:17,508 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 06:42:40,036 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 06:42:44,817 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 06:42:47,188 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 06:46:53,577 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 06:49:04,949 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 06:49:11,512 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 06:49:15,194 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 06:49:35,338 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 06:49:54,254 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 06:50:00,849 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 06:50:02,871 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 06:50:10,156 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 06:50:17,917 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 06:50:26,111 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 06:50:28,170 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 06:50:33,367 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 06:50:36,311 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 06:50:45,987 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 06:50:48,415 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 06:50:50,550 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 06:51:14,461 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 06:51:19,822 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 06:51:26,126 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 06:51:28,734 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 06:51:32,160 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:12:29,335 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:12:42,696 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:13:21,793 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:13:23,264 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:14:26,521 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:14:28,637 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:14:34,352 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:14:37,470 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:14:39,508 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:14:44,902 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:14:51,980 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:15:02,138 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:15:03,188 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:15:07,070 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:15:13,607 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:15:23,278 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:15:56,329 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:16:00,189 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:16:06,157 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:16:07,445 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:16:09,934 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:16:14,775 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:16:18,193 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:16:20,147 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:16:23,747 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:16:25,839 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:16:27,701 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:16:29,169 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:16:41,755 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:16:44,698 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:16:53,338 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:18:33,076 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:18:34,453 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:18:35,623 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:18:43,197 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:18:47,179 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:19:18,476 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:19:21,441 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:19:27,215 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:19:32,864 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:19:43,313 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:21:06,335 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:21:17,501 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:21:22,525 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:21:42,596 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:21:47,426 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:21:51,965 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:21:56,610 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:21:59,802 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:22:03,739 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:22:04,890 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:22:19,215 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:22:21,020 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:22:26,264 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:22:27,980 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:22:31,337 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:22:34,021 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:22:37,051 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:23:14,410 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:23:15,826 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:23:23,071 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:23:55,589 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:23:56,718 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:24:05,784 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:24:09,689 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:24:14,181 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:24:24,568 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:24:28,435 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:24:32,965 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:24:49,646 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:32:16,194 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:32:19,049 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:32:21,047 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:37:33,011 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:37:34,670 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:37:36,501 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:37:38,943 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:37:44,471 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:37:49,950 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:37:55,573 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:38:02,257 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:38:04,082 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:38:09,676 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:38:11,200 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:38:16,207 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:38:19,590 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:38:25,433 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:41:25,446 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:41:29,235 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:43:28,594 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:43:31,289 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:43:39,977 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:43:46,557 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:43:47,746 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:44:05,438 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:44:48,561 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:44:51,302 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:44:59,042 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:45:59,828 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:46:06,460 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:46:29,588 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:46:30,677 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:46:40,849 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:46:43,854 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:46:48,664 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:46:57,103 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:47:11,639 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:47:19,552 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:47:59,866 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:48:01,882 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:48:04,785 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:48:15,149 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:48:18,963 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:48:20,638 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:48:22,974 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:48:38,211 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:48:40,686 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:48:47,696 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:48:54,311 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:48:56,337 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:49:03,875 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:49:09,962 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:49:12,662 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:49:14,446 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:49:17,077 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:49:22,928 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:49:38,919 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:49:42,519 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:49:49,400 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:49:52,949 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:49:56,072 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:49:58,229 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:50:02,104 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:50:06,006 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:50:09,297 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:50:13,505 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:50:18,618 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:50:20,832 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:50:24,307 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:50:26,828 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:50:31,517 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:50:39,531 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:50:43,165 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:50:45,241 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:50:49,347 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:50:55,151 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:50:57,223 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:51:04,829 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:51:25,209 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:51:34,524 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 07:51:36,066 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 08:09:14,350 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 08:10:34,839 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 08:18:05,065 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 08:18:06,653 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 08:48:59,828 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 08:57:54,378 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 08:57:59,160 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 08:59:41,436 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 08:59:48,665 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 08:59:50,182 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 09:00:22,268 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 09:00:35,109 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 09:00:37,139 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 09:00:44,343 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 09:01:15,524 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 09:57:26,238 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 09:57:28,940 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 09:58:45,277 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-11 09:58:45,279 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 09:58:45,279 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 09:58:45,309 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 09:58:45,309 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 09:58:45,310 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 09:58:45,310 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 09:58:45,311 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 09:58:45,312 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 09:58:45,312 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 09:58:45,312 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-11 09:58:45,313 | DEBUG | hackthon_support_agent.QuestionService | Generating questions for project_id: de3487c5-82fe-4a79-a7ca-e61d58476f80 with idea_prompt: プロジェクトタイトル: AIプロジェクト
プロジェクトアイディア: AIを活用したアイディア
期間: 2025-09-11 〜 2025-09-11 18:58
人数: 2
2025-09-11 09:58:45,313 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-09-11 09:58:51,271 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-11 09:58:51,272 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 09:58:51,272 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 09:58:51,273 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 09:58:51,273 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 09:58:51,274 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 09:58:51,274 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 09:58:51,275 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 09:58:51,275 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 09:58:51,276 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 09:58:51,276 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-11 09:58:59,504 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-11 09:58:59,505 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 09:58:59,505 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 09:58:59,507 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 09:58:59,508 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 09:58:59,509 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 09:58:59,509 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 09:58:59,510 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 09:58:59,510 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 09:58:59,511 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 09:58:59,511 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-11 09:58:59,512 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.generate_summary_document'
2025-09-11 09:59:02,777 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-11 09:59:02,778 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 09:59:02,778 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 09:59:02,779 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 09:59:02,779 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 09:59:02,780 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 09:59:02,780 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 09:59:02,781 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 09:59:02,782 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 09:59:02,782 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 09:59:02,782 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-11 09:59:19,296 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-11 09:59:19,297 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 09:59:19,297 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 09:59:19,300 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 09:59:19,300 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 09:59:19,301 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 09:59:19,301 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 09:59:19,301 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 09:59:19,301 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 09:59:19,302 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 09:59:19,302 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-11 09:59:19,303 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.generate_summary_document'
2025-09-11 10:00:06,333 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 10:00:09,885 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 10:00:16,988 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 10:00:20,377 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 10:00:30,040 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-11 10:00:30,040 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 10:00:30,041 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:00:30,051 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:00:30,051 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:00:30,053 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:00:30,053 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:00:30,054 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:00:30,054 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:00:30,055 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:00:30,055 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-11 10:00:30,082 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.generate_summary_document'
2025-09-11 10:00:32,540 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-11 10:00:32,541 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 10:00:32,541 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:00:32,542 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:00:32,542 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:00:32,543 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:00:32,544 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:00:32,545 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:00:32,545 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:00:32,546 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:00:32,546 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-11 10:00:32,549 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-11 10:01:58,786 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-11 10:03:54,487 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-11 10:03:54,488 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 10:03:54,488 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:03:54,498 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:03:54,499 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:03:54,500 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:03:54,500 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:03:54,502 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:03:54,502 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:03:54,503 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:03:54,503 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-11 10:03:54,507 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-11 10:07:30,037 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-11 10:07:30,038 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 10:07:30,038 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:07:30,040 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:07:30,041 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:07:30,042 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:07:30,043 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:07:30,044 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:07:30,044 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:07:30,046 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:07:30,046 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-11 10:07:30,052 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-11 10:08:11,446 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-11 10:08:11,446 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 10:08:11,446 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:08:11,448 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:08:11,448 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:08:11,449 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:08:11,449 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:08:11,450 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:08:11,450 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:08:11,451 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:08:11,451 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-11 10:08:11,454 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-11 10:10:32,631 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-11 10:10:32,632 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 10:10:32,632 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:10:32,635 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:10:32,635 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:10:32,636 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:10:32,636 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:10:32,637 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:10:32,637 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:10:32,638 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:10:32,638 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-11 10:10:32,641 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-11 10:10:41,637 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-11 10:10:41,638 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 10:10:41,638 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:10:41,640 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:10:41,640 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:10:41,644 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:10:41,645 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:10:41,647 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:10:41,647 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:10:41,649 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:10:41,649 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-11 10:10:41,653 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-11 10:10:41,656 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-11 10:10:41,657 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 10:10:41,657 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:10:41,659 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:10:41,659 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:10:41,660 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:10:41,660 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:10:41,661 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:10:41,661 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:10:41,662 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:10:41,663 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-11 10:10:41,667 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-11 10:10:43,051 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-11 10:10:43,052 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 10:10:43,053 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:10:43,054 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:10:43,055 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:10:43,056 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:10:43,057 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:10:43,059 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:10:43,060 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:10:43,062 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:10:43,063 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-11 10:10:43,070 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-11 10:10:43,312 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-11 10:10:43,313 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 10:10:43,313 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:10:43,314 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:10:43,314 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:10:43,315 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:10:43,315 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:10:43,316 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:10:43,316 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:10:43,317 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:10:43,317 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-11 10:10:43,321 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-11 10:10:58,250 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-11 10:10:58,251 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 10:10:58,251 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:10:58,253 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:10:58,253 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:10:58,255 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:10:58,255 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:10:58,257 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:10:58,258 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:10:58,259 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-11 10:10:58,260 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:10:58,260 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-11 10:10:58,261 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 10:10:58,265 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-11 10:10:58,265 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:10:58,269 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:10:58,269 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:10:58,270 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:10:58,270 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:10:58,272 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:10:58,272 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:10:58,273 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:10:58,273 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-11 10:10:58,279 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-11 10:11:49,637 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-11 10:11:49,637 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 10:11:49,637 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:11:49,639 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:11:49,639 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:11:49,641 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:11:49,641 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:11:49,642 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:11:49,642 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:11:49,644 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:11:49,644 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-11 10:11:49,648 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-11 10:11:49,895 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-11 10:11:49,896 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 10:11:49,896 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:11:49,897 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:11:49,897 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:11:49,898 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:11:49,898 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:11:49,899 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:11:49,899 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:11:49,900 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:11:49,900 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-11 10:11:49,902 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-11 10:24:51,251 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-11 10:24:51,252 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 10:24:51,252 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:24:51,253 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:24:51,253 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:24:51,254 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:24:51,255 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:24:51,255 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:24:51,256 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:24:51,256 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:24:51,256 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-11 10:24:51,259 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.generate_summary_document'
2025-09-11 10:24:56,572 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-11 10:24:56,573 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 10:24:56,573 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:24:56,574 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:24:56,574 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:24:56,575 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:24:56,575 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:24:56,575 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:24:56,575 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:24:56,576 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:24:56,576 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-11 10:24:56,580 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-11 10:28:21,895 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-11 10:28:21,896 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 10:28:21,896 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:28:21,898 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:28:21,898 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:28:21,899 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:28:21,899 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:28:21,900 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:28:21,900 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:28:21,901 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:28:21,901 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-11 10:28:21,905 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-11 10:28:38,537 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-11 10:28:38,538 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 10:28:38,538 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:28:38,539 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:28:38,540 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:28:38,541 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:28:38,541 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:28:38,542 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:28:38,542 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:28:38,543 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:28:38,543 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-11 10:28:38,547 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-11 10:34:07,806 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-11 10:34:07,807 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 10:34:07,807 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:34:07,808 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:34:07,808 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:34:07,809 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:34:07,809 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:34:07,810 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:34:07,811 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:34:07,812 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:34:07,812 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-11 10:34:07,821 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-11 10:34:08,063 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-11 10:34:08,064 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 10:34:08,064 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:34:08,065 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:34:08,065 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:34:08,066 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:34:08,066 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:34:08,068 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:34:08,068 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:34:08,068 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:34:08,068 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-11 10:34:08,071 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-11 10:41:23,510 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-11 10:41:23,513 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 10:41:23,513 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:41:23,514 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:41:23,515 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:41:23,516 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:41:23,516 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:41:23,517 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:41:23,517 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:41:23,518 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:41:23,518 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-11 10:41:23,522 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.generate_summary_document'
2025-09-11 10:41:27,554 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-11 10:41:27,555 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 10:41:27,555 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:41:27,556 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:41:27,556 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:41:27,557 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:41:27,557 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:41:27,558 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:41:27,558 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:41:27,559 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:41:27,559 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-11 10:41:27,562 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-11 10:41:53,687 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-11 10:41:53,688 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 10:41:53,688 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:41:53,690 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:41:53,690 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:41:53,692 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:41:53,692 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:41:53,693 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:41:53,693 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:41:53,694 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:41:53,695 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-11 10:41:53,699 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-11 10:41:54,117 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-11 10:41:54,118 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 10:41:54,118 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:41:54,119 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:41:54,119 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:41:54,120 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:41:54,120 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:41:54,121 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:41:54,121 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:41:54,122 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:41:54,122 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-11 10:41:54,125 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-11 10:42:47,065 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-11 10:42:47,066 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 10:42:47,066 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:42:47,067 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:42:47,067 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:42:47,068 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:42:47,068 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:42:47,069 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:42:47,069 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:42:47,070 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:42:47,070 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-11 10:42:47,073 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.generate_summary_document'
2025-09-11 10:42:51,593 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-11 10:42:51,594 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 10:42:51,594 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:42:51,595 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:42:51,596 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:42:51,596 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:42:51,596 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:42:51,597 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:42:51,597 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:42:51,598 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:42:51,598 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-11 10:42:52,131 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-11 10:42:52,132 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 10:42:52,132 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:42:52,133 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:42:52,133 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:42:52,134 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:42:52,135 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:42:52,135 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:42:52,136 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:42:52,136 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:42:52,136 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-11 10:42:52,141 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-11 10:42:52,146 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-11 10:42:52,147 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 10:42:52,147 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:42:52,149 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:42:52,149 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:42:52,150 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:42:52,150 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:42:52,151 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:42:52,151 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:42:52,152 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:42:52,152 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-11 10:42:52,156 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-11 10:43:29,853 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-11 10:43:29,854 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 10:43:29,854 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:43:29,855 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:43:29,855 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:43:29,856 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:43:29,856 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:43:29,857 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:43:29,857 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:43:29,858 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:43:29,858 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-11 10:43:29,861 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.generate_summary_document'
2025-09-11 10:43:33,651 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-11 10:43:33,652 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 10:43:33,652 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:43:33,653 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:43:33,653 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:43:33,654 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:43:33,654 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:43:33,655 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:43:33,655 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:43:33,656 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:43:33,656 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-11 10:43:33,659 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-11 10:44:12,472 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-11 10:44:12,473 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 10:44:12,473 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:44:12,474 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:44:12,474 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:44:12,475 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:44:12,475 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:44:12,477 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:44:12,477 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:44:12,477 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:44:12,478 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-11 10:44:12,482 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-11 10:45:14,097 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-11 10:45:14,097 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 10:45:14,097 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:45:14,099 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:45:14,099 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:45:14,099 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:45:14,100 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:45:14,100 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:45:14,100 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:45:14,101 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:45:14,101 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-11 10:45:14,104 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.generate_summary_document'
2025-09-11 10:45:19,661 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-11 10:45:19,661 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 10:45:19,662 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:45:19,662 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:45:19,663 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:45:19,663 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:45:19,663 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:45:19,664 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:45:19,664 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:45:19,665 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:45:19,665 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-11 10:45:20,354 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-11 10:45:20,355 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 10:45:20,355 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:45:20,357 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:45:20,357 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:45:20,359 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:45:20,359 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:45:20,361 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:45:20,361 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:45:20,362 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:45:20,362 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-11 10:45:20,367 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-11 10:45:20,373 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-11 10:45:20,374 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 10:45:20,374 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:45:20,375 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:45:20,375 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:45:20,376 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:45:20,376 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:45:20,377 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:45:20,377 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:45:20,378 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:45:20,378 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-11 10:45:20,381 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-11 10:45:47,986 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-11 10:45:47,987 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 10:45:47,987 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:45:47,989 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:45:47,989 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:45:47,990 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:45:47,990 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:45:47,992 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:45:47,993 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:45:47,994 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:45:47,994 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-11 10:45:47,997 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.generate_summary_document'
2025-09-11 10:45:51,875 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-11 10:45:51,875 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 10:45:51,875 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:45:51,877 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:45:51,877 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:45:51,878 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:45:51,878 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:45:51,879 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:45:51,879 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:45:51,880 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:45:51,880 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-11 10:45:51,883 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-11 10:46:57,681 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-11 10:46:57,682 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 10:46:57,682 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:46:57,684 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:46:57,684 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:46:57,685 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:46:57,685 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:46:57,686 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:46:57,686 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:46:57,687 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:46:57,687 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-11 10:46:57,690 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-11 10:47:59,809 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-11 10:47:59,810 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 10:47:59,810 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:47:59,811 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:47:59,812 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:47:59,812 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:47:59,812 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:47:59,813 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:47:59,813 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:47:59,814 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:47:59,814 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-11 10:47:59,818 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.generate_summary_document'
2025-09-11 10:48:03,044 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-11 10:48:03,044 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 10:48:03,044 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:48:03,045 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:48:03,046 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:48:03,046 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:48:03,046 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:48:03,047 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:48:03,048 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:48:03,048 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:48:03,049 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-11 10:48:03,286 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-11 10:48:03,287 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 10:48:03,287 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:48:03,288 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:48:03,288 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:48:03,289 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:48:03,290 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:48:03,290 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:48:03,291 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:48:03,291 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:48:03,291 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-11 10:48:03,295 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-11 10:48:03,698 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-11 10:48:03,699 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 10:48:03,699 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:48:03,700 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:48:03,700 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:48:03,701 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:48:03,701 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:48:03,702 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:48:03,702 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 10:48:03,703 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 10:48:03,703 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-11 10:48:03,706 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-11 11:59:38,367 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-11 11:59:38,369 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 11:59:38,369 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 11:59:38,370 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 11:59:38,370 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 11:59:38,372 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 11:59:38,372 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 11:59:38,373 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 11:59:38,373 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 11:59:38,374 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 11:59:38,374 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-11 11:59:38,378 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.generate_summary_document'
2025-09-11 11:59:42,317 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-11 11:59:42,318 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-11 11:59:42,318 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 11:59:42,320 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 11:59:42,320 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 11:59:42,320 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 11:59:42,321 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 11:59:42,321 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 11:59:42,321 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-11 11:59:42,322 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-11 11:59:42,322 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-11 11:59:42,325 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-17 09:52:10,477 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-17 09:52:11,710 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-17 09:52:29,292 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-17 09:52:29,293 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-17 09:52:29,293 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 09:52:29,316 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 09:52:29,316 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 09:52:29,317 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 09:52:29,317 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 09:52:29,318 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 09:52:29,319 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 09:52:29,320 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 09:52:29,320 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-17 09:52:29,320 | DEBUG | hackthon_support_agent.QuestionService | Generating questions for project_id: 0421756f-8b29-4806-be77-5511922b45ec with idea_prompt: プロジェクトタイトル: A
プロジェクトアイディア: A
期間: 2025-09-17 〜 2025-09-17 18:52
人数: 2
2025-09-17 09:52:29,320 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-09-17 09:52:38,711 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-17 09:52:38,712 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-17 09:52:38,712 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 09:52:38,713 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 09:52:38,713 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 09:52:38,714 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 09:52:38,714 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 09:52:38,715 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 09:52:38,715 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 09:52:38,716 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 09:52:38,716 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-17 09:52:41,574 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-17 09:52:41,575 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-17 09:52:41,575 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 09:52:41,577 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 09:52:41,577 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 09:52:41,579 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 09:52:41,579 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 09:52:41,580 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 09:52:41,580 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 09:52:41,580 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 09:52:41,580 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-17 09:52:41,582 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.generate_summary_document'
2025-09-17 09:52:46,640 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-17 09:52:46,641 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-17 09:52:46,641 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 09:52:46,642 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 09:52:46,642 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 09:52:46,643 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 09:52:46,643 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 09:52:46,644 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 09:52:46,644 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 09:52:46,645 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 09:52:46,645 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-17 09:52:50,429 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-17 09:52:50,431 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-17 09:52:50,431 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 09:52:50,434 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-17 09:52:50,435 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 09:52:50,436 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 09:52:50,437 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-17 09:52:50,439 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 09:52:50,438 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 09:52:50,439 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 09:52:50,441 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 09:52:50,442 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 09:52:50,442 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 09:52:50,442 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 09:52:50,444 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 09:52:50,445 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 09:52:50,445 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 09:52:50,447 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-17 09:52:50,452 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 09:52:50,455 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-17 09:52:50,456 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 09:52:50,460 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 09:52:50,460 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-17 09:52:50,467 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-17 09:53:04,950 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-17 09:53:04,950 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-17 09:53:04,951 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-17 09:53:04,952 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-17 09:53:04,953 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 09:53:04,953 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 09:53:04,955 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 09:53:04,955 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 09:53:04,956 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 09:53:04,956 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 09:53:04,957 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 09:53:04,957 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 09:53:04,958 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 09:53:04,958 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 09:53:04,959 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 09:53:04,959 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 09:53:04,960 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 09:53:04,960 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 09:53:04,960 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 09:53:04,960 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-17 09:53:04,964 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-17 09:53:04,965 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 09:53:05,046 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-17 09:53:05,049 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-17 09:54:50,772 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-17 09:55:01,265 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-17 09:56:14,379 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-17 09:56:22,830 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-17 09:56:28,212 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-17 09:57:58,375 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-17 10:07:17,555 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-17 12:59:30,954 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-17 12:59:30,959 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-17 12:59:30,959 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 12:59:31,045 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 12:59:31,045 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 12:59:31,047 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 12:59:31,047 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 12:59:31,048 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 12:59:31,048 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 12:59:31,049 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 12:59:31,049 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-17 12:59:31,049 | DEBUG | hackthon_support_agent.QuestionService | Generating questions for project_id: b87ceab8-fb58-4e21-b331-114858771665 with idea_prompt: プロジェクトタイトル: ハッカソン支援エージェント
プロジェクトアイディア: ハッカソンを支援するためのアプリケーションを作りたい。特にプロジェクトの要件定義からすべてを作る
期間: 2025-09-17 〜 2025-09-17 18:53
人数: 3
2025-09-17 12:59:31,050 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-09-17 12:59:35,314 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-17 12:59:35,315 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-17 12:59:35,315 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 12:59:35,316 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 12:59:35,317 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 12:59:35,317 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 12:59:35,317 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 12:59:35,318 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 12:59:35,318 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 12:59:35,319 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 12:59:35,319 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-17 12:59:59,332 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-17 12:59:59,333 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-17 12:59:59,333 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 12:59:59,335 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 12:59:59,335 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 12:59:59,336 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 12:59:59,336 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 12:59:59,337 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 12:59:59,337 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 12:59:59,338 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 12:59:59,338 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-17 12:59:59,339 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.generate_summary_document'
2025-09-17 13:00:04,767 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-17 13:00:04,768 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-17 13:00:04,769 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:00:04,770 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:00:04,770 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:00:04,771 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:00:04,771 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:00:04,773 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:00:04,773 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:00:04,775 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:00:04,775 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-17 13:00:05,542 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-17 13:00:05,543 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-17 13:00:05,543 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-17 13:00:05,544 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:00:05,545 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-17 13:00:05,547 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:00:05,547 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:00:05,547 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:00:05,549 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:00:05,549 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:00:05,550 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:00:05,550 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:00:05,552 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:00:05,552 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:00:05,552 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:00:05,552 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:00:05,554 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:00:05,554 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:00:05,555 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-17 13:00:05,555 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:00:05,568 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-17 13:00:06,025 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:00:06,026 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-17 13:00:06,030 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-17 13:02:33,591 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-17 13:02:33,593 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-17 13:02:33,593 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:02:33,606 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:02:33,606 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:02:33,608 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:02:33,608 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:02:33,609 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:02:33,609 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:02:33,610 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:02:33,610 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-17 13:02:33,619 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-17 13:02:34,044 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-17 13:02:34,045 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-17 13:02:34,045 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:02:34,046 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:02:34,046 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:02:34,047 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:02:34,047 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:02:34,048 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:02:34,048 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:02:34,049 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:02:34,049 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-17 13:02:34,053 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-17 13:02:42,746 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-17 13:02:42,746 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-17 13:02:42,747 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:02:42,748 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:02:42,748 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:02:42,749 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:02:42,749 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:02:42,750 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:02:42,751 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:02:42,752 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:02:42,752 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-17 13:02:42,754 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.generate_summary_document'
2025-09-17 13:02:50,094 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-17 13:02:50,095 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-17 13:02:50,095 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:02:50,096 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:02:50,096 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:02:50,097 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:02:50,097 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:02:50,098 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:02:50,099 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:02:50,099 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:02:50,099 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-17 13:02:50,103 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-17 13:03:18,412 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-17 13:03:18,412 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-17 13:03:18,413 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:03:18,414 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:03:18,414 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:03:18,415 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:03:18,416 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:03:18,416 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:03:18,417 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:03:18,417 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:03:18,417 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-17 13:03:18,422 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-17 13:03:18,821 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-17 13:03:18,822 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-17 13:03:18,822 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:03:18,823 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:03:18,824 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:03:18,824 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:03:18,824 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:03:18,825 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:03:18,825 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:03:18,826 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:03:18,826 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-17 13:03:18,829 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-17 13:05:13,418 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-17 13:05:23,286 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-17 13:07:06,357 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-17 13:07:06,358 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-17 13:07:06,358 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:07:06,372 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:07:06,372 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:07:06,373 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:07:06,373 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:07:06,374 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:07:06,374 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:07:06,375 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:07:06,375 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-17 13:07:06,382 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-17 13:07:06,657 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-17 13:07:06,658 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-17 13:07:06,658 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:07:06,659 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:07:06,659 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:07:06,660 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:07:06,661 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:07:06,662 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:07:06,662 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:07:06,663 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:07:06,663 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-17 13:07:06,666 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-17 13:13:17,622 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-17 13:13:17,623 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-17 13:13:17,623 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:13:17,626 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:13:17,627 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:13:17,628 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-17 13:13:17,630 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-17 13:13:17,630 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:13:17,630 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:13:17,630 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:13:17,632 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:13:17,633 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:13:17,633 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:13:17,633 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:13:17,635 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:13:17,635 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:13:17,635 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:13:17,636 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-17 13:13:17,642 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-17 13:13:17,643 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:13:17,646 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:13:17,647 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:13:17,647 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-17 13:13:17,651 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-17 13:13:28,110 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-17 13:13:28,111 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-17 13:13:28,111 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:13:28,114 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:13:28,114 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:13:28,115 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:13:28,115 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:13:28,227 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:13:28,227 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:13:28,229 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:13:28,229 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-17 13:13:28,231 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.generate_summary_document'
2025-09-17 13:13:33,565 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-17 13:13:33,565 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-17 13:13:33,566 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:13:33,567 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:13:33,567 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:13:33,568 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:13:33,568 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:13:33,568 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:13:33,568 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:13:33,569 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:13:33,569 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-17 13:13:33,572 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-17 13:14:16,239 | DEBUG | hackthon_support_agent.FunctionService | Initializing BaseService (provider=google)
2025-09-17 13:14:16,240 | INFO | hackthon_support_agent.FunctionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-17 13:14:16,240 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:14:16,242 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:14:16,242 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:14:16,243 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:14:16,243 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:14:16,245 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:14:16,245 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:14:16,246 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:14:16,246 | DEBUG | hackthon_support_agent.FunctionService | LLMs initialized
2025-09-17 13:14:16,246 | DEBUG | hackthon_support_agent.FunctionService | Generating functional requirements for project_id: b87ceab8-fb58-4e21-b331-114858771665
2025-09-17 13:14:16,249 | DEBUG | hackthon_support_agent.FunctionService | Fetching prompt 'function_service.generate_functional_requirements'
2025-09-17 13:14:16,642 | DEBUG | hackthon_support_agent.FunctionService | Initializing BaseService (provider=google)
2025-09-17 13:14:16,643 | INFO | hackthon_support_agent.FunctionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-17 13:14:16,644 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:14:16,645 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:14:16,645 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:14:16,646 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:14:16,646 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:14:16,647 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:14:16,647 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:14:16,648 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:14:16,649 | DEBUG | hackthon_support_agent.FunctionService | LLMs initialized
2025-09-17 13:14:16,649 | DEBUG | hackthon_support_agent.FunctionService | Generating functional requirements for project_id: b87ceab8-fb58-4e21-b331-114858771665
2025-09-17 13:14:16,652 | DEBUG | hackthon_support_agent.FunctionService | Fetching prompt 'function_service.generate_functional_requirements'
2025-09-17 13:14:27,641 | DEBUG | hackthon_support_agent.FunctionService | Generating clarification questions for 2 low-confidence requirements
2025-09-17 13:14:27,642 | DEBUG | hackthon_support_agent.FunctionService | Fetching prompt 'function_service.generate_clarification_questions'
2025-09-17 13:14:29,059 | DEBUG | hackthon_support_agent.FunctionService | Generating clarification questions for 3 low-confidence requirements
2025-09-17 13:14:29,059 | DEBUG | hackthon_support_agent.FunctionService | Fetching prompt 'function_service.generate_clarification_questions'
2025-09-17 13:14:30,063 | DEBUG | hackthon_support_agent.FunctionService | Saving functional requirements to project document: b87ceab8-fb58-4e21-b331-114858771665
2025-09-17 13:14:30,068 | DEBUG | hackthon_support_agent.FunctionService | Saving 3 clarification questions to database
2025-09-17 13:14:30,070 | ERROR | hackthon_support_agent.FunctionService | Failed to save clarification questions: Can't match sentinel values in result set to parameter sets; key '5a8c4b7d-cb59-4ab4-83b9-31035e0abc4e' was not found. There may be a mismatch between the datatype passed to the DBAPI driver vs. that which it returns in a result row.  Ensure the given Python value matches the expected result type *exactly*, taking care to not rely upon implicit conversions which may occur such as when using strings in place of UUID or integer values, etc. 
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 914, in _deliver_insertmanyvalues_batches
    rows_by_sentinel[sentinel_keys]
    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^
KeyError: '5a8c4b7d-cb59-4ab4-83b9-31035e0abc4e'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/function_service.py", line 314, in save_clarification_questions
    self.db.commit()
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2032, in commit
    trans.commit(_to_root=True)
  File "<string>", line 2, in commit
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
    ret_value = fn(self, *arg, **kw)
                ^^^^^^^^^^^^^^^^^^^^
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1313, in commit
    self._prepare_impl()
  File "<string>", line 2, in _prepare_impl
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
    ret_value = fn(self, *arg, **kw)
                ^^^^^^^^^^^^^^^^^^^^
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1288, in _prepare_impl
    self.session.flush()
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4345, in flush
    self._flush(objects)
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4480, in _flush
    with util.safe_reraise():
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 224, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4441, in _flush
    flush_context.execute()
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 466, in execute
    rec.execute(self)
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 642, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 93, in save_obj
    _emit_insert_statements(
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 1143, in _emit_insert_statements
    result = connection.execute(
             ^^^^^^^^^^^^^^^^^^^
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1415, in execute
    return meth(
           ^^^^^
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 523, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1637, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1840, in _execute_context
    return self._exec_insertmany_context(dialect, context)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2029, in _exec_insertmany_context
    for imv_batch in dialect._deliver_insertmanyvalues_batches(
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 921, in _deliver_insertmanyvalues_batches
    raise exc.InvalidRequestError(
sqlalchemy.exc.InvalidRequestError: Can't match sentinel values in result set to parameter sets; key '5a8c4b7d-cb59-4ab4-83b9-31035e0abc4e' was not found. There may be a mismatch between the datatype passed to the DBAPI driver vs. that which it returns in a result row.  Ensure the given Python value matches the expected result type *exactly*, taking care to not rely upon implicit conversions which may occur such as when using strings in place of UUID or integer values, etc. 
2025-09-17 13:14:32,725 | DEBUG | hackthon_support_agent.FunctionService | Saving functional requirements to project document: b87ceab8-fb58-4e21-b331-114858771665
2025-09-17 13:14:32,730 | DEBUG | hackthon_support_agent.FunctionService | Saving 6 clarification questions to database
2025-09-17 13:14:32,732 | ERROR | hackthon_support_agent.FunctionService | Failed to save clarification questions: Can't match sentinel values in result set to parameter sets; key '69f6db38-f972-4c42-ae4a-0c5587f2ca09' was not found. There may be a mismatch between the datatype passed to the DBAPI driver vs. that which it returns in a result row.  Ensure the given Python value matches the expected result type *exactly*, taking care to not rely upon implicit conversions which may occur such as when using strings in place of UUID or integer values, etc. 
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 914, in _deliver_insertmanyvalues_batches
    rows_by_sentinel[sentinel_keys]
    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^
KeyError: '69f6db38-f972-4c42-ae4a-0c5587f2ca09'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/function_service.py", line 314, in save_clarification_questions
    self.db.commit()
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2032, in commit
    trans.commit(_to_root=True)
  File "<string>", line 2, in commit
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
    ret_value = fn(self, *arg, **kw)
                ^^^^^^^^^^^^^^^^^^^^
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1313, in commit
    self._prepare_impl()
  File "<string>", line 2, in _prepare_impl
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
    ret_value = fn(self, *arg, **kw)
                ^^^^^^^^^^^^^^^^^^^^
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1288, in _prepare_impl
    self.session.flush()
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4345, in flush
    self._flush(objects)
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4480, in _flush
    with util.safe_reraise():
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 224, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4441, in _flush
    flush_context.execute()
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 466, in execute
    rec.execute(self)
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 642, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 93, in save_obj
    _emit_insert_statements(
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 1143, in _emit_insert_statements
    result = connection.execute(
             ^^^^^^^^^^^^^^^^^^^
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1415, in execute
    return meth(
           ^^^^^
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 523, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1637, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1840, in _execute_context
    return self._exec_insertmany_context(dialect, context)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2029, in _exec_insertmany_context
    for imv_batch in dialect._deliver_insertmanyvalues_batches(
  File "/workspaces/hackathon_support_agent/venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 921, in _deliver_insertmanyvalues_batches
    raise exc.InvalidRequestError(
sqlalchemy.exc.InvalidRequestError: Can't match sentinel values in result set to parameter sets; key '69f6db38-f972-4c42-ae4a-0c5587f2ca09' was not found. There may be a mismatch between the datatype passed to the DBAPI driver vs. that which it returns in a result row.  Ensure the given Python value matches the expected result type *exactly*, taking care to not rely upon implicit conversions which may occur such as when using strings in place of UUID or integer values, etc. 
2025-09-17 13:15:26,660 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-17 13:15:35,271 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-17 13:15:47,923 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-17 13:16:57,242 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-17 13:16:57,244 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-17 13:16:57,244 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:16:57,264 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:16:57,264 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-17 13:16:57,264 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:16:57,266 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-17 13:16:57,267 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:16:57,267 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:16:57,268 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:16:57,269 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:16:57,269 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:16:57,270 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:16:57,270 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:16:57,271 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:16:57,272 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:16:57,273 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:16:57,273 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-17 13:16:57,278 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-17 13:16:57,279 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:16:57,279 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:16:57,282 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:16:57,283 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-17 13:16:57,286 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-17 13:20:49,065 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-17 13:20:58,516 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-17 13:21:17,484 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-17 13:21:35,115 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-17 13:25:27,926 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-17 13:25:40,544 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-17 13:28:06,300 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-17 13:28:06,301 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-17 13:28:06,301 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:28:06,312 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:28:06,312 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:28:06,313 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:28:06,313 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:28:06,314 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:28:06,314 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:28:06,315 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:28:06,315 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-17 13:28:06,340 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.generate_summary_document'
2025-09-17 13:28:12,881 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-17 13:28:12,882 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-17 13:28:12,882 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:28:12,883 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:28:12,883 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:28:12,884 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:28:12,884 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:28:12,885 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:28:12,886 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:28:12,886 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:28:12,886 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-17 13:28:13,885 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-17 13:28:13,886 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-17 13:28:13,886 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:28:13,892 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:28:13,893 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:28:13,895 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:28:13,895 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:28:13,897 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:28:13,897 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:28:13,899 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:28:13,899 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-17 13:28:13,907 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-17 13:28:13,912 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-17 13:28:13,914 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-17 13:28:13,914 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:28:13,917 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:28:13,917 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:28:13,919 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:28:13,919 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:28:13,921 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:28:13,921 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:28:13,924 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:28:13,925 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-17 13:28:13,933 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-17 13:28:38,685 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-17 13:28:38,686 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-17 13:28:38,686 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:28:38,688 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:28:38,689 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:28:38,691 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:28:38,693 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:28:38,694 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-17 13:28:38,694 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:28:38,695 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:28:38,696 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-17 13:28:38,697 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:28:38,699 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:28:38,701 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:28:38,701 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-17 13:28:38,702 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:28:38,707 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-17 13:28:38,851 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:28:38,852 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:28:38,853 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:28:38,854 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:28:38,855 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:28:38,855 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-17 13:28:38,860 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-17 13:28:55,331 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-17 13:28:55,332 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-17 13:28:55,332 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:28:55,333 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:28:55,333 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:28:55,334 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:28:55,334 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:28:55,334 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:28:55,335 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:28:55,335 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:28:55,336 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-17 13:28:55,336 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: b87ceab8-fb58-4e21-b331-114858771665
2025-09-17 13:28:55,339 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.confidence_feedback.generate_confidence_feedback'
2025-09-17 13:28:55,339 | ERROR | hackthon_support_agent.SummaryService | Prompt 'generate_confidence_feedback' not found under service 'summary_service.confidence_feedback' in prompts.toml
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/base_service.py", line 148, in get_prompt
    prompt = self.prompts[service_name][prompt_name]
             ~~~~~~~~~~~~^^^^^^^^^^^^^^
KeyError: 'summary_service.confidence_feedback'
2025-09-17 13:31:58,235 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-17 13:32:14,168 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-17 13:32:24,407 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-17 13:33:28,585 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-17 13:33:28,586 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-17 13:33:28,586 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:33:28,597 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:33:28,598 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:33:28,599 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:33:28,599 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:33:28,600 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:33:28,600 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:33:28,601 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:33:28,601 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-17 13:33:28,606 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-17 13:33:28,846 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-17 13:33:28,847 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-17 13:33:28,847 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:33:28,848 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:33:28,848 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:33:28,849 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:33:28,849 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:33:28,852 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:33:28,852 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:33:28,853 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:33:28,853 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-17 13:33:28,858 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-17 13:33:39,492 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-17 13:33:39,492 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-17 13:33:39,493 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:33:39,494 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:33:39,494 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:33:39,495 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:33:39,495 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:33:39,497 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:33:39,497 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:33:39,498 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:33:39,499 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-17 13:33:39,504 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-17 13:34:48,705 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-17 13:34:48,706 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-17 13:34:48,706 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:34:48,708 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:34:48,708 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:34:48,709 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:34:48,709 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:34:48,710 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:34:48,710 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:34:48,711 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:34:48,711 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-17 13:34:48,711 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: b87ceab8-fb58-4e21-b331-114858771665
2025-09-17 13:34:48,823 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.confidence_feedback.generate_confidence_feedback'
2025-09-17 13:34:48,823 | ERROR | hackthon_support_agent.SummaryService | Prompt 'generate_confidence_feedback' not found under service 'summary_service.confidence_feedback' in prompts.toml
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/base_service.py", line 148, in get_prompt
    prompt = self.prompts[service_name][prompt_name]
             ~~~~~~~~~~~~^^^^^^^^^^^^^^
KeyError: 'summary_service.confidence_feedback'
2025-09-17 13:35:51,652 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-17 13:36:09,993 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-17 13:36:28,851 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-17 13:37:14,582 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-17 13:37:14,583 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-17 13:37:14,583 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:37:14,594 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:37:14,594 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:37:14,595 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:37:14,595 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:37:14,596 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:37:14,596 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:37:14,597 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:37:14,597 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-17 13:37:14,601 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-17 13:37:14,836 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-17 13:37:14,837 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-17 13:37:14,837 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:37:14,838 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:37:14,838 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:37:14,839 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:37:14,839 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:37:14,840 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:37:14,840 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:37:14,841 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:37:14,841 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-17 13:37:14,844 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-17 13:37:19,798 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-17 13:37:19,799 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-17 13:37:19,799 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:37:19,800 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:37:19,801 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:37:19,802 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:37:19,802 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:37:19,803 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:37:19,803 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:37:19,804 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:37:19,804 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-17 13:37:19,804 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: b87ceab8-fb58-4e21-b331-114858771665
2025-09-17 13:37:19,809 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.confidence_feedback.generate_confidence_feedback'
2025-09-17 13:37:19,809 | ERROR | hackthon_support_agent.SummaryService | Prompt 'generate_confidence_feedback' not found under service 'summary_service.confidence_feedback' in prompts.toml
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/base_service.py", line 148, in get_prompt
    prompt = self.prompts[service_name][prompt_name]
             ~~~~~~~~~~~~^^^^^^^^^^^^^^
KeyError: 'summary_service.confidence_feedback'
2025-09-17 13:37:19,809 | ERROR | hackthon_support_agent.SummaryService | Failed to get prompt: Prompt 'generate_confidence_feedback' not found in service 'summary_service.confidence_feedback' in prompts.toml
2025-09-17 13:37:30,563 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-17 13:37:30,564 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-17 13:37:30,564 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:37:30,565 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:37:30,565 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:37:30,566 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:37:30,566 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:37:30,567 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:37:30,568 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:37:30,569 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:37:30,569 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-17 13:37:30,569 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: b87ceab8-fb58-4e21-b331-114858771665
2025-09-17 13:37:30,684 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.confidence_feedback.generate_confidence_feedback'
2025-09-17 13:37:30,684 | ERROR | hackthon_support_agent.SummaryService | Prompt 'generate_confidence_feedback' not found under service 'summary_service.confidence_feedback' in prompts.toml
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/base_service.py", line 148, in get_prompt
    prompt = self.prompts[service_name][prompt_name]
             ~~~~~~~~~~~~^^^^^^^^^^^^^^
KeyError: 'summary_service.confidence_feedback'
2025-09-17 13:37:30,685 | ERROR | hackthon_support_agent.SummaryService | Failed to get prompt: Prompt 'generate_confidence_feedback' not found in service 'summary_service.confidence_feedback' in prompts.toml
2025-09-17 13:40:23,906 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-17 13:40:23,907 | ERROR | hackthon_support_agent.SummaryService | Failed to load prompts from /workspaces/hackathon_support_agent/back/services/prompts.toml
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/base_service.py", line 80, in __init__
    self.prompts: Dict[str, Dict[str, str]] = tomllib.load(f)
                                              ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/tomllib/_parser.py", line 66, in load
    return loads(s, parse_float=parse_float)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/tomllib/_parser.py", line 113, in loads
    pos, header = create_dict_rule(src, pos, out)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/tomllib/_parser.py", line 290, in create_dict_rule
    raise suffixed_err(src, pos, f"Cannot declare {key} twice")
tomllib.TOMLDecodeError: Cannot declare ('summary_service',) twice (at line 407, column 17)
2025-09-17 13:41:53,856 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-17 13:41:53,857 | ERROR | hackthon_support_agent.MVPJudgeService | Failed to load prompts from /workspaces/hackathon_support_agent/back/services/prompts.toml
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/base_service.py", line 80, in __init__
    self.prompts: Dict[str, Dict[str, str]] = tomllib.load(f)
                                              ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/tomllib/_parser.py", line 66, in load
    return loads(s, parse_float=parse_float)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/tomllib/_parser.py", line 113, in loads
    pos, header = create_dict_rule(src, pos, out)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/tomllib/_parser.py", line 290, in create_dict_rule
    raise suffixed_err(src, pos, f"Cannot declare {key} twice")
tomllib.TOMLDecodeError: Cannot declare ('summary_service',) twice (at line 407, column 17)
2025-09-17 13:41:54,106 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-17 13:41:54,107 | ERROR | hackthon_support_agent.MVPJudgeService | Failed to load prompts from /workspaces/hackathon_support_agent/back/services/prompts.toml
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/base_service.py", line 80, in __init__
    self.prompts: Dict[str, Dict[str, str]] = tomllib.load(f)
                                              ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/tomllib/_parser.py", line 66, in load
    return loads(s, parse_float=parse_float)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/tomllib/_parser.py", line 113, in loads
    pos, header = create_dict_rule(src, pos, out)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/tomllib/_parser.py", line 290, in create_dict_rule
    raise suffixed_err(src, pos, f"Cannot declare {key} twice")
tomllib.TOMLDecodeError: Cannot declare ('summary_service',) twice (at line 407, column 17)
2025-09-17 13:41:54,300 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-17 13:41:54,301 | ERROR | hackthon_support_agent.SummaryService | Failed to load prompts from /workspaces/hackathon_support_agent/back/services/prompts.toml
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/base_service.py", line 80, in __init__
    self.prompts: Dict[str, Dict[str, str]] = tomllib.load(f)
                                              ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/tomllib/_parser.py", line 66, in load
    return loads(s, parse_float=parse_float)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/tomllib/_parser.py", line 113, in loads
    pos, header = create_dict_rule(src, pos, out)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/tomllib/_parser.py", line 290, in create_dict_rule
    raise suffixed_err(src, pos, f"Cannot declare {key} twice")
tomllib.TOMLDecodeError: Cannot declare ('summary_service',) twice (at line 407, column 17)
2025-09-17 13:41:54,334 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-17 13:41:54,335 | ERROR | hackthon_support_agent.SummaryService | Failed to load prompts from /workspaces/hackathon_support_agent/back/services/prompts.toml
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/base_service.py", line 80, in __init__
    self.prompts: Dict[str, Dict[str, str]] = tomllib.load(f)
                                              ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/tomllib/_parser.py", line 66, in load
    return loads(s, parse_float=parse_float)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/tomllib/_parser.py", line 113, in loads
    pos, header = create_dict_rule(src, pos, out)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/tomllib/_parser.py", line 290, in create_dict_rule
    raise suffixed_err(src, pos, f"Cannot declare {key} twice")
tomllib.TOMLDecodeError: Cannot declare ('summary_service',) twice (at line 407, column 17)
2025-09-17 13:42:21,879 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-17 13:42:21,880 | ERROR | hackthon_support_agent.SummaryService | Failed to load prompts from /workspaces/hackathon_support_agent/back/services/prompts.toml
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/base_service.py", line 80, in __init__
    self.prompts: Dict[str, Dict[str, str]] = tomllib.load(f)
                                              ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/tomllib/_parser.py", line 66, in load
    return loads(s, parse_float=parse_float)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/tomllib/_parser.py", line 113, in loads
    pos, header = create_dict_rule(src, pos, out)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/tomllib/_parser.py", line 290, in create_dict_rule
    raise suffixed_err(src, pos, f"Cannot declare {key} twice")
tomllib.TOMLDecodeError: Cannot declare ('summary_service',) twice (at line 407, column 17)
2025-09-17 13:43:59,546 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-17 13:43:59,547 | ERROR | hackthon_support_agent.SummaryService | Failed to load prompts from /workspaces/hackathon_support_agent/back/services/prompts.toml
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/base_service.py", line 80, in __init__
    self.prompts: Dict[str, Dict[str, str]] = tomllib.load(f)
                                              ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/tomllib/_parser.py", line 66, in load
    return loads(s, parse_float=parse_float)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/tomllib/_parser.py", line 113, in loads
    pos, header = create_dict_rule(src, pos, out)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/tomllib/_parser.py", line 290, in create_dict_rule
    raise suffixed_err(src, pos, f"Cannot declare {key} twice")
tomllib.TOMLDecodeError: Cannot declare ('summary_service',) twice (at line 407, column 17)
2025-09-17 13:46:55,001 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-17 13:46:55,002 | ERROR | hackthon_support_agent.SummaryService | Failed to load prompts from /workspaces/hackathon_support_agent/back/services/prompts.toml
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/base_service.py", line 80, in __init__
    self.prompts: Dict[str, Dict[str, str]] = tomllib.load(f)
                                              ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/tomllib/_parser.py", line 66, in load
    return loads(s, parse_float=parse_float)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/tomllib/_parser.py", line 113, in loads
    pos, header = create_dict_rule(src, pos, out)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/tomllib/_parser.py", line 290, in create_dict_rule
    raise suffixed_err(src, pos, f"Cannot declare {key} twice")
tomllib.TOMLDecodeError: Cannot declare ('summary_service',) twice (at line 407, column 17)
2025-09-17 13:46:59,193 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-17 13:46:59,194 | ERROR | hackthon_support_agent.SummaryService | Failed to load prompts from /workspaces/hackathon_support_agent/back/services/prompts.toml
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/base_service.py", line 80, in __init__
    self.prompts: Dict[str, Dict[str, str]] = tomllib.load(f)
                                              ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/tomllib/_parser.py", line 66, in load
    return loads(s, parse_float=parse_float)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/tomllib/_parser.py", line 113, in loads
    pos, header = create_dict_rule(src, pos, out)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/tomllib/_parser.py", line 290, in create_dict_rule
    raise suffixed_err(src, pos, f"Cannot declare {key} twice")
tomllib.TOMLDecodeError: Cannot declare ('summary_service',) twice (at line 407, column 17)
2025-09-17 13:48:19,811 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-17 13:48:19,812 | ERROR | hackthon_support_agent.SummaryService | Failed to load prompts from /workspaces/hackathon_support_agent/back/services/prompts.toml
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/base_service.py", line 80, in __init__
    self.prompts: Dict[str, Dict[str, str]] = tomllib.load(f)
                                              ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/tomllib/_parser.py", line 66, in load
    return loads(s, parse_float=parse_float)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/tomllib/_parser.py", line 113, in loads
    pos, header = create_dict_rule(src, pos, out)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/tomllib/_parser.py", line 290, in create_dict_rule
    raise suffixed_err(src, pos, f"Cannot declare {key} twice")
tomllib.TOMLDecodeError: Cannot declare ('summary_service',) twice (at line 407, column 17)
2025-09-17 13:51:20,371 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-17 13:51:20,372 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-17 13:51:20,373 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:51:20,375 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:51:20,375 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:51:20,376 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:51:20,376 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:51:20,377 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:51:20,377 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:51:20,378 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:51:20,378 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-17 13:51:20,383 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.generate_summary_document'
2025-09-17 13:51:29,284 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: b87ceab8-fb58-4e21-b331-114858771665
2025-09-17 13:51:29,288 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.confidence_feedback.generate_confidence_feedback'
2025-09-17 13:51:29,288 | ERROR | hackthon_support_agent.SummaryService | Prompt 'generate_confidence_feedback' not found under service 'summary_service.confidence_feedback' in prompts.toml
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/base_service.py", line 148, in get_prompt
    prompt = self.prompts[service_name][prompt_name]
             ~~~~~~~~~~~~^^^^^^^^^^^^^^
KeyError: 'summary_service.confidence_feedback'
2025-09-17 13:51:29,288 | ERROR | hackthon_support_agent.SummaryService | Failed to get prompt: Prompt 'generate_confidence_feedback' not found in service 'summary_service.confidence_feedback' in prompts.toml
2025-09-17 13:51:36,323 | WARNING | hackthon_support_agent.SummaryService | Failed to generate confidence feedback: Got invalid return object. Expected key `value_feedback` to be present, but got {'overall_confidence': 0.65, 'clarity_score': 0.7, 'feasibility_score': 0.8, 'scope_score': 0.6, 'value_score': 0.95, 'completeness_score': 0.5, 'clarity_feedback': 'ビジョン、課題、提供価値、ペルソナ、利用シナリオ、差別化ポイント、将来展望は比較的明確に記述されています。しかし、Q&Aを通じて、MVPのMust-have機能、非機能要件、入出力定義、受入基準、主要リスク/依存関係など、具体的な要件定義のレベルでは、まだ曖昧さが残っています。特に、Must-have機能の具体的な粒度や、受入基準の定量的な定義が不足しています。', 'feasibility_feedback': '提案されている機能（アイデアの具体化支援、タスク管理、技術選定サポート、開発プロセスガイド）は、現在のAI技術やWebアプリケーション開発技術で実現可能と考えられます。特にAIによるパーソナライズされた提案は、実現可能性が高いです。ただし、AIの提案精度や、初心者向けのUI/UXの実現には一定の技術的挑戦が伴います。', 'scope_feedback': 'MVPのスコープは、ハッカソン期間内で実現可能な範囲に絞るべきですが、現時点では「アイデアの具現化から開発プロセスガイドまで」と広範に定義されており、MVPとしてどこまでを実装すべきかの線引きが曖昧です。Q&Aで「アイデアをMVP定義に落とし込む支援」「タスク自動生成・割り当て」「技術選定提案」がMust-haveとされていますが、これらもさらに具体的な機能範囲を定義する必要があります。将来展望にある機能（コード生成、デバッグ支援など）は、MVPのスコープ外と明確に区別する必要があります。', 'completeness_feedback': 'ビジョン、課題、提供価値、ペルソナ、利用シナリオはよく記述されており、プロダクトの方向性やユーザーへの価値は理解しやすいです。しかし、開発を進める上で不可欠な、詳細な機能要件、非機能要件（特にパフォーマンス、セキュリティ、可用性）、入出力の具体的なデータ構造やAPI仕様、詳細な受入基準、リスクに対する具体的な対応策などが不足しています。Q&Aで補完されている部分もありますが、仕様書本体でより具体的に記述されるべきです。', 'improvement_suggestions': ['MVPのMust-have機能について、各機能の具体的な粒度（例：タスク生成の最小単位、技術選定のアルゴリズム、ガイドのステップ数）を定義してください。', '非機能要件について、最低限満たすべきパフォーマンス基準（例：画面遷移時間、API応答時間）、セキュリティ要件（例：個人情報非保持）、可用性要件（例：ハッカソン期間中の稼働率）を定義してください。', '入出力定義について、MVPで扱う主要なデータ（アイデア、MVP定義、タスク、技術スタックなど）のデータ構造（JSONスキーマなど）を定義し、主要なAPIエンドポイントの仕様を記述してください。', '受入基準について、定量的な指標（例：80%のチームがMVP定義を完了できる、AI提案の満足度がX%以上など）を設定してください。', '主要リスク/依存について、各リスクに対する具体的な軽減策や対応計画を記述してください。', 'MVPのスコープをより明確にするため、MVPで「やらないこと」を明確に定義してください（例：コード生成機能、複雑な認証機能など）。', 'UI/UXに関する具体的な要件（例：ウィザード形式の採用、視覚的な進捗表示など）を、利用シナリオやペルソナのニーズと紐づけて詳細化してください。'], 'confidence_reason': 'プロダクトのビジョン、ターゲットユーザー、提供価値は明確であり、ユーザーにとって非常に価値のあるプロダクトになり得ると確信しています。技術的な実現可能性も高いと考えられます。しかし、MVPのスコープ定義、機能の詳細化、非機能要件、入出力定義、受入基準など、開発に必要な情報の完全性と明確性が不足しており、現時点での確信度は中程度です。これらの不足点を解消することで、確信度はさらに高まります。'}
For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE 
2025-09-17 13:51:36,332 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-17 13:51:36,333 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-17 13:51:36,333 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:51:36,335 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:51:36,335 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:51:36,335 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:51:36,335 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:51:36,336 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:51:36,336 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:51:36,337 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:51:36,337 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-17 13:51:36,341 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-17 13:53:26,915 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-17 13:53:26,916 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-17 13:53:26,916 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:53:26,918 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:53:26,918 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:53:26,919 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:53:26,919 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:53:26,920 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:53:26,920 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-17 13:53:26,921 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-17 13:53:26,921 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-17 13:53:26,921 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: b87ceab8-fb58-4e21-b331-114858771665
2025-09-17 13:53:26,925 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.confidence_feedback.generate_confidence_feedback'
2025-09-17 13:53:26,925 | ERROR | hackthon_support_agent.SummaryService | Prompt 'generate_confidence_feedback' not found under service 'summary_service.confidence_feedback' in prompts.toml
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/base_service.py", line 148, in get_prompt
    prompt = self.prompts[service_name][prompt_name]
             ~~~~~~~~~~~~^^^^^^^^^^^^^^
KeyError: 'summary_service.confidence_feedback'
2025-09-17 13:53:26,926 | ERROR | hackthon_support_agent.SummaryService | Failed to get prompt: Prompt 'generate_confidence_feedback' not found in service 'summary_service.confidence_feedback' in prompts.toml
2025-09-18 01:59:56,455 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-18 01:59:56,459 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-18 01:59:56,459 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 01:59:56,464 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 01:59:56,464 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 01:59:56,466 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 01:59:56,466 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 01:59:56,467 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 01:59:56,467 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 01:59:56,468 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 01:59:56,468 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-18 01:59:56,474 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-18 01:59:56,692 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-18 01:59:56,693 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-18 01:59:56,694 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 01:59:56,695 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 01:59:56,695 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 01:59:56,696 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 01:59:56,696 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 01:59:56,697 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 01:59:56,697 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 01:59:56,698 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 01:59:56,698 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-18 01:59:56,702 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-18 02:00:00,071 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-18 02:00:00,072 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-18 02:00:00,072 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:00:00,073 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:00:00,073 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:00:00,074 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:00:00,074 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:00:00,075 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:00:00,075 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:00:00,077 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:00:00,077 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-18 02:00:00,077 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: b87ceab8-fb58-4e21-b331-114858771665
2025-09-18 02:00:00,082 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.confidence_feedback.generate_confidence_feedback'
2025-09-18 02:00:00,082 | ERROR | hackthon_support_agent.SummaryService | Prompt 'generate_confidence_feedback' not found under service 'summary_service.confidence_feedback' in prompts.toml
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/base_service.py", line 148, in get_prompt
    prompt = self.prompts[service_name][prompt_name]
             ~~~~~~~~~~~~^^^^^^^^^^^^^^
KeyError: 'summary_service.confidence_feedback'
2025-09-18 02:00:00,083 | ERROR | hackthon_support_agent.SummaryService | Failed to get prompt: Prompt 'generate_confidence_feedback' not found in service 'summary_service.confidence_feedback' in prompts.toml
2025-09-18 02:00:00,884 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-18 02:00:00,884 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-18 02:00:00,885 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:00:00,886 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:00:00,886 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:00:00,887 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:00:00,887 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:00:00,888 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:00:00,888 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:00:00,889 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:00:00,890 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-18 02:00:00,890 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: b87ceab8-fb58-4e21-b331-114858771665
2025-09-18 02:00:00,895 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.confidence_feedback.generate_confidence_feedback'
2025-09-18 02:00:00,895 | ERROR | hackthon_support_agent.SummaryService | Prompt 'generate_confidence_feedback' not found under service 'summary_service.confidence_feedback' in prompts.toml
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/base_service.py", line 148, in get_prompt
    prompt = self.prompts[service_name][prompt_name]
             ~~~~~~~~~~~~^^^^^^^^^^^^^^
KeyError: 'summary_service.confidence_feedback'
2025-09-18 02:00:00,896 | ERROR | hackthon_support_agent.SummaryService | Failed to get prompt: Prompt 'generate_confidence_feedback' not found in service 'summary_service.confidence_feedback' in prompts.toml
2025-09-18 02:01:03,046 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-18 02:01:03,047 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-18 02:01:03,047 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:01:03,048 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:01:03,048 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:01:03,049 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:01:03,049 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:01:03,050 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:01:03,050 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:01:03,051 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:01:03,051 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-18 02:01:03,055 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-18 02:01:03,322 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-18 02:01:03,323 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-18 02:01:03,323 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:01:03,324 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:01:03,324 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:01:03,325 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:01:03,325 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:01:03,326 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:01:03,326 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:01:03,326 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:01:03,327 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-18 02:01:03,329 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-18 02:01:13,935 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-18 02:01:13,936 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-18 02:01:13,936 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:01:13,937 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:01:13,937 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:01:13,938 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:01:13,938 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:01:13,939 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:01:13,939 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:01:13,940 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:01:13,940 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-18 02:01:13,940 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: b87ceab8-fb58-4e21-b331-114858771665
2025-09-18 02:01:13,944 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.confidence_feedback.generate_confidence_feedback'
2025-09-18 02:01:13,944 | ERROR | hackthon_support_agent.SummaryService | Prompt 'generate_confidence_feedback' not found under service 'summary_service.confidence_feedback' in prompts.toml
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/base_service.py", line 148, in get_prompt
    prompt = self.prompts[service_name][prompt_name]
             ~~~~~~~~~~~~^^^^^^^^^^^^^^
KeyError: 'summary_service.confidence_feedback'
2025-09-18 02:01:13,945 | ERROR | hackthon_support_agent.SummaryService | Failed to get prompt: Prompt 'generate_confidence_feedback' not found in service 'summary_service.confidence_feedback' in prompts.toml
2025-09-18 02:01:15,116 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-18 02:01:15,117 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-18 02:01:15,117 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:01:15,118 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:01:15,118 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:01:15,119 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:01:15,119 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:01:15,121 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:01:15,121 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:01:15,122 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:01:15,122 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-18 02:01:15,122 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: b87ceab8-fb58-4e21-b331-114858771665
2025-09-18 02:01:15,126 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.confidence_feedback.generate_confidence_feedback'
2025-09-18 02:01:15,126 | ERROR | hackthon_support_agent.SummaryService | Prompt 'generate_confidence_feedback' not found under service 'summary_service.confidence_feedback' in prompts.toml
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/base_service.py", line 148, in get_prompt
    prompt = self.prompts[service_name][prompt_name]
             ~~~~~~~~~~~~^^^^^^^^^^^^^^
KeyError: 'summary_service.confidence_feedback'
2025-09-18 02:01:15,126 | ERROR | hackthon_support_agent.SummaryService | Failed to get prompt: Prompt 'generate_confidence_feedback' not found in service 'summary_service.confidence_feedback' in prompts.toml
2025-09-18 02:01:54,966 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-18 02:01:54,967 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-18 02:01:54,968 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:01:54,974 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:01:54,974 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:01:54,975 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:01:54,975 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:01:54,976 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:01:54,977 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:01:54,978 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:01:54,978 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-18 02:01:54,978 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: b87ceab8-fb58-4e21-b331-114858771665
2025-09-18 02:01:54,984 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.confidence_feedback.generate_confidence_feedback'
2025-09-18 02:01:54,985 | ERROR | hackthon_support_agent.SummaryService | Prompt 'generate_confidence_feedback' not found under service 'summary_service.confidence_feedback' in prompts.toml
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/base_service.py", line 148, in get_prompt
    prompt = self.prompts[service_name][prompt_name]
             ~~~~~~~~~~~~^^^^^^^^^^^^^^
KeyError: 'summary_service.confidence_feedback'
2025-09-18 02:01:54,985 | ERROR | hackthon_support_agent.SummaryService | Failed to get prompt: Prompt 'generate_confidence_feedback' not found in service 'summary_service.confidence_feedback' in prompts.toml
2025-09-18 02:05:21,892 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-18 02:06:52,133 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-18 02:06:52,134 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-18 02:06:52,134 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:06:52,150 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:06:52,151 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:06:52,152 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:06:52,152 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:06:52,153 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:06:52,153 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:06:52,154 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:06:52,154 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-18 02:06:52,160 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-18 02:06:52,402 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-18 02:06:52,403 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-18 02:06:52,403 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:06:52,405 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:06:52,405 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:06:52,406 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:06:52,406 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:06:52,407 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:06:52,407 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:06:52,408 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:06:52,408 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-18 02:06:52,412 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-18 02:06:54,739 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-18 02:06:54,740 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-18 02:06:54,740 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:06:54,741 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:06:54,741 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:06:54,742 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:06:54,742 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:06:54,743 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:06:54,743 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:06:54,744 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:06:54,744 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-18 02:06:54,744 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: b87ceab8-fb58-4e21-b331-114858771665
2025-09-18 02:06:54,750 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.confidence_feedback'
2025-09-18 02:06:54,876 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-18 02:06:54,876 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-18 02:06:54,877 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:06:54,878 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:06:54,878 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:06:54,879 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:06:54,879 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:06:54,880 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:06:54,880 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:06:54,881 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:06:54,881 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-18 02:06:54,881 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: b87ceab8-fb58-4e21-b331-114858771665
2025-09-18 02:06:54,886 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.confidence_feedback'
2025-09-18 02:08:04,434 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-18 02:08:04,435 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-18 02:08:04,435 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:08:04,437 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:08:04,437 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:08:04,437 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:08:04,437 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:08:04,438 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:08:04,438 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:08:04,439 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:08:04,439 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-18 02:08:04,439 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: b87ceab8-fb58-4e21-b331-114858771665
2025-09-18 02:08:04,444 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.confidence_feedback'
2025-09-18 02:08:08,398 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-18 02:08:08,399 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-18 02:08:08,399 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:08:08,401 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:08:08,401 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:08:08,402 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:08:08,402 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:08:08,403 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:08:08,403 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:08:08,404 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:08:08,404 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-18 02:08:08,408 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-18 02:08:08,822 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-18 02:08:08,824 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-18 02:08:08,824 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:08:08,825 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:08:08,825 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:08:08,826 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:08:08,826 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:08:08,827 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:08:08,827 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:08:08,828 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:08:08,828 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-18 02:08:08,830 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-18 02:08:11,718 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-18 02:08:11,719 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-18 02:08:11,719 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:08:11,720 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:08:11,720 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:08:11,721 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:08:11,721 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:08:11,722 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:08:11,722 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:08:11,723 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:08:11,723 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-18 02:08:11,723 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: b87ceab8-fb58-4e21-b331-114858771665
2025-09-18 02:08:11,728 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.confidence_feedback'
2025-09-18 02:08:12,159 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-18 02:08:12,160 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-18 02:08:12,160 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:08:12,161 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:08:12,161 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:08:12,162 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:08:12,162 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:08:12,163 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:08:12,163 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:08:12,164 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:08:12,164 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-18 02:08:12,164 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: b87ceab8-fb58-4e21-b331-114858771665
2025-09-18 02:08:12,169 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.confidence_feedback'
2025-09-18 02:08:19,925 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-18 02:08:19,926 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-18 02:08:19,926 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:08:19,928 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:08:19,928 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:08:19,928 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:08:19,928 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:08:19,929 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:08:19,929 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:08:19,930 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:08:19,930 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-18 02:08:19,930 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: b87ceab8-fb58-4e21-b331-114858771665
2025-09-18 02:08:19,936 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.confidence_feedback'
2025-09-18 02:13:13,754 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-18 02:13:13,755 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-18 02:13:13,755 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:13:13,757 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:13:13,758 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:13:13,759 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:13:13,760 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:13:13,761 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:13:13,761 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:13:13,762 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:13:13,762 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-18 02:13:13,765 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-18 02:13:14,011 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-18 02:13:14,012 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-18 02:13:14,012 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:13:14,013 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:13:14,013 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:13:14,014 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:13:14,014 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:13:14,015 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:13:14,015 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:13:14,016 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:13:14,016 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-18 02:13:14,020 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-18 02:13:16,604 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-18 02:13:16,605 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-18 02:13:16,605 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:13:16,606 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:13:16,606 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:13:16,607 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:13:16,607 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:13:16,608 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:13:16,608 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:13:16,609 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:13:16,609 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-18 02:13:16,610 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: b87ceab8-fb58-4e21-b331-114858771665
2025-09-18 02:13:16,615 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.confidence_feedback'
2025-09-18 02:13:17,782 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-18 02:13:17,783 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-18 02:13:17,783 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:13:17,784 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:13:17,784 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:13:17,785 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:13:17,785 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:13:17,787 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:13:17,787 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:13:17,788 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:13:17,788 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-18 02:13:17,788 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: b87ceab8-fb58-4e21-b331-114858771665
2025-09-18 02:13:17,795 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.confidence_feedback'
2025-09-18 02:14:22,026 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-18 02:14:22,027 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-18 02:14:22,027 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:14:22,028 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:14:22,028 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:14:22,029 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:14:22,029 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:14:22,030 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:14:22,030 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:14:22,031 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:14:22,032 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-18 02:14:22,032 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: b87ceab8-fb58-4e21-b331-114858771665
2025-09-18 02:14:22,036 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.confidence_feedback'
2025-09-18 02:20:55,977 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-18 02:20:55,979 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-18 02:20:55,979 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:20:55,983 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:20:55,983 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:20:55,984 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:20:55,985 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:20:55,985 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:20:55,985 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:20:55,986 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:20:55,986 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-18 02:20:55,991 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-18 02:20:56,217 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-18 02:20:56,218 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-18 02:20:56,218 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:20:56,219 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:20:56,219 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:20:56,220 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:20:56,220 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:20:56,221 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:20:56,221 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:20:56,222 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:20:56,222 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-18 02:20:56,224 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-18 02:20:58,646 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-18 02:20:58,647 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-18 02:20:58,647 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:20:58,649 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:20:58,649 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:20:58,650 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:20:58,650 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:20:58,651 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:20:58,651 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:20:58,652 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:20:58,652 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-18 02:20:58,652 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: b87ceab8-fb58-4e21-b331-114858771665
2025-09-18 02:20:58,657 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.confidence_feedback'
2025-09-18 02:21:00,053 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-18 02:21:00,054 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-18 02:21:00,054 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:21:00,056 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:21:00,056 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:21:00,057 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:21:00,057 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:21:00,059 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:21:00,059 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:21:00,060 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:21:00,060 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-18 02:21:00,061 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: b87ceab8-fb58-4e21-b331-114858771665
2025-09-18 02:21:00,066 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.confidence_feedback'
2025-09-18 02:23:06,968 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-18 02:23:06,970 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-18 02:23:06,970 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:23:06,973 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:23:06,973 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-18 02:23:06,973 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:23:06,975 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-18 02:23:06,976 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:23:06,976 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:23:06,976 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:23:06,978 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:23:06,978 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:23:06,978 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:23:06,979 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:23:06,980 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:23:06,980 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:23:06,981 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:23:06,981 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-18 02:23:06,985 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-18 02:23:06,985 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:23:06,987 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:23:06,988 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:23:06,988 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-18 02:23:06,992 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-18 02:23:09,429 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-18 02:23:09,430 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-18 02:23:09,430 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:23:09,431 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:23:09,431 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:23:09,432 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:23:09,432 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:23:09,434 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:23:09,434 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:23:09,435 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:23:09,435 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-18 02:23:09,435 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: b87ceab8-fb58-4e21-b331-114858771665
2025-09-18 02:23:09,440 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.confidence_feedback'
2025-09-18 02:23:10,908 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-18 02:23:10,909 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-18 02:23:10,909 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:23:10,910 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:23:10,910 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:23:10,911 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:23:10,911 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:23:10,912 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:23:10,912 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:23:10,912 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:23:10,913 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-18 02:23:10,913 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: b87ceab8-fb58-4e21-b331-114858771665
2025-09-18 02:23:10,917 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.confidence_feedback'
2025-09-18 02:23:17,597 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-18 02:23:17,598 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-18 02:23:17,598 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:23:17,599 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:23:17,599 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:23:17,600 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:23:17,600 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:23:17,602 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:23:17,602 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-18 02:23:17,603 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-18 02:23:17,603 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-18 02:23:17,603 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: b87ceab8-fb58-4e21-b331-114858771665
2025-09-18 02:23:17,609 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.confidence_feedback'
2025-09-21 05:12:56,283 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-21 05:12:57,481 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-21 06:02:27,751 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-21 06:02:27,753 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-21 06:02:27,753 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 06:02:27,784 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 06:02:27,784 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 06:02:27,785 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 06:02:27,785 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 06:02:27,786 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 06:02:27,786 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 06:02:27,787 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 06:02:27,787 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-21 06:02:27,787 | DEBUG | hackthon_support_agent.QuestionService | Generating questions for project_id: c8541d04-ae24-4f56-abc6-24c1788558e9 with idea_prompt: プロジェクトタイトル: ハッカソン支援エージェント
プロジェクトアイディア: ハッカソンを支援するためのエージェント
期間: 2025-09-21 〜 2025-09-27 15:01
人数: 4
2025-09-21 06:02:27,787 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-09-21 06:02:34,557 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-21 06:02:34,558 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-21 06:02:34,558 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 06:02:34,559 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 06:02:34,559 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 06:02:34,560 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 06:02:34,560 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 06:02:34,561 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 06:02:34,561 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 06:02:34,563 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 06:02:34,563 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-21 06:02:40,619 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-21 06:02:40,620 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-21 06:02:40,620 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 06:02:40,624 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 06:02:40,624 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 06:02:40,625 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 06:02:40,625 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 06:02:40,626 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 06:02:40,626 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 06:02:40,627 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 06:02:40,627 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-21 06:02:40,628 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.generate_summary_document'
2025-09-21 06:02:46,903 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-21 06:02:46,904 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-21 06:02:46,905 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 06:02:46,906 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 06:02:46,906 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 06:02:46,906 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 06:02:46,907 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 06:02:46,908 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 06:02:46,908 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 06:02:46,908 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 06:02:46,909 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-21 06:02:50,909 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-21 06:02:50,911 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-21 06:02:50,911 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 06:02:50,916 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 06:02:50,916 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 06:02:50,917 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 06:02:50,917 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 06:02:50,918 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 06:02:50,918 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 06:02:51,018 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 06:02:51,019 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-21 06:02:51,022 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-21 06:02:51,022 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-21 06:02:51,025 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-21 06:02:51,025 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 06:02:51,026 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 06:02:51,027 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 06:02:51,027 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 06:02:51,028 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 06:02:51,028 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 06:02:51,028 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 06:02:51,029 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 06:02:51,029 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-21 06:02:51,032 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-21 06:02:52,344 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-21 06:02:52,345 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-21 06:02:52,346 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 06:02:52,347 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 06:02:52,347 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 06:02:52,347 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 06:02:52,348 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 06:02:52,349 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 06:02:52,349 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 06:02:52,349 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 06:02:52,349 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-21 06:02:52,349 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: c8541d04-ae24-4f56-abc6-24c1788558e9
2025-09-21 06:02:52,351 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.confidence_feedback'
2025-09-21 06:02:52,351 | ERROR | hackthon_support_agent.SummaryService | Prompt 'confidence_feedback' not found under service 'summary_service' in prompts.toml
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/base_service.py", line 148, in get_prompt
    prompt = self.prompts[service_name][prompt_name]
             ~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^
KeyError: 'confidence_feedback'
2025-09-21 06:02:52,352 | ERROR | hackthon_support_agent.SummaryService | Failed to get prompt: Prompt 'confidence_feedback' not found in service 'summary_service' in prompts.toml
2025-09-21 06:02:53,784 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-21 06:02:53,785 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-21 06:02:53,785 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 06:02:53,786 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 06:02:53,786 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 06:02:53,787 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 06:02:53,787 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 06:02:53,788 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 06:02:53,788 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 06:02:53,789 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 06:02:53,789 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-21 06:02:53,789 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: c8541d04-ae24-4f56-abc6-24c1788558e9
2025-09-21 06:02:53,791 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.confidence_feedback'
2025-09-21 06:02:53,791 | ERROR | hackthon_support_agent.SummaryService | Prompt 'confidence_feedback' not found under service 'summary_service' in prompts.toml
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/base_service.py", line 148, in get_prompt
    prompt = self.prompts[service_name][prompt_name]
             ~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^
KeyError: 'confidence_feedback'
2025-09-21 06:02:53,792 | ERROR | hackthon_support_agent.SummaryService | Failed to get prompt: Prompt 'confidence_feedback' not found in service 'summary_service' in prompts.toml
2025-09-21 06:03:06,677 | DEBUG | hackthon_support_agent.FunctionService | Initializing BaseService (provider=google)
2025-09-21 06:03:06,678 | INFO | hackthon_support_agent.FunctionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-21 06:03:06,678 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 06:03:06,679 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 06:03:06,680 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 06:03:06,681 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 06:03:06,681 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 06:03:06,682 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 06:03:06,682 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 06:03:06,683 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 06:03:06,683 | DEBUG | hackthon_support_agent.FunctionService | LLMs initialized
2025-09-21 06:03:06,683 | DEBUG | hackthon_support_agent.FunctionService | Generating functional requirements for project_id: c8541d04-ae24-4f56-abc6-24c1788558e9
2025-09-21 06:03:06,685 | DEBUG | hackthon_support_agent.FunctionService | Fetching prompt 'function_service.generate_functional_requirements'
2025-09-21 06:03:06,900 | DEBUG | hackthon_support_agent.FunctionService | Initializing BaseService (provider=google)
2025-09-21 06:03:06,901 | INFO | hackthon_support_agent.FunctionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-21 06:03:06,901 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 06:03:06,902 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 06:03:06,902 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 06:03:06,903 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 06:03:06,903 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 06:03:06,904 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 06:03:06,904 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 06:03:06,905 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 06:03:06,905 | DEBUG | hackthon_support_agent.FunctionService | LLMs initialized
2025-09-21 06:03:06,905 | DEBUG | hackthon_support_agent.FunctionService | Generating functional requirements for project_id: c8541d04-ae24-4f56-abc6-24c1788558e9
2025-09-21 06:03:06,909 | DEBUG | hackthon_support_agent.FunctionService | Fetching prompt 'function_service.generate_functional_requirements'
2025-09-21 06:03:13,551 | DEBUG | hackthon_support_agent.FunctionService | Generating clarification questions for 3 low-confidence requirements
2025-09-21 06:03:13,551 | DEBUG | hackthon_support_agent.FunctionService | Fetching prompt 'function_service.generate_clarification_questions'
2025-09-21 06:03:15,024 | DEBUG | hackthon_support_agent.FunctionService | Saving functional requirements to project document: c8541d04-ae24-4f56-abc6-24c1788558e9
2025-09-21 06:03:15,029 | DEBUG | hackthon_support_agent.FunctionService | Saving 3 clarification questions to database
2025-09-21 06:03:18,971 | DEBUG | hackthon_support_agent.FunctionService | Generating clarification questions for 3 low-confidence requirements
2025-09-21 06:03:18,971 | DEBUG | hackthon_support_agent.FunctionService | Fetching prompt 'function_service.generate_clarification_questions'
2025-09-21 06:03:20,590 | DEBUG | hackthon_support_agent.FunctionService | Saving functional requirements to project document: c8541d04-ae24-4f56-abc6-24c1788558e9
2025-09-21 06:03:20,594 | DEBUG | hackthon_support_agent.FunctionService | Saving 3 clarification questions to database
2025-09-21 06:05:09,233 | DEBUG | hackthon_support_agent.FunctionService | Initializing BaseService (provider=google)
2025-09-21 06:05:09,234 | INFO | hackthon_support_agent.FunctionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-21 06:05:09,234 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 06:05:09,235 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 06:05:09,235 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 06:05:09,236 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 06:05:09,236 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 06:05:09,237 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 06:05:09,237 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 06:05:09,238 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 06:05:09,238 | DEBUG | hackthon_support_agent.FunctionService | LLMs initialized
2025-09-21 06:05:09,238 | DEBUG | hackthon_support_agent.FunctionService | Generating functional requirements for project_id: c8541d04-ae24-4f56-abc6-24c1788558e9
2025-09-21 06:05:09,242 | DEBUG | hackthon_support_agent.FunctionService | Fetching prompt 'function_service.generate_functional_requirements'
2025-09-21 06:05:16,306 | DEBUG | hackthon_support_agent.FunctionService | Generating clarification questions for 2 low-confidence requirements
2025-09-21 06:05:16,306 | DEBUG | hackthon_support_agent.FunctionService | Fetching prompt 'function_service.generate_clarification_questions'
2025-09-21 06:05:18,024 | DEBUG | hackthon_support_agent.FunctionService | Saving functional requirements to project document: c8541d04-ae24-4f56-abc6-24c1788558e9
2025-09-21 06:05:18,028 | DEBUG | hackthon_support_agent.FunctionService | Saving 5 clarification questions to database
2025-09-21 06:08:37,926 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-21 06:08:39,180 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-21 06:09:05,770 | DEBUG | hackthon_support_agent.FrameworkService | Initializing BaseService (provider=google)
2025-09-21 06:09:05,771 | INFO | hackthon_support_agent.FrameworkService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-21 06:09:05,772 | DEBUG | hackthon_support_agent.FrameworkService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 06:09:05,783 | INFO | hackthon_support_agent.FrameworkService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 06:09:05,783 | DEBUG | hackthon_support_agent.FrameworkService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 06:09:05,784 | INFO | hackthon_support_agent.FrameworkService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 06:09:05,785 | DEBUG | hackthon_support_agent.FrameworkService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 06:09:05,785 | INFO | hackthon_support_agent.FrameworkService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 06:09:05,786 | DEBUG | hackthon_support_agent.FrameworkService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 06:09:05,786 | INFO | hackthon_support_agent.FrameworkService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 06:09:05,786 | DEBUG | hackthon_support_agent.FrameworkService | LLMs initialized
2025-09-21 06:09:05,787 | DEBUG | hackthon_support_agent.FrameworkService | Fetching prompt 'framework_service.generate_simple_recommendations'
2025-09-21 06:13:27,686 | DEBUG | hackthon_support_agent.FrameworkService | Initializing BaseService (provider=google)
2025-09-21 06:13:27,687 | INFO | hackthon_support_agent.FrameworkService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-21 06:13:27,688 | DEBUG | hackthon_support_agent.FrameworkService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 06:13:27,695 | INFO | hackthon_support_agent.FrameworkService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 06:13:27,695 | DEBUG | hackthon_support_agent.FrameworkService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 06:13:27,697 | INFO | hackthon_support_agent.FrameworkService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 06:13:27,698 | DEBUG | hackthon_support_agent.FrameworkService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 06:13:27,698 | INFO | hackthon_support_agent.FrameworkService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 06:13:27,698 | DEBUG | hackthon_support_agent.FrameworkService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 06:13:27,700 | INFO | hackthon_support_agent.FrameworkService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 06:13:27,700 | DEBUG | hackthon_support_agent.FrameworkService | LLMs initialized
2025-09-21 06:13:27,700 | DEBUG | hackthon_support_agent.FrameworkService | Fetching prompt 'framework_service.generate_simple_recommendations'
2025-09-21 06:17:17,950 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-21 06:39:48,409 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-21 06:39:58,698 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-21 06:40:04,927 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-21 06:40:08,095 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-21 06:43:59,504 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-21 06:43:59,701 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-21 06:43:59,702 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-21 06:43:59,703 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 06:43:59,715 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-21 06:43:59,716 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-21 06:43:59,718 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 06:43:59,741 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 06:43:59,741 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 06:43:59,741 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 06:43:59,741 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 06:43:59,743 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 06:43:59,744 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 06:43:59,745 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 06:43:59,746 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 06:43:59,746 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 06:43:59,747 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 06:43:59,748 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 06:43:59,749 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 06:43:59,749 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 06:43:59,750 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-21 06:43:59,755 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-21 06:43:59,755 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 06:43:59,756 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-21 06:43:59,760 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-21 06:44:04,172 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-21 06:44:04,173 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-21 06:44:04,173 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 06:44:04,174 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 06:44:04,175 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 06:44:04,175 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 06:44:04,175 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 06:44:04,176 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 06:44:04,177 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 06:44:04,177 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 06:44:04,178 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-21 06:44:04,178 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: c8541d04-ae24-4f56-abc6-24c1788558e9
2025-09-21 06:44:04,182 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.confidence_feedback'
2025-09-21 06:44:04,182 | ERROR | hackthon_support_agent.SummaryService | Prompt 'confidence_feedback' not found under service 'summary_service' in prompts.toml
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/base_service.py", line 148, in get_prompt
    prompt = self.prompts[service_name][prompt_name]
             ~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^
KeyError: 'confidence_feedback'
2025-09-21 06:44:04,182 | ERROR | hackthon_support_agent.SummaryService | Failed to get prompt: Prompt 'confidence_feedback' not found in service 'summary_service' in prompts.toml
2025-09-21 06:44:05,254 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-21 06:44:05,255 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-21 06:44:05,255 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 06:44:05,256 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 06:44:05,257 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 06:44:05,257 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 06:44:05,257 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 06:44:05,258 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 06:44:05,258 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 06:44:05,259 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 06:44:05,259 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-21 06:44:05,259 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: c8541d04-ae24-4f56-abc6-24c1788558e9
2025-09-21 06:44:05,262 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.confidence_feedback'
2025-09-21 06:44:05,262 | ERROR | hackthon_support_agent.SummaryService | Prompt 'confidence_feedback' not found under service 'summary_service' in prompts.toml
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/base_service.py", line 148, in get_prompt
    prompt = self.prompts[service_name][prompt_name]
             ~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^
KeyError: 'confidence_feedback'
2025-09-21 06:44:05,263 | ERROR | hackthon_support_agent.SummaryService | Failed to get prompt: Prompt 'confidence_feedback' not found in service 'summary_service' in prompts.toml
2025-09-21 06:45:27,109 | DEBUG | hackthon_support_agent.FrameworkService | Initializing BaseService (provider=google)
2025-09-21 06:45:27,110 | INFO | hackthon_support_agent.FrameworkService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-21 06:45:27,110 | DEBUG | hackthon_support_agent.FrameworkService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 06:45:27,111 | INFO | hackthon_support_agent.FrameworkService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 06:45:27,112 | DEBUG | hackthon_support_agent.FrameworkService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 06:45:27,112 | INFO | hackthon_support_agent.FrameworkService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 06:45:27,112 | DEBUG | hackthon_support_agent.FrameworkService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 06:45:27,113 | INFO | hackthon_support_agent.FrameworkService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 06:45:27,113 | DEBUG | hackthon_support_agent.FrameworkService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 06:45:27,114 | INFO | hackthon_support_agent.FrameworkService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 06:45:27,114 | DEBUG | hackthon_support_agent.FrameworkService | LLMs initialized
2025-09-21 06:45:27,114 | DEBUG | hackthon_support_agent.FrameworkService | Fetching prompt 'framework_service.generate_simple_recommendations'
2025-09-21 07:06:20,602 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-21 07:06:20,604 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-21 07:06:20,604 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:06:20,606 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:06:20,607 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:06:20,608 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:06:20,608 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:06:20,608 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:06:20,608 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:06:20,609 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:06:20,609 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-21 07:06:20,609 | DEBUG | hackthon_support_agent.QuestionService | Generating questions for project_id: 6a8a5a83-a250-454c-9a9e-03d6b9d3aad1 with idea_prompt: プロジェクトタイトル: AI
プロジェクトアイディア: ハッカソン支援エージェント
期間: 2025-09-21 〜 2025-09-21 16:06
人数: 3
2025-09-21 07:06:20,610 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-09-21 07:06:24,250 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-21 07:06:24,250 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-21 07:06:24,251 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:06:24,252 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:06:24,252 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:06:24,252 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:06:24,253 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:06:24,253 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:06:24,254 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:06:24,254 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:06:24,254 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-21 07:06:29,630 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-21 07:06:29,631 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-21 07:06:29,631 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:06:29,632 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:06:29,632 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:06:29,633 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:06:29,633 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:06:29,634 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:06:29,634 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:06:29,635 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:06:29,635 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-21 07:06:29,636 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.generate_summary_document'
2025-09-21 07:06:34,120 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-21 07:06:34,121 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-21 07:06:34,121 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:06:34,122 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:06:34,122 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:06:34,123 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:06:34,123 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:06:34,124 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:06:34,124 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:06:34,125 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:06:34,125 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-21 07:06:34,361 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-21 07:06:34,365 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-21 07:06:34,366 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-21 07:06:34,366 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:06:34,370 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-21 07:06:34,371 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:06:34,371 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:06:34,371 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:06:34,373 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:06:34,375 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:06:34,375 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:06:34,375 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:06:34,377 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:06:34,379 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:06:34,380 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:06:34,381 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:06:34,382 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:06:34,384 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:06:34,384 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:06:34,384 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-21 07:06:34,391 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-21 07:06:34,394 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:06:34,394 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-21 07:06:34,399 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-21 07:06:35,973 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-21 07:06:35,974 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-21 07:06:35,974 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:06:35,976 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:06:35,976 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:06:35,976 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:06:35,977 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:06:35,977 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:06:35,978 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:06:35,978 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:06:35,979 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-21 07:06:35,979 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: 6a8a5a83-a250-454c-9a9e-03d6b9d3aad1
2025-09-21 07:06:35,980 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.confidence_feedback'
2025-09-21 07:06:35,981 | ERROR | hackthon_support_agent.SummaryService | Prompt 'confidence_feedback' not found under service 'summary_service' in prompts.toml
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/base_service.py", line 148, in get_prompt
    prompt = self.prompts[service_name][prompt_name]
             ~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^
KeyError: 'confidence_feedback'
2025-09-21 07:06:35,981 | ERROR | hackthon_support_agent.SummaryService | Failed to get prompt: Prompt 'confidence_feedback' not found in service 'summary_service' in prompts.toml
2025-09-21 07:06:36,251 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-21 07:06:36,252 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-21 07:06:36,252 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:06:36,253 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:06:36,253 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:06:36,254 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:06:36,254 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:06:36,255 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:06:36,255 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:06:36,256 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:06:36,256 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-21 07:06:36,256 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: 6a8a5a83-a250-454c-9a9e-03d6b9d3aad1
2025-09-21 07:06:36,258 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.confidence_feedback'
2025-09-21 07:06:36,258 | ERROR | hackthon_support_agent.SummaryService | Prompt 'confidence_feedback' not found under service 'summary_service' in prompts.toml
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/base_service.py", line 148, in get_prompt
    prompt = self.prompts[service_name][prompt_name]
             ~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^
KeyError: 'confidence_feedback'
2025-09-21 07:06:36,258 | ERROR | hackthon_support_agent.SummaryService | Failed to get prompt: Prompt 'confidence_feedback' not found in service 'summary_service' in prompts.toml
2025-09-21 07:06:48,840 | DEBUG | hackthon_support_agent.FunctionService | Initializing BaseService (provider=google)
2025-09-21 07:06:48,841 | INFO | hackthon_support_agent.FunctionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-21 07:06:48,841 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:06:48,842 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:06:48,842 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:06:48,843 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:06:48,843 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:06:48,844 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:06:48,844 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:06:48,845 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:06:48,845 | DEBUG | hackthon_support_agent.FunctionService | LLMs initialized
2025-09-21 07:06:48,845 | DEBUG | hackthon_support_agent.FunctionService | Generating functional requirements for project_id: 6a8a5a83-a250-454c-9a9e-03d6b9d3aad1
2025-09-21 07:06:48,847 | DEBUG | hackthon_support_agent.FunctionService | Fetching prompt 'function_service.generate_functional_requirements'
2025-09-21 07:06:49,276 | DEBUG | hackthon_support_agent.FunctionService | Initializing BaseService (provider=google)
2025-09-21 07:06:49,277 | INFO | hackthon_support_agent.FunctionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-21 07:06:49,277 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:06:49,278 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:06:49,278 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:06:49,280 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:06:49,280 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:06:49,281 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:06:49,281 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:06:49,282 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:06:49,282 | DEBUG | hackthon_support_agent.FunctionService | LLMs initialized
2025-09-21 07:06:49,282 | DEBUG | hackthon_support_agent.FunctionService | Generating functional requirements for project_id: 6a8a5a83-a250-454c-9a9e-03d6b9d3aad1
2025-09-21 07:06:49,284 | DEBUG | hackthon_support_agent.FunctionService | Fetching prompt 'function_service.generate_functional_requirements'
2025-09-21 07:06:55,420 | DEBUG | hackthon_support_agent.FunctionService | Generating clarification questions for 2 low-confidence requirements
2025-09-21 07:06:55,420 | DEBUG | hackthon_support_agent.FunctionService | Fetching prompt 'function_service.generate_clarification_questions'
2025-09-21 07:06:56,758 | DEBUG | hackthon_support_agent.FunctionService | Saving functional requirements to project document: 6a8a5a83-a250-454c-9a9e-03d6b9d3aad1
2025-09-21 07:06:56,804 | DEBUG | hackthon_support_agent.FunctionService | Saving 3 clarification questions to database
2025-09-21 07:06:56,814 | DEBUG | hackthon_support_agent.FunctionService | Generating clarification questions for 2 low-confidence requirements
2025-09-21 07:06:56,815 | DEBUG | hackthon_support_agent.FunctionService | Fetching prompt 'function_service.generate_clarification_questions'
2025-09-21 07:06:58,879 | DEBUG | hackthon_support_agent.FunctionService | Saving functional requirements to project document: 6a8a5a83-a250-454c-9a9e-03d6b9d3aad1
2025-09-21 07:06:58,884 | DEBUG | hackthon_support_agent.FunctionService | Saving 5 clarification questions to database
2025-09-21 07:07:06,056 | DEBUG | hackthon_support_agent.FrameworkService | Initializing BaseService (provider=google)
2025-09-21 07:07:06,057 | INFO | hackthon_support_agent.FrameworkService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-21 07:07:06,057 | DEBUG | hackthon_support_agent.FrameworkService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:07:06,058 | INFO | hackthon_support_agent.FrameworkService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:07:06,058 | DEBUG | hackthon_support_agent.FrameworkService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:07:06,059 | INFO | hackthon_support_agent.FrameworkService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:07:06,060 | DEBUG | hackthon_support_agent.FrameworkService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:07:06,060 | INFO | hackthon_support_agent.FrameworkService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:07:06,060 | DEBUG | hackthon_support_agent.FrameworkService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:07:06,061 | INFO | hackthon_support_agent.FrameworkService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:07:06,061 | DEBUG | hackthon_support_agent.FrameworkService | LLMs initialized
2025-09-21 07:07:06,061 | DEBUG | hackthon_support_agent.FrameworkService | Fetching prompt 'framework_service.generate_simple_recommendations'
2025-09-21 07:08:31,414 | DEBUG | hackthon_support_agent.FrameworkService | Initializing BaseService (provider=google)
2025-09-21 07:08:31,415 | INFO | hackthon_support_agent.FrameworkService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-21 07:08:31,415 | DEBUG | hackthon_support_agent.FrameworkService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:08:31,416 | INFO | hackthon_support_agent.FrameworkService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:08:31,416 | DEBUG | hackthon_support_agent.FrameworkService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:08:31,417 | INFO | hackthon_support_agent.FrameworkService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:08:31,417 | DEBUG | hackthon_support_agent.FrameworkService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:08:31,418 | INFO | hackthon_support_agent.FrameworkService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:08:31,418 | DEBUG | hackthon_support_agent.FrameworkService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:08:31,419 | INFO | hackthon_support_agent.FrameworkService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:08:31,419 | DEBUG | hackthon_support_agent.FrameworkService | LLMs initialized
2025-09-21 07:08:31,419 | DEBUG | hackthon_support_agent.FrameworkService | Fetching prompt 'framework_service.generate_simple_recommendations'
2025-09-21 07:09:03,132 | DEBUG | hackthon_support_agent.FrameworkService | Initializing BaseService (provider=google)
2025-09-21 07:09:03,133 | INFO | hackthon_support_agent.FrameworkService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-21 07:09:03,133 | DEBUG | hackthon_support_agent.FrameworkService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:09:03,134 | INFO | hackthon_support_agent.FrameworkService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:09:03,134 | DEBUG | hackthon_support_agent.FrameworkService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:09:03,136 | INFO | hackthon_support_agent.FrameworkService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:09:03,136 | DEBUG | hackthon_support_agent.FrameworkService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:09:03,137 | INFO | hackthon_support_agent.FrameworkService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:09:03,137 | DEBUG | hackthon_support_agent.FrameworkService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:09:03,137 | INFO | hackthon_support_agent.FrameworkService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:09:03,137 | DEBUG | hackthon_support_agent.FrameworkService | LLMs initialized
2025-09-21 07:09:03,138 | DEBUG | hackthon_support_agent.FrameworkService | Fetching prompt 'framework_service.generate_simple_recommendations'
2025-09-21 07:20:45,115 | DEBUG | hackthon_support_agent.FrameworkService | Initializing BaseService (provider=google)
2025-09-21 07:20:45,116 | INFO | hackthon_support_agent.FrameworkService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-21 07:20:45,117 | DEBUG | hackthon_support_agent.FrameworkService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:20:45,119 | INFO | hackthon_support_agent.FrameworkService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:20:45,119 | DEBUG | hackthon_support_agent.FrameworkService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:20:45,120 | INFO | hackthon_support_agent.FrameworkService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:20:45,120 | DEBUG | hackthon_support_agent.FrameworkService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:20:45,121 | INFO | hackthon_support_agent.FrameworkService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:20:45,121 | DEBUG | hackthon_support_agent.FrameworkService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:20:45,122 | INFO | hackthon_support_agent.FrameworkService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:20:45,122 | DEBUG | hackthon_support_agent.FrameworkService | LLMs initialized
2025-09-21 07:20:45,122 | DEBUG | hackthon_support_agent.FrameworkService | Fetching prompt 'framework_service.generate_simple_recommendations'
2025-09-21 07:21:36,936 | DEBUG | hackthon_support_agent.TechnologyService | Initializing BaseService (provider=google)
2025-09-21 07:21:36,938 | INFO | hackthon_support_agent.TechnologyService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-21 07:21:36,938 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:21:36,939 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:21:36,939 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:21:36,940 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:21:36,941 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:21:36,942 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:21:36,942 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:21:36,943 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:21:36,943 | DEBUG | hackthon_support_agent.TechnologyService | LLMs initialized
2025-09-21 07:21:36,943 | DEBUG | hackthon_support_agent.TechnologyService | Fetching prompt 'technology_service.generate_technology_document'
2025-09-21 07:21:36,943 | ERROR | hackthon_support_agent.TechnologyService | Prompt 'generate_technology_document' not found under service 'technology_service' in prompts.toml
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/base_service.py", line 148, in get_prompt
    prompt = self.prompts[service_name][prompt_name]
             ~~~~~~~~~~~~^^^^^^^^^^^^^^
KeyError: 'technology_service'
2025-09-21 07:21:36,948 | DEBUG | hackthon_support_agent.TechnologyService | Initializing BaseService (provider=google)
2025-09-21 07:21:36,949 | INFO | hackthon_support_agent.TechnologyService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-21 07:21:36,949 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:21:36,950 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:21:36,950 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:21:36,951 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:21:36,951 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:21:36,952 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:21:36,952 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:21:36,953 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:21:36,953 | DEBUG | hackthon_support_agent.TechnologyService | LLMs initialized
2025-09-21 07:21:36,954 | DEBUG | hackthon_support_agent.TechnologyService | Fetching prompt 'technology_service.generate_technology_document'
2025-09-21 07:21:36,954 | ERROR | hackthon_support_agent.TechnologyService | Prompt 'generate_technology_document' not found under service 'technology_service' in prompts.toml
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/base_service.py", line 148, in get_prompt
    prompt = self.prompts[service_name][prompt_name]
             ~~~~~~~~~~~~^^^^^^^^^^^^^^
KeyError: 'technology_service'
2025-09-21 07:24:50,788 | DEBUG | hackthon_support_agent.TechnologyService | Initializing BaseService (provider=google)
2025-09-21 07:24:50,789 | INFO | hackthon_support_agent.TechnologyService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-21 07:24:50,789 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:24:50,790 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:24:50,790 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:24:50,792 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:24:50,792 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:24:50,792 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:24:50,793 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:24:50,793 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:24:50,793 | DEBUG | hackthon_support_agent.TechnologyService | LLMs initialized
2025-09-21 07:24:50,794 | DEBUG | hackthon_support_agent.TechnologyService | Fetching prompt 'technology_service.generate_technology_document'
2025-09-21 07:24:51,211 | DEBUG | hackthon_support_agent.TechnologyService | Initializing BaseService (provider=google)
2025-09-21 07:24:51,212 | INFO | hackthon_support_agent.TechnologyService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-21 07:24:51,213 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:24:51,215 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:24:51,215 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:24:51,216 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:24:51,216 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:24:51,217 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:24:51,217 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:24:51,218 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:24:51,218 | DEBUG | hackthon_support_agent.TechnologyService | LLMs initialized
2025-09-21 07:24:51,218 | DEBUG | hackthon_support_agent.TechnologyService | Fetching prompt 'technology_service.generate_technology_document'
2025-09-21 07:37:04,664 | DEBUG | hackthon_support_agent.TechnologyService | Initializing BaseService (provider=google)
2025-09-21 07:37:04,667 | INFO | hackthon_support_agent.TechnologyService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-21 07:37:04,667 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:37:04,669 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:37:04,669 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:37:04,670 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:37:04,671 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:37:04,671 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:37:04,672 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:37:04,672 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:37:04,672 | DEBUG | hackthon_support_agent.TechnologyService | LLMs initialized
2025-09-21 07:37:04,673 | DEBUG | hackthon_support_agent.TechnologyService | Fetching prompt 'technology_service.generate_technology_document'
2025-09-21 07:37:05,081 | DEBUG | hackthon_support_agent.TechnologyService | Initializing BaseService (provider=google)
2025-09-21 07:37:05,082 | INFO | hackthon_support_agent.TechnologyService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-21 07:37:05,082 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:37:05,083 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:37:05,083 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:37:05,084 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:37:05,084 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:37:05,085 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:37:05,085 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:37:05,085 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:37:05,085 | DEBUG | hackthon_support_agent.TechnologyService | LLMs initialized
2025-09-21 07:37:05,086 | DEBUG | hackthon_support_agent.TechnologyService | Fetching prompt 'technology_service.generate_technology_document'
2025-09-21 07:38:02,554 | DEBUG | hackthon_support_agent.TechnologyService | Initializing BaseService (provider=google)
2025-09-21 07:38:02,555 | INFO | hackthon_support_agent.TechnologyService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-21 07:38:02,555 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:38:02,556 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:38:02,556 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:38:02,557 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:38:02,557 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:38:02,558 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:38:02,558 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:38:02,559 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:38:02,559 | DEBUG | hackthon_support_agent.TechnologyService | LLMs initialized
2025-09-21 07:38:02,559 | DEBUG | hackthon_support_agent.TechnologyService | Fetching prompt 'technology_service.generate_technology_document'
2025-09-21 07:39:57,122 | DEBUG | hackthon_support_agent.TechnologyService | Initializing BaseService (provider=google)
2025-09-21 07:39:57,123 | INFO | hackthon_support_agent.TechnologyService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-21 07:39:57,123 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:39:57,126 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:39:57,127 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:39:57,128 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:39:57,128 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:39:57,129 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:39:57,129 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:39:57,130 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:39:57,130 | DEBUG | hackthon_support_agent.TechnologyService | LLMs initialized
2025-09-21 07:39:57,130 | DEBUG | hackthon_support_agent.TechnologyService | Fetching prompt 'technology_service.generate_technology_document'
2025-09-21 07:43:48,096 | DEBUG | hackthon_support_agent.TechnologyService | Initializing BaseService (provider=google)
2025-09-21 07:43:48,098 | INFO | hackthon_support_agent.TechnologyService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-21 07:43:48,098 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:43:48,099 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:43:48,099 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:43:48,100 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:43:48,100 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:43:48,101 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:43:48,101 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:43:48,101 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:43:48,102 | DEBUG | hackthon_support_agent.TechnologyService | LLMs initialized
2025-09-21 07:43:48,102 | DEBUG | hackthon_support_agent.TechnologyService | Fetching prompt 'technology_service.generate_technology_document'
2025-09-21 07:45:59,094 | DEBUG | hackthon_support_agent.TechnologyService | Initializing BaseService (provider=google)
2025-09-21 07:45:59,095 | INFO | hackthon_support_agent.TechnologyService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-21 07:45:59,095 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:45:59,097 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:45:59,097 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:45:59,098 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:45:59,098 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:45:59,099 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:45:59,099 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:45:59,100 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:45:59,100 | DEBUG | hackthon_support_agent.TechnologyService | LLMs initialized
2025-09-21 07:45:59,100 | DEBUG | hackthon_support_agent.TechnologyService | Fetching prompt 'technology_service.generate_technology_document'
2025-09-21 07:46:35,826 | DEBUG | hackthon_support_agent.TechnologyService | Initializing BaseService (provider=google)
2025-09-21 07:46:35,827 | INFO | hackthon_support_agent.TechnologyService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-21 07:46:35,828 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:46:35,829 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:46:35,829 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:46:35,830 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:46:35,830 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:46:35,831 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:46:35,831 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:46:35,832 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:46:35,832 | DEBUG | hackthon_support_agent.TechnologyService | LLMs initialized
2025-09-21 07:46:35,832 | DEBUG | hackthon_support_agent.TechnologyService | Fetching prompt 'technology_service.generate_technology_document'
2025-09-21 07:57:23,001 | DEBUG | hackthon_support_agent.TechnologyService | Initializing BaseService (provider=google)
2025-09-21 07:57:23,003 | INFO | hackthon_support_agent.TechnologyService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-21 07:57:23,003 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:57:23,008 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:57:23,008 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:57:23,009 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:57:23,010 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:57:23,010 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:57:23,010 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 07:57:23,011 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 07:57:23,011 | DEBUG | hackthon_support_agent.TechnologyService | LLMs initialized
2025-09-21 07:57:23,011 | DEBUG | hackthon_support_agent.TechnologyService | Fetching prompt 'technology_service.generate_technology_document'
2025-09-21 08:31:54,431 | DEBUG | hackthon_support_agent.TechnologyService | Initializing BaseService (provider=google)
2025-09-21 08:31:54,433 | INFO | hackthon_support_agent.TechnologyService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-21 08:31:54,433 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 08:31:54,435 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 08:31:54,435 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 08:31:54,436 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 08:31:54,436 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 08:31:54,437 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 08:31:54,437 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 08:31:54,440 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 08:31:54,440 | DEBUG | hackthon_support_agent.TechnologyService | LLMs initialized
2025-09-21 08:31:54,440 | DEBUG | hackthon_support_agent.TechnologyService | Fetching prompt 'technology_service.generate_technology_document'
2025-09-21 08:37:51,334 | DEBUG | hackthon_support_agent.TechnologyService | Initializing BaseService (provider=google)
2025-09-21 08:37:51,336 | INFO | hackthon_support_agent.TechnologyService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-21 08:37:51,337 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 08:37:51,338 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 08:37:51,339 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 08:37:51,340 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 08:37:51,340 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 08:37:51,341 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 08:37:51,341 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 08:37:51,342 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 08:37:51,342 | DEBUG | hackthon_support_agent.TechnologyService | LLMs initialized
2025-09-21 08:37:51,342 | DEBUG | hackthon_support_agent.TechnologyService | Fetching prompt 'technology_service.generate_technology_document'
2025-09-21 08:41:46,536 | DEBUG | hackthon_support_agent.TechnologyService | Initializing BaseService (provider=google)
2025-09-21 08:41:46,537 | INFO | hackthon_support_agent.TechnologyService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-21 08:41:46,537 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 08:41:46,539 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 08:41:46,539 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 08:41:46,540 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 08:41:46,540 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 08:41:46,541 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 08:41:46,541 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 08:41:46,542 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 08:41:46,542 | DEBUG | hackthon_support_agent.TechnologyService | LLMs initialized
2025-09-21 08:41:46,542 | DEBUG | hackthon_support_agent.TechnologyService | Fetching prompt 'technology_service.generate_technology_document'
2025-09-21 08:42:06,441 | DEBUG | hackthon_support_agent.TechnologyService | Initializing BaseService (provider=google)
2025-09-21 08:42:06,442 | INFO | hackthon_support_agent.TechnologyService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-21 08:42:06,442 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 08:42:06,443 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 08:42:06,443 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 08:42:06,444 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 08:42:06,444 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 08:42:06,445 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 08:42:06,445 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 08:42:06,445 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 08:42:06,446 | DEBUG | hackthon_support_agent.TechnologyService | LLMs initialized
2025-09-21 08:42:06,446 | DEBUG | hackthon_support_agent.TechnologyService | Fetching prompt 'technology_service.generate_technology_document'
2025-09-21 08:48:42,767 | DEBUG | hackthon_support_agent.TechnologyService | Initializing BaseService (provider=google)
2025-09-21 08:48:42,768 | INFO | hackthon_support_agent.TechnologyService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-21 08:48:42,768 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 08:48:42,769 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 08:48:42,770 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 08:48:42,770 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 08:48:42,770 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 08:48:42,771 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 08:48:42,771 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 08:48:42,772 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 08:48:42,772 | DEBUG | hackthon_support_agent.TechnologyService | LLMs initialized
2025-09-21 08:48:42,772 | DEBUG | hackthon_support_agent.TechnologyService | Fetching prompt 'technology_service.generate_technology_document'
2025-09-21 08:48:52,868 | DEBUG | hackthon_support_agent.TechnologyService | Initializing BaseService (provider=google)
2025-09-21 08:48:52,869 | INFO | hackthon_support_agent.TechnologyService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-21 08:48:52,869 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 08:48:52,870 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 08:48:52,870 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 08:48:52,871 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 08:48:52,871 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 08:48:52,872 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 08:48:52,872 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 08:48:52,873 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 08:48:52,873 | DEBUG | hackthon_support_agent.TechnologyService | LLMs initialized
2025-09-21 08:48:52,873 | DEBUG | hackthon_support_agent.TechnologyService | Fetching prompt 'technology_service.generate_technology_document'
2025-09-21 08:49:05,138 | DEBUG | hackthon_support_agent.TechnologyService | Initializing BaseService (provider=google)
2025-09-21 08:49:05,139 | INFO | hackthon_support_agent.TechnologyService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-21 08:49:05,139 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 08:49:05,140 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 08:49:05,140 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 08:49:05,141 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 08:49:05,141 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 08:49:05,142 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 08:49:05,142 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 08:49:05,143 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 08:49:05,143 | DEBUG | hackthon_support_agent.TechnologyService | LLMs initialized
2025-09-21 08:49:05,143 | DEBUG | hackthon_support_agent.TechnologyService | Fetching prompt 'technology_service.generate_technology_document'
2025-09-21 09:40:51,239 | DEBUG | hackthon_support_agent.TechnologyService | Initializing BaseService (provider=google)
2025-09-21 09:40:51,241 | INFO | hackthon_support_agent.TechnologyService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-21 09:40:51,241 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 09:40:51,243 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 09:40:51,243 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 09:40:51,244 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 09:40:51,245 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 09:40:51,247 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 09:40:51,247 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 09:40:51,248 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 09:40:51,248 | DEBUG | hackthon_support_agent.TechnologyService | LLMs initialized
2025-09-21 09:40:51,248 | DEBUG | hackthon_support_agent.TechnologyService | Fetching prompt 'technology_service.generate_technology_document'
2025-09-21 09:44:29,249 | DEBUG | hackthon_support_agent.TechnologyService | Initializing BaseService (provider=google)
2025-09-21 09:44:29,250 | INFO | hackthon_support_agent.TechnologyService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-21 09:44:29,250 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 09:44:29,252 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 09:44:29,252 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 09:44:29,253 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 09:44:29,253 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 09:44:29,254 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 09:44:29,254 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 09:44:29,255 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 09:44:29,255 | DEBUG | hackthon_support_agent.TechnologyService | LLMs initialized
2025-09-21 09:44:29,255 | DEBUG | hackthon_support_agent.TechnologyService | Fetching prompt 'technology_service.generate_technology_document'
2025-09-21 12:24:30,486 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-21 12:24:46,386 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-21 14:40:59,530 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-21 14:41:00,859 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-21 14:41:15,180 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-21 14:41:16,434 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-09-21 14:41:50,870 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-21 14:41:50,871 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-21 14:41:50,872 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 14:41:50,895 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 14:41:50,896 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 14:41:50,897 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 14:41:50,897 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 14:41:50,898 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 14:41:50,898 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 14:41:50,898 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 14:41:50,898 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-21 14:41:50,898 | DEBUG | hackthon_support_agent.QuestionService | Generating questions for project_id: 3b3427a0-5ae1-409c-a72a-9843d6977645 with idea_prompt: プロジェクトタイトル: AIプロジェクト
プロジェクトアイディア: AIを活用したプロダクト
期間: 2025-09-21 〜 2025-09-21 23:41
人数: 2
2025-09-21 14:41:50,899 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-09-21 14:41:54,879 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-21 14:41:54,880 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-21 14:41:54,880 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 14:41:54,881 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 14:41:54,881 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 14:41:54,882 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 14:41:54,882 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 14:41:54,883 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 14:41:54,883 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 14:41:54,884 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 14:41:54,884 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-21 14:42:09,368 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-21 14:42:09,370 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-21 14:42:09,370 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 14:42:09,372 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 14:42:09,372 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 14:42:09,373 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 14:42:09,373 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 14:42:09,374 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 14:42:09,374 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 14:42:09,375 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 14:42:09,375 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-21 14:42:09,376 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.generate_summary_document'
2025-09-21 14:42:11,993 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-21 14:42:11,995 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-21 14:42:11,995 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 14:42:11,996 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 14:42:11,996 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 14:42:11,997 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 14:42:11,997 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 14:42:11,998 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 14:42:11,998 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 14:42:11,999 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 14:42:11,999 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-21 14:42:16,400 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-21 14:42:16,402 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-21 14:42:16,402 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 14:42:16,407 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 14:42:16,407 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 14:42:16,408 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 14:42:16,409 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 14:42:16,410 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 14:42:16,410 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-21 14:42:16,411 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 14:42:16,534 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 14:42:16,535 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-21 14:42:16,535 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-21 14:42:16,535 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 14:42:16,540 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-21 14:42:16,543 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 14:42:16,544 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 14:42:16,546 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 14:42:16,546 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 14:42:16,548 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 14:42:16,548 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 14:42:16,549 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 14:42:16,549 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-21 14:42:16,553 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-21 14:42:17,646 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-21 14:42:17,647 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-21 14:42:17,647 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 14:42:17,648 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 14:42:17,649 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 14:42:17,649 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 14:42:17,650 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 14:42:17,651 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 14:42:17,651 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 14:42:17,652 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 14:42:17,652 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-21 14:42:17,652 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: 3b3427a0-5ae1-409c-a72a-9843d6977645
2025-09-21 14:42:17,654 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.confidence_feedback'
2025-09-21 14:42:17,654 | ERROR | hackthon_support_agent.SummaryService | Prompt 'confidence_feedback' not found under service 'summary_service' in prompts.toml
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/base_service.py", line 148, in get_prompt
    prompt = self.prompts[service_name][prompt_name]
             ~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^
KeyError: 'confidence_feedback'
2025-09-21 14:42:17,655 | ERROR | hackthon_support_agent.SummaryService | Failed to get prompt: Prompt 'confidence_feedback' not found in service 'summary_service' in prompts.toml
2025-09-21 14:42:19,151 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-21 14:42:19,153 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-21 14:42:19,153 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 14:42:19,154 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 14:42:19,154 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 14:42:19,154 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 14:42:19,154 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 14:42:19,155 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 14:42:19,156 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 14:42:19,156 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 14:42:19,156 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-21 14:42:19,156 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: 3b3427a0-5ae1-409c-a72a-9843d6977645
2025-09-21 14:42:19,158 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.confidence_feedback'
2025-09-21 14:42:19,158 | ERROR | hackthon_support_agent.SummaryService | Prompt 'confidence_feedback' not found under service 'summary_service' in prompts.toml
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/base_service.py", line 148, in get_prompt
    prompt = self.prompts[service_name][prompt_name]
             ~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^
KeyError: 'confidence_feedback'
2025-09-21 14:42:19,159 | ERROR | hackthon_support_agent.SummaryService | Failed to get prompt: Prompt 'confidence_feedback' not found in service 'summary_service' in prompts.toml
2025-09-21 14:42:36,381 | DEBUG | hackthon_support_agent.FunctionService | Initializing BaseService (provider=google)
2025-09-21 14:42:36,382 | INFO | hackthon_support_agent.FunctionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-21 14:42:36,382 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 14:42:36,383 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 14:42:36,383 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 14:42:36,384 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 14:42:36,384 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 14:42:36,386 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 14:42:36,386 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 14:42:36,387 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 14:42:36,387 | DEBUG | hackthon_support_agent.FunctionService | LLMs initialized
2025-09-21 14:42:36,387 | DEBUG | hackthon_support_agent.FunctionService | Generating functional requirements for project_id: 3b3427a0-5ae1-409c-a72a-9843d6977645
2025-09-21 14:42:36,389 | DEBUG | hackthon_support_agent.FunctionService | Fetching prompt 'function_service.generate_functional_requirements'
2025-09-21 14:42:36,658 | DEBUG | hackthon_support_agent.FunctionService | Initializing BaseService (provider=google)
2025-09-21 14:42:36,659 | INFO | hackthon_support_agent.FunctionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-21 14:42:36,659 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 14:42:36,660 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 14:42:36,660 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 14:42:36,661 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 14:42:36,661 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 14:42:36,662 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 14:42:36,662 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 14:42:36,662 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 14:42:36,663 | DEBUG | hackthon_support_agent.FunctionService | LLMs initialized
2025-09-21 14:42:36,663 | DEBUG | hackthon_support_agent.FunctionService | Generating functional requirements for project_id: 3b3427a0-5ae1-409c-a72a-9843d6977645
2025-09-21 14:42:36,665 | DEBUG | hackthon_support_agent.FunctionService | Fetching prompt 'function_service.generate_functional_requirements'
2025-09-21 14:42:42,359 | DEBUG | hackthon_support_agent.FunctionService | Generating clarification questions for 3 low-confidence requirements
2025-09-21 14:42:42,360 | DEBUG | hackthon_support_agent.FunctionService | Fetching prompt 'function_service.generate_clarification_questions'
2025-09-21 14:42:43,331 | DEBUG | hackthon_support_agent.FunctionService | Generating clarification questions for 2 low-confidence requirements
2025-09-21 14:42:43,331 | DEBUG | hackthon_support_agent.FunctionService | Fetching prompt 'function_service.generate_clarification_questions'
2025-09-21 14:42:44,886 | DEBUG | hackthon_support_agent.FunctionService | Saving functional requirements to project document: 3b3427a0-5ae1-409c-a72a-9843d6977645
2025-09-21 14:42:44,892 | DEBUG | hackthon_support_agent.FunctionService | Saving 4 clarification questions to database
2025-09-21 14:42:44,908 | DEBUG | hackthon_support_agent.FunctionService | Saving functional requirements to project document: 3b3427a0-5ae1-409c-a72a-9843d6977645
2025-09-21 14:42:44,912 | DEBUG | hackthon_support_agent.FunctionService | Saving 6 clarification questions to database
2025-09-21 14:43:31,062 | DEBUG | hackthon_support_agent.FrameworkService | Initializing BaseService (provider=google)
2025-09-21 14:43:31,063 | INFO | hackthon_support_agent.FrameworkService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-21 14:43:31,064 | DEBUG | hackthon_support_agent.FrameworkService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 14:43:31,065 | INFO | hackthon_support_agent.FrameworkService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 14:43:31,065 | DEBUG | hackthon_support_agent.FrameworkService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 14:43:31,066 | INFO | hackthon_support_agent.FrameworkService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 14:43:31,066 | DEBUG | hackthon_support_agent.FrameworkService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 14:43:31,067 | INFO | hackthon_support_agent.FrameworkService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 14:43:31,067 | DEBUG | hackthon_support_agent.FrameworkService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 14:43:31,068 | INFO | hackthon_support_agent.FrameworkService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 14:43:31,068 | DEBUG | hackthon_support_agent.FrameworkService | LLMs initialized
2025-09-21 14:43:31,068 | DEBUG | hackthon_support_agent.FrameworkService | Fetching prompt 'framework_service.generate_simple_recommendations'
2025-09-21 14:44:51,432 | DEBUG | hackthon_support_agent.TechnologyService | Initializing BaseService (provider=google)
2025-09-21 14:44:51,433 | INFO | hackthon_support_agent.TechnologyService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-21 14:44:51,433 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 14:44:51,435 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 14:44:51,435 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 14:44:51,437 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 14:44:51,437 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 14:44:51,438 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 14:44:51,438 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 14:44:51,439 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 14:44:51,439 | DEBUG | hackthon_support_agent.TechnologyService | LLMs initialized
2025-09-21 14:44:51,439 | DEBUG | hackthon_support_agent.TechnologyService | Fetching prompt 'technology_service.generate_technology_document'
2025-09-21 14:44:51,675 | DEBUG | hackthon_support_agent.TechnologyService | Initializing BaseService (provider=google)
2025-09-21 14:44:51,677 | INFO | hackthon_support_agent.TechnologyService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-21 14:44:51,677 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 14:44:51,678 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 14:44:51,678 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 14:44:51,679 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 14:44:51,679 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 14:44:51,680 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 14:44:51,680 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-21 14:44:51,681 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-21 14:44:51,681 | DEBUG | hackthon_support_agent.TechnologyService | LLMs initialized
2025-09-21 14:44:51,681 | DEBUG | hackthon_support_agent.TechnologyService | Fetching prompt 'technology_service.generate_technology_document'
2025-09-22 13:31:25,901 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-22 13:31:25,903 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-22 13:31:25,903 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-22 13:31:25,907 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-22 13:31:25,907 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-22 13:31:25,908 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-22 13:31:25,908 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-22 13:31:25,909 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-22 13:31:25,909 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-22 13:31:25,910 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-22 13:31:25,910 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-22 13:31:25,910 | DEBUG | hackthon_support_agent.QuestionService | Generating questions for project_id: d108ad3e-60b1-46f7-9aae-cfba3b8be409 with idea_prompt: プロジェクトタイトル: ハッカソン支援エージェント
プロジェクトアイディア: AIエージェントを用いたアプリケーションプラットフォーム
期間: 2025-09-22 〜 2025-09-24 22:30
人数: 3
2025-09-22 13:31:25,910 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-09-22 13:31:30,119 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-09-22 13:31:30,121 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-22 13:31:30,121 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-22 13:31:30,122 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-22 13:31:30,122 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-22 13:31:30,122 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-22 13:31:30,122 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-22 13:31:30,123 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-22 13:31:30,123 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-22 13:31:30,124 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-22 13:31:30,124 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-09-22 13:31:37,613 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-22 13:31:37,614 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-22 13:31:37,614 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-22 13:31:37,616 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-22 13:31:37,616 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-22 13:31:37,617 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-22 13:31:37,617 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-22 13:31:37,618 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-22 13:31:37,618 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-22 13:31:37,618 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-22 13:31:37,618 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-22 13:31:37,620 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.generate_summary_document'
2025-09-22 13:31:41,017 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-22 13:31:41,019 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-22 13:31:41,019 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-22 13:31:41,020 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-22 13:31:41,020 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-22 13:31:41,020 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-22 13:31:41,020 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-22 13:31:41,021 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-22 13:31:41,021 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-22 13:31:41,022 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-22 13:31:41,022 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-22 13:33:00,206 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-22 13:33:00,208 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-22 13:33:00,208 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-22 13:33:00,210 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-22 13:33:00,210 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-22 13:33:00,212 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-22 13:33:00,213 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-22 13:33:00,214 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-22 13:33:00,214 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-22 13:33:00,214 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-22 13:33:00,214 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-22 13:33:00,223 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-22 13:33:00,426 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-22 13:33:00,427 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-22 13:33:00,427 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-22 13:33:00,428 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-22 13:33:00,428 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-22 13:33:00,429 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-22 13:33:00,429 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-22 13:33:00,430 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-22 13:33:00,430 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-22 13:33:00,431 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-22 13:33:00,431 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-22 13:33:00,434 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-22 13:33:01,755 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-22 13:33:01,756 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-22 13:33:01,756 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-22 13:33:01,757 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-22 13:33:01,757 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-22 13:33:01,758 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-22 13:33:01,758 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-22 13:33:01,759 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-22 13:33:01,759 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-22 13:33:01,760 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-22 13:33:01,761 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-22 13:33:01,761 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: d108ad3e-60b1-46f7-9aae-cfba3b8be409
2025-09-22 13:33:01,762 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.confidence_feedback'
2025-09-22 13:33:01,763 | ERROR | hackthon_support_agent.SummaryService | Prompt 'confidence_feedback' not found under service 'summary_service' in prompts.toml
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/base_service.py", line 148, in get_prompt
    prompt = self.prompts[service_name][prompt_name]
             ~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^
KeyError: 'confidence_feedback'
2025-09-22 13:33:01,764 | ERROR | hackthon_support_agent.SummaryService | Failed to get prompt: Prompt 'confidence_feedback' not found in service 'summary_service' in prompts.toml
2025-09-22 13:33:02,043 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-22 13:33:02,044 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-22 13:33:02,044 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-22 13:33:02,045 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-22 13:33:02,046 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-22 13:33:02,046 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-22 13:33:02,046 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-22 13:33:02,047 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-22 13:33:02,047 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-22 13:33:02,048 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-22 13:33:02,048 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-22 13:33:02,048 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: d108ad3e-60b1-46f7-9aae-cfba3b8be409
2025-09-22 13:33:02,050 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.confidence_feedback'
2025-09-22 13:33:02,050 | ERROR | hackthon_support_agent.SummaryService | Prompt 'confidence_feedback' not found under service 'summary_service' in prompts.toml
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/base_service.py", line 148, in get_prompt
    prompt = self.prompts[service_name][prompt_name]
             ~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^
KeyError: 'confidence_feedback'
2025-09-22 13:33:02,050 | ERROR | hackthon_support_agent.SummaryService | Failed to get prompt: Prompt 'confidence_feedback' not found in service 'summary_service' in prompts.toml
2025-09-22 13:34:40,978 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-22 13:34:40,979 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-22 13:34:40,980 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-22 13:34:40,981 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-22 13:34:40,981 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-22 13:34:40,982 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-22 13:34:40,982 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-22 13:34:40,983 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-22 13:34:40,983 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-22 13:34:40,984 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-22 13:34:40,984 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-22 13:34:40,987 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-22 13:34:41,249 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-09-22 13:34:41,250 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-22 13:34:41,250 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-22 13:34:41,251 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-22 13:34:41,251 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-22 13:34:41,252 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-22 13:34:41,252 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-22 13:34:41,254 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-22 13:34:41,254 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-22 13:34:41,255 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-22 13:34:41,255 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-09-22 13:34:41,258 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-09-22 13:34:42,386 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-22 13:34:42,387 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-22 13:34:42,387 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-22 13:34:42,389 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-22 13:34:42,389 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-22 13:34:42,389 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-22 13:34:42,390 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-22 13:34:42,391 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-22 13:34:42,391 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-22 13:34:42,391 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-22 13:34:42,391 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-22 13:34:42,391 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: d108ad3e-60b1-46f7-9aae-cfba3b8be409
2025-09-22 13:34:42,393 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.confidence_feedback'
2025-09-22 13:34:42,393 | ERROR | hackthon_support_agent.SummaryService | Prompt 'confidence_feedback' not found under service 'summary_service' in prompts.toml
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/base_service.py", line 148, in get_prompt
    prompt = self.prompts[service_name][prompt_name]
             ~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^
KeyError: 'confidence_feedback'
2025-09-22 13:34:42,393 | ERROR | hackthon_support_agent.SummaryService | Failed to get prompt: Prompt 'confidence_feedback' not found in service 'summary_service' in prompts.toml
2025-09-22 13:34:43,526 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-09-22 13:34:43,527 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-22 13:34:43,527 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-22 13:34:43,528 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-22 13:34:43,528 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-22 13:34:43,529 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-22 13:34:43,529 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-22 13:34:43,530 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-22 13:34:43,530 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-22 13:34:43,531 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-22 13:34:43,531 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-09-22 13:34:43,531 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: d108ad3e-60b1-46f7-9aae-cfba3b8be409
2025-09-22 13:34:43,533 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.confidence_feedback'
2025-09-22 13:34:43,533 | ERROR | hackthon_support_agent.SummaryService | Prompt 'confidence_feedback' not found under service 'summary_service' in prompts.toml
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/base_service.py", line 148, in get_prompt
    prompt = self.prompts[service_name][prompt_name]
             ~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^
KeyError: 'confidence_feedback'
2025-09-22 13:34:43,533 | ERROR | hackthon_support_agent.SummaryService | Failed to get prompt: Prompt 'confidence_feedback' not found in service 'summary_service' in prompts.toml
2025-09-22 13:38:13,347 | DEBUG | hackthon_support_agent.FunctionService | Initializing BaseService (provider=google)
2025-09-22 13:38:13,349 | INFO | hackthon_support_agent.FunctionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-22 13:38:13,349 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-22 13:38:13,350 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-22 13:38:13,350 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-22 13:38:13,351 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-22 13:38:13,351 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-22 13:38:13,352 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-22 13:38:13,352 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-22 13:38:13,353 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-22 13:38:13,353 | DEBUG | hackthon_support_agent.FunctionService | LLMs initialized
2025-09-22 13:38:13,353 | DEBUG | hackthon_support_agent.FunctionService | Generating functional requirements for project_id: d108ad3e-60b1-46f7-9aae-cfba3b8be409
2025-09-22 13:38:13,355 | DEBUG | hackthon_support_agent.FunctionService | Fetching prompt 'function_service.generate_functional_requirements'
2025-09-22 13:38:13,583 | DEBUG | hackthon_support_agent.FunctionService | Initializing BaseService (provider=google)
2025-09-22 13:38:13,584 | INFO | hackthon_support_agent.FunctionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-22 13:38:13,584 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-22 13:38:13,585 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-22 13:38:13,585 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-22 13:38:13,586 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-22 13:38:13,586 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-22 13:38:13,587 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-22 13:38:13,587 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-22 13:38:13,588 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-22 13:38:13,588 | DEBUG | hackthon_support_agent.FunctionService | LLMs initialized
2025-09-22 13:38:13,588 | DEBUG | hackthon_support_agent.FunctionService | Generating functional requirements for project_id: d108ad3e-60b1-46f7-9aae-cfba3b8be409
2025-09-22 13:38:13,590 | DEBUG | hackthon_support_agent.FunctionService | Fetching prompt 'function_service.generate_functional_requirements'
2025-09-22 13:38:21,317 | DEBUG | hackthon_support_agent.FunctionService | Generating clarification questions for 4 low-confidence requirements
2025-09-22 13:38:21,318 | DEBUG | hackthon_support_agent.FunctionService | Fetching prompt 'function_service.generate_clarification_questions'
2025-09-22 13:38:21,796 | DEBUG | hackthon_support_agent.FunctionService | Generating clarification questions for 5 low-confidence requirements
2025-09-22 13:38:21,796 | DEBUG | hackthon_support_agent.FunctionService | Fetching prompt 'function_service.generate_clarification_questions'
2025-09-22 13:38:23,414 | DEBUG | hackthon_support_agent.FunctionService | Saving functional requirements to project document: d108ad3e-60b1-46f7-9aae-cfba3b8be409
2025-09-22 13:38:23,419 | DEBUG | hackthon_support_agent.FunctionService | Saving 4 clarification questions to database
2025-09-22 13:38:23,642 | DEBUG | hackthon_support_agent.FunctionService | Saving functional requirements to project document: d108ad3e-60b1-46f7-9aae-cfba3b8be409
2025-09-22 13:38:23,646 | DEBUG | hackthon_support_agent.FunctionService | Saving 5 clarification questions to database
2025-09-22 13:38:34,362 | DEBUG | hackthon_support_agent.FrameworkService | Initializing BaseService (provider=google)
2025-09-22 13:38:34,363 | INFO | hackthon_support_agent.FrameworkService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-22 13:38:34,363 | DEBUG | hackthon_support_agent.FrameworkService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-22 13:38:34,365 | INFO | hackthon_support_agent.FrameworkService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-22 13:38:34,365 | DEBUG | hackthon_support_agent.FrameworkService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-22 13:38:34,365 | INFO | hackthon_support_agent.FrameworkService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-22 13:38:34,366 | DEBUG | hackthon_support_agent.FrameworkService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-22 13:38:34,367 | INFO | hackthon_support_agent.FrameworkService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-22 13:38:34,367 | DEBUG | hackthon_support_agent.FrameworkService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-22 13:38:34,368 | INFO | hackthon_support_agent.FrameworkService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-22 13:38:34,368 | DEBUG | hackthon_support_agent.FrameworkService | LLMs initialized
2025-09-22 13:38:34,368 | DEBUG | hackthon_support_agent.FrameworkService | Fetching prompt 'framework_service.generate_simple_recommendations'
2025-09-22 13:38:57,280 | DEBUG | hackthon_support_agent.TechnologyService | Initializing BaseService (provider=google)
2025-09-22 13:38:57,281 | DEBUG | hackthon_support_agent.TechnologyService | Initializing BaseService (provider=google)
2025-09-22 13:38:57,283 | INFO | hackthon_support_agent.TechnologyService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-22 13:38:57,285 | INFO | hackthon_support_agent.TechnologyService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-09-22 13:38:57,285 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-22 13:38:57,285 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-22 13:38:57,289 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-22 13:38:57,290 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-22 13:38:57,291 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-22 13:38:57,291 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-22 13:38:57,292 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-22 13:38:57,293 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-22 13:38:57,294 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-22 13:38:57,294 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-22 13:38:57,295 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-22 13:38:57,297 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-22 13:38:57,297 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-22 13:38:57,297 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-09-22 13:38:57,299 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-22 13:38:57,299 | DEBUG | hackthon_support_agent.TechnologyService | LLMs initialized
2025-09-22 13:38:57,299 | DEBUG | hackthon_support_agent.TechnologyService | Fetching prompt 'technology_service.generate_technology_document'
2025-09-22 13:38:57,300 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-09-22 13:38:57,303 | DEBUG | hackthon_support_agent.TechnologyService | LLMs initialized
2025-09-22 13:38:57,303 | DEBUG | hackthon_support_agent.TechnologyService | Fetching prompt 'technology_service.generate_technology_document'
2025-10-01 11:26:40,484 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-10-01 11:26:41,925 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-10-01 11:27:45,855 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-10-01 11:27:58,534 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-10-01 11:27:59,952 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-10-01 11:28:39,248 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-10-01 11:28:45,590 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-10-01 11:28:46,945 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-10-01 11:29:35,070 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-10-01 11:29:42,533 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-10-01 11:30:09,410 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-10-01 11:30:10,703 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-10-01 11:30:13,245 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-10-01 11:30:13,246 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-10-01 11:30:13,246 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-01 11:30:13,270 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-01 11:30:13,270 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-01 11:30:13,272 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-01 11:30:13,272 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-01 11:30:13,273 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-01 11:30:13,273 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-01 11:30:13,274 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-01 11:30:13,274 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-10-01 11:30:13,274 | DEBUG | hackthon_support_agent.QuestionService | Generating questions for project_id: ae736b54-8dda-4492-8ae5-13920b2c81d5 with idea_prompt: プロジェクトタイトル: ハッカソン支援エージェント
プロジェクトアイディア: ハッカソン支援エージェント
期間: 2025-10-01 〜 2025-10-10 20:26
2025-10-01 11:30:13,274 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-10-01 11:30:17,665 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-10-01 11:30:17,666 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-10-01 11:30:17,666 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-01 11:30:17,667 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-01 11:30:17,667 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-01 11:30:17,668 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-01 11:30:17,668 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-01 11:30:17,669 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-01 11:30:17,669 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-01 11:30:17,671 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-01 11:30:17,671 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-10-01 11:31:09,913 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-10-01 11:31:09,914 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-10-01 11:31:09,914 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-01 11:31:09,918 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-01 11:31:09,918 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-01 11:31:09,920 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-01 11:31:09,920 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-01 11:31:09,922 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-01 11:31:09,922 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-01 11:31:09,923 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-01 11:31:09,924 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-10-01 11:31:09,927 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.generate_summary_document'
2025-10-01 11:31:14,731 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-10-01 11:31:14,732 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-10-01 11:31:14,732 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-01 11:31:14,733 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-01 11:31:14,733 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-01 11:31:14,734 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-01 11:31:14,734 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-01 11:31:14,735 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-01 11:31:14,736 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-01 11:31:14,737 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-01 11:31:14,737 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-10-01 11:31:19,563 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-10-01 11:31:19,567 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-10-01 11:31:19,567 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-01 11:31:19,572 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-01 11:31:19,572 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-01 11:31:19,574 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-01 11:31:19,574 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-01 11:31:19,578 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-01 11:31:19,579 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-01 11:31:19,581 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-10-01 11:31:19,582 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-01 11:31:19,583 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-10-01 11:31:19,584 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-10-01 11:31:19,590 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-10-01 11:31:19,590 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-01 11:31:19,596 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-01 11:31:19,596 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-01 11:31:19,598 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-01 11:31:19,598 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-01 11:31:19,601 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-01 11:31:19,602 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-01 11:31:19,606 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-01 11:31:19,606 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-10-01 11:31:19,612 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-10-01 11:35:15,049 | DEBUG | hackthon_support_agent.FunctionService | Initializing BaseService (provider=google)
2025-10-01 11:35:15,050 | INFO | hackthon_support_agent.FunctionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-10-01 11:35:15,050 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-01 11:35:15,053 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-01 11:35:15,053 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-01 11:35:15,054 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-01 11:35:15,054 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-01 11:35:15,055 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-01 11:35:15,055 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-01 11:35:15,056 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-01 11:35:15,056 | DEBUG | hackthon_support_agent.FunctionService | LLMs initialized
2025-10-01 11:35:15,056 | DEBUG | hackthon_support_agent.FunctionService | Generating functional requirements for project_id: ae736b54-8dda-4492-8ae5-13920b2c81d5
2025-10-01 11:35:15,058 | DEBUG | hackthon_support_agent.FunctionService | Fetching prompt 'function_service.generate_functional_requirements'
2025-10-01 11:35:15,484 | DEBUG | hackthon_support_agent.FunctionService | Initializing BaseService (provider=google)
2025-10-01 11:35:15,485 | INFO | hackthon_support_agent.FunctionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-10-01 11:35:15,486 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-01 11:35:15,487 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-01 11:35:15,487 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-01 11:35:15,488 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-01 11:35:15,488 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-01 11:35:15,489 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-01 11:35:15,489 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-01 11:35:15,490 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-01 11:35:15,490 | DEBUG | hackthon_support_agent.FunctionService | LLMs initialized
2025-10-01 11:35:15,490 | DEBUG | hackthon_support_agent.FunctionService | Generating functional requirements for project_id: ae736b54-8dda-4492-8ae5-13920b2c81d5
2025-10-01 11:35:15,492 | DEBUG | hackthon_support_agent.FunctionService | Fetching prompt 'function_service.generate_functional_requirements'
2025-10-01 11:35:22,166 | DEBUG | hackthon_support_agent.FunctionService | Generating clarification questions for 3 low-confidence requirements
2025-10-01 11:35:22,187 | DEBUG | hackthon_support_agent.FunctionService | Fetching prompt 'function_service.generate_clarification_questions'
2025-10-01 11:35:22,192 | DEBUG | hackthon_support_agent.FunctionService | Generating clarification questions for 2 low-confidence requirements
2025-10-01 11:35:22,195 | DEBUG | hackthon_support_agent.FunctionService | Fetching prompt 'function_service.generate_clarification_questions'
2025-10-01 11:35:24,179 | DEBUG | hackthon_support_agent.FunctionService | Saving functional requirements to project document: ae736b54-8dda-4492-8ae5-13920b2c81d5
2025-10-01 11:35:24,184 | DEBUG | hackthon_support_agent.FunctionService | Saving 5 clarification questions to database
2025-10-01 11:35:24,667 | DEBUG | hackthon_support_agent.FunctionService | Saving functional requirements to project document: ae736b54-8dda-4492-8ae5-13920b2c81d5
2025-10-01 11:35:24,671 | DEBUG | hackthon_support_agent.FunctionService | Saving 6 clarification questions to database
2025-10-01 11:39:29,389 | DEBUG | hackthon_support_agent.FunctionService | Initializing BaseService (provider=google)
2025-10-01 11:39:29,390 | INFO | hackthon_support_agent.FunctionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-10-01 11:39:29,390 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-01 11:39:29,392 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-01 11:39:29,392 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-01 11:39:29,393 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-01 11:39:29,393 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-01 11:39:29,394 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-01 11:39:29,395 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-01 11:39:29,396 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-01 11:39:29,396 | DEBUG | hackthon_support_agent.FunctionService | LLMs initialized
2025-10-01 11:39:29,396 | DEBUG | hackthon_support_agent.FunctionService | Generating confidence feedback for project_id: ae736b54-8dda-4492-8ae5-13920b2c81d5
2025-10-01 11:39:29,400 | DEBUG | hackthon_support_agent.FunctionService | Fetching prompt 'function_service.confidence_feedback.generate_confidence_feedback'
2025-10-01 11:39:29,401 | ERROR | hackthon_support_agent.FunctionService | Prompt 'generate_confidence_feedback' not found under service 'function_service.confidence_feedback' in prompts.toml
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/base_service.py", line 148, in get_prompt
    prompt = self.prompts[service_name][prompt_name]
             ~~~~~~~~~~~~^^^^^^^^^^^^^^
KeyError: 'function_service.confidence_feedback'
2025-10-01 11:39:40,247 | DEBUG | hackthon_support_agent.FunctionService | Initializing BaseService (provider=google)
2025-10-01 11:39:40,248 | INFO | hackthon_support_agent.FunctionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-10-01 11:39:40,248 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-01 11:39:40,250 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-01 11:39:40,250 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-01 11:39:40,251 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-01 11:39:40,252 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-01 11:39:40,253 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-01 11:39:40,253 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-01 11:39:40,254 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-01 11:39:40,254 | DEBUG | hackthon_support_agent.FunctionService | LLMs initialized
2025-10-01 11:39:40,255 | DEBUG | hackthon_support_agent.FunctionService | Generating functional requirements for project_id: ae736b54-8dda-4492-8ae5-13920b2c81d5
2025-10-01 11:39:40,257 | DEBUG | hackthon_support_agent.FunctionService | Fetching prompt 'function_service.generate_functional_requirements'
2025-10-01 11:39:47,984 | DEBUG | hackthon_support_agent.FunctionService | Generating clarification questions for 3 low-confidence requirements
2025-10-01 11:39:47,984 | DEBUG | hackthon_support_agent.FunctionService | Fetching prompt 'function_service.generate_clarification_questions'
2025-10-01 11:39:50,465 | DEBUG | hackthon_support_agent.FunctionService | Saving functional requirements to project document: ae736b54-8dda-4492-8ae5-13920b2c81d5
2025-10-01 11:39:50,470 | DEBUG | hackthon_support_agent.FunctionService | Saving 5 clarification questions to database
2025-10-01 11:40:26,571 | DEBUG | hackthon_support_agent.FrameworkService | Initializing BaseService (provider=google)
2025-10-01 11:40:26,572 | INFO | hackthon_support_agent.FrameworkService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-10-01 11:40:26,573 | DEBUG | hackthon_support_agent.FrameworkService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-01 11:40:26,574 | INFO | hackthon_support_agent.FrameworkService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-01 11:40:26,574 | DEBUG | hackthon_support_agent.FrameworkService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-01 11:40:26,576 | INFO | hackthon_support_agent.FrameworkService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-01 11:40:26,576 | DEBUG | hackthon_support_agent.FrameworkService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-01 11:40:26,577 | INFO | hackthon_support_agent.FrameworkService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-01 11:40:26,578 | DEBUG | hackthon_support_agent.FrameworkService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-01 11:40:26,579 | INFO | hackthon_support_agent.FrameworkService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-01 11:40:26,579 | DEBUG | hackthon_support_agent.FrameworkService | LLMs initialized
2025-10-01 11:40:26,579 | DEBUG | hackthon_support_agent.FrameworkService | Fetching prompt 'framework_service.generate_simple_recommendations'
2025-10-01 11:40:50,830 | DEBUG | hackthon_support_agent.TechnologyService | Initializing BaseService (provider=google)
2025-10-01 11:40:50,831 | INFO | hackthon_support_agent.TechnologyService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-10-01 11:40:50,831 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-01 11:40:50,833 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-01 11:40:50,833 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-01 11:40:50,834 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-01 11:40:50,834 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-01 11:40:50,835 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-01 11:40:50,835 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-01 11:40:50,836 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-01 11:40:50,836 | DEBUG | hackthon_support_agent.TechnologyService | LLMs initialized
2025-10-01 11:40:50,837 | DEBUG | hackthon_support_agent.TechnologyService | Fetching prompt 'technology_service.generate_technology_document'
2025-10-01 11:40:51,252 | DEBUG | hackthon_support_agent.TechnologyService | Initializing BaseService (provider=google)
2025-10-01 11:40:51,253 | INFO | hackthon_support_agent.TechnologyService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-10-01 11:40:51,254 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-01 11:40:51,255 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-01 11:40:51,255 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-01 11:40:51,256 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-01 11:40:51,256 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-01 11:40:51,257 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-01 11:40:51,257 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-01 11:40:51,258 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-01 11:40:51,258 | DEBUG | hackthon_support_agent.TechnologyService | LLMs initialized
2025-10-01 11:40:51,258 | DEBUG | hackthon_support_agent.TechnologyService | Fetching prompt 'technology_service.generate_technology_document'
2025-10-05 06:46:09,053 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-10-05 08:05:20,596 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-10-05 08:05:26,153 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-10-05 08:05:28,684 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-10-05 08:05:31,022 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-10-05 08:05:35,049 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-10-05 08:05:59,090 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-10-05 08:06:04,446 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-10-05 08:06:18,863 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-10-05 08:06:21,429 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-10-05 08:06:23,099 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-10-05 08:06:49,367 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-10-05 09:23:13,767 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-10-05 09:23:19,583 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-10-05 09:23:21,672 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-10-05 10:08:59,779 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-10-05 10:08:59,781 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-10-05 10:08:59,781 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 10:08:59,813 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 10:08:59,813 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 10:08:59,814 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 10:08:59,814 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 10:08:59,816 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 10:08:59,816 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 10:08:59,817 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 10:08:59,817 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-10-05 10:08:59,817 | DEBUG | hackthon_support_agent.QuestionService | Generating questions for project_id: 5fc475ca-ea7a-4d11-805f-c4d0f54a940d with idea_prompt: プロジェクトタイトル: AIプロジェクト
プロジェクトアイディア: ハッカソン支援エージェント
期間: 2025-10-05 〜 2025-10-17 19:08
2025-10-05 10:08:59,817 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-10-05 10:09:03,990 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-10-05 10:09:03,991 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-10-05 10:09:03,991 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 10:09:03,993 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 10:09:03,993 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 10:09:03,994 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 10:09:03,994 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 10:09:03,995 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 10:09:03,995 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 10:09:03,996 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 10:09:03,997 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-10-05 11:05:29,109 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-10-05 11:14:23,056 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-10-05 11:14:24,402 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-10-05 11:15:14,410 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-10-05 11:15:14,412 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-10-05 11:15:14,412 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 11:15:14,435 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 11:15:14,435 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 11:15:14,437 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 11:15:14,437 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 11:15:14,438 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 11:15:14,438 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 11:15:14,440 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 11:15:14,440 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-10-05 11:15:14,440 | DEBUG | hackthon_support_agent.QuestionService | Generating questions for project_id: f55c72dd-fa56-43f7-9177-236a2156676a with idea_prompt: プロジェクトタイトル: ハッカソン支援エージェント
プロジェクトアイディア: ハッカソン支援エージェント
期間: 2025-10-05 〜 2025-10-24 20:14
2025-10-05 11:15:14,440 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-10-05 11:15:19,912 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-10-05 11:15:19,913 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-10-05 11:15:19,914 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 11:15:19,915 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 11:15:19,915 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 11:15:19,916 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 11:15:19,916 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 11:15:19,917 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 11:15:19,917 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 11:15:19,918 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 11:15:19,918 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-10-05 11:20:23,501 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-10-05 11:20:23,502 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-10-05 11:20:23,502 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 11:20:23,506 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 11:20:23,506 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 11:20:23,508 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 11:20:23,508 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 11:20:23,509 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 11:20:23,509 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 11:20:23,509 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 11:20:23,510 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-10-05 11:20:23,510 | DEBUG | hackthon_support_agent.QuestionService | Generating questions for project_id: d1a28b1e-4cce-49c9-bcbf-36b20b2d8152 with idea_prompt: プロジェクトタイトル: ハッカソン支援エージェント
プロジェクトアイディア: ハッカソン支援エージェント
期間: 2025-10-05 〜 2025-11-06 20:20
2025-10-05 11:20:23,510 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-10-05 11:20:29,238 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-10-05 11:20:29,240 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-10-05 11:20:29,240 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 11:20:29,241 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 11:20:29,241 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 11:20:29,242 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 11:20:29,242 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 11:20:29,243 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 11:20:29,243 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 11:20:29,244 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 11:20:29,244 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-10-05 11:21:59,935 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-10-05 11:22:36,830 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-10-05 11:22:36,831 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-10-05 11:22:36,831 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 11:22:36,843 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 11:22:36,844 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 11:22:36,845 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 11:22:36,845 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 11:22:36,847 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 11:22:36,847 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 11:22:36,848 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 11:22:36,848 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-10-05 11:22:36,848 | DEBUG | hackthon_support_agent.QuestionService | Generating questions for project_id: e5627512-fa1d-4cea-9c6b-8ab84c089814 with idea_prompt: プロジェクトタイトル: ハッカソン支援エージェント
プロジェクトアイディア: ハッカソン支援エージェント
期間: 2025-10-05 〜 2025-10-16 20:22
2025-10-05 11:22:36,848 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-10-05 11:22:41,339 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-10-05 11:22:41,340 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-10-05 11:22:41,340 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 11:22:41,341 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 11:22:41,342 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 11:22:41,343 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 11:22:41,343 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 11:22:41,344 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 11:22:41,344 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 11:22:41,345 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 11:22:41,345 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-10-05 11:25:38,276 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-10-05 11:27:46,926 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-10-05 11:27:46,927 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-10-05 11:27:46,927 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 11:27:46,938 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 11:27:46,939 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 11:27:46,940 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 11:27:46,940 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 11:27:46,941 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 11:27:46,942 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 11:27:46,943 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 11:27:46,943 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-10-05 11:27:46,944 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.generate_summary_document'
2025-10-05 11:27:50,980 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-10-05 11:27:50,982 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-10-05 11:27:50,982 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 11:27:50,983 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 11:27:50,983 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 11:27:50,984 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 11:27:50,984 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 11:27:50,985 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 11:27:50,985 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 11:27:50,987 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 11:27:50,987 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-10-05 11:27:54,901 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-10-05 11:27:54,903 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-10-05 11:27:54,903 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 11:27:54,905 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 11:27:54,905 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 11:27:54,906 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 11:27:54,906 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 11:27:54,907 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 11:27:54,907 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 11:27:54,908 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 11:27:54,908 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-10-05 11:27:54,909 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.generate_summary_document'
2025-10-05 11:27:56,450 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-10-05 11:27:56,451 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-10-05 11:27:56,451 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 11:27:56,453 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 11:27:56,453 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 11:27:56,455 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 11:27:56,455 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 11:27:56,456 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 11:27:56,456 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 11:27:56,457 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 11:27:56,457 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-10-05 11:27:56,461 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-10-05 11:27:56,872 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-10-05 11:27:56,874 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-10-05 11:27:56,874 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 11:27:56,876 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 11:27:56,877 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 11:27:56,878 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 11:27:56,878 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 11:27:56,879 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 11:27:56,880 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 11:27:56,881 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 11:27:56,881 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-10-05 11:27:56,884 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-10-05 11:27:58,635 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-10-05 11:27:58,636 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-10-05 11:27:58,636 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 11:27:58,638 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 11:27:58,638 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 11:27:58,638 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 11:27:58,639 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 11:27:58,640 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 11:27:58,640 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 11:27:58,640 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 11:27:58,641 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-10-05 11:28:07,394 | DEBUG | hackthon_support_agent.FunctionService | Initializing BaseService (provider=google)
2025-10-05 11:28:07,395 | DEBUG | hackthon_support_agent.FunctionService | Initializing BaseService (provider=google)
2025-10-05 11:28:07,396 | INFO | hackthon_support_agent.FunctionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-10-05 11:28:07,398 | INFO | hackthon_support_agent.FunctionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-10-05 11:28:07,398 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 11:28:07,398 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 11:28:07,400 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 11:28:07,401 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 11:28:07,402 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 11:28:07,403 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 11:28:07,403 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 11:28:07,403 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 11:28:07,404 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 11:28:07,405 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 11:28:07,405 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 11:28:07,406 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 11:28:07,407 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 11:28:07,407 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 11:28:07,408 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 11:28:07,408 | DEBUG | hackthon_support_agent.FunctionService | LLMs initialized
2025-10-05 11:28:07,409 | DEBUG | hackthon_support_agent.FunctionService | Generating functional requirements for project_id: e5627512-fa1d-4cea-9c6b-8ab84c089814
2025-10-05 11:28:07,410 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 11:28:07,410 | DEBUG | hackthon_support_agent.FunctionService | LLMs initialized
2025-10-05 11:28:07,410 | DEBUG | hackthon_support_agent.FunctionService | Generating functional requirements for project_id: e5627512-fa1d-4cea-9c6b-8ab84c089814
2025-10-05 11:28:07,411 | DEBUG | hackthon_support_agent.FunctionService | Fetching prompt 'function_service.generate_functional_requirements'
2025-10-05 11:28:07,414 | DEBUG | hackthon_support_agent.FunctionService | Fetching prompt 'function_service.generate_functional_requirements'
2025-10-05 11:28:13,243 | DEBUG | hackthon_support_agent.FunctionService | Generating clarification questions for 4 low-confidence requirements
2025-10-05 11:28:13,244 | DEBUG | hackthon_support_agent.FunctionService | Fetching prompt 'function_service.generate_clarification_questions'
2025-10-05 11:28:13,428 | DEBUG | hackthon_support_agent.FunctionService | Generating clarification questions for 2 low-confidence requirements
2025-10-05 11:28:13,428 | DEBUG | hackthon_support_agent.FunctionService | Fetching prompt 'function_service.generate_clarification_questions'
2025-10-05 11:28:15,154 | DEBUG | hackthon_support_agent.FunctionService | Saving functional requirements to project document: e5627512-fa1d-4cea-9c6b-8ab84c089814
2025-10-05 11:28:15,158 | DEBUG | hackthon_support_agent.FunctionService | Saving 4 clarification questions to database
2025-10-05 11:28:16,440 | DEBUG | hackthon_support_agent.FunctionService | Saving functional requirements to project document: e5627512-fa1d-4cea-9c6b-8ab84c089814
2025-10-05 11:28:16,444 | DEBUG | hackthon_support_agent.FunctionService | Saving 8 clarification questions to database
2025-10-05 11:29:46,090 | DEBUG | hackthon_support_agent.TechnologyService | Initializing BaseService (provider=google)
2025-10-05 11:29:46,091 | INFO | hackthon_support_agent.TechnologyService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-10-05 11:29:46,091 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 11:29:46,092 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 11:29:46,092 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 11:29:46,094 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 11:29:46,094 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 11:29:46,095 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 11:29:46,095 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 11:29:46,095 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 11:29:46,095 | DEBUG | hackthon_support_agent.TechnologyService | LLMs initialized
2025-10-05 11:29:46,096 | DEBUG | hackthon_support_agent.TechnologyService | Fetching prompt 'technology_service.generate_technology_document'
2025-10-05 11:29:46,524 | DEBUG | hackthon_support_agent.TechnologyService | Initializing BaseService (provider=google)
2025-10-05 11:29:46,525 | INFO | hackthon_support_agent.TechnologyService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-10-05 11:29:46,525 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 11:29:46,526 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 11:29:46,526 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 11:29:46,527 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 11:29:46,527 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 11:29:46,528 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 11:29:46,528 | DEBUG | hackthon_support_agent.TechnologyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 11:29:46,529 | INFO | hackthon_support_agent.TechnologyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 11:29:46,530 | DEBUG | hackthon_support_agent.TechnologyService | LLMs initialized
2025-10-05 11:29:46,530 | DEBUG | hackthon_support_agent.TechnologyService | Fetching prompt 'technology_service.generate_technology_document'
2025-10-05 11:30:23,455 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-10-05 11:30:23,458 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-10-05 11:30:23,459 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-10-05 11:30:23,459 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 11:30:23,460 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-10-05 11:30:23,461 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 11:30:23,464 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 11:30:23,465 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 11:30:23,466 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 11:30:23,466 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 11:30:23,467 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 11:30:23,468 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 11:30:23,468 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 11:30:23,469 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 11:30:23,469 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 11:30:23,470 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 11:30:23,471 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 11:30:23,471 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 11:30:23,472 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 11:30:23,472 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-10-05 11:30:23,476 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-10-05 11:30:23,476 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 11:30:23,478 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-10-05 11:30:23,482 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-10-05 12:03:03,844 | DEBUG | hackthon_support_agent.FunctionService | Initializing BaseService (provider=google)
2025-10-05 12:03:03,846 | INFO | hackthon_support_agent.FunctionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-10-05 12:03:03,846 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 12:03:03,854 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 12:03:03,854 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 12:03:03,856 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 12:03:03,856 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 12:03:03,857 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 12:03:03,857 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 12:03:03,858 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 12:03:03,858 | DEBUG | hackthon_support_agent.FunctionService | LLMs initialized
2025-10-05 12:03:03,858 | DEBUG | hackthon_support_agent.FunctionService | Generating confidence feedback for project_id: e5627512-fa1d-4cea-9c6b-8ab84c089814
2025-10-05 12:03:03,864 | DEBUG | hackthon_support_agent.FunctionService | Fetching prompt 'function_service.confidence_feedback.generate_confidence_feedback'
2025-10-05 12:03:03,864 | ERROR | hackthon_support_agent.FunctionService | Prompt 'generate_confidence_feedback' not found under service 'function_service.confidence_feedback' in prompts.toml
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/base_service.py", line 148, in get_prompt
    prompt = self.prompts[service_name][prompt_name]
             ~~~~~~~~~~~~^^^^^^^^^^^^^^
KeyError: 'function_service.confidence_feedback'
2025-10-05 12:21:33,443 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-10-05 12:21:40,172 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-10-05 12:22:11,165 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-10-05 12:22:11,166 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-10-05 12:22:11,166 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 12:22:11,184 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 12:22:11,184 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 12:22:11,186 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 12:22:11,186 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 12:22:11,188 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 12:22:11,188 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 12:22:11,189 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 12:22:11,190 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-10-05 12:22:11,193 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-10-05 12:22:11,269 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-10-05 12:22:11,270 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-10-05 12:22:11,270 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 12:22:11,271 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 12:22:11,272 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 12:22:11,273 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 12:22:11,273 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 12:22:11,274 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 12:22:11,274 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 12:22:11,275 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 12:22:11,275 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-10-05 12:22:11,278 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-10-05 12:22:16,619 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-10-05 12:22:16,621 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-10-05 12:22:16,621 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 12:22:16,627 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 12:22:16,628 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 12:22:16,631 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-10-05 12:22:16,631 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 12:22:16,632 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 12:22:16,633 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-10-05 12:22:16,636 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 12:22:16,637 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 12:22:16,639 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 12:22:16,640 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 12:22:16,640 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 12:22:16,645 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 12:22:16,645 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-10-05 12:22:16,652 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 12:22:16,654 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-10-05 12:22:16,655 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 12:22:16,659 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 12:22:16,659 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 12:22:16,661 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 12:22:16,661 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-10-05 12:22:16,667 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-10-05 12:28:48,812 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-10-05 12:29:03,242 | DEBUG | hackthon_support_agent.FunctionService | Initializing BaseService (provider=google)
2025-10-05 12:29:03,243 | INFO | hackthon_support_agent.FunctionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-10-05 12:29:03,243 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 12:29:03,257 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 12:29:03,257 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 12:29:03,259 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 12:29:03,259 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 12:29:03,260 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 12:29:03,260 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 12:29:03,261 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 12:29:03,261 | DEBUG | hackthon_support_agent.FunctionService | LLMs initialized
2025-10-05 12:29:03,261 | DEBUG | hackthon_support_agent.FunctionService | Generating functional requirements for project_id: e5627512-fa1d-4cea-9c6b-8ab84c089814
2025-10-05 12:29:03,265 | DEBUG | hackthon_support_agent.FunctionService | Fetching prompt 'function_service.generate_functional_requirements'
2025-10-05 12:29:10,806 | DEBUG | hackthon_support_agent.FunctionService | Generating clarification questions for 5 low-confidence requirements
2025-10-05 12:29:10,806 | DEBUG | hackthon_support_agent.FunctionService | Fetching prompt 'function_service.generate_clarification_questions'
2025-10-05 12:29:15,651 | DEBUG | hackthon_support_agent.FunctionService | Saving functional requirements to project document: e5627512-fa1d-4cea-9c6b-8ab84c089814
2025-10-05 12:29:15,658 | DEBUG | hackthon_support_agent.FunctionService | Saving 10 clarification questions to database
2025-10-05 14:02:01,239 | DEBUG | hackthon_support_agent.FrameworkService | Initializing BaseService (provider=google)
2025-10-05 14:02:01,245 | INFO | hackthon_support_agent.FrameworkService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-10-05 14:02:01,245 | DEBUG | hackthon_support_agent.FrameworkService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 14:02:01,277 | INFO | hackthon_support_agent.FrameworkService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 14:02:01,278 | DEBUG | hackthon_support_agent.FrameworkService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 14:02:01,286 | INFO | hackthon_support_agent.FrameworkService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 14:02:01,287 | DEBUG | hackthon_support_agent.FrameworkService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 14:02:01,290 | INFO | hackthon_support_agent.FrameworkService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 14:02:01,290 | DEBUG | hackthon_support_agent.FrameworkService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-05 14:02:01,293 | INFO | hackthon_support_agent.FrameworkService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-05 14:02:01,293 | DEBUG | hackthon_support_agent.FrameworkService | LLMs initialized
2025-10-05 14:02:01,294 | DEBUG | hackthon_support_agent.FrameworkService | Fetching prompt 'framework_service.generate_simple_recommendations'
