"""
InteractiveHandsOnAgent: ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒãƒ³ã‚ºã‚ªãƒ³ç”Ÿæˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ

ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã§æ®µéšçš„ã«ç”Ÿæˆã—ã€å¿…è¦ã«å¿œã˜ã¦é¸æŠè‚¢ã‚’æç¤ºã™ã‚‹å¯¾è©±å‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã€‚
- ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã§ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã‚’èª¤é­”åŒ–ã—ãªãŒã‚‰æ®µéšçš„ã«ç”Ÿæˆ
- å¿…è¦ãªæ™‚ã ã‘é¸æŠè‚¢ã‚’æç¤ºï¼ˆæŠ€è¡“é¸å®šãªã©ï¼‰
- ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã«ã€Œã§ããŸã€ã‚’å¾…ã¤MVPã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
- å„ã‚¹ãƒ†ãƒƒãƒ—ã§DBä¿å­˜ï¼ˆä¸­æ–­æ™‚ã‚‚é€²æ—ã‚’ä¿æŒï¼‰
"""

import asyncio
import json
import uuid
from typing import Dict, Optional, AsyncGenerator, List, Any
from datetime import datetime
from dataclasses import asdict
from enum import Enum

from sqlalchemy.orm import Session
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage, SystemMessage

from models.project_base import Task, TaskHandsOn, TaskDependency
from services.tech_selection_service import TechSelectionService

# å‹å®šç¾©ã¯ hands_on ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‹ã‚‰ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from services.hands_on.types import (
    GenerationPhase,
    ChoiceOption,
    ChoiceRequest,
    InputPrompt,
    ImplementationStep,
    Decision,
    DependencyTaskInfo,
    StepRequirements,
    SessionState,
)


class InteractiveHandsOnAgent:
    """
    ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒãƒ³ã‚ºã‚ªãƒ³ç”Ÿæˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ

    SSEã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã§æ®µéšçš„ã«ç”Ÿæˆã—ã€ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã«ãƒ¦ãƒ¼ã‚¶ãƒ¼ç¢ºèªã‚’å¾…ã¤ã€‚
    å„ã‚¹ãƒ†ãƒƒãƒ—å®Œäº†æ™‚ã«DBã«ä¿å­˜ã—ã€ä¸­æ–­ã—ã¦ã‚‚é€²æ—ã‚’ä¿æŒã™ã‚‹ã€‚
    """

    def __init__(
        self,
        db: Session,
        task: Task,
        project_context: Dict,
        config: Optional[Dict] = None,
        dependency_context: Optional[Dict] = None
    ):
        self.db = db
        self.task = task
        self.project_context = project_context
        self.config = config or {}
        self.dependency_context = dependency_context or {}

        # LLMåˆæœŸåŒ–
        self.llm = ChatGoogleGenerativeAI(
            model=self.config.get("model", "gemini-2.0-flash"),
            temperature=0.7
        )

        # æŠ€è¡“é¸å®šã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–
        self.tech_service = TechSelectionService(db)

        # æ±ºå®šæ¸ˆã¿domainã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥
        self.decided_domains = self.tech_service.get_decided_domains(
            task.project_id, task.task_id
        )

        # ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ ç‰¹å®š
        self.ecosystem = self._detect_ecosystem(project_context.get('tech_stack', []))

    def _get_task_position(self) -> Dict:
        """ã‚¿ã‚¹ã‚¯ã®å…¨ä½“ã«ãŠã‘ã‚‹ä½ç½®ã¥ã‘ã‚’å–å¾—"""
        dependencies_from = self.db.query(TaskDependency).filter(
            TaskDependency.target_task_id == self.task.task_id
        ).all()

        dependencies_to = self.db.query(TaskDependency).filter(
            TaskDependency.source_task_id == self.task.task_id
        ).all()

        prev_tasks = []
        for dep in dependencies_from:
            source_task = self.db.query(Task).filter(
                Task.task_id == dep.source_task_id
            ).first()
            if source_task:
                prev_tasks.append({
                    "task_id": str(source_task.task_id),
                    "title": source_task.title,
                    "category": source_task.category
                })

        next_tasks = []
        for dep in dependencies_to:
            target_task = self.db.query(Task).filter(
                Task.task_id == dep.target_task_id
            ).first()
            if target_task:
                next_tasks.append({
                    "task_id": str(target_task.task_id),
                    "title": target_task.title,
                    "category": target_task.category
                })

        return {
            "current": {
                "task_id": str(self.task.task_id),
                "title": self.task.title,
                "category": self.task.category or "æœªåˆ†é¡"
            },
            "previous_tasks": prev_tasks,
            "next_tasks": next_tasks,
            "position_description": self._build_position_description(prev_tasks, next_tasks)
        }

    def _build_position_description(
        self,
        prev_tasks: List[Dict],
        next_tasks: List[Dict]
    ) -> str:
        """ä½ç½®ã¥ã‘ã®èª¬æ˜æ–‡ã‚’ç”Ÿæˆ"""
        parts = []

        if prev_tasks:
            prev_names = [t["title"] for t in prev_tasks[:3]]
            parts.append(f"å‰æã‚¿ã‚¹ã‚¯: {', '.join(prev_names)}")

        if next_tasks:
            next_names = [t["title"] for t in next_tasks[:3]]
            parts.append(f"æ¬¡ã®ã‚¿ã‚¹ã‚¯: {', '.join(next_names)}")

        if not parts:
            return "ã“ã®ã‚¿ã‚¹ã‚¯ã¯ç‹¬ç«‹ã—ãŸã‚¿ã‚¹ã‚¯ã§ã™ã€‚"

        return " â†’ ".join(parts)

    def _detect_ecosystem(self, tech_stack: List[str]) -> Optional[str]:
        """
        tech_stackã‹ã‚‰ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ ã‚’ç‰¹å®š

        Args:
            tech_stack: æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯ã®ãƒªã‚¹ãƒˆ

        Returns:
            "python", "next.js"ç­‰ã€ã¾ãŸã¯ç‰¹å®šã§ããªã„å ´åˆã¯None
        """
        tech_stack_lower = [t.lower() for t in tech_stack]

        # Pythonç³»
        python_indicators = ["python", "fastapi", "flask", "django", "sqlalchemy"]
        if any(indicator in " ".join(tech_stack_lower) for indicator in python_indicators):
            return "python"

        # Next.js/Reactç³»
        nextjs_indicators = ["next.js", "nextjs", "next", "react"]
        if any(indicator in " ".join(tech_stack_lower) for indicator in nextjs_indicators):
            return "next.js"

        # Node.jsç³»
        nodejs_indicators = ["node.js", "nodejs", "express"]
        if any(indicator in " ".join(tech_stack_lower) for indicator in nodejs_indicators):
            return "node.js"

        return None

    async def _check_tech_selection(self, session: SessionState, force_choice: bool = False) -> Dict:
        """
        æŠ€è¡“é¸å®šãŒå¿…è¦ã‹ã©ã†ã‹ã‚’åˆ¤æ–­ï¼ˆDBãƒ—ãƒªã‚»ãƒƒãƒˆ + LLMåˆ¤æ–­ï¼‰

        LLMã¯domainæ¤œå‡ºã®ã¿è¡Œã„ã€é¸æŠè‚¢ã¯DBã‹ã‚‰å–å¾—ã™ã‚‹ã€‚

        Returns:
            é¸æŠãŒå¿…è¦ãªå ´åˆ:
            {
                "needs_choice": True,
                "domain_key": "orm_python",
                "question": "ã©ã®ORMã‚’ä½¿ç”¨ã—ã¾ã™ã‹ï¼Ÿ",
                "options": [{"id": "...", "label": "...", "description": "...", "pros": [...], "cons": [...]}]
            }
            æ—¢ã«æ±ºã¾ã£ã¦ã„ã‚‹å ´åˆ:
            {
                "needs_choice": False,
                "decided": "SQLAlchemy",
                "reason": "ã‚¿ã‚¹ã‚¯èª¬æ˜ã§æŒ‡å®šæ¸ˆã¿"
            }
        """
        # åˆ©ç”¨å¯èƒ½ãªdomainã‚’å–å¾—
        domains = self.tech_service.get_available_domains(self.ecosystem)
        if not domains:
            return {"needs_choice": False, "decided": None, "reason": "åˆ©ç”¨å¯èƒ½ãªæŠ€è¡“é ˜åŸŸãŒã‚ã‚Šã¾ã›ã‚“"}

        # æ±ºå®šæ¸ˆã¿domainã‚’å–å¾—ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ä½¿ç”¨ï¼‰
        decided_text = self.tech_service.get_decided_for_prompt(
            self.task.project_id, self.task.task_id
        )

        # domainä¸€è¦§ã‚’ãƒ†ã‚­ã‚¹ãƒˆåŒ–
        domains_text = "\n".join([f"- {d.key}: {d.name}" for d in domains])

        prompt = f"""
ä»¥ä¸‹ã®ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè£…ã™ã‚‹ã«ã‚ãŸã‚Šã€æŠ€è¡“é¸å®šãŒå¿…è¦ã‹ã©ã†ã‹åˆ¤æ–­ã—ã¦ãã ã•ã„ã€‚

## ã‚¿ã‚¹ã‚¯æƒ…å ±
- ã‚¿ã‚¤ãƒˆãƒ«: {self.task.title}
- èª¬æ˜: {self.task.description or 'ãªã—'}

## ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±
- æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯: {', '.join(self.project_context.get('tech_stack', []))}
- ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯: {self.project_context.get('framework', 'æœªè¨­å®š')}

## åˆ©ç”¨å¯èƒ½ãªæŠ€è¡“é ˜åŸŸï¼ˆãƒ—ãƒªã‚»ãƒƒãƒˆã‚ã‚Šï¼‰
{domains_text}

## ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§æ±ºå®šæ¸ˆã¿ï¼ˆã“ã‚Œã‚‰ã¯é™¤å¤–ï¼‰
{decided_text}

## åˆ¤æ–­åŸºæº–
ä»¥ä¸‹ã®å ´åˆã¯é¸æŠä¸è¦ï¼ˆneeds_selection: falseï¼‰:
- ã‚¿ã‚¹ã‚¯èª¬æ˜ã§æ—¢ã«æŠ€è¡“ãŒæ˜è¨˜ã•ã‚Œã¦ã„ã‚‹ï¼ˆä¾‹: ã€ŒSQLAlchemyã§ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆã€ï¼‰
- ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§æ±ºå®šæ¸ˆã¿ã®æŠ€è¡“é ˜åŸŸã®ã¿ä½¿ç”¨ã™ã‚‹
- æŠ€è¡“é¸å®šã¨ç„¡é–¢ä¿‚ãªã‚¿ã‚¹ã‚¯ï¼ˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä½œæˆã€ãƒ†ã‚¹ãƒˆã€ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ç­‰ï¼‰
- é¸æŠã®ä½™åœ°ãŒãªã„ï¼ˆãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯æŒ‡å®šã§é¸æŠè‚¢ãŒ1ã¤ã—ã‹ãªã„ï¼‰

é¸æŠãŒå¿…è¦ãªå ´åˆã®ã¿ã€domain_keyã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

## å‡ºåŠ›å½¢å¼ï¼ˆJSONï¼‰
é¸æŠä¸è¦ã®å ´åˆ:
{{
  "needs_selection": false,
  "decided": "æ±ºå®šæ¸ˆã¿ã®æŠ€è¡“åï¼ˆã‚ã‚Œã°ï¼‰",
  "reason": "ç†ç”±"
}}

é¸æŠãŒå¿…è¦ãªå ´åˆ:
{{
  "needs_selection": true,
  "domain_key": "åˆ©ç”¨å¯èƒ½ãªæŠ€è¡“é ˜åŸŸã®key"
}}
"""

        try:
            response = await self.llm.ainvoke([
                SystemMessage(content="æŠ€è¡“é¸å®šã‚’åˆ¤æ–­ã™ã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚JSONå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚"),
                HumanMessage(content=prompt)
            ])

            content = response.content
            if "```json" in content:
                content = content.split("```json")[1].split("```")[0]
            elif "```" in content:
                content = content.split("```")[1].split("```")[0]

            result = json.loads(content.strip())

            if not result.get("needs_selection"):
                return {
                    "needs_choice": False,
                    "decided": result.get("decided"),
                    "reason": result.get("reason", "")
                }

            # DBã‹ã‚‰stackã‚’å–å¾—
            domain_key = result.get("domain_key")
            if not domain_key:
                return {"needs_choice": False, "decided": None, "reason": "domain_keyãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“"}

            stacks = self.tech_service.get_stacks_for_domain(domain_key, self.ecosystem)
            if not stacks:
                return {"needs_choice": False, "decided": None, "reason": f"domain '{domain_key}' ã«é¸æŠè‚¢ãŒã‚ã‚Šã¾ã›ã‚“"}

            # domainã‚’å–å¾—
            domain = self.tech_service.get_domain_by_key(domain_key)
            if not domain:
                return {"needs_choice": False, "decided": None, "reason": f"domain '{domain_key}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"}

            # ç¾åœ¨ã®é¸æŠå¯¾è±¡domainã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«è¨˜éŒ²
            session.current_domain_key = domain_key

            return {
                "needs_choice": True,
                "domain_key": domain_key,
                "question": domain.decision_prompt,
                "options": [
                    {
                        "id": s.key,
                        "label": s.label,
                        "description": s.summary,
                        "pros": s.pros or [],
                        "cons": s.cons or []
                    }
                    for s in stacks
                ]
            }

        except Exception as e:
            return {"needs_choice": False, "decided": None, "reason": f"åˆ¤æ–­ã§ãã¾ã›ã‚“ã§ã—ãŸ: {str(e)}"}

    async def _check_step_requirements(
        self,
        step: 'ImplementationStep',
        session: 'SessionState'
    ) -> 'StepRequirements':
        """
        ã‚¹ãƒ†ãƒƒãƒ—å†…ã®è¦ä»¶ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆæ¦‚å¿µèª¬æ˜ãƒ»æŠ€è¡“é¸å®šãŒå¿…è¦ã‹ã‚’åˆ¤æ–­ï¼‰

        1å›ã®LLMãƒªã‚¯ã‚¨ã‚¹ãƒˆã§ä»¥ä¸‹ã‚’å–å¾—ï¼š
        - objective: ã‚¹ãƒ†ãƒƒãƒ—ã®ç›®çš„
        - prerequisite: å‰ææ¦‚å¿µï¼ˆå¿…è¦ãªå ´åˆï¼‰
        - tech_selection: æŠ€è¡“é¸å®šï¼ˆå¿…è¦ãªå ´åˆï¼‰

        Returns:
            StepRequirements ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        """
        # æ—¢ã«ã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã§é¸æŠæ¸ˆã¿ã®æŠ€è¡“ãŒã‚ã‚Œã°å«ã‚ã‚‹
        step_choice_text = ""
        if step.step_number in session.step_choices:
            choice = session.step_choices[step.step_number]
            step_choice_text = f"\n## ã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã§é¸æŠæ¸ˆã¿ã®æŠ€è¡“\n- {choice.get('selected', '')}\n"

        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§æ±ºå®šæ¸ˆã¿ã®æŠ€è¡“
        decided_tech_text = ""
        if session.project_implementation_overview:
            decided_tech_text = f"\n## ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§æ±ºå®šæ¸ˆã¿ã®æŠ€è¡“\n{session.project_implementation_overview}\n"

        prompt = f"""
ä»¥ä¸‹ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’å®Ÿè£…ã™ã‚‹ã«ã‚ãŸã‚Šã€å‰æçŸ¥è­˜ã®èª¬æ˜ã¨æŠ€è¡“é¸å®šãŒå¿…è¦ã‹ã‚’åˆ¤æ–­ã—ã¦ãã ã•ã„ã€‚

## ã‚¿ã‚¹ã‚¯æƒ…å ±
- ã‚¿ã‚¤ãƒˆãƒ«: {self.task.title}
- èª¬æ˜: {self.task.description or 'ãªã—'}
- ã‚«ãƒ†ã‚´ãƒª: {self.task.category or 'æœªåˆ†é¡'}

## ç¾åœ¨ã®ã‚¹ãƒ†ãƒƒãƒ—
- ã‚¹ãƒ†ãƒƒãƒ—{step.step_number}: {step.title}
- èª¬æ˜: {step.description}

## ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±
- æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯: {', '.join(self.project_context.get('tech_stack', []))}
- ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯: {self.project_context.get('framework', 'æœªè¨­å®š')}
{decided_tech_text}
{step_choice_text}

## åˆ¤æ–­åŸºæº–

### å‰ææ¦‚å¿µï¼ˆprerequisiteï¼‰
- ã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã§ä½¿ã†æ¦‚å¿µãƒ»ç”¨èªã§ã€åˆå¿ƒè€…ãŒçŸ¥ã‚‰ãªã„å¯èƒ½æ€§ãŒã‚ã‚‹ã‚‚ã®ãŒã‚ã‚Œã°æç¤º
- æ¦‚å¿µåã¨ç°¡æ½”ãªèª¬æ˜ï¼ˆ1-2æ–‡ï¼‰ã®ã¿
- æ—¢çŸ¥ã®åŸºæœ¬æ¦‚å¿µï¼ˆå¤‰æ•°ã€é–¢æ•°ãªã©ï¼‰ã¯ä¸è¦

### æŠ€è¡“é¸å®šï¼ˆtech_selectionï¼‰
- ã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã§è¤‡æ•°ã®é¸æŠè‚¢ãŒã‚ã‚‹æŠ€è¡“æ±ºå®šãŒå¿…è¦ãªå ´åˆã®ã¿
- ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚„å‰ã®ã‚¹ãƒ†ãƒƒãƒ—ã§æ—¢ã«æ±ºã¾ã£ã¦ã„ã‚‹å ´åˆã¯ä¸è¦
- é¸æŠè‚¢ã¯ä»£è¡¨çš„ãªã‚‚ã®2-4å€‹ã€ãã‚Œãã‚Œåå‰ã¨ç°¡æ½”ãªèª¬æ˜

## å‡ºåŠ›å½¢å¼ï¼ˆJSONï¼‰
{{
  "objective": "ã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã§ä½•ã‚’ã™ã‚‹ã‹ï¼ˆ1æ–‡ï¼‰",
  "prerequisite": {{
    "needed": true/false,
    "concept": "æ¦‚å¿µåï¼ˆä¾‹: DBãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰",
    "brief": "ç°¡æ½”ãªèª¬æ˜ï¼ˆ1-2æ–‡ï¼‰"
  }},
  "tech_selection": {{
    "needed": true/false,
    "question": "é¸å®šã®è³ªå•ï¼ˆä¾‹: ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ„ãƒ¼ãƒ«ã‚’é¸ã³ã¾ã—ã‚‡ã†ï¼‰",
    "options": [
      {{"id": "tool1", "name": "ãƒ„ãƒ¼ãƒ«å", "description": "ç°¡æ½”ãªèª¬æ˜"}}
    ]
  }}
}}
"""

        try:
            response = await self.llm.ainvoke([
                SystemMessage(content="ãƒãƒ³ã‚ºã‚ªãƒ³ãƒ¬ã‚¯ãƒãƒ£ãƒ¼ã®ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚åˆå¿ƒè€…å‘ã‘ã«å¿…è¦ãªèª¬æ˜ã‚’åˆ¤æ–­ã—ã¦JSONå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚"),
                HumanMessage(content=prompt)
            ])

            content = response.content
            if "```json" in content:
                content = content.split("```json")[1].split("```")[0]
            elif "```" in content:
                content = content.split("```")[1].split("```")[0]

            data = json.loads(content.strip())

            # StepRequirements ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’æ§‹ç¯‰
            prereq = data.get("prerequisite", {})
            tech = data.get("tech_selection", {})

            return StepRequirements(
                objective=data.get("objective", step.description),
                prerequisite_concept=prereq.get("concept") if prereq.get("needed") else None,
                prerequisite_brief=prereq.get("brief") if prereq.get("needed") else None,
                tech_selection_needed=tech.get("needed", False),
                tech_selection_question=tech.get("question") if tech.get("needed") else None,
                tech_selection_options=tech.get("options", []) if tech.get("needed") else []
            )
        except Exception:
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼ˆé¸å®šä¸è¦ï¼‰
            return StepRequirements(
                objective=step.description,
                tech_selection_needed=False
            )

    async def _save_progress(self, session: SessionState, state: str = "generating") -> TaskHandsOn:
        """é€²æ—ã‚’DBã«ä¿å­˜ï¼ˆä¸­é–“ä¿å­˜ï¼‰"""
        existing = self.db.query(TaskHandsOn).filter(
            TaskHandsOn.task_id == self.task.task_id
        ).first()

        # å®Ÿè£…ã‚¹ãƒ†ãƒƒãƒ—ã‚’JSONã«å¤‰æ›
        steps_data = [
            {
                "step_number": s.step_number,
                "title": s.title,
                "description": s.description,
                "content": s.content,
                "is_completed": s.is_completed,
                "user_feedback": s.user_feedback
            }
            for s in session.implementation_steps
        ]

        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³å±¥æ­´
        interactions = [
            {"type": "choice", "choice_id": k, **v}
            for k, v in session.user_choices.items()
        ]

        # æ±ºå®šäº‹é …ã‚’JSONã«å¤‰æ›
        decisions_data = [
            {
                "step_number": d.step_number,
                "description": d.description,
                "reason": d.reason
            }
            for d in session.decisions
        ]

        # ä¿ç•™ä¸­ã®å¤‰æ›´ææ¡ˆ
        pending_decision_data = session.pending_decision if session.pending_decision else None

        # ä¿ç•™ä¸­ã®å…¥åŠ›ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        pending_input_data = None
        if session.pending_input:
            pending_input_data = {
                "prompt_id": session.pending_input.prompt_id,
                "question": session.pending_input.question,
                "placeholder": session.pending_input.placeholder,
                "options": session.pending_input.options
            }

        # ä¿ç•™ä¸­ã®é¸æŠè‚¢ï¼ˆpending_choiceï¼‰
        pending_choice_data = None
        if session.pending_choice:
            pending_choice_data = {
                "choice_id": session.pending_choice.choice_id,
                "question": session.pending_choice.question,
                "options": [
                    {
                        "id": opt.id,
                        "label": opt.label,
                        "description": opt.description,
                        "pros": opt.pros,
                        "cons": opt.cons
                    }
                    for opt in session.pending_choice.options
                ],
                "allow_custom": session.pending_choice.allow_custom,
                "skip_allowed": session.pending_choice.skip_allowed,
                "research_hint": session.pending_choice.research_hint
            }

        # ç¢ºèªå¾…ã¡çŠ¶æ…‹ã‚’pending_stateãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«ä¿å­˜
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³å¾©å¸°æ™‚ã«æ­£ç¢ºã«çŠ¶æ…‹ã‚’å¾©å…ƒã™ã‚‹ãŸã‚
        pending_state_data = None
        if session.pending_choice:
            pending_state_data = {
                "type": "choice",
                "state": {"choice": pending_choice_data},
                "entered_at": datetime.now().isoformat(),
                "phase": session.phase.value
            }
        elif session.pending_input:
            # ã‚¹ãƒ†ãƒƒãƒ—å®Œäº†ç¢ºèªã‹é€šå¸¸ã®å…¥åŠ›ã‹ã‚’åˆ¤å®š
            pending_type = "step_confirmation" if session.phase == GenerationPhase.WAITING_STEP_COMPLETE else "input"
            pending_state_data = {
                "type": pending_type,
                "state": {"input": pending_input_data},
                "entered_at": datetime.now().isoformat(),
                "phase": session.phase.value
            }

        # ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã®æŠ€è¡“é¸æŠã‚’JSONåŒ–ï¼ˆã‚­ãƒ¼ã‚’strã«å¤‰æ›ï¼‰
        step_choices_data = {
            str(k): v for k, v in session.step_choices.items()
        }

        user_interactions_data = {
            "choices": interactions,
            "inputs": session.user_inputs,
            "steps": steps_data,
            "current_step": session.current_step_index,
            "phase": session.phase.value,
            "decisions": decisions_data,
            "pending_decision": pending_decision_data,
            "pending_input": pending_input_data,
            "pending_choice": pending_choice_data,  # é¸æŠè‚¢å¾…ã¡çŠ¶æ…‹ã‚‚ä¿å­˜
            "step_choices": step_choices_data,
            "project_implementation_overview": session.project_implementation_overview
        }

        # å®Œäº†æ™‚ã¯å®Ÿè£…ãƒªã‚½ãƒ¼ã‚¹ã‚µãƒãƒªãƒ¼ã‚’ç”Ÿæˆ
        implementation_resources = None
        if state == "completed":
            implementation_resources = await self._generate_implementation_resources(session)

        if existing:
            existing.overview = session.generated_content.get("overview", "")
            existing.implementation_steps = session.generated_content.get("implementation", "")
            existing.verification = session.generated_content.get("verification", "")
            existing.technical_context = session.generated_content.get("context", "")
            existing.user_interactions = user_interactions_data
            existing.generation_mode = "interactive"
            existing.generation_state = state
            existing.session_id = session.session_id
            existing.pending_state = pending_state_data  # ç¢ºèªå¾…ã¡çŠ¶æ…‹ã‚’ä¿å­˜
            existing.updated_at = datetime.now()
            if implementation_resources:
                existing.implementation_resources = implementation_resources
            self.db.commit()
            return existing
        else:
            hands_on = TaskHandsOn(
                task_id=self.task.task_id,
                overview=session.generated_content.get("overview", ""),
                implementation_steps=session.generated_content.get("implementation", ""),
                verification=session.generated_content.get("verification", ""),
                technical_context=session.generated_content.get("context", ""),
                generation_model=self.config.get("model", "gemini-2.0-flash"),
                quality_score=0.8,
                generation_mode="interactive",
                generation_state=state,
                session_id=session.session_id,
                user_interactions=user_interactions_data,
                implementation_resources=implementation_resources,
                pending_state=pending_state_data  # ç¢ºèªå¾…ã¡çŠ¶æ…‹ã‚’ä¿å­˜
            )
            self.db.add(hands_on)
            self.db.commit()
            self.db.refresh(hands_on)
            return hands_on

    async def _summarize_implementation(self, predecessor_task: Dict) -> Optional[str]:
        """
        å®Œäº†æ¸ˆã¿ä¾å­˜ã‚¿ã‚¹ã‚¯ã®å®Ÿè£…å†…å®¹ã‚’ã‚µãƒãƒªãƒ¼

        Args:
            predecessor_task: ä¾å­˜ã‚¿ã‚¹ã‚¯æƒ…å ±ï¼ˆhands_on_contentã‚’å«ã‚€ï¼‰

        Returns:
            å®Ÿè£…ã‚µãƒãƒªãƒ¼ï¼ˆä¾‹ï¼šã€ŒPOST /api/chat ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆå®Ÿè£…æ¸ˆã¿ã€Gemini APIçµ±åˆæ¸ˆã¿ã€ï¼‰
        """
        hands_on_content = predecessor_task.get("hands_on_content")
        if not hands_on_content:
            return None

        overview = hands_on_content.get("overview", "")
        steps = hands_on_content.get("steps", [])
        impl_summary = hands_on_content.get("implementation_summary", "")

        # ã‚¹ãƒ†ãƒƒãƒ—å†…å®¹ã‚’çµåˆ
        steps_text = "\n".join([
            f"- {s.get('title', '')}: {s.get('content', '')[:300]}"
            for s in steps[:5]  # æœ€å¤§5ã‚¹ãƒ†ãƒƒãƒ—
        ])

        prompt = f"""
ä»¥ä¸‹ã®å®Œäº†æ¸ˆã¿ã‚¿ã‚¹ã‚¯ã®å®Ÿè£…å†…å®¹ã‹ã‚‰ã€ã€Œä½•ãŒå®Ÿè£…ã•ã‚ŒãŸã‹ã€ã‚’ç°¡æ½”ã«ç®‡æ¡æ›¸ãã§ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚
ç‰¹ã«APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã€ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã€ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã€å¤–éƒ¨ã‚µãƒ¼ãƒ“ã‚¹é€£æºãªã©ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚

## ã‚¿ã‚¹ã‚¯
ã‚¿ã‚¤ãƒˆãƒ«: {predecessor_task.get('title', '')}
èª¬æ˜: {predecessor_task.get('description', '')}

## æ¦‚è¦
{overview[:500]}

## å®Ÿè£…ã‚¹ãƒ†ãƒƒãƒ—
{steps_text}

## å®Ÿè£…å†…å®¹ã‚µãƒãƒªãƒ¼
{impl_summary[:500]}

## å‡ºåŠ›å½¢å¼
- å®Ÿè£…ã•ã‚ŒãŸAPIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼ˆã‚ã‚Œã°ï¼‰
- å®Ÿè£…ã•ã‚ŒãŸã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ/ã‚¯ãƒ©ã‚¹ï¼ˆã‚ã‚Œã°ï¼‰
- é€£æºã—ãŸå¤–éƒ¨ã‚µãƒ¼ãƒ“ã‚¹ï¼ˆã‚ã‚Œã°ï¼‰
- ãã®ä»–ã®å®Ÿè£…å†…å®¹

ç°¡æ½”ã«3-5è¡Œã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
"""

        try:
            response = await self.llm.ainvoke([
                SystemMessage(content="å®Ÿè£…å†…å®¹ã‚’ç°¡æ½”ã«ã¾ã¨ã‚ã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"),
                HumanMessage(content=prompt)
            ])
            return response.content.strip()
        except Exception as e:
            return f"ã‚µãƒãƒªãƒ¼ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)}"

    async def _generate_implementation_resources(self, session: SessionState) -> Dict:
        """
        ã‚¿ã‚¹ã‚¯å®Œäº†æ™‚ã«å®Ÿè£…æ¸ˆã¿ãƒªã‚½ãƒ¼ã‚¹ã‚’JSONå½¢å¼ã§æŠ½å‡º

        Returns:
            {
                "apis": ["POST /api/chat", "GET /api/users/{id}"],
                "components": ["ChatComponent", "UserList"],
                "services": ["GeminiService"],
                "files": ["src/app/api/chat/route.ts"],
                "summary": "ãƒãƒ£ãƒƒãƒˆAPIã¨Geminiçµ±åˆã‚’å®Ÿè£…"
            }
        """
        overview = session.generated_content.get("overview", "")
        implementation = session.generated_content.get("implementation", "")

        # ã‚¹ãƒ†ãƒƒãƒ—å†…å®¹ã‚’å–å¾—
        steps_text = ""
        for step in session.implementation_steps:
            if step.content:
                steps_text += f"\n### {step.title}\n{step.content[:500]}\n"

        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æŠ€è¡“é¸æŠã‚’å–å¾—ï¼ˆæ–°å½¢å¼: domain_key/stack_key å¯¾å¿œï¼‰
        choices_text = ""
        if session.user_choices:
            choices_text = "\n## æŠ€è¡“é¸æŠ\n"
            for choice_id, choice_data in session.user_choices.items():
                if "domain_key" in choice_data and "stack_key" in choice_data:
                    # æ–°å½¢å¼: DBãƒ—ãƒªã‚»ãƒƒãƒˆã‹ã‚‰ã®é¸æŠ
                    domain = self.tech_service.get_domain_by_key(choice_data["domain_key"])
                    domain_name = domain.name if domain else choice_data["domain_key"]
                    choices_text += f"- {domain_name}: {choice_data['stack_key']}\n"
                else:
                    # å¾“æ¥å½¢å¼ï¼ˆå¾Œæ–¹äº’æ›ï¼‰
                    selected = choice_data.get("selected", "")
                    if selected:
                        choices_text += f"- {selected}\n"

        prompt = f"""
ä»¥ä¸‹ã®å®Œäº†ã—ãŸã‚¿ã‚¹ã‚¯ã‹ã‚‰ã€å®Ÿè£…ã•ã‚ŒãŸãƒªã‚½ãƒ¼ã‚¹ã¨æŠ€è¡“æ±ºå®šã‚’JSONå½¢å¼ã§æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚

## ã‚¿ã‚¹ã‚¯æƒ…å ±
- ã‚¿ã‚¤ãƒˆãƒ«: {self.task.title}
- èª¬æ˜: {self.task.description or 'ãªã—'}

## æ¦‚è¦
{overview[:500]}

## å®Ÿè£…å†…å®¹
{implementation[:1500]}

## ã‚¹ãƒ†ãƒƒãƒ—
{steps_text[:1500]}
{choices_text}
## å‡ºåŠ›å½¢å¼ï¼ˆJSONï¼‰
{{
  "apis": ["POST /api/xxx", "GET /api/yyy"],  // å®Ÿè£…ã—ãŸAPIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
  "components": ["XxxComponent"],  // å®Ÿè£…ã—ãŸReactã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆç­‰
  "services": ["XxxService"],  // å®Ÿè£…ã—ãŸã‚µãƒ¼ãƒ“ã‚¹ã‚¯ãƒ©ã‚¹ç­‰
  "files": ["src/xxx/yyy.ts"],  // ä¸»è¦ãªä½œæˆãƒ»ä¿®æ­£ãƒ•ã‚¡ã‚¤ãƒ«
  "tech_decisions": ["REST APIã‚’ä½¿ç”¨", "TypeScriptã‚’æ¡ç”¨"],  // æŠ€è¡“æ±ºå®š
  "summary": "ã€‡ã€‡æ©Ÿèƒ½ã‚’å®Ÿè£…"  // 1è¡Œã‚µãƒãƒªãƒ¼
}}

**æ³¨æ„:**
- å­˜åœ¨ã—ãªã„ã‚‚ã®ã¯ç©ºé…åˆ—[]ã«ã™ã‚‹
- ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã¯ä¸»è¦ãªã‚‚ã®ã®ã¿ï¼ˆæœ€å¤§5ã¤ï¼‰
- summaryã¯20æ–‡å­—ä»¥å†…
"""

        try:
            response = await self.llm.ainvoke([
                SystemMessage(content="å®Ÿè£…å†…å®¹ã‹ã‚‰ãƒªã‚½ãƒ¼ã‚¹ã‚’æŠ½å‡ºã™ã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚JSONå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚"),
                HumanMessage(content=prompt)
            ])

            content = response.content
            if "```json" in content:
                content = content.split("```json")[1].split("```")[0]
            elif "```" in content:
                content = content.split("```")[1].split("```")[0]

            return json.loads(content.strip())
        except Exception as e:
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ç©ºã®ãƒªã‚½ãƒ¼ã‚¹
            return {
                "apis": [],
                "components": [],
                "services": [],
                "files": [],
                "tech_decisions": [],
                "summary": self.task.title[:20] if self.task.title else ""
            }

    async def _generate_implementation_plan(
        self,
        user_choices: Dict[str, Any],
        session: SessionState
    ) -> List[ImplementationStep]:
        """MVPã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§å®Ÿè£…ã‚¹ãƒ†ãƒƒãƒ—ã‚’è¨ˆç”»"""
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼é¸æŠã‚’æ–‡å­—åˆ—åŒ–ï¼ˆæ–°å½¢å¼: domain_key/stack_key å¯¾å¿œï¼‰
        choices_text = ""
        if user_choices:
            for choice_id, choice_data in user_choices.items():
                if "domain_key" in choice_data and "stack_key" in choice_data:
                    # æ–°å½¢å¼: DBãƒ—ãƒªã‚»ãƒƒãƒˆã‹ã‚‰ã®é¸æŠ
                    domain = self.tech_service.get_domain_by_key(choice_data["domain_key"])
                    domain_name = domain.name if domain else choice_data["domain_key"]
                    choices_text += f"- {domain_name}: {choice_data['stack_key']}\n"
                else:
                    # å¾“æ¥å½¢å¼ï¼ˆå¾Œæ–¹äº’æ›ï¼‰
                    choices_text += f"- é¸æŠ: {choice_data.get('selected', 'ãªã—')}\n"

        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå…¨ä½“ã§æ±ºå®šæ¸ˆã¿ã®æŠ€è¡“ï¼ˆDBã‹ã‚‰å–å¾—ï¼‰
        decided_tech_section = ""
        if self.decided_domains:
            decided_tech_section = "\n## ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§æ±ºå®šæ¸ˆã¿ã®æŠ€è¡“ï¼ˆå¿…ãšä½¿ç”¨ã™ã‚‹ã“ã¨ï¼‰\n"
            for domain_key, stack_key in self.decided_domains.items():
                domain = self.tech_service.get_domain_by_key(domain_key)
                domain_name = domain.name if domain else domain_key
                decided_tech_section += f"- {domain_name}: {stack_key}\n"

        # ä¾å­˜ã‚¿ã‚¹ã‚¯ã®å®Ÿè£…ã‚µãƒãƒªãƒ¼ã‚’å–å¾—ï¼ˆç›´æ¥ä¾å­˜ã®ã¿è©³ç´°ï¼‰
        dependency_summary = ""
        if session.predecessor_tasks:
            completed_deps = [
                dep for dep in session.predecessor_tasks
                if dep.hands_on_status == "completed" and dep.implementation_summary
            ]
            if completed_deps:
                dependency_summary = "\n## ç›´æ¥ä¾å­˜ã‚¿ã‚¹ã‚¯ã§å®Ÿè£…æ¸ˆã¿ã®å†…å®¹ï¼ˆå¿…ãšåˆ©ç”¨ã™ã‚‹ã“ã¨ï¼‰\n"
                for dep in completed_deps:
                    dependency_summary += f"\n### {dep.title}\n{dep.implementation_summary}\n"

        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå…¨ä½“ã®å®Ÿè£…æ¦‚è¦ï¼ˆé«˜ãƒ¬ãƒ™ãƒ«ã€é‡è¤‡å›é¿ç”¨ï¼‰
        project_overview_section = ""
        if session.project_implementation_overview:
            project_overview_section = f"""
## ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå†…ã§å®Ÿè£…æ¸ˆã¿ã®æ©Ÿèƒ½ï¼ˆé‡è¤‡å®Ÿè£…ã‚’é¿ã‘ã‚‹ã“ã¨ï¼‰
ä»¥ä¸‹ã®æ©Ÿèƒ½ã¯æ—¢ã«ä»–ã®ã‚¿ã‚¹ã‚¯ã§å®Ÿè£…æ¸ˆã¿ã§ã™ã€‚å†å®Ÿè£…ã›ãšã€æ—¢å­˜ã®ã‚‚ã®ã‚’åˆ©ç”¨ã—ã¦ãã ã•ã„ã€‚

{session.project_implementation_overview}
"""

        # ãƒ¢ãƒƒã‚¯å®Ÿè£…ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã®è¿½åŠ æŒ‡ç¤º
        mock_instruction = ""
        if session.dependency_decision == "mock":
            incomplete_deps = [
                dep for dep in session.predecessor_tasks
                if dep.hands_on_status != "completed"
            ]
            if incomplete_deps:
                dep_titles = ", ".join([dep.title for dep in incomplete_deps])
                mock_instruction = f"""
## ãƒ¢ãƒƒã‚¯å®Ÿè£…ã«ã¤ã„ã¦
ä¾å­˜ã‚¿ã‚¹ã‚¯ã€Œ{dep_titles}ã€ãŒæœªå®Œäº†ã®ãŸã‚ã€ãƒ¢ãƒƒã‚¯å®Ÿè£…ã§é€²ã‚ã¾ã™ã€‚
- ä¾å­˜ã‚¿ã‚¹ã‚¯ã¨ã®æ¥ç¶šéƒ¨åˆ†ã¯ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’æ˜ç¢ºã«å®šç¾©
- ãƒ¢ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã‚„ã‚¹ã‚¿ãƒ–é–¢æ•°ã‚’ä½¿ç”¨
- å¾Œã§çµåˆã—ã‚„ã™ã„ã‚ˆã†ã«è¨­è¨ˆ
"""

        # å¾Œç¶šã‚¿ã‚¹ã‚¯æƒ…å ±ã‚’å–å¾—ï¼ˆã‚¹ã‚³ãƒ¼ãƒ—åˆ¤æ–­ç”¨ï¼‰
        successor_tasks_text = ""
        if session.successor_tasks:
            successor_tasks_text = "\n## ã“ã®ã‚¿ã‚¹ã‚¯ã®å¾Œã«å®Ÿè£…äºˆå®šã®ã‚¿ã‚¹ã‚¯ï¼ˆã“ã‚Œã‚‰ã¯ã“ã®ã‚¿ã‚¹ã‚¯ã®ã‚¹ã‚³ãƒ¼ãƒ—å¤–ï¼‰\n"
            for st in session.successor_tasks:
                successor_tasks_text += f"- {st.title}: {st.description[:100] if st.description else 'ãªã—'}\n"

        prompt = f"""
ä»¥ä¸‹ã®ã‚¿ã‚¹ã‚¯ã‚’MVPã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§æ®µéšçš„ã«å®Ÿè£…ã™ã‚‹è¨ˆç”»ã‚’ç«‹ã¦ã¦ãã ã•ã„ã€‚
{dependency_summary}
{project_overview_section}

## ã‚¿ã‚¹ã‚¯æƒ…å ±
- ã‚¿ã‚¤ãƒˆãƒ«: {self.task.title}
- èª¬æ˜: {self.task.description or 'ãªã—'}
- ã‚«ãƒ†ã‚´ãƒª: {self.task.category or 'æœªåˆ†é¡'}
{choices_text}
{decided_tech_section}
{successor_tasks_text}

## ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±
- æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯: {', '.join(self.project_context.get('tech_stack', []))}
- ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯: {self.project_context.get('framework', 'æœªè¨­å®š')}
{mock_instruction}

## é‡è¦ï¼šã‚¹ã‚³ãƒ¼ãƒ—ã®åˆ¶ç´„
**ã“ã®ã‚¿ã‚¹ã‚¯ã®ã‚¹ã‚³ãƒ¼ãƒ—ï¼ˆã‚«ãƒ†ã‚´ãƒª: {self.task.category or 'æœªåˆ†é¡'}ï¼‰å†…ã®ã¿ã§è¨ˆç”»ã‚’ç«‹ã¦ã¦ãã ã•ã„ã€‚**

- ã‚¿ã‚¹ã‚¯ã®ã‚¿ã‚¤ãƒˆãƒ«ã¨èª¬æ˜ã«è¨˜è¼‰ã•ã‚ŒãŸç¯„å›²ã®ã¿ã‚’å®Ÿè£…ã™ã‚‹
- å¾Œç¶šã‚¿ã‚¹ã‚¯ã¨ã—ã¦æŒ™ã’ã‚‰ã‚Œã¦ã„ã‚‹å†…å®¹ã¯çµ¶å¯¾ã«å«ã‚ãªã„
- ä¾‹: ã€ŒDBè¨­è¨ˆã€ã‚¿ã‚¹ã‚¯ãªã‚‰ã‚¹ã‚­ãƒ¼ãƒå®šç¾©ãƒ»ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¾ã§ã€‚APIå®Ÿè£…ã¯å¾Œç¶šã‚¿ã‚¹ã‚¯
- ä¾‹: ã€Œãƒ¢ãƒ‡ãƒ«å®šç¾©ã€ã‚¿ã‚¹ã‚¯ãªã‚‰ãƒ¢ãƒ‡ãƒ«ã‚¯ãƒ©ã‚¹ã®ä½œæˆã¾ã§ã€‚CRUDæ“ä½œã¯å¾Œç¶šã‚¿ã‚¹ã‚¯
- ã‚¹ã‚³ãƒ¼ãƒ—å¤–ã®å®Ÿè£…ãŒå¿…è¦ã«è¦‹ãˆã¦ã‚‚ã€ãã‚Œã¯å¾Œç¶šã‚¿ã‚¹ã‚¯ã§è¡Œã†

## è¨ˆç”»ã®ãƒ«ãƒ¼ãƒ«
1. æœ€åˆã®ã‚¹ãƒ†ãƒƒãƒ—ã¯å¿…ãšã€Œãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ/ãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆãƒ»åˆæœŸè¨­å®šã€
2. æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã¯ã€ŒåŸºæœ¬çš„ãªå‹•ä½œç¢ºèªãŒã§ãã‚‹æœ€å°æ§‹æˆã€
3. ãã®å¾Œã€ã‚³ã‚¢æ©Ÿèƒ½ã‚’æ®µéšçš„ã«è¿½åŠ 
4. å„ã‚¹ãƒ†ãƒƒãƒ—ã¯ç‹¬ç«‹ã—ã¦å‹•ä½œç¢ºèªã§ãã‚‹å˜ä½ã«ã™ã‚‹
5. ã‚¹ãƒ†ãƒƒãƒ—æ•°ã¯3ã€œ5å€‹ç¨‹åº¦
6. **å®Ÿè£…æ¸ˆã¿ã®æ©Ÿèƒ½ã¯å†å®Ÿè£…ã—ãªã„**
7. **å¾Œç¶šã‚¿ã‚¹ã‚¯ã®å†…å®¹ã¯çµ¶å¯¾ã«å«ã‚ãªã„**

## å‡ºåŠ›å½¢å¼ï¼ˆJSONï¼‰
{{
  "steps": [
    {{
      "step_number": 1,
      "title": "ã‚¹ãƒ†ãƒƒãƒ—ã®ã‚¿ã‚¤ãƒˆãƒ«",
      "description": "ã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã§ä½•ã‚’ã™ã‚‹ã‹ï¼ˆ1-2æ–‡ï¼‰"
    }}
  ]
}}
"""

        response = await self.llm.ainvoke([
            SystemMessage(content="ã‚ãªãŸã¯MVPé–‹ç™ºã®ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã§ã™ã€‚JSONå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚"),
            HumanMessage(content=prompt)
        ])

        try:
            content = response.content
            if "```json" in content:
                content = content.split("```json")[1].split("```")[0]
            elif "```" in content:
                content = content.split("```")[1].split("```")[0]

            data = json.loads(content.strip())

            return [
                ImplementationStep(
                    step_number=s["step_number"],
                    title=s["title"],
                    description=s["description"]
                )
                for s in data.get("steps", [])
            ]
        except (json.JSONDecodeError, KeyError):
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ã‚¹ãƒ†ãƒƒãƒ—
            return [
                ImplementationStep(1, "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåˆæœŸè¨­å®š", "å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ã¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆã—ã¾ã™"),
                ImplementationStep(2, "åŸºæœ¬å®Ÿè£…", "æœ€å°é™ã®å‹•ä½œã™ã‚‹å®Ÿè£…ã‚’ä½œæˆã—ã¾ã™"),
                ImplementationStep(3, "æ©Ÿèƒ½è¿½åŠ ", "ã‚³ã‚¢æ©Ÿèƒ½ã‚’å®Ÿè£…ã—ã¾ã™"),
            ]

    async def _generate_step_content(
        self,
        step: ImplementationStep,
        user_choices: Dict[str, Any],
        previous_steps: List[ImplementationStep],
        decisions: List[Decision] = None,
        session: SessionState = None
    ) -> AsyncGenerator[str, None]:
        """ã‚¹ãƒ†ãƒƒãƒ—ã®å®Ÿè£…å†…å®¹ã‚’ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ç”Ÿæˆ"""
        # ã‚¿ã‚¹ã‚¯å…¨ä½“ã®é¸æŠï¼ˆæ–°å½¢å¼: domain_key/stack_key å¯¾å¿œï¼‰
        choices_text = ""
        if user_choices:
            for choice_id, choice_data in user_choices.items():
                if "domain_key" in choice_data and "stack_key" in choice_data:
                    # æ–°å½¢å¼: DBãƒ—ãƒªã‚»ãƒƒãƒˆã‹ã‚‰ã®é¸æŠ
                    domain = self.tech_service.get_domain_by_key(choice_data["domain_key"])
                    domain_name = domain.name if domain else choice_data["domain_key"]
                    choices_text += f"- {domain_name}: {choice_data['stack_key']}\n"
                else:
                    # å¾“æ¥å½¢å¼ï¼ˆå¾Œæ–¹äº’æ›ï¼‰
                    choices_text += f"- é¸æŠ: {choice_data.get('selected', 'ãªã—')}\n"

        # ã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã§é¸æŠã—ãŸæŠ€è¡“
        step_choice_text = ""
        if session and step.step_number in session.step_choices:
            step_choice = session.step_choices[step.step_number]
            if "domain_key" in step_choice and "stack_key" in step_choice:
                # æ–°å½¢å¼
                domain = self.tech_service.get_domain_by_key(step_choice["domain_key"])
                domain_name = domain.name if domain else step_choice["domain_key"]
                step_choice_text = f"\n## ã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã§é¸æŠã—ãŸæŠ€è¡“ï¼ˆå¿…ãšã“ã‚Œã‚’ä½¿ã£ã¦å®Ÿè£…ã™ã‚‹ã“ã¨ï¼‰\n- **{domain_name}: {step_choice['stack_key']}**\n"
            else:
                # å¾“æ¥å½¢å¼
                step_choice_text = f"\n## ã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã§é¸æŠã—ãŸæŠ€è¡“ï¼ˆå¿…ãšã“ã‚Œã‚’ä½¿ã£ã¦å®Ÿè£…ã™ã‚‹ã“ã¨ï¼‰\n- **{step_choice.get('selected', '')}**\n"

        prev_steps_text = ""
        if previous_steps:
            prev_steps_text = "\n## å®Œäº†æ¸ˆã¿ã‚¹ãƒ†ãƒƒãƒ—\n"
            for ps in previous_steps:
                prev_steps_text += f"- ã‚¹ãƒ†ãƒƒãƒ—{ps.step_number}: {ps.title} âœ“\n"

        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ¡ç”¨ã—ãŸæ±ºå®šäº‹é …
        decisions_context = ""
        if decisions:
            decisions_context = "\n## ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ¡ç”¨ã—ãŸæ±ºå®šäº‹é …ï¼ˆå¿…ãšåæ˜ ã—ã¦ãã ã•ã„ï¼‰\n"
            for d in decisions:
                decisions_context += f"- **{d.description}**ï¼ˆã‚¹ãƒ†ãƒƒãƒ—{d.step_number}ã§æ±ºå®šï¼‰\n"

        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå†…ã§å®Ÿè£…æ¸ˆã¿ã®æ©Ÿèƒ½
        project_overview_context = ""
        if session and session.project_implementation_overview:
            project_overview_context = f"""
## ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå†…ã§å®Ÿè£…æ¸ˆã¿ã®æ©Ÿèƒ½ï¼ˆå†å®Ÿè£…ã—ãªã„ã“ã¨ï¼‰
{session.project_implementation_overview}
"""

        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå…¨ä½“ã§æ±ºå®šæ¸ˆã¿ã®æŠ€è¡“ï¼ˆDBã‹ã‚‰å–å¾—ï¼‰
        decided_tech_context = ""
        if self.decided_domains:
            decided_tech_context = "\n## ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§æ±ºå®šæ¸ˆã¿ã®æŠ€è¡“ï¼ˆå¿…ãšä½¿ç”¨ã™ã‚‹ã“ã¨ï¼‰\n"
            for domain_key, stack_key in self.decided_domains.items():
                domain = self.tech_service.get_domain_by_key(domain_key)
                domain_name = domain.name if domain else domain_key
                decided_tech_context += f"- {domain_name}: {stack_key}\n"

        prompt = f"""
ä»¥ä¸‹ã®ã‚¹ãƒ†ãƒƒãƒ—ã®è©³ç´°ãªå®Ÿè£…æ‰‹é †ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚
{project_overview_context}

## ã‚¿ã‚¹ã‚¯æƒ…å ±
- ã‚¿ã‚¤ãƒˆãƒ«: {self.task.title}
- èª¬æ˜: {self.task.description or 'ãªã—'}
- ã‚«ãƒ†ã‚´ãƒª: {self.task.category or 'æœªåˆ†é¡'}
{choices_text}
{decided_tech_context}
{step_choice_text}
{prev_steps_text}
{decisions_context}

## ç¾åœ¨ã®ã‚¹ãƒ†ãƒƒãƒ—
- ã‚¹ãƒ†ãƒƒãƒ—{step.step_number}: {step.title}
- ç›®çš„: {step.description}

## ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±
- æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯: {', '.join(self.project_context.get('tech_stack', []))}
- ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯: {self.project_context.get('framework', 'æœªè¨­å®š')}
- ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ : {self.project_context.get('directory_info', 'æœªè¨­å®š')[:500]}

## é‡è¦ãªæ³¨æ„äº‹é …
- **ã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã®ç¯„å›²å†…ã®ã¿ã§å®Ÿè£…ã™ã‚‹ã“ã¨**ï¼ˆã‚¹ã‚³ãƒ¼ãƒ—å¤–ã®å†…å®¹ã¯æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã¾ãŸã¯åˆ¥ã‚¿ã‚¹ã‚¯ã§è¡Œã†ï¼‰
- ã€Œã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã§é¸æŠã—ãŸæŠ€è¡“ã€ã¯å¿…ãšãã‚Œã‚’ä½¿ã£ã¦å®Ÿè£…ã—ã¦ãã ã•ã„
- ã€Œãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ¡ç”¨ã—ãŸæ±ºå®šäº‹é …ã€ã¯å¿…ãšåæ˜ ã—ã¦ãã ã•ã„
- ã€Œå®Ÿè£…æ¸ˆã¿ã®æ©Ÿèƒ½ã€ã¯å†å®Ÿè£…ã—ãªã„ã§ãã ã•ã„ï¼ˆæ—¢å­˜ã®ã‚‚ã®ã‚’import/å‘¼ã³å‡ºã—ã—ã¦åˆ©ç”¨ï¼‰

## å‡ºåŠ›å½¢å¼
Markdownå½¢å¼ã§ä»¥ä¸‹ã‚’å«ã‚ã¦ãã ã•ã„ï¼š

### ã‚¹ãƒ†ãƒƒãƒ—{step.step_number}: {step.title}

#### ç›®çš„

ã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã®ç›®çš„ã‚’1-2æ–‡ã§èª¬æ˜

#### å®Ÿè£…æ‰‹é †

1. æœ€åˆã«ã‚„ã‚‹ã“ã¨

```è¨€èª
ã‚³ãƒ¼ãƒ‰ä¾‹
```

2. æ¬¡ã«ã‚„ã‚‹ã“ã¨

```è¨€èª
ã‚³ãƒ¼ãƒ‰ä¾‹
```

#### å‹•ä½œç¢ºèª

ã“ã®ã‚¹ãƒ†ãƒƒãƒ—ãŒå®Œäº†ã—ãŸã‹ç¢ºèªã™ã‚‹æ–¹æ³•

---

**é‡è¦ãªæ›¸å¼ãƒ«ãƒ¼ãƒ«:**
- å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®é–“ã«ã¯å¿…ãšç©ºè¡Œã‚’å…¥ã‚Œã‚‹
- è¦‹å‡ºã—ï¼ˆ###, ####ï¼‰ã®å‰å¾Œã«ã¯ç©ºè¡Œã‚’å…¥ã‚Œã‚‹
- ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã®å‰å¾Œã«ã¯ç©ºè¡Œã‚’å…¥ã‚Œã‚‹
- ç®‡æ¡æ›¸ãã®å‰å¾Œã«ã¯ç©ºè¡Œã‚’å…¥ã‚Œã‚‹
"""

        async for chunk in self.llm.astream([
            SystemMessage(content="ã‚ãªãŸã¯ä¸å¯§ãªé–‹ç™ºã‚¬ã‚¤ãƒ‰ã‚’ä½œæˆã™ã‚‹ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ¡ç”¨ã—ãŸæ±ºå®šäº‹é …ï¼ˆè¨€èªã€ãƒ©ã‚¤ãƒ–ãƒ©ãƒªç­‰ï¼‰ã¯å¿…ãšåæ˜ ã—ã¦ãã ã•ã„ã€‚"),
            HumanMessage(content=prompt)
        ]):
            if chunk.content:
                yield chunk.content

    async def generate_stream(
        self,
        session: SessionState
    ) -> AsyncGenerator[Dict, None]:
        """
        ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã§ãƒãƒ³ã‚ºã‚ªãƒ³ã‚’ç”Ÿæˆ

        Yields:
            SSEã‚¤ãƒ™ãƒ³ãƒˆè¾æ›¸
        """
        try:
            # Phase 0: ä¾å­˜ã‚¿ã‚¹ã‚¯ãƒã‚§ãƒƒã‚¯
            if session.phase == GenerationPhase.DEPENDENCY_CHECK:
                # ä¾å­˜ã‚¿ã‚¹ã‚¯æƒ…å ±ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«è¨­å®š
                if self.dependency_context:
                    predecessor_tasks = self.dependency_context.get("predecessor_tasks", [])
                    has_incomplete = self.dependency_context.get("has_incomplete_predecessors", False)

                    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå…¨ä½“ã®å®Ÿè£…æ¦‚è¦ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«è¨­å®š
                    session.project_implementation_overview = self.dependency_context.get(
                        "project_implementation_overview", ""
                    )

                    # ä¾å­˜ã‚¿ã‚¹ã‚¯æƒ…å ±ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜ï¼ˆpredecessorsï¼‰
                    for pt in predecessor_tasks:
                        session.predecessor_tasks.append(DependencyTaskInfo(
                            task_id=pt["task_id"],
                            title=pt["title"],
                            description=pt["description"],
                            hands_on_status=pt["hands_on_status"],
                            implementation_summary=None  # å¾Œã§ã‚µãƒãƒªãƒ¼ç”Ÿæˆ
                        ))

                    # å¾Œç¶šã‚¿ã‚¹ã‚¯æƒ…å ±ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜ï¼ˆsuccessors: ã‚¹ã‚³ãƒ¼ãƒ—åˆ¤æ–­ç”¨ï¼‰
                    successor_tasks = self.dependency_context.get("successor_tasks", [])
                    for st in successor_tasks:
                        session.successor_tasks.append(DependencyTaskInfo(
                            task_id=st["task_id"],
                            title=st["title"],
                            description=st.get("description", ""),
                            hands_on_status="not_started",  # å¾Œç¶šã‚¿ã‚¹ã‚¯ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã¯å‚ç…§ã—ãªã„
                            implementation_summary=None
                        ))

                    # æœªå®Œäº†ã®ä¾å­˜ã‚¿ã‚¹ã‚¯ãŒã‚ã‚‹å ´åˆã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ç¢ºèª
                    if has_incomplete:
                        incomplete_tasks = [
                            pt for pt in predecessor_tasks
                            if pt["hands_on_status"] != "completed"
                        ]
                        task_list = "\n".join([f"- {pt['title']}" for pt in incomplete_tasks])

                        yield {"type": "section_start", "section": "dependency_check"}
                        warning_text = f"""âš ï¸ **æœªå®Œäº†ã®ä¾å­˜ã‚¿ã‚¹ã‚¯ãŒã‚ã‚Šã¾ã™**

ã“ã®ã‚¿ã‚¹ã‚¯ã¯ä»¥ä¸‹ã®ã‚¿ã‚¹ã‚¯ã«ä¾å­˜ã—ã¦ã„ã¾ã™ãŒã€ã¾ã å®Œäº†ã—ã¦ã„ã¾ã›ã‚“ï¼š

{task_list}

ã©ã®ã‚ˆã†ã«é€²ã‚ã¾ã™ã‹ï¼Ÿ
"""
                        for chunk in self._chunk_text(warning_text):
                            yield {"type": "chunk", "content": chunk}
                            await asyncio.sleep(0.02)

                        yield {"type": "section_complete", "section": "dependency_check"}

                        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«é¸æŠã‚’æ±‚ã‚ã‚‹
                        session.phase = GenerationPhase.WAITING_DEPENDENCY_DECISION
                        session.pending_input = InputPrompt(
                            prompt_id="dependency_decision",
                            question="ä¾å­˜ã‚¿ã‚¹ã‚¯ãŒæœªå®Œäº†ã§ã™ã€‚ã©ã®ã‚ˆã†ã«é€²ã‚ã¾ã™ã‹ï¼Ÿ",
                            options=["ãã®ã¾ã¾é€²ã‚ã‚‹", "ãƒ¢ãƒƒã‚¯ã§é€²ã‚ã‚‹ï¼ˆå¾Œã§çµåˆï¼‰", "å…ˆã«ä¾å­˜ã‚¿ã‚¹ã‚¯ã‚’å®Œäº†ã•ã›ã‚‹"]
                        )
                        await self._save_progress(session, "waiting_input")
                        yield {
                            "type": "step_confirmation_required",
                            "prompt": {
                                "prompt_id": session.pending_input.prompt_id,
                                "question": session.pending_input.question,
                                "options": session.pending_input.options
                            }
                        }
                        return

                    # å®Œäº†æ¸ˆã¿ã®ä¾å­˜ã‚¿ã‚¹ã‚¯ãŒã‚ã‚‹å ´åˆã¯ã‚µãƒãƒªãƒ¼ã‚’ç”Ÿæˆ
                    completed_tasks = [
                        pt for pt in predecessor_tasks
                        if pt["hands_on_status"] == "completed" and pt.get("hands_on_content")
                    ]
                    if completed_tasks:
                        yield {"type": "section_start", "section": "dependency_summary"}
                        summary_text = "ğŸ“‹ **ç›´æ¥ä¾å­˜ã‚¿ã‚¹ã‚¯ã®å®Ÿè£…çŠ¶æ³**\n\n"
                        for pt in completed_tasks:
                            summary_text += f"**{pt['title']}** ã¯å®Œäº†æ¸ˆã¿ã§ã™ã€‚\n"
                            # LLMã§ã‚µãƒãƒªãƒ¼ã‚’ç”Ÿæˆ
                            impl_summary = await self._summarize_implementation(pt)
                            if impl_summary:
                                summary_text += f"{impl_summary}\n\n"
                                # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜
                                for dep_info in session.predecessor_tasks:
                                    if dep_info.task_id == pt["task_id"]:
                                        dep_info.implementation_summary = impl_summary
                                        break

                        for chunk in self._chunk_text(summary_text):
                            yield {"type": "chunk", "content": chunk}
                            await asyncio.sleep(0.02)
                        yield {"type": "section_complete", "section": "dependency_summary"}
                        session.generated_content["dependency_summary"] = summary_text

                    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå…¨ä½“ã®å®Ÿè£…æ¦‚è¦ãŒã‚ã‚‹å ´åˆã¯è¡¨ç¤º
                    if session.project_implementation_overview:
                        yield {"type": "section_start", "section": "project_overview"}
                        project_text = "ğŸ“¦ **ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå†…ã®å®Ÿè£…æ¸ˆã¿æ©Ÿèƒ½**\n\nä»¥ä¸‹ã®æ©Ÿèƒ½ã¯æ—¢ã«ä»–ã®ã‚¿ã‚¹ã‚¯ã§å®Ÿè£…æ¸ˆã¿ã§ã™ã€‚é‡è¤‡ã—ã¦å®Ÿè£…ã—ãªã„ã§ãã ã•ã„ã€‚\n\n"
                        project_text += session.project_implementation_overview
                        project_text += "\n"

                        for chunk in self._chunk_text(project_text):
                            yield {"type": "chunk", "content": chunk}
                            await asyncio.sleep(0.02)
                        yield {"type": "section_complete", "section": "project_overview"}
                        session.generated_content["project_overview"] = project_text

                # ä¾å­˜ã‚¿ã‚¹ã‚¯ãŒãªã„ã€ã¾ãŸã¯å‡¦ç†å®Œäº†ã—ãŸã‚‰CONTEXTã¸
                session.phase = GenerationPhase.CONTEXT

            # Phase 1: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼ˆã‚¿ã‚¹ã‚¯ã®ä½ç½®ã¥ã‘ï¼‰
            if session.phase == GenerationPhase.CONTEXT:
                position = self._get_task_position()

                yield {
                    "type": "context",
                    "position": position["position_description"],
                    "dependencies": [t["title"] for t in position["previous_tasks"]],
                    "dependents": [t["title"] for t in position["next_tasks"]]
                }

                # ã‚»ã‚¯ã‚·ãƒ§ãƒ³é–‹å§‹ã‚’é€šçŸ¥
                yield {"type": "section_start", "section": "context"}

                context_text = self._build_context_text(position)
                for chunk in self._chunk_text(context_text):
                    yield {"type": "chunk", "content": chunk}
                    await asyncio.sleep(0.02)

                session.generated_content["context"] = context_text
                yield {"type": "section_complete", "section": "context"}
                session.phase = GenerationPhase.OVERVIEW

                # ä¸­é–“ä¿å­˜
                await self._save_progress(session, "generating")
                yield {"type": "progress_saved", "phase": "context"}

            # Phase 2: æ¦‚è¦ç”Ÿæˆï¼ˆæ¦‚è¦ç”Ÿæˆã®ã¿ã€æŠ€è¡“é¸å®šã¯åˆ¥ãƒ•ã‚§ãƒ¼ã‚ºï¼‰
            if session.phase == GenerationPhase.OVERVIEW:
                # æ¦‚è¦ãŒæœªç”Ÿæˆã®å ´åˆã®ã¿ç”Ÿæˆ
                if not session.generated_content.get("overview"):
                    yield {"type": "section_start", "section": "overview"}

                    async for chunk in self._stream_overview():
                        yield {"type": "chunk", "content": chunk}
                        session.generated_content["overview"] = session.generated_content.get("overview", "") + chunk

                    yield {"type": "section_complete", "section": "overview"}

                    # ä¸­é–“ä¿å­˜
                    await self._save_progress(session, "generating")
                    yield {"type": "progress_saved", "phase": "overview"}

                # æ¬¡ã®ãƒ•ã‚§ãƒ¼ã‚ºã¸
                session.phase = GenerationPhase.TECH_CHECK

            # Phase 2.5: æŠ€è¡“é¸å®šåˆ¤æ–­ï¼ˆç‹¬ç«‹ãƒ•ã‚§ãƒ¼ã‚ºï¼‰
            if session.phase == GenerationPhase.TECH_CHECK:
                # æ—¢ã«é¸æŠæ¸ˆã¿ãªã‚‰å®Ÿè£…è¨ˆç”»ã¸
                if session.user_choices:
                    session.phase = GenerationPhase.IMPLEMENTATION_PLANNING
                else:
                    force_choice = session.generated_content.get("force_choice") == "true"
                    if force_choice:
                        del session.generated_content["force_choice"]  # ãƒ•ãƒ©ã‚°ã‚’ã‚¯ãƒªã‚¢

                    tech_check = await self._check_tech_selection(session, force_choice=force_choice)

                    if tech_check.get("needs_choice"):
                        # é¸æŠè‚¢ã‚’æç¤º
                        choice_id = f"choice_{uuid.uuid4().hex[:8]}"
                        options = tech_check.get("options", [])

                        session.pending_choice = ChoiceRequest(
                            choice_id=choice_id,
                            question=tech_check.get("question", "æŠ€è¡“ã‚’é¸å®šã—ã¾ã—ã‚‡ã†"),
                            options=[
                                ChoiceOption(
                                    id=opt.get("id", f"opt_{i}"),
                                    label=opt.get("label", ""),
                                    description=opt.get("description", ""),
                                    pros=opt.get("pros", []),
                                    cons=opt.get("cons", [])
                                )
                                for i, opt in enumerate(options)
                            ],
                            allow_custom=True,
                            skip_allowed=True
                        )
                        session.phase = GenerationPhase.CHOICE_REQUIRED

                        await self._save_progress(session, "waiting_input")

                        yield {
                            "type": "choice_required",
                            "choice": {
                                "choice_id": choice_id,
                                "question": tech_check.get("question"),
                                "options": options,
                                "allow_custom": True,
                                "skip_allowed": True
                            }
                        }
                        return
                    elif tech_check.get("decided"):
                        # æ—¢ã«æ±ºã¾ã£ã¦ã„ã‚‹å ´åˆã¯ç¢ºèªã‚’æ±‚ã‚ã‚‹
                        decided = tech_check.get("decided")
                        reason = tech_check.get("reason", "")

                        yield {"type": "chunk", "content": f"\n\n**æŠ€è¡“é¸å®š**: {decided}\n{reason}\n\n"}

                        # ç¢ºèªã‚’æ±‚ã‚ã‚‹
                        session.pending_input = InputPrompt(
                            prompt_id="confirm_auto_decided",
                            question=f"{decided}ã§é€²ã‚ã¦ã‚ˆã‚ã—ã„ã§ã™ã‹ï¼Ÿ",
                            options=["OK", "åˆ¥ã®é¸æŠè‚¢ã‚’æ¤œè¨"]
                        )
                        session.phase = GenerationPhase.WAITING_CHOICE_CONFIRM

                        # ä¸€æ™‚çš„ã«è¨˜éŒ²ï¼ˆç¢ºèªå¾Œã«æ­£å¼è¨˜éŒ²ï¼‰
                        session.user_choices["auto_decided"] = {
                            "selected": decided,
                            "note": reason
                        }

                        await self._save_progress(session, "waiting_input")

                        yield {
                            "type": "user_input_required",
                            "prompt": {
                                "prompt_id": "confirm_auto_decided",
                                "question": f"{decided}ã§é€²ã‚ã¦ã‚ˆã‚ã—ã„ã§ã™ã‹ï¼Ÿ",
                                "options": ["OK", "åˆ¥ã®é¸æŠè‚¢ã‚’æ¤œè¨"]
                            }
                        }
                        return
                    else:
                        # æŠ€è¡“é¸å®šä¸è¦ã®å ´åˆã¯å®Ÿè£…è¨ˆç”»ã¸
                        session.phase = GenerationPhase.IMPLEMENTATION_PLANNING

            # Phase 3: å®Ÿè£…è¨ˆç”»
            if session.phase == GenerationPhase.IMPLEMENTATION_PLANNING:
                yield {"type": "section_start", "section": "planning"}
                yield {"type": "chunk", "content": "\n\n### å®Ÿè£…è¨ˆç”»\n\nMVPã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§æ®µéšçš„ã«å®Ÿè£…ã—ã¦ã„ãã¾ã™ã€‚\n\n"}

                # ã‚¹ãƒ†ãƒƒãƒ—ã‚’è¨ˆç”»ï¼ˆä¾å­˜ã‚¿ã‚¹ã‚¯æƒ…å ±ã‚‚è€ƒæ…®ï¼‰
                session.implementation_steps = await self._generate_implementation_plan(session.user_choices, session)

                # ã‚¹ãƒ†ãƒƒãƒ—ä¸€è¦§ã‚’è¡¨ç¤º
                steps_overview = ""
                for step in session.implementation_steps:
                    steps_overview += f"**ã‚¹ãƒ†ãƒƒãƒ—{step.step_number}**: {step.title}\n"
                    steps_overview += f"  - {step.description}\n\n"

                for chunk in self._chunk_text(steps_overview):
                    yield {"type": "chunk", "content": chunk}
                    await asyncio.sleep(0.02)

                yield {"type": "section_complete", "section": "planning"}

                # ä¸­é–“ä¿å­˜
                await self._save_progress(session, "generating")

                session.current_step_index = 0
                session.phase = GenerationPhase.IMPLEMENTATION_STEP

            # Phase 4: å®Ÿè£…ã‚¹ãƒ†ãƒƒãƒ—ï¼ˆã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã«ç”Ÿæˆâ†’ç¢ºèªå¾…ã¡ï¼‰
            if session.phase == GenerationPhase.IMPLEMENTATION_STEP:
                if session.current_step_index < len(session.implementation_steps):
                    current_step = session.implementation_steps[session.current_step_index]
                    previous_steps = session.implementation_steps[:session.current_step_index]

                    yield {
                        "type": "step_start",
                        "step_number": current_step.step_number,
                        "step_title": current_step.title,
                        "total_steps": len(session.implementation_steps)
                    }

                    # ã‚»ã‚¯ã‚·ãƒ§ãƒ³é–‹å§‹ã‚’é€šçŸ¥
                    section_name = f"step_{current_step.step_number}"
                    yield {"type": "section_start", "section": section_name}

                    # ã‚¹ãƒ†ãƒƒãƒ—å†…ã®è¦ä»¶ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆæ¦‚å¿µèª¬æ˜ãƒ»æŠ€è¡“é¸å®šãŒå¿…è¦ã‹ï¼‰
                    requirements = await self._check_step_requirements(current_step, session)
                    session.current_step_requirements = requirements

                    # ç›®çš„ã‚’å‡ºåŠ›
                    yield {"type": "chunk", "content": f"### ã‚¹ãƒ†ãƒƒãƒ—{current_step.step_number}: {current_step.title}\n\n"}
                    yield {"type": "chunk", "content": f"**ç›®çš„**: {requirements.objective}\n\n"}

                    # å‰ææ¦‚å¿µãŒã‚ã‚Œã°èª¬æ˜
                    if requirements.prerequisite_concept:
                        yield {"type": "chunk", "content": f"**{requirements.prerequisite_concept}ã¨ã¯**: {requirements.prerequisite_brief}\n\n"}

                    # æŠ€è¡“é¸å®šãŒå¿…è¦ãªå ´åˆ
                    if requirements.tech_selection_needed and requirements.tech_selection_options:
                        # ã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã§æ—¢ã«é¸æŠæ¸ˆã¿ã§ãªã‘ã‚Œã°é¸æŠè‚¢ã‚’æç¤º
                        if current_step.step_number not in session.step_choices:
                            yield {"type": "section_complete", "section": section_name}

                            # é¸æŠè‚¢ã‚’æç¤º
                            choice_id = f"step_{current_step.step_number}_tech"
                            session.pending_choice = ChoiceRequest(
                                choice_id=choice_id,
                                question=requirements.tech_selection_question or "æŠ€è¡“ã‚’é¸æŠã—ã¦ãã ã•ã„",
                                options=[
                                    ChoiceOption(
                                        id=opt.get("id", f"opt_{i}"),
                                        label=opt.get("name", ""),
                                        description=opt.get("description", ""),
                                        pros=[],
                                        cons=[]
                                    )
                                    for i, opt in enumerate(requirements.tech_selection_options)
                                ],
                                allow_custom=True,
                                skip_allowed=False
                            )
                            session.phase = GenerationPhase.WAITING_STEP_CHOICE

                            await self._save_progress(session, "waiting_input")

                            yield {
                                "type": "step_choice_required",
                                "step_number": current_step.step_number,
                                "choice": {
                                    "choice_id": choice_id,
                                    "question": requirements.tech_selection_question,
                                    "options": [
                                        {"id": opt.get("id", f"opt_{i}"), "name": opt.get("name", ""), "description": opt.get("description", "")}
                                        for i, opt in enumerate(requirements.tech_selection_options)
                                    ],
                                    "allow_custom": True
                                }
                            }
                            return

                    # æŠ€è¡“é¸å®šä¸è¦ or é¸æŠæ¸ˆã¿ â†’ å®Ÿè£…å†…å®¹ã‚’ç”Ÿæˆ
                    step_content = f"### ã‚¹ãƒ†ãƒƒãƒ—{current_step.step_number}: {current_step.title}\n\n"
                    step_content += f"**ç›®çš„**: {requirements.objective}\n\n"
                    if requirements.prerequisite_concept:
                        step_content += f"**{requirements.prerequisite_concept}ã¨ã¯**: {requirements.prerequisite_brief}\n\n"

                    # é¸æŠæ¸ˆã¿ã®æŠ€è¡“ãŒã‚ã‚Œã°è¡¨ç¤º
                    if current_step.step_number in session.step_choices:
                        choice = session.step_choices[current_step.step_number]
                        yield {"type": "chunk", "content": f"**é¸æŠã—ãŸæŠ€è¡“**: {choice.get('selected', '')}\n\n"}
                        step_content += f"**é¸æŠã—ãŸæŠ€è¡“**: {choice.get('selected', '')}\n\n"

                    yield {"type": "chunk", "content": "---\n\n"}
                    step_content += "---\n\n"

                    # å®Ÿè£…æ‰‹é †ã‚’ç”Ÿæˆ
                    async for chunk in self._generate_step_content(
                        current_step,
                        session.user_choices,
                        previous_steps,
                        session.decisions,
                        session
                    ):
                        yield {"type": "chunk", "content": chunk}
                        step_content += chunk

                    current_step.content = step_content

                    # å®Ÿè£…å†…å®¹ã‚’ç´¯ç©
                    session.generated_content["implementation"] = session.generated_content.get("implementation", "") + "\n\n" + step_content

                    yield {"type": "section_complete", "section": section_name}
                    yield {"type": "step_complete", "step_number": current_step.step_number}

                    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ç¢ºèªå¾…ã¡çŠ¶æ…‹ã‚’è¨­å®š
                    session.phase = GenerationPhase.WAITING_STEP_COMPLETE
                    session.pending_input = InputPrompt(
                        prompt_id=f"step_{current_step.step_number}_complete",
                        question=f"ã‚¹ãƒ†ãƒƒãƒ—{current_step.step_number}ã€Œ{current_step.title}ã€ã¯å®Œäº†ã—ã¾ã—ãŸã‹ï¼Ÿ",
                        placeholder="ã§ããŸ / è³ªå•ãŒã‚ã‚‹",
                        options=["ã§ããŸ", "è³ªå•ãŒã‚ã‚‹", "ã‚¹ã‚­ãƒƒãƒ—"]
                    )

                    # pending_inputã‚’è¨­å®šã—ãŸå¾Œã«ä¿å­˜
                    await self._save_progress(session, "waiting_input")
                    yield {"type": "progress_saved", "phase": f"step_{current_step.step_number}"}

                    yield {
                        "type": "step_confirmation_required",
                        "prompt": {
                            "prompt_id": session.pending_input.prompt_id,
                            "question": session.pending_input.question,
                            "options": session.pending_input.options
                        }
                    }
                    return
                else:
                    # å…¨ã‚¹ãƒ†ãƒƒãƒ—å®Œäº†
                    session.phase = GenerationPhase.VERIFICATION

            # Phase 5: å‹•ä½œç¢ºèª
            if session.phase == GenerationPhase.VERIFICATION:
                yield {"type": "section_start", "section": "verification"}

                async for chunk in self._stream_verification():
                    yield {"type": "chunk", "content": chunk}
                    session.generated_content["verification"] = session.generated_content.get("verification", "") + chunk

                yield {"type": "section_complete", "section": "verification"}

                # ä¸­é–“ä¿å­˜
                await self._save_progress(session, "generating")

                session.phase = GenerationPhase.COMPLETE

            # Phase 6: å®Œäº†
            if session.phase == GenerationPhase.COMPLETE:
                hands_on = await self._save_progress(session, "completed")

                yield {
                    "type": "done",
                    "hands_on_id": str(hands_on.hands_on_id),
                    "session_id": session.session_id
                }

        except Exception as e:
            # ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚é€²æ—ã‚’ä¿å­˜
            try:
                await self._save_progress(session, "generating")
            except:
                pass
            yield {"type": "error", "message": str(e)}

    def _build_context_text(self, position: Dict) -> str:
        """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆèª¬æ˜ãƒ†ã‚­ã‚¹ãƒˆã‚’æ§‹ç¯‰"""
        parts = [f"## {self.task.title}\n\n"]

        if self.task.description:
            parts.append(f"{self.task.description}\n\n")

        parts.append(f"### ã‚¿ã‚¹ã‚¯ã®ä½ç½®ã¥ã‘\n\n")
        parts.append(f"{position['position_description']}\n\n")

        if position["previous_tasks"]:
            parts.append("**å‰æã¨ãªã‚‹ã‚¿ã‚¹ã‚¯:**\n\n")
            for task in position["previous_tasks"][:3]:
                parts.append(f"- {task['title']}\n")
            parts.append("\n")

        if position["next_tasks"]:
            parts.append("**ã“ã®ã‚¿ã‚¹ã‚¯å®Œäº†å¾Œã«å®Ÿè£…ã§ãã‚‹ã‚¿ã‚¹ã‚¯:**\n\n")
            for task in position["next_tasks"][:3]:
                parts.append(f"- {task['title']}\n")
            parts.append("\n")

        return "".join(parts)

    def _chunk_text(self, text: str, chunk_size: int = 5) -> List[str]:
        """ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²ï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ç”¨ï¼‰"""
        words = list(text)
        return [
            "".join(words[i:i + chunk_size])
            for i in range(0, len(words), chunk_size)
        ]

    async def _stream_overview(self) -> AsyncGenerator[str, None]:
        """æ¦‚è¦ã‚’ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ç”Ÿæˆ"""
        prompt = f"""
ä»¥ä¸‹ã®ã‚¿ã‚¹ã‚¯ã®æ¦‚è¦ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚
ã“ã®ã‚¿ã‚¹ã‚¯ã§ä½•ã‚’å®Ÿè£…ã™ã‚‹ã‹ã€ãªãœå¿…è¦ã‹ã‚’ç°¡æ½”ã«èª¬æ˜ã—ã¦ãã ã•ã„ã€‚

## ã‚¿ã‚¹ã‚¯æƒ…å ±
- ã‚¿ã‚¤ãƒˆãƒ«: {self.task.title}
- èª¬æ˜: {self.task.description or 'ãªã—'}
- ã‚«ãƒ†ã‚´ãƒª: {self.task.category or 'æœªåˆ†é¡'}
- å„ªå…ˆåº¦: {self.task.priority or 'Must'}

## ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±
- æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯: {', '.join(self.project_context.get('tech_stack', []))}
- ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯: {self.project_context.get('framework', 'æœªè¨­å®š')}

## å‡ºåŠ›å½¢å¼
Markdownå½¢å¼ã§ã€200-300æ–‡å­—ç¨‹åº¦ã§èª¬æ˜ã—ã¦ãã ã•ã„ã€‚

**é‡è¦ãªæ›¸å¼ãƒ«ãƒ¼ãƒ«:**
- æ®µè½é–“ã«ã¯å¿…ãšç©ºè¡Œã‚’å…¥ã‚Œã‚‹
- è¦‹å‡ºã—ï¼ˆ##, ###ï¼‰ã®å‰å¾Œã«ã¯ç©ºè¡Œã‚’å…¥ã‚Œã‚‹
- ç®‡æ¡æ›¸ãã®å‰å¾Œã«ã¯ç©ºè¡Œã‚’å…¥ã‚Œã‚‹
"""

        async for chunk in self.llm.astream([
            SystemMessage(content="ã‚ãªãŸã¯é–‹ç™ºã‚¬ã‚¤ãƒ‰ã‚’ä½œæˆã™ã‚‹ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã§ã™ã€‚"),
            HumanMessage(content=prompt)
        ]):
            if chunk.content:
                yield chunk.content

    async def _stream_verification(self) -> AsyncGenerator[str, None]:
        """å‹•ä½œç¢ºèªæ‰‹é †ã‚’ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ç”Ÿæˆ"""
        prompt = f"""
ä»¥ä¸‹ã®ã‚¿ã‚¹ã‚¯å…¨ä½“ã®æœ€çµ‚å‹•ä½œç¢ºèªæ–¹æ³•ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚

## ã‚¿ã‚¹ã‚¯æƒ…å ±
- ã‚¿ã‚¤ãƒˆãƒ«: {self.task.title}
- èª¬æ˜: {self.task.description or 'ãªã—'}

## å‡ºåŠ›å½¢å¼
Markdownå½¢å¼ã§ã€ä»¥ä¸‹ã®æ§‹æˆã§èª¬æ˜ã—ã¦ãã ã•ã„ï¼š

### æœ€çµ‚å‹•ä½œç¢ºèª

1. ã€‡ã€‡ã‚’ç¢ºèª
2. ã€‡ã€‡ã‚’å®Ÿè¡Œ
3. æœŸå¾…ã•ã‚Œã‚‹çµæœ: ã€‡ã€‡

### ã‚ˆãã‚ã‚‹ã‚¨ãƒ©ãƒ¼ã¨å¯¾å‡¦æ³•

- **ã‚¨ãƒ©ãƒ¼1**: ã€‡ã€‡

  - åŸå› : ã€‡ã€‡
  - å¯¾å‡¦æ³•: ã€‡ã€‡

**é‡è¦ãªæ›¸å¼ãƒ«ãƒ¼ãƒ«:**
- å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ãƒ»æ®µè½ã®é–“ã«ã¯å¿…ãšç©ºè¡Œã‚’å…¥ã‚Œã‚‹
- è¦‹å‡ºã—ï¼ˆ###ï¼‰ã®å‰å¾Œã«ã¯ç©ºè¡Œã‚’å…¥ã‚Œã‚‹
- ç®‡æ¡æ›¸ãã®å‰å¾Œã«ã¯ç©ºè¡Œã‚’å…¥ã‚Œã‚‹
"""

        async for chunk in self.llm.astream([
            SystemMessage(content="ã‚ãªãŸã¯é–‹ç™ºã‚¬ã‚¤ãƒ‰ã‚’ä½œæˆã™ã‚‹ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã§ã™ã€‚"),
            HumanMessage(content=prompt)
        ]):
            if chunk.content:
                yield chunk.content

    async def _generate_pros_cons_analysis(
        self,
        choice_type: str,
        user_choice: str,
        user_note: Optional[str] = None
    ) -> str:
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®é¸æŠã«å¯¾ã™ã‚‹ãƒ¡ãƒªãƒ‡ãƒ¡åˆ†æã‚’ç”Ÿæˆ"""
        prompt = f"""
ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒä»¥ä¸‹ã®é¸æŠã‚’ã—ã¾ã—ãŸã€‚ãƒ¡ãƒªãƒƒãƒˆãƒ»ãƒ‡ãƒ¡ãƒªãƒƒãƒˆã‚’ç°¡æ½”ã«åˆ†æã—ã¦ãã ã•ã„ã€‚

## é¸æŠå†…å®¹
- é¸æŠ: {user_choice}
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ¡ãƒ¢: {user_note or 'ãªã—'}

## ã‚¿ã‚¹ã‚¯æƒ…å ±
- ã‚¿ã‚¤ãƒˆãƒ«: {self.task.title}
- èª¬æ˜: {self.task.description or 'ãªã—'}

## ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±
- æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯: {', '.join(self.project_context.get('tech_stack', []))}

## å‡ºåŠ›å½¢å¼
ä»¥ä¸‹ã®å½¢å¼ã§ã€ç°¡æ½”ã«ï¼ˆå…¨ä½“ã§200æ–‡å­—ç¨‹åº¦ï¼‰åˆ†æã—ã¦ãã ã•ã„ï¼š

**{user_choice}ã®ç‰¹å¾´:**

âœ“ ãƒ¡ãƒªãƒƒãƒˆ1
âœ“ ãƒ¡ãƒªãƒƒãƒˆ2

â–³ æ³¨æ„ç‚¹1
â–³ æ³¨æ„ç‚¹2

ã“ã®é¸æŠã§é€²ã‚ã¾ã™ã‹ï¼Ÿ
"""

        response = await self.llm.ainvoke([
            SystemMessage(content="ã‚ãªãŸã¯æŠ€è¡“é¸å®šã®ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼ã§ã™ã€‚ç°¡æ½”ã«åˆ†æã—ã¦ãã ã•ã„ã€‚"),
            HumanMessage(content=prompt)
        ])

        return response.content

    async def handle_user_response(
        self,
        session: SessionState,
        response_type: str,
        choice_id: Optional[str] = None,
        selected: Optional[str] = None,
        user_input: Optional[str] = None,
        user_note: Optional[str] = None
    ) -> AsyncGenerator[Dict, None]:
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¿œç­”ã‚’å‡¦ç†ã—ã¦ç”Ÿæˆã‚’ç¶™ç¶š"""
        session.updated_at = datetime.now()

        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¿œç­”ã‚’ã‚¤ãƒ™ãƒ³ãƒˆã¨ã—ã¦é€šçŸ¥
        yield {
            "type": "user_response",
            "response_type": response_type,
            "choice_id": choice_id,
            "selected": selected,
            "user_input": user_input,
            "user_note": user_note
        }

        if response_type == "choice":
            # ã‚¹ãƒ†ãƒƒãƒ—å†…æŠ€è¡“é¸å®šã®å ´åˆ
            if session.phase == GenerationPhase.WAITING_STEP_CHOICE:
                current_step = session.implementation_steps[session.current_step_index]

                # ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã®é¸æŠã‚’è¨˜éŒ²
                session.step_choices[current_step.step_number] = {
                    "selected": selected or user_input,
                    "note": user_note
                }

                # å…¨ä½“ã® user_choices ã«ã‚‚è¨˜éŒ²ï¼ˆå¾Œã®å‚ç…§ç”¨ï¼‰
                session.user_choices[choice_id] = {
                    "selected": selected or user_input,
                    "note": user_note
                }

                session.pending_choice = None
                session.phase = GenerationPhase.IMPLEMENTATION_STEP

                yield {"type": "chunk", "content": f"\n\n**é¸æŠ**: {selected or user_input}\n\n"}

                await self._save_progress(session, "generating")

                # ç”Ÿæˆã‚’ç¶™ç¶šï¼ˆå®Ÿè£…å†…å®¹ã®ç”Ÿæˆã¸ï¼‰
                async for event in self.generate_stream(session):
                    yield event
                return

            # ã‚¿ã‚¹ã‚¯å…¨ä½“ã®æŠ€è¡“é¸å®šã®å ´åˆ
            # é¸æŠã‚’è¨˜éŒ²ï¼ˆdomain_keyãŒã‚ã‚‹å ´åˆã¯æ–°å½¢å¼ï¼‰
            if session.current_domain_key:
                session.user_choices[choice_id] = {
                    "domain_key": session.current_domain_key,
                    "stack_key": selected or user_input
                }
                # æ±ºå®šæ¸ˆã¿domainã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«è¿½åŠ 
                self.decided_domains[session.current_domain_key] = selected or user_input
            else:
                # å¾“æ¥å½¢å¼ï¼ˆå¾Œæ–¹äº’æ›ï¼‰
                session.user_choices[choice_id] = {
                    "selected": selected or user_input,
                    "note": user_note
                }

            # ãƒ¡ãƒªãƒ‡ãƒ¡åˆ†æã‚’ç”Ÿæˆ
            if session.pending_choice:
                analysis = await self._generate_pros_cons_analysis(
                    session.pending_choice.choice_id,
                    selected or user_input,
                    user_note
                )

                yield {"type": "section_start", "section": "analysis"}
                for chunk in self._chunk_text(analysis):
                    yield {"type": "chunk", "content": chunk}
                    await asyncio.sleep(0.02)
                yield {"type": "section_complete", "section": "analysis"}

                # ç¢ºèªã‚’æ±‚ã‚ã‚‹
                session.pending_input = InputPrompt(
                    prompt_id="confirm_choice",
                    question="ã“ã®é¸æŠã§é€²ã‚ã¾ã™ã‹ï¼Ÿ",
                    options=["OK", "åˆ¥ã®é¸æŠè‚¢ã‚’æ¤œè¨"]
                )
                session.phase = GenerationPhase.WAITING_CHOICE_CONFIRM

                # pending_inputã‚’è¨­å®šã—ãŸå¾Œã«ä¿å­˜
                await self._save_progress(session, "waiting_input")

                yield {
                    "type": "user_input_required",
                    "prompt": {
                        "prompt_id": "confirm_choice",
                        "question": "ã“ã®é¸æŠã§é€²ã‚ã¾ã™ã‹ï¼Ÿ",
                        "options": ["OK", "åˆ¥ã®é¸æŠè‚¢ã‚’æ¤œè¨"]
                    }
                }
                return

        elif response_type == "input":
            # ä¾å­˜ã‚¿ã‚¹ã‚¯å¯¾å¿œæ–¹é‡ã¸ã®å¿œç­”
            if session.phase == GenerationPhase.WAITING_DEPENDENCY_DECISION:
                session.pending_input = None
                if user_input == "ãã®ã¾ã¾é€²ã‚ã‚‹":
                    session.dependency_decision = "proceed"
                    yield {"type": "chunk", "content": "\n\nä¾å­˜ã‚¿ã‚¹ã‚¯ã‚’ç„¡è¦–ã—ã¦é€²ã‚ã¾ã™ã€‚\n\n"}
                elif user_input == "ãƒ¢ãƒƒã‚¯ã§é€²ã‚ã‚‹ï¼ˆå¾Œã§çµåˆï¼‰":
                    session.dependency_decision = "mock"
                    yield {"type": "chunk", "content": "\n\nãƒ¢ãƒƒã‚¯å®Ÿè£…ã§é€²ã‚ã¾ã™ã€‚å¾Œã§ä¾å­˜ã‚¿ã‚¹ã‚¯ã¨çµåˆã—ã¦ãã ã•ã„ã€‚\n\n"}
                elif user_input == "å…ˆã«ä¾å­˜ã‚¿ã‚¹ã‚¯ã‚’å®Œäº†ã•ã›ã‚‹":
                    session.dependency_decision = "redirect"
                    # ä¾å­˜ã‚¿ã‚¹ã‚¯ã¸ã®ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆã‚’é€šçŸ¥
                    incomplete_tasks = [
                        pt for pt in session.predecessor_tasks
                        if pt.hands_on_status != "completed"
                    ]
                    if incomplete_tasks:
                        yield {
                            "type": "redirect_to_task",
                            "task_id": incomplete_tasks[0].task_id,
                            "task_title": incomplete_tasks[0].title,
                            "message": f"å…ˆã«ã€Œ{incomplete_tasks[0].title}ã€ã‚’å®Œäº†ã•ã›ã¦ãã ã•ã„ã€‚"
                        }
                    return
                else:
                    session.dependency_decision = "proceed"

                session.phase = GenerationPhase.CONTEXT
                await self._save_progress(session, "generating")

            # é¸æŠç¢ºèªã¸ã®å¿œç­”
            elif session.phase == GenerationPhase.WAITING_CHOICE_CONFIRM:
                if user_input and user_input.upper() in ["OK", "ã¯ã„", "YES", "é€²ã‚ã‚‹"]:
                    session.phase = GenerationPhase.IMPLEMENTATION_PLANNING
                    session.pending_choice = None
                    session.pending_input = None
                else:
                    # åˆ¥ã®é¸æŠè‚¢ã‚’æ¤œè¨ â†’ TECH_CHECKã«æˆ»ã—ã¦å¼·åˆ¶çš„ã«é¸æŠè‚¢ã‚’æç¤º
                    # OVERVIEWã¯ç”Ÿæˆæ¸ˆã¿ãªã®ã§ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã‚‹
                    session.phase = GenerationPhase.TECH_CHECK
                    session.pending_input = None
                    session.user_choices = {}
                    # é¸æŠè‚¢ã‚’å¼·åˆ¶ç”Ÿæˆã™ã‚‹ãƒ•ãƒ©ã‚°ã‚’ã‚»ãƒƒãƒˆ
                    session.generated_content["force_choice"] = "true"

            # ã‚¹ãƒ†ãƒƒãƒ—å®Œäº†ç¢ºèªã¸ã®å¿œç­”
            elif session.phase == GenerationPhase.WAITING_STEP_COMPLETE:
                current_step = session.implementation_steps[session.current_step_index]

                if user_input in ["ã§ããŸ", "å®Œäº†", "done"]:
                    current_step.is_completed = True
                    current_step.user_feedback = "completed"
                    session.current_step_index += 1
                    session.phase = GenerationPhase.IMPLEMENTATION_STEP
                    session.pending_input = None

                elif user_input == "ã‚¹ã‚­ãƒƒãƒ—":
                    current_step.is_completed = True
                    current_step.user_feedback = "skipped"
                    session.current_step_index += 1
                    session.phase = GenerationPhase.IMPLEMENTATION_STEP
                    session.pending_input = None

                elif user_input in ["è³ªå•ãŒã‚ã‚‹", "ã¾ã è³ªå•ãŒã‚ã‚‹"]:
                    # è³ªå•å…¥åŠ›ã‚’æ±‚ã‚ã‚‹
                    session.pending_input = InputPrompt(
                        prompt_id=f"question_step_{current_step.step_number}",
                        question=f"ã‚¹ãƒ†ãƒƒãƒ—{current_step.step_number}ã€Œ{current_step.title}ã€ã«ã¤ã„ã¦è³ªå•ã—ã¦ãã ã•ã„",
                        placeholder="ã‚ã‹ã‚‰ãªã„ã“ã¨ã‚„è©°ã¾ã£ã¦ã„ã‚‹ç‚¹ã‚’å…¥åŠ›..."
                    )
                    # pending_inputã‚’è¨­å®šã—ãŸå¾Œã«ä¿å­˜
                    await self._save_progress(session, "waiting_input")
                    yield {
                        "type": "user_input_required",
                        "prompt": {
                            "prompt_id": session.pending_input.prompt_id,
                            "question": session.pending_input.question,
                            "placeholder": session.pending_input.placeholder
                        }
                    }
                    return

                elif user_input == "æ¡ç”¨ã™ã‚‹" and session.pending_decision:
                    # å¤‰æ›´ææ¡ˆã‚’æ¡ç”¨
                    new_decision = Decision(
                        step_number=current_step.step_number,
                        description=session.pending_decision["proposal"],
                        reason=session.pending_decision["reason"]
                    )
                    session.decisions.append(new_decision)
                    yield {"type": "chunk", "content": f"\n\nâœ“ **æ±ºå®šäº‹é …ã¨ã—ã¦ä¿å­˜ã—ã¾ã—ãŸ:** {session.pending_decision['proposal']}\n\n"}
                    session.pending_decision = None

                    # æ±ºå®šã‚’åæ˜ ã—ã¦ã‚¹ãƒ†ãƒƒãƒ—å†…å®¹ã‚’å†ç”Ÿæˆ
                    yield {"type": "chunk", "content": f"---\n\n**æ±ºå®šã‚’åæ˜ ã—ã¦ã€ã‚¹ãƒ†ãƒƒãƒ—{current_step.step_number}ã®å†…å®¹ã‚’æ›´æ–°ã—ã¾ã™...**\n\n"}
                    yield {"type": "section_start", "section": f"step_{current_step.step_number}_updated"}

                    previous_steps = [s for s in session.implementation_steps[:session.current_step_index]]
                    updated_content = ""
                    async for chunk in self._generate_step_content(
                        current_step,
                        session.user_choices,
                        previous_steps,
                        session.decisions,
                        session
                    ):
                        yield {"type": "chunk", "content": chunk}
                        updated_content += chunk

                    current_step.content = updated_content
                    yield {"type": "section_complete", "section": f"step_{current_step.step_number}_updated"}

                    # å†åº¦ã‚¹ãƒ†ãƒƒãƒ—ç¢ºèªã‚’æ±‚ã‚ã‚‹
                    session.pending_input = InputPrompt(
                        prompt_id=f"step_{current_step.step_number}_complete",
                        question=f"ã‚¹ãƒ†ãƒƒãƒ—{current_step.step_number}ã€Œ{current_step.title}ã€ã®æ›´æ–°å†…å®¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚å®Œäº†ã—ã¾ã—ãŸã‹ï¼Ÿ",
                        options=["ã§ããŸ", "ã¾ã è³ªå•ãŒã‚ã‚‹", "ã‚¹ã‚­ãƒƒãƒ—"]
                    )
                    # pending_inputã‚’è¨­å®šã—ãŸå¾Œã«ä¿å­˜
                    await self._save_progress(session, "waiting_input")
                    yield {
                        "type": "step_confirmation_required",
                        "prompt": {
                            "prompt_id": session.pending_input.prompt_id,
                            "question": session.pending_input.question,
                            "options": session.pending_input.options
                        }
                    }
                    return

                elif user_input == "æ¡ç”¨ã—ãªã„" and session.pending_decision:
                    # å¤‰æ›´ææ¡ˆã‚’æ¡ç”¨ã—ãªã„
                    yield {"type": "chunk", "content": "\n\nç¾çŠ¶ã®ã¾ã¾é€²ã‚ã¾ã™ã€‚\n\n"}
                    session.pending_decision = None

                    # å†åº¦ã‚¹ãƒ†ãƒƒãƒ—ç¢ºèªã‚’æ±‚ã‚ã‚‹
                    session.pending_input = InputPrompt(
                        prompt_id=f"step_{current_step.step_number}_complete",
                        question=f"ã‚¹ãƒ†ãƒƒãƒ—{current_step.step_number}ã€Œ{current_step.title}ã€ã¯å®Œäº†ã—ã¾ã—ãŸã‹ï¼Ÿ",
                        options=["ã§ããŸ", "ã¾ã è³ªå•ãŒã‚ã‚‹", "ã‚¹ã‚­ãƒƒãƒ—"]
                    )
                    # pending_inputã‚’è¨­å®šã—ãŸå¾Œã«ä¿å­˜
                    await self._save_progress(session, "waiting_input")
                    yield {
                        "type": "step_confirmation_required",
                        "prompt": {
                            "prompt_id": session.pending_input.prompt_id,
                            "question": session.pending_input.question,
                            "options": session.pending_input.options
                        }
                    }
                    return

                else:
                    # ãã®ä»–ã®å…¥åŠ›ã¯è³ªå•/ææ¡ˆã¨ã—ã¦åˆ†æ
                    current_step.user_feedback = user_input

                    # å¤‰æ›´ææ¡ˆã‹ã©ã†ã‹ã‚’åˆ†æ
                    decision_proposal = await self._analyze_question_for_decision(user_input, current_step)

                    if decision_proposal:
                        # å¤‰æ›´ææ¡ˆãŒæ¤œå‡ºã•ã‚ŒãŸ â†’ ãƒ¡ãƒªãƒ‡ãƒ¡åˆ†æã—ã¦ã‹ã‚‰æ¡ç”¨ç¢ºèª
                        session.pending_decision = decision_proposal
                        yield {"type": "section_start", "section": "proposal"}
                        yield {"type": "chunk", "content": f"\n\n**å¤‰æ›´ææ¡ˆã‚’æ¤œå‡ºã—ã¾ã—ãŸ:**\n\n"}
                        yield {"type": "chunk", "content": f"ğŸ“ **{decision_proposal['proposal']}**\n\n"}

                        # ãƒ¡ãƒªãƒ‡ãƒ¡åˆ†æã‚’ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°
                        yield {"type": "chunk", "content": "---\n\n"}
                        async for chunk in self._stream_pros_cons_analysis(
                            decision_proposal['proposal'],
                            current_step
                        ):
                            yield {"type": "chunk", "content": chunk}

                        yield {"type": "chunk", "content": "\n\n---\n\n"}
                        yield {"type": "section_complete", "section": "proposal"}

                        session.pending_input = InputPrompt(
                            prompt_id=f"decision_confirm_{current_step.step_number}",
                            question="ã“ã®å¤‰æ›´ã‚’æ¡ç”¨ã—ã¾ã™ã‹ï¼Ÿ",
                            options=["æ¡ç”¨ã™ã‚‹", "æ¡ç”¨ã—ãªã„"]
                        )
                        # pending_inputã‚’è¨­å®šã—ãŸå¾Œã«ä¿å­˜
                        await self._save_progress(session, "waiting_input")
                        yield {
                            "type": "user_input_required",
                            "prompt": {
                                "prompt_id": session.pending_input.prompt_id,
                                "question": session.pending_input.question,
                                "options": session.pending_input.options
                            }
                        }
                        return
                    else:
                        # å˜ç´”ãªè³ªå• â†’ å›ç­”ã®ã¿
                        yield {"type": "section_start", "section": "answer"}
                        async for chunk in self._stream_answer_question(user_input, current_step, session.decisions):
                            yield {"type": "chunk", "content": chunk}
                        yield {"type": "section_complete", "section": "answer"}

                        # å†åº¦ã‚¹ãƒ†ãƒƒãƒ—ç¢ºèªã‚’æ±‚ã‚ã‚‹
                        session.pending_input = InputPrompt(
                            prompt_id=f"step_{current_step.step_number}_complete",
                            question=f"è³ªå•ã«å›ç­”ã—ã¾ã—ãŸã€‚ã‚¹ãƒ†ãƒƒãƒ—{current_step.step_number}ã€Œ{current_step.title}ã€ã¯å®Œäº†ã—ã¾ã—ãŸã‹ï¼Ÿ",
                            options=["ã§ããŸ", "ã¾ã è³ªå•ãŒã‚ã‚‹", "ã‚¹ã‚­ãƒƒãƒ—"]
                        )
                        # pending_inputã‚’è¨­å®šã—ãŸå¾Œã«ä¿å­˜
                        await self._save_progress(session, "waiting_input")
                        yield {
                            "type": "step_confirmation_required",
                            "prompt": {
                                "prompt_id": session.pending_input.prompt_id,
                                "question": session.pending_input.question,
                                "options": session.pending_input.options
                            }
                        }
                        return

        elif response_type == "skip":
            if session.phase == GenerationPhase.CHOICE_REQUIRED:
                session.phase = GenerationPhase.IMPLEMENTATION_PLANNING
                session.pending_choice = None
                session.pending_input = None
            elif session.phase == GenerationPhase.WAITING_STEP_COMPLETE:
                current_step = session.implementation_steps[session.current_step_index]
                current_step.is_completed = True
                current_step.user_feedback = "skipped"
                session.current_step_index += 1
                session.phase = GenerationPhase.IMPLEMENTATION_STEP
                session.pending_input = None

        # ä¸­é–“ä¿å­˜
        await self._save_progress(session, "generating")

        # ç”Ÿæˆã‚’ç¶™ç¶š
        async for event in self.generate_stream(session):
            yield event

    async def _answer_question(self, question: str, step: ImplementationStep) -> str:
        """ã‚¹ãƒ†ãƒƒãƒ—ã«é–¢ã™ã‚‹è³ªå•ã«å›ç­”"""
        prompt = f"""
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®è³ªå•ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚

## ç¾åœ¨ã®ã‚¹ãƒ†ãƒƒãƒ—
- ã‚¹ãƒ†ãƒƒãƒ—{step.step_number}: {step.title}
- èª¬æ˜: {step.description}

## ã‚¹ãƒ†ãƒƒãƒ—ã®å†…å®¹
{step.content[:1000]}

## ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•
{question}

## å›ç­”ãƒ«ãƒ¼ãƒ«
- ç°¡æ½”ã«ï¼ˆ200æ–‡å­—ç¨‹åº¦ï¼‰å›ç­”
- å…·ä½“çš„ãªã‚³ãƒ¼ãƒ‰ä¾‹ãŒã‚ã‚Œã°å«ã‚ã‚‹
- æ®µè½é–“ã«ã¯ç©ºè¡Œã‚’å…¥ã‚Œã‚‹
"""

        response = await self.llm.ainvoke([
            SystemMessage(content="ã‚ãªãŸã¯ä¸å¯§ãªé–‹ç™ºã‚µãƒãƒ¼ã‚¿ãƒ¼ã§ã™ã€‚"),
            HumanMessage(content=prompt)
        ])

        return response.content

    async def _stream_answer_question(
        self,
        question: str,
        step: ImplementationStep,
        decisions: List[Decision] = None
    ) -> AsyncGenerator[str, None]:
        """ã‚¹ãƒ†ãƒƒãƒ—ã«é–¢ã™ã‚‹è³ªå•ã«ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã§å›ç­”"""
        # æ—¢å­˜ã®æ±ºå®šäº‹é …ã‚’ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«å«ã‚ã‚‹
        decisions_context = ""
        if decisions:
            decisions_context = "\n## æ¡ç”¨æ¸ˆã¿ã®æ±ºå®šäº‹é …ï¼ˆã“ã‚Œã‚‰ã‚’è€ƒæ…®ã—ã¦å›ç­”ã—ã¦ãã ã•ã„ï¼‰\n"
            for d in decisions:
                decisions_context += f"- {d.description}\n"

        prompt = f"""
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®è³ªå•ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚

## ç¾åœ¨ã®ã‚¹ãƒ†ãƒƒãƒ—
- ã‚¹ãƒ†ãƒƒãƒ—{step.step_number}: {step.title}
- èª¬æ˜: {step.description}

## ã‚¹ãƒ†ãƒƒãƒ—ã®å†…å®¹
{step.content[:1500]}
{decisions_context}

## ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•
{question}

## å›ç­”ãƒ«ãƒ¼ãƒ«
- ã‚ã‹ã‚Šã‚„ã™ãä¸å¯§ã«å›ç­”
- å…·ä½“çš„ãªã‚³ãƒ¼ãƒ‰ä¾‹ãŒã‚ã‚Œã°å«ã‚ã‚‹
- æ®µè½é–“ã«ã¯ç©ºè¡Œã‚’å…¥ã‚Œã‚‹
- ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã®å‰å¾Œã«ã¯ç©ºè¡Œã‚’å…¥ã‚Œã‚‹
- æ¡ç”¨æ¸ˆã¿ã®æ±ºå®šäº‹é …ãŒã‚ã‚‹å ´åˆã¯ã€ãã‚Œã‚’è€ƒæ…®ã—ã¦å›ç­”ã—ã¦ãã ã•ã„
"""

        async for chunk in self.llm.astream([
            SystemMessage(content="ã‚ãªãŸã¯ä¸å¯§ãªé–‹ç™ºã‚µãƒãƒ¼ã‚¿ãƒ¼ã§ã™ã€‚åˆå¿ƒè€…ã«ã‚‚ã‚ã‹ã‚Šã‚„ã™ãèª¬æ˜ã—ã¦ãã ã•ã„ã€‚"),
            HumanMessage(content=prompt)
        ]):
            if chunk.content:
                yield chunk.content

    async def _stream_pros_cons_analysis(
        self,
        proposal: str,
        step: ImplementationStep
    ) -> AsyncGenerator[str, None]:
        """å¤‰æ›´ææ¡ˆã®ãƒ¡ãƒªãƒƒãƒˆãƒ»ãƒ‡ãƒ¡ãƒªãƒƒãƒˆã‚’ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã§åˆ†æ"""
        prompt = f"""
ä»¥ä¸‹ã®å¤‰æ›´ææ¡ˆã«ã¤ã„ã¦ã€ãƒ¡ãƒªãƒƒãƒˆã¨ãƒ‡ãƒ¡ãƒªãƒƒãƒˆã‚’ç°¡æ½”ã«åˆ†æã—ã¦ãã ã•ã„ã€‚

## å¤‰æ›´ææ¡ˆ
{proposal}

## ç¾åœ¨ã®ã‚¹ãƒ†ãƒƒãƒ—
- ã‚¹ãƒ†ãƒƒãƒ—{step.step_number}: {step.title}
- å†…å®¹: {step.content[:500]}

## ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±
- æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯: {', '.join(self.project_context.get('tech_stack', []))}

## å‡ºåŠ›å½¢å¼
ä»¥ä¸‹ã®å½¢å¼ã§ã€ç°¡æ½”ã«ï¼ˆå…¨ä½“ã§150-200æ–‡å­—ç¨‹åº¦ï¼‰åˆ†æã—ã¦ãã ã•ã„ï¼š

**ãƒ¡ãƒªãƒƒãƒˆ:**

âœ“ ãƒ¡ãƒªãƒƒãƒˆ1
âœ“ ãƒ¡ãƒªãƒƒãƒˆ2

**ãƒ‡ãƒ¡ãƒªãƒƒãƒˆãƒ»æ³¨æ„ç‚¹:**

â–³ æ³¨æ„ç‚¹1
â–³ æ³¨æ„ç‚¹2
"""

        async for chunk in self.llm.astream([
            SystemMessage(content="æŠ€è¡“é¸å®šã®ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼ã¨ã—ã¦ã€ç°¡æ½”ã«ãƒ¡ãƒªãƒ‡ãƒ¡ã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚"),
            HumanMessage(content=prompt)
        ]):
            if chunk.content:
                yield chunk.content

    async def _analyze_question_for_decision(
        self,
        question: str,
        step: ImplementationStep
    ) -> Optional[Dict[str, str]]:
        """
        è³ªå•ã‚’åˆ†æã—ã€å¤‰æ›´ææ¡ˆãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹åˆ¤æ–­ã€‚
        å«ã¾ã‚Œã¦ã„ã‚Œã°ææ¡ˆå†…å®¹ã‚’è¿”ã™ã€ãªã‘ã‚Œã°Noneã€‚
        """
        prompt = f"""
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚

## ã‚¹ãƒ†ãƒƒãƒ—ã®å†…å®¹
- ã‚¹ãƒ†ãƒƒãƒ—{step.step_number}: {step.title}
- å†…å®¹: {step.content[:800]}

## ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›
ã€Œ{question}ã€

## åˆ†æã‚¿ã‚¹ã‚¯
ã“ã®å…¥åŠ›ãŒä»¥ä¸‹ã®ã©ã¡ã‚‰ã‹ã‚’åˆ¤æ–­ã—ã¦ãã ã•ã„ï¼š

A) **å¤‰æ›´ææ¡ˆãƒ»è¦æœ›**: æŠ€è¡“é¸æŠã€è¨€èªã€ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã€ã‚¢ãƒ—ãƒ­ãƒ¼ãƒãªã©ã‚’å¤‰æ›´ã—ãŸã„æ„å›³ãŒã‚ã‚‹
   ä¾‹: ã€ŒTypeScriptã®æ–¹ãŒã„ã„ã€ã€ŒReduxã˜ã‚ƒãªãã¦zustandã‚’ä½¿ã„ãŸã„ã€ã€Œã‚‚ã£ã¨ã‚·ãƒ³ãƒ—ãƒ«ã«ã§ããªã„ï¼Ÿã€

B) **å˜ç´”ãªè³ªå•**: ç†è§£ã‚’æ·±ã‚ã‚‹ãŸã‚ã®è³ªå•ã€ã‚¨ãƒ©ãƒ¼ã®ç›¸è«‡ãªã©
   ä¾‹: ã€Œã“ã‚Œã©ã†ã„ã†æ„å‘³ï¼Ÿã€ã€Œãªãœã“ã†ã™ã‚‹ã®ï¼Ÿã€ã€Œã‚¨ãƒ©ãƒ¼ãŒå‡ºãŸã€

## å‡ºåŠ›å½¢å¼ï¼ˆJSONï¼‰
å¤‰æ›´ææ¡ˆã®å ´åˆ:
{{"type": "decision", "proposal": "ã€‡ã€‡ã‚’ä½¿ç”¨ã™ã‚‹", "reason": "ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã€‡ã€‡ã¨è¨€ã£ãŸãŸã‚"}}

å˜ç´”ãªè³ªå•ã®å ´åˆ:
{{"type": "question"}}
"""

        response = await self.llm.ainvoke([
            SystemMessage(content="JSONå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚"),
            HumanMessage(content=prompt)
        ])

        try:
            content = response.content
            if "```json" in content:
                content = content.split("```json")[1].split("```")[0]
            elif "```" in content:
                content = content.split("```")[1].split("```")[0]

            data = json.loads(content.strip())

            if data.get("type") == "decision":
                return {
                    "proposal": data.get("proposal", ""),
                    "reason": data.get("reason", "")
                }
            return None
        except (json.JSONDecodeError, KeyError):
            return None


# ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†ã¯ hands_on ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‹ã‚‰ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from services.hands_on.state import (
    default_manager as _session_manager,
    get_session,
    create_session,
    delete_session,
    restore_session_from_db,
)

# å¾Œæ–¹äº’æ›æ€§: _session_storeã¸ã®å‚ç…§ã‚’ç¶­æŒ
_session_store = _session_manager._store
