2025-10-17 00:43:39,348 | DEBUG | hackthon_support_agent.DomainCompletenessEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-10-17 00:43:39,356 | INFO | hackthon_support_agent.DomainCompletenessEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-10-17 00:43:39,357 | DEBUG | hackthon_support_agent.DomainCompletenessEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-10-17 00:43:39,363 | INFO | hackthon_support_agent.DomainCompletenessEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-10-17 00:43:39,363 | DEBUG | hackthon_support_agent.DomainCompletenessEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-10-17 00:43:39,368 | INFO | hackthon_support_agent.DomainCompletenessEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-10-17 00:43:39,369 | DEBUG | hackthon_support_agent.DomainCompletenessEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-17 00:43:39,370 | INFO | hackthon_support_agent.DomainCompletenessEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-17 00:43:39,371 | DEBUG | hackthon_support_agent.DomainCompletenessEvaluator | LLMs initialized
2025-10-17 00:43:39,372 | DEBUG | hackthon_support_agent.TaskDependencyService | Initializing BaseService (provider=google)
2025-10-17 00:43:39,374 | INFO | hackthon_support_agent.TaskDependencyService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-10-17 00:43:39,375 | DEBUG | hackthon_support_agent.TaskDependencyService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-10-17 00:43:39,377 | INFO | hackthon_support_agent.TaskDependencyService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-10-17 00:43:39,378 | DEBUG | hackthon_support_agent.TaskDependencyService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-10-17 00:43:39,381 | INFO | hackthon_support_agent.TaskDependencyService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-10-17 00:43:39,381 | DEBUG | hackthon_support_agent.TaskDependencyService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-10-17 00:43:39,384 | INFO | hackthon_support_agent.TaskDependencyService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-10-17 00:43:39,384 | DEBUG | hackthon_support_agent.TaskDependencyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-17 00:43:39,386 | INFO | hackthon_support_agent.TaskDependencyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-17 00:43:39,386 | DEBUG | hackthon_support_agent.TaskDependencyService | LLMs initialized
2025-10-17 00:43:39,387 | DEBUG | hackthon_support_agent.TaskPositionService | Initializing BaseService (provider=google)
2025-10-17 00:43:39,391 | INFO | hackthon_support_agent.TaskPositionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-10-17 00:43:39,391 | DEBUG | hackthon_support_agent.TaskPositionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-10-17 00:43:39,394 | INFO | hackthon_support_agent.TaskPositionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-10-17 00:43:39,394 | DEBUG | hackthon_support_agent.TaskPositionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-10-17 00:43:39,396 | INFO | hackthon_support_agent.TaskPositionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-10-17 00:43:39,397 | DEBUG | hackthon_support_agent.TaskPositionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-10-17 00:43:39,399 | INFO | hackthon_support_agent.TaskPositionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-10-17 00:43:39,400 | DEBUG | hackthon_support_agent.TaskPositionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-10-17 00:43:39,402 | INFO | hackthon_support_agent.TaskPositionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-10-17 00:43:39,403 | DEBUG | hackthon_support_agent.TaskPositionService | LLMs initialized
2025-10-17 00:44:31,812 | INFO | hackthon_support_agent.TaskGenerationService | ✅ Batch batch_1: All tasks validated successfully on attempt 1
2025-10-17 00:45:00,987 | INFO | hackthon_support_agent.TaskGenerationService | ✅ Batch batch_2: All tasks validated successfully on attempt 1
2025-10-17 00:45:23,023 | INFO | hackthon_support_agent.TaskGenerationService | ✅ Batch batch_3: All tasks validated successfully on attempt 1
2025-10-17 00:45:42,063 | INFO | hackthon_support_agent.TaskGenerationService | ✅ Batch batch_4: All tasks validated successfully on attempt 1
2025-10-18 10:13:13,392 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-10-18 10:13:45,149 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-10-18 10:21:54,653 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-10-18 10:22:05,526 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-10-18 10:49:34,027 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-10-18 11:22:34,189 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-10-18 11:23:03,578 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-10-18 11:23:47,327 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-10-18 11:26:36,955 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-10-18 22:49:21,097 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-10-18 22:49:54,129 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-10-18 22:50:04,497 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-10-18 23:09:53,629 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-10-18 23:14:29,845 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-10-18 23:14:44,435 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-10-19 00:24:01,615 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-10 11:48:11,319 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-10 11:48:11,320 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-11-10 11:48:11,322 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-10 11:48:11,322 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-10 11:48:11,336 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-10 11:48:11,336 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-10 11:48:11,337 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-10 11:48:11,337 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-10 11:48:11,338 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-10 11:48:11,338 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-10 11:48:11,338 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-10 11:48:11,338 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-11-10 11:48:11,338 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-11-10 11:48:44,058 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-10 11:48:44,060 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-11-10 11:48:44,062 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-10 11:48:44,062 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-10 11:48:44,083 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-10 11:48:44,083 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-10 11:48:44,084 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-10 11:48:44,084 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-10 11:48:44,085 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-10 11:48:44,085 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-10 11:48:44,085 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-10 11:48:44,085 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-11-10 11:48:44,085 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-11-10 11:48:53,254 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-10 11:48:53,256 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-11-10 11:48:53,257 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-10 11:48:53,257 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-10 11:48:53,266 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-10 11:48:53,266 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-10 11:48:53,267 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-10 11:48:53,267 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-10 11:48:53,268 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-10 11:48:53,268 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-10 11:48:53,268 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-10 11:48:53,268 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-11-10 11:48:53,268 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-11-10 11:48:53,269 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-11-10 11:48:53,270 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-10 11:48:53,270 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-10 11:48:53,271 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-10 11:48:53,271 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-10 11:48:53,272 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-10 11:48:53,272 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-10 11:48:53,272 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-10 11:48:53,272 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-10 11:48:53,273 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-10 11:48:53,273 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-11-10 11:48:53,273 | DEBUG | hackthon_support_agent.QuestionService | Generating questions for project_id: 40cb21de-b951-4c29-8d01-a63bf2c4aa71 with idea_prompt: 大学生向けの勉強記録アプリ。毎日の学習時間を記録して、友達と共有できる。期間は2週間、メンバーは3人。
2025-11-10 11:48:53,273 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-11-10 11:49:02,953 | INFO | hackthon_support_agent.QuestionService | Generated 7 questions for project_id: 40cb21de-b951-4c29-8d01-a63bf2c4aa71
2025-11-11 00:33:59,387 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 00:34:02,687 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 00:44:00,741 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-11-11 00:44:00,745 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 00:44:00,746 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 00:44:00,770 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 00:44:00,771 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 00:44:00,772 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 00:44:00,772 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 00:44:00,773 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 00:44:00,773 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 00:44:00,774 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 00:44:00,775 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-11-11 00:44:00,775 | DEBUG | hackthon_support_agent.QuestionService | Generating questions for project_id: 7e2309a6-1982-483f-baca-3b1dc259b268 with idea_prompt: プロジェクトタイトル: オンライン学習プラットフォーム
プロジェクトアイディア: 学生の学力と得意不得意に合わせたAIを用いた動的な課題作成サービス
期間: 2025-11-11 〜 2026-01-11 09:39
2025-11-11 00:44:00,775 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-11-11 00:44:13,928 | INFO | hackthon_support_agent.QuestionService | Generated 7 questions for project_id: 7e2309a6-1982-483f-baca-3b1dc259b268
2025-11-11 00:44:13,938 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-11-11 00:44:13,941 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 00:44:13,941 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 00:44:13,943 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 00:44:13,944 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 00:44:13,946 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 00:44:13,946 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 00:44:13,949 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 00:44:13,950 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 00:44:13,951 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 00:44:13,951 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-11-11 00:49:28,810 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-11-11 00:49:28,816 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 00:49:28,816 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 00:49:28,826 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 00:49:28,827 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 00:49:28,829 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 00:49:28,829 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 00:49:28,830 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 00:49:28,830 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 00:49:28,832 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 00:49:28,832 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-11-11 00:49:28,840 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.generate_summary_document'
2025-11-11 00:49:42,950 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-11-11 00:49:42,953 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 00:49:42,953 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 00:49:42,957 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 00:49:42,957 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 00:49:42,958 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 00:49:42,958 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 00:49:42,959 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 00:49:42,960 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 00:49:42,961 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 00:49:42,961 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-11-11 00:49:59,400 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-11-11 00:49:59,404 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 00:49:59,404 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 00:49:59,418 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 00:49:59,418 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 00:49:59,427 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 00:49:59,428 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 00:49:59,434 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 00:49:59,435 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 00:49:59,440 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 00:49:59,441 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-11-11 00:49:59,453 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-11-11 01:24:30,668 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 01:24:44,168 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 01:30:54,881 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 01:31:17,271 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 01:31:53,195 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 01:33:37,994 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 01:36:37,001 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 01:36:52,287 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 01:37:09,296 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 01:39:50,941 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 01:40:22,437 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 01:40:26,308 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 01:40:28,264 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 01:50:43,096 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 01:50:46,105 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 01:51:20,106 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 01:51:44,705 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 01:52:13,663 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 10:52:16,361 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 01:54:02,910 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 01:54:05,643 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 01:54:08,209 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 01:56:47,257 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 10:57:28,978 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 10:57:40,608 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 01:58:04,343 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 01:58:37,287 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 01:59:02,020 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 01:59:06,232 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 01:59:11,152 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 01:59:30,034 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 01:59:51,021 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 01:59:59,784 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 01:59:59,879 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-11-11 01:59:59,881 | ERROR | hackthon_support_agent.SummaryService | Failed to load prompts from /workspaces/hackathon_support_agent/back/services/prompts.toml
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/base_service.py", line 80, in __init__
    self.prompts: Dict[str, Dict[str, str]] = tomllib.load(f)
                                              ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/tomllib/_parser.py", line 66, in load
    return loads(s, parse_float=parse_float)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/tomllib/_parser.py", line 102, in loads
    pos = key_value_rule(src, pos, out, header, parse_float)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/tomllib/_parser.py", line 349, in key_value_rule
    raise suffixed_err(src, pos, "Cannot overwrite a value")
tomllib.TOMLDecodeError: Cannot overwrite a value (at line 439, column 4)
2025-11-11 02:03:32,010 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 02:03:32,628 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-11-11 02:03:32,642 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 02:03:32,644 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 02:03:32,704 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 02:03:32,704 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 02:03:32,709 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 02:03:32,712 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 02:03:32,715 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 02:03:32,718 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 02:03:32,721 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 02:03:32,722 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-11-11 02:03:32,732 | INFO | hackthon_support_agent.SummaryService | 初回生成：全Q&Aから仕様書を生成します。
2025-11-11 02:03:32,741 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.generate_summary_document'
2025-11-11 02:03:41,876 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: 57a052a6-7d6f-478d-9a57-71d6a0591e2a
2025-11-11 02:03:41,880 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.evaluate_specification'
2025-11-11 02:03:53,638 | INFO | hackthon_support_agent.SummaryService | 既存仕様書を検出。差分ベースで更新します。
2025-11-11 02:03:53,644 | INFO | hackthon_support_agent.SummaryService | 差分検出: 手動編集=False, 新規Q&A=1件
2025-11-11 02:03:53,647 | INFO | hackthon_support_agent.SummaryService | 新規キャッシュを作成: 57a052a6-7d6f-478d-9a57-71d6a0591e2a
2025-11-11 02:03:53,867 | ERROR | hackthon_support_agent.SummaryService | キャッシュ使用中にエラー: 400 Cached content is too small. total_token_count=874, min_total_token_count=1024
2025-11-11 02:03:53,868 | INFO | hackthon_support_agent.SummaryService | フォールバック: キャッシュなしで生成
2025-11-11 02:04:02,074 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: 57a052a6-7d6f-478d-9a57-71d6a0591e2a
2025-11-11 02:04:02,076 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.evaluate_specification'
2025-11-11 02:04:14,873 | INFO | hackthon_support_agent.SummaryService | 手動編集を検出: 11行の差分
2025-11-11 02:13:11,484 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 02:14:05,572 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 11:14:23,910 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 11:14:24,039 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-11-11 11:14:24,041 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 11:14:24,041 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 11:14:24,066 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 11:14:24,066 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 11:14:24,067 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 11:14:24,067 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 11:14:24,068 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 11:14:24,068 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 11:14:24,069 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 11:14:24,069 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-11-11 11:14:24,069 | INFO | hackthon_support_agent.SummaryService | 手動編集を検出: 12行の差分
2025-11-11 11:14:24,070 | INFO | hackthon_support_agent.SummaryService | 新規キャッシュを作成: ebee063f-519d-45b2-9fe0-942d043b8045
2025-11-11 11:14:24,070 | INFO | hackthon_support_agent.SummaryService | キャッシュ作成成功: cached_project_ebee063f-519d-45b2-9fe0-942d043b8045
2025-11-11 11:14:24,070 | INFO | hackthon_support_agent.SummaryService | キャッシュ使用で仕様書更新完了
2025-11-11 11:14:24,071 | INFO | hackthon_support_agent.SummaryService | 既存キャッシュを使用: cached_project_ebee063f-519d-45b2-9fe0-942d043b8045
2025-11-11 11:14:24,071 | INFO | hackthon_support_agent.SummaryService | キャッシュ使用で仕様書更新完了
2025-11-11 11:14:24,071 | INFO | hackthon_support_agent.SummaryService | 既存仕様書を検出。差分ベースで更新します。
2025-11-11 02:29:05,229 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 02:32:13,366 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 02:33:14,894 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 02:33:35,128 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 02:33:37,136 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 02:34:51,447 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 02:35:41,360 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 02:35:44,476 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 02:35:54,548 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 02:35:54,841 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-11-11 02:35:54,844 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 02:35:54,845 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 02:35:54,857 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 02:35:54,858 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 02:35:54,860 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 02:35:54,860 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 02:35:54,862 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 02:35:54,862 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 02:35:54,864 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 02:35:54,864 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-11-11 02:35:54,865 | INFO | hackthon_support_agent.SummaryService | 手動編集を検出: 12行の差分
2025-11-11 02:35:54,866 | INFO | hackthon_support_agent.SummaryService | 新規キャッシュを作成: 82515801-efd1-4e83-8c74-dde848780ca5
2025-11-11 02:35:54,867 | INFO | hackthon_support_agent.SummaryService | キャッシュ作成成功: <MagicMock name='genai.Client().caches.create().name' id='281473165736080'>
2025-11-11 02:35:54,870 | ERROR | hackthon_support_agent.SummaryService | キャッシュ使用中にエラー: 1 validation error for GenerateContentConfig
cached_content
  Input should be a valid string [type=string_type, input_value=<MagicMock name='genai.Cl...e' id='281473165736080'>, input_type=MagicMock]
    For further information visit https://errors.pydantic.dev/2.12/v/string_type
2025-11-11 02:35:54,870 | INFO | hackthon_support_agent.SummaryService | フォールバック: キャッシュなしで生成
2025-11-11 02:35:58,737 | INFO | hackthon_support_agent.SummaryService | 新規キャッシュを作成: 82515801-efd1-4e83-8c74-dde848780ca5
2025-11-11 02:35:58,738 | INFO | hackthon_support_agent.SummaryService | キャッシュ作成成功: <MagicMock name='genai.Client().caches.create().name' id='281473165736080'>
2025-11-11 02:35:58,739 | ERROR | hackthon_support_agent.SummaryService | キャッシュ使用中にエラー: 1 validation error for GenerateContentConfig
cached_content
  Input should be a valid string [type=string_type, input_value=<MagicMock name='genai.Cl...e' id='281473165736080'>, input_type=MagicMock]
    For further information visit https://errors.pydantic.dev/2.12/v/string_type
2025-11-11 02:35:58,739 | INFO | hackthon_support_agent.SummaryService | フォールバック: キャッシュなしで生成
2025-11-11 02:36:01,220 | INFO | hackthon_support_agent.SummaryService | 既存仕様書を検出。差分ベースで更新します。
2025-11-11 02:36:17,534 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 02:36:17,878 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-11-11 02:36:17,880 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 02:36:17,880 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 02:36:17,892 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 02:36:17,892 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 02:36:17,894 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 02:36:17,894 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 02:36:17,895 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 02:36:17,896 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 02:36:17,897 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 02:36:17,898 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-11-11 02:36:17,951 | INFO | hackthon_support_agent.SummaryService | 初回生成：全Q&Aから仕様書を生成します。
2025-11-11 02:36:17,956 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.generate_summary_document'
2025-11-11 02:36:28,783 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: 74e1f170-2287-4a98-b8e6-ef5f065c4a68
2025-11-11 02:36:28,786 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.evaluate_specification'
2025-11-11 02:36:50,820 | INFO | hackthon_support_agent.SummaryService | 既存仕様書を検出。差分ベースで更新します。
2025-11-11 02:36:50,825 | INFO | hackthon_support_agent.SummaryService | 差分検出: 手動編集=False, 新規Q&A=1件
2025-11-11 02:36:50,826 | INFO | hackthon_support_agent.SummaryService | 新規キャッシュを作成: 74e1f170-2287-4a98-b8e6-ef5f065c4a68
2025-11-11 02:36:51,017 | ERROR | hackthon_support_agent.SummaryService | キャッシュ使用中にエラー: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'Cached content is too small. total_token_count=898, min_total_token_count=4096', 'status': 'INVALID_ARGUMENT'}}
2025-11-11 02:36:51,017 | INFO | hackthon_support_agent.SummaryService | フォールバック: キャッシュなしで生成
2025-11-11 02:36:56,426 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: 74e1f170-2287-4a98-b8e6-ef5f065c4a68
2025-11-11 02:36:56,428 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.evaluate_specification'
2025-11-11 02:37:22,231 | INFO | hackthon_support_agent.SummaryService | 手動編集を検出: 11行の差分
2025-11-11 03:36:31,142 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-11-11 03:36:31,148 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 03:36:31,148 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 03:36:31,194 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 03:36:31,195 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 03:36:31,197 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 03:36:31,197 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 03:36:31,199 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 03:36:31,199 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 03:36:31,201 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 03:36:31,201 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-11-11 03:36:31,202 | DEBUG | hackthon_support_agent.QuestionService | Generating questions for project_id: 1979ebfa-c199-430c-924e-b8a11f1f7f93 with idea_prompt: プロジェクトタイトル: オンライン学習プラットフォーム
プロジェクトアイディア: 学生の学力と得意不得意に合わせたAIを用いた動的な課題作成サービス
期間: 2025-11-11 〜 2025-12-11 12:36
2025-11-11 03:36:31,202 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-11-11 03:36:47,826 | INFO | hackthon_support_agent.QuestionService | Generated 6 questions for project_id: 1979ebfa-c199-430c-924e-b8a11f1f7f93
2025-11-11 03:36:47,873 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-11-11 03:36:47,889 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 03:36:47,890 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 03:36:47,904 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 03:36:47,905 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 03:36:47,918 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 03:36:47,921 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 03:36:47,957 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 03:36:47,958 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 03:36:47,967 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 03:36:47,968 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-11-11 03:36:54,451 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-11-11 03:36:54,455 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 03:36:54,455 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 03:36:54,461 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 03:36:54,461 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 03:36:54,464 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 03:36:54,464 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 03:36:54,465 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 03:36:54,466 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 03:36:54,467 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 03:36:54,467 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-11-11 03:36:54,564 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.generate_summary_document'
2025-11-11 03:37:09,209 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-11-11 03:37:09,212 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 03:37:09,213 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 03:37:09,215 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 03:37:09,216 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 03:37:09,217 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 03:37:09,217 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 03:37:09,219 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 03:37:09,220 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 03:37:09,221 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 03:37:09,221 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-11-11 03:37:09,718 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-11-11 03:37:09,721 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 03:37:09,722 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 03:37:09,725 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 03:37:09,726 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 03:37:09,729 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 03:37:09,729 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 03:37:09,731 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 03:37:09,732 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 03:37:09,734 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 03:37:09,734 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-11-11 03:37:09,752 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-11-11 03:37:30,361 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-11-11 03:37:30,366 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 03:37:30,367 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 03:37:30,375 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 03:37:30,375 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 03:37:30,377 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 03:37:30,377 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 03:37:30,381 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 03:37:30,381 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 03:37:30,383 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 03:37:30,383 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-11-11 03:37:30,419 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: 1979ebfa-c199-430c-924e-b8a11f1f7f93
2025-11-11 03:37:30,424 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.evaluate_specification'
2025-11-11 03:40:45,147 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-11-11 03:40:45,158 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 03:40:45,158 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 03:40:45,170 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 03:40:45,171 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 03:40:45,173 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 03:40:45,174 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 03:40:45,176 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 03:40:45,176 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 03:40:45,177 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 03:40:45,178 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-11-11 03:40:45,222 | INFO | hackthon_support_agent.SummaryService | 既存仕様書を検出。差分ベースで更新します。
2025-11-11 03:40:45,232 | INFO | hackthon_support_agent.SummaryService | 差分検出: 手動編集=False, 新規Q&A=5件
2025-11-11 03:40:45,234 | INFO | hackthon_support_agent.SummaryService | 新規キャッシュを作成: 1979ebfa-c199-430c-924e-b8a11f1f7f93
2025-11-11 03:40:45,432 | ERROR | hackthon_support_agent.SummaryService | キャッシュ使用中にエラー: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'Cached content is too small. total_token_count=1047, min_total_token_count=4096', 'status': 'INVALID_ARGUMENT'}}
2025-11-11 03:40:45,433 | INFO | hackthon_support_agent.SummaryService | フォールバック: キャッシュなしで生成
2025-11-11 03:40:56,133 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: 1979ebfa-c199-430c-924e-b8a11f1f7f93
2025-11-11 03:40:56,135 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.evaluate_specification'
2025-11-11 03:41:13,488 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-11-11 03:41:13,491 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 03:41:13,491 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 03:41:13,494 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 03:41:13,494 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 03:41:13,497 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 03:41:13,497 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 03:41:13,500 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 03:41:13,500 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 03:41:13,503 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 03:41:13,503 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-11-11 03:41:13,508 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-11-11 03:42:38,160 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-11-11 03:42:38,166 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 03:42:38,167 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 03:42:38,178 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 03:42:38,178 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 03:42:38,181 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 03:42:38,181 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 03:42:38,185 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 03:42:38,186 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 03:42:38,188 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 03:42:38,188 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-11-11 03:42:38,235 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: 1979ebfa-c199-430c-924e-b8a11f1f7f93
2025-11-11 03:42:38,244 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.evaluate_specification'
2025-11-11 03:55:19,908 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 03:56:37,756 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 04:04:22,100 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-11-11 04:04:22,107 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 04:04:22,107 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 04:04:22,191 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 04:04:22,192 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 04:04:22,197 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 04:04:22,198 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 04:04:22,203 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 04:04:22,203 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 04:04:22,209 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 04:04:22,210 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-11-11 04:04:22,226 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-11-11 04:04:33,452 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-11-11 04:04:33,471 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 04:04:33,471 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 04:04:33,479 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 04:04:33,479 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 04:04:33,481 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 04:04:33,481 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 04:04:33,484 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 04:04:33,484 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 04:04:33,486 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 04:04:33,486 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-11-11 04:04:33,596 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: 1979ebfa-c199-430c-924e-b8a11f1f7f93
2025-11-11 04:04:33,610 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.evaluate_specification'
2025-11-11 13:04:42,405 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 04:05:01,211 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-11-11 04:05:01,218 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 04:05:01,218 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 04:05:01,238 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 04:05:01,238 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 04:05:01,240 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 04:05:01,240 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 04:05:01,243 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 04:05:01,244 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 04:05:01,246 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 04:05:01,246 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-11-11 04:05:01,289 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: 1979ebfa-c199-430c-924e-b8a11f1f7f93
2025-11-11 04:05:01,302 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.evaluate_specification'
2025-11-11 04:06:16,978 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 04:06:21,357 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 04:06:29,062 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 04:06:29,574 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-11-11 04:06:29,578 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 04:06:29,578 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 04:06:29,620 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 04:06:29,622 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 04:06:29,634 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 04:06:29,639 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 04:06:29,654 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 04:06:29,662 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 04:06:29,675 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 04:06:29,678 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-11-11 04:06:29,779 | INFO | hackthon_support_agent.SummaryService | 初回生成：全Q&Aから仕様書を生成します。
2025-11-11 04:06:29,782 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.generate_summary_document'
2025-11-11 04:06:41,442 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: 98a20802-009a-40e2-a7b4-4497eceaf203
2025-11-11 04:06:41,446 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.evaluate_specification'
2025-11-11 04:06:50,914 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-11-11 04:06:50,918 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 04:06:50,918 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 04:06:50,940 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 04:06:50,941 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 04:06:50,943 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 04:06:50,944 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 04:06:50,945 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 04:06:50,946 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 04:06:50,947 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 04:06:50,948 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-11-11 04:06:50,954 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-11-11 04:06:52,432 | INFO | hackthon_support_agent.SummaryService | 不足情報から追加Q&Aを生成: 【ユーザー像】想定ユーザーである大学生の具体的な年齢層（例: 学年）や、ハッカソン以外の学業・生活と...
2025-11-11 04:06:52,782 | INFO | hackthon_support_agent.SummaryService | 不足情報から追加Q&Aを生成: 【利用シーン】このアプリがハッカソン期間中の具体的にいつ（時間帯）利用され、どのくらいの頻度で使われ...
2025-11-11 04:06:52,788 | INFO | hackthon_support_agent.SummaryService | 不足情報から追加Q&Aを生成: 【非機能要件】このアシスタントアプリ自体のパフォーマンス、セキュリティ、スケーラビリティ、可用性とい...
2025-11-11 04:06:52,794 | INFO | hackthon_support_agent.SummaryService | 不足情報から追加Q&Aを生成: 【技術要件】このアシスタントアプリを開発するにあたり、どのような技術スタック（例: Webアプリ、モ...
2025-11-11 04:06:52,798 | INFO | hackthon_support_agent.SummaryService | 不足情報から追加Q&Aを生成: 【競合分析】既存の汎用的なドキュメントツールや類似サービスと比較して、本アプリが提供する独自の強みや...
2025-11-11 04:06:52,832 | INFO | hackthon_support_agent.SummaryService | 既存仕様書を検出。差分ベースで更新します。
2025-11-11 04:06:52,840 | INFO | hackthon_support_agent.SummaryService | 差分検出: 手動編集=False, 新規Q&A=6件
2025-11-11 04:06:52,843 | INFO | hackthon_support_agent.SummaryService | 新規キャッシュを作成: 98a20802-009a-40e2-a7b4-4497eceaf203
2025-11-11 04:06:53,093 | ERROR | hackthon_support_agent.SummaryService | キャッシュ使用中にエラー: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'Cached content is too small. total_token_count=1078, min_total_token_count=4096', 'status': 'INVALID_ARGUMENT'}}
2025-11-11 04:06:53,094 | INFO | hackthon_support_agent.SummaryService | フォールバック: キャッシュなしで生成
2025-11-11 04:07:00,715 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: 98a20802-009a-40e2-a7b4-4497eceaf203
2025-11-11 04:07:00,720 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.evaluate_specification'
2025-11-11 04:07:04,121 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-11-11 04:07:04,146 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 04:07:04,147 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 04:07:04,175 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 04:07:04,177 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 04:07:04,181 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 04:07:04,182 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 04:07:04,194 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 04:07:04,195 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 04:07:04,199 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 04:07:04,200 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-11-11 04:07:04,831 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: 1979ebfa-c199-430c-924e-b8a11f1f7f93
2025-11-11 04:07:04,896 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.evaluate_specification'
2025-11-11 04:07:18,949 | INFO | hackthon_support_agent.SummaryService | 不足情報から追加Q&Aを生成: 【ユーザー要件】想定ユーザーである大学生の具体的な年齢層（学年）、ハッカソン以外の学業・生活とのバラ...
2025-11-11 04:07:18,954 | INFO | hackthon_support_agent.SummaryService | 不足情報から追加Q&Aを生成: 【ユーザー要件】このアプリがハッカソン期間中の具体的にいつ（時間帯）、どのくらいの頻度で利用され、ハ...
2025-11-11 04:07:18,955 | INFO | hackthon_support_agent.SummaryService | 不足情報から追加Q&Aを生成: 【企画要件】既存の汎用的なドキュメントツールや類似サービスと比較して、本アプリが提供する独自の強みや...
2025-11-11 04:07:18,956 | INFO | hackthon_support_agent.SummaryService | 不足情報から追加Q&Aを生成: 【非機能要件】このアシスタントアプリ自体のパフォーマンス（応答速度、同時接続数など）、セキュリティ（...
2025-11-11 04:07:18,957 | INFO | hackthon_support_agent.SummaryService | 不足情報から追加Q&Aを生成: 【技術要件】技術スタックとしてNext.jsとFastAPIが挙げられていますが、データベースの種類...
2025-11-11 04:07:18,970 | INFO | hackthon_support_agent.SummaryService | 手動編集を検出: 11行の差分
2025-11-11 04:14:13,616 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 04:14:21,850 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 04:22:59,126 | DEBUG | hackthon_support_agent.FunctionService | Initializing BaseService (provider=google)
2025-11-11 04:22:59,130 | INFO | hackthon_support_agent.FunctionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 04:22:59,130 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 04:22:59,158 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 04:22:59,158 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 04:22:59,160 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 04:22:59,160 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 04:22:59,161 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 04:22:59,162 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 04:22:59,162 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 04:22:59,163 | DEBUG | hackthon_support_agent.FunctionService | LLMs initialized
2025-11-11 04:22:59,163 | DEBUG | hackthon_support_agent.FunctionService | Generating functional requirements for project_id: 1979ebfa-c199-430c-924e-b8a11f1f7f93
2025-11-11 04:22:59,168 | DEBUG | hackthon_support_agent.FunctionService | Fetching prompt 'function_service.generate_functional_requirements'
2025-11-11 04:23:49,596 | DEBUG | hackthon_support_agent.FunctionService | Saving functional requirements to project document: 1979ebfa-c199-430c-924e-b8a11f1f7f93
2025-11-11 16:15:28,105 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 16:51:23,142 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 16:51:23,242 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:51:23,243 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:51:23,244 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:23,269 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:23,269 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:23,270 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:23,270 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:23,271 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:23,271 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:51:23,272 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:51:23,272 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:51:23,272 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:51:23,273 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:51:23,273 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:23,274 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:23,274 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:23,274 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:23,274 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:23,275 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:23,275 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:51:23,276 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:51:23,276 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:51:23,281 | INFO | hackthon_support_agent.BaseService | [PLANNING] Starting planning phase
2025-11-11 16:51:23,281 | INFO | hackthon_support_agent.BaseService | [PLANNING] Plan created: 3 focus areas
2025-11-11 16:51:23,366 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:51:23,368 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:51:23,368 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:23,369 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:23,369 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:23,369 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:23,369 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:23,370 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:23,370 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:51:23,370 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:51:23,371 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:51:23,371 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:51:23,372 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:51:23,372 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:23,373 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:23,373 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:23,373 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:23,373 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:23,376 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:23,376 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:51:23,377 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:51:23,377 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:51:23,381 | INFO | hackthon_support_agent.BaseService | [CACHE] Creating context cache
2025-11-11 16:51:23,382 | WARNING | hackthon_support_agent.BaseService | [CACHE] Failed to create real cache: cannot import name 'genai' from 'google' (unknown location)
2025-11-11 16:51:23,382 | WARNING | hackthon_support_agent.BaseService | [CACHE] Falling back to mock cache (no token savings)
2025-11-11 16:51:23,382 | INFO | hackthon_support_agent.BaseService | [CACHE] Cache created: projects/test_project_001/caches/1762847483, TTL: 60min
2025-11-11 16:51:23,382 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:51:23,384 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:51:23,384 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:23,385 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:23,385 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:23,385 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:23,385 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:23,386 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:23,386 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:51:23,386 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:51:23,386 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:51:23,386 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:51:23,388 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:51:23,388 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:23,389 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:23,389 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:23,389 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:23,389 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:23,390 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:23,390 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:51:23,390 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:51:23,390 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:51:23,395 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Starting parallel extraction
2025-11-11 16:51:23,395 | INFO | hackthon_support_agent.BaseService | [PARALLEL] Processing 2 focus areas in parallel
2025-11-11 16:51:23,395 | INFO | hackthon_support_agent.BaseService | [MAP_REDUCE] Starting map-reduce extraction for 認証
2025-11-11 16:51:23,395 | ERROR | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] Error in 認証: name 're' is not defined
2025-11-11 16:51:23,395 | INFO | hackthon_support_agent.BaseService | [MAP_REDUCE] Starting map-reduce extraction for データ管理
2025-11-11 16:51:23,395 | ERROR | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] Error in データ管理: name 're' is not defined
2025-11-11 16:51:23,395 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Completed: 2 areas processed in parallel
2025-11-11 16:51:23,396 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:51:23,398 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:51:23,398 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:23,398 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:23,398 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:23,399 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:23,399 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:23,400 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:23,400 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:51:23,400 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:51:23,400 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:51:23,400 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:51:23,402 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:51:23,402 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:23,402 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:23,402 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:23,403 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:23,403 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:23,403 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:23,403 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:51:23,404 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:51:23,404 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:51:23,408 | INFO | hackthon_support_agent.BaseService | [MERGE] Merging results from all focus areas
2025-11-11 16:51:23,408 | INFO | hackthon_support_agent.BaseService | [MERGE] Merged: 3 unique functions
2025-11-11 16:51:23,409 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:51:23,411 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:51:23,411 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:23,411 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:23,412 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:23,412 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:23,412 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:23,413 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:23,413 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:51:23,413 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:51:23,413 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:51:23,413 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:51:23,415 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:51:23,415 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:23,415 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:23,415 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:23,417 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:23,417 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:23,418 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:23,418 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:51:23,418 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:51:23,418 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:51:23,423 | INFO | hackthon_support_agent.BaseService | [FINAL_VALIDATION] Starting final validation
2025-11-11 16:51:44,608 | INFO | hackthon_support_agent.BaseService | [FINAL_VALIDATION] Judgment: APPROVE
2025-11-11 16:51:44,616 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:51:44,617 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:51:44,617 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:44,619 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:44,619 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:44,619 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:44,619 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:44,620 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:44,620 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:51:44,621 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:51:44,621 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:51:44,621 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:51:44,622 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:51:44,622 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:44,623 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:44,623 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:44,623 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:44,623 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:44,624 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:44,624 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:51:44,624 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:51:44,624 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:51:44,629 | INFO | hackthon_support_agent.BaseService | [PERSISTENCE] Saving to database
2025-11-11 16:51:44,629 | ERROR | hackthon_support_agent.BaseService | [PERSISTENCE] Persistence failed: FunctionStructuringPipeline._save_to_database() got an unexpected keyword argument 'final_data'
2025-11-11 16:51:44,635 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:51:44,637 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:51:44,637 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:44,638 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:44,638 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:44,638 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:44,638 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:44,639 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:44,639 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:51:44,639 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:51:44,639 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:51:44,639 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:51:44,641 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:51:44,641 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:44,643 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:44,643 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:44,644 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:44,644 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:44,645 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:44,645 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:51:44,645 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:51:44,645 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:51:44,650 | INFO | hackthon_support_agent.BaseService | [COVERAGE] Analyzing coverage
2025-11-11 16:51:44,650 | INFO | hackthon_support_agent.BaseService | [COVERAGE] Coverage: 5.0%, Status: continue
2025-11-11 16:51:44,651 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:51:44,652 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:51:44,652 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:44,653 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:44,653 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:44,653 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:44,653 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:44,654 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:44,654 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:51:44,655 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:51:44,655 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:51:44,655 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:51:44,656 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:51:44,656 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:44,657 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:44,657 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:44,657 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:44,657 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:44,658 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:44,658 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:51:44,658 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:51:44,658 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:51:44,663 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:51:44,665 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:51:44,665 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:44,666 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:44,666 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:44,666 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:44,666 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:44,667 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:44,667 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:51:44,667 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:51:44,667 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:51:44,667 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:51:44,669 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:51:44,669 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:44,669 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:44,669 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:44,670 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:44,670 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:44,670 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:44,670 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:51:44,671 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:51:44,671 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:51:44,676 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:51:44,677 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:51:44,678 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:44,678 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:44,678 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:44,679 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:44,679 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:44,679 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:44,679 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:51:44,681 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:51:44,682 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:51:44,682 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:51:44,683 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:51:44,683 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:44,684 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:44,684 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:44,684 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:44,684 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:44,685 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:44,685 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:51:44,686 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:51:44,686 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:51:44,690 | INFO | hackthon_support_agent.BaseService | [COVERAGE_DECISION] Max iterations reached, ending workflow
2025-11-11 16:51:44,695 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:51:44,696 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:51:44,696 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:44,697 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:44,697 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:44,697 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:44,698 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:44,698 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:44,698 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:51:44,699 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:51:44,699 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:51:44,699 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:51:44,700 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:51:44,700 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:44,701 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:44,701 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:44,701 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:44,701 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:44,702 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:44,702 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:51:44,703 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:51:44,703 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:51:44,719 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:51:44,721 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:51:44,721 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:44,721 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:44,721 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:44,722 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:44,722 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:44,723 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:44,723 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:51:44,723 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:51:44,723 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:51:44,723 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:51:44,725 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:51:44,725 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:44,725 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:44,726 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:44,726 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:44,726 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:44,727 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:44,727 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:51:44,728 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:51:44,728 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:51:44,745 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:51:44,746 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:51:44,746 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:44,747 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:44,747 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:44,747 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:44,748 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:44,748 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:44,748 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:51:44,749 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:51:44,749 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:51:44,749 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:51:44,750 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:51:44,750 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:44,751 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:44,751 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:44,751 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:44,751 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:44,752 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:44,752 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:51:44,752 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:51:44,752 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:51:44,759 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:51:44,760 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:51:44,760 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:44,761 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:44,761 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:44,762 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:44,762 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:44,762 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:44,762 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:51:44,763 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:51:44,763 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:51:44,763 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:51:44,764 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:51:44,764 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:44,765 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:44,765 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:44,765 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:44,765 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:44,766 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:44,766 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:51:44,766 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:51:44,766 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:51:44,909 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:51:44,911 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:51:44,911 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:44,911 | WARNING | hackthon_support_agent.BaseService | GOOGLE_API_KEY is not set
2025-11-11 16:51:53,942 | ERROR | hackthon_support_agent.BaseService | Failed to load LLM (provider=google, model=gemini-2.5-flash)
Traceback (most recent call last):
  File "/Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/base_service.py", line 107, in _load_llm
    llm = ChatGoogleGenerativeAI(
          ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/akatuki/.pyenv/versions/3.12.7/lib/python3.12/site-packages/langchain_google_genai/chat_models.py", line 1531, in __init__
    super().__init__(**kwargs)
  File "/Users/akatuki/.pyenv/versions/3.12.7/lib/python3.12/site-packages/langchain_core/load/serializable.py", line 115, in __init__
    super().__init__(*args, **kwargs)
  File "/Users/akatuki/.pyenv/versions/3.12.7/lib/python3.12/site-packages/pydantic/main.py", line 214, in __init__
    validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/akatuki/.pyenv/versions/3.12.7/lib/python3.12/site-packages/langchain_google_genai/chat_models.py", line 1592, in validate_environment
    self.client = genaix.build_generative_service(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/akatuki/.pyenv/versions/3.12.7/lib/python3.12/site-packages/langchain_google_genai/_genai_extension.py", line 286, in build_generative_service
    return v1betaGenerativeServiceClient(**config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/akatuki/.pyenv/versions/3.12.7/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py", line 698, in __init__
    self._transport = transport_init(
                      ^^^^^^^^^^^^^^^
  File "/Users/akatuki/.pyenv/versions/3.12.7/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/grpc.py", line 234, in __init__
    super().__init__(
  File "/Users/akatuki/.pyenv/versions/3.12.7/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/base.py", line 104, in __init__
    credentials, _ = google.auth.default(
                     ^^^^^^^^^^^^^^^^^^^^
  File "/Users/akatuki/.pyenv/versions/3.12.7/lib/python3.12/site-packages/google/auth/_default.py", line 719, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
2025-11-11 16:51:54,086 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:51:54,088 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:51:54,088 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:54,090 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:54,090 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:54,091 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:54,091 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:54,092 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:54,092 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:51:54,092 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:51:54,092 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:51:54,092 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:51:54,094 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:51:54,094 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:54,094 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:54,095 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:54,095 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:54,095 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:51:54,096 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:51:54,096 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:51:54,096 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:51:54,096 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:53:27,515 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 16:53:27,659 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:53:27,661 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:53:27,661 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:53:27,685 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:53:27,685 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:53:27,686 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:53:27,686 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:53:27,686 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:53:27,687 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:53:27,688 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:53:27,688 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:53:27,688 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:53:27,689 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:53:27,689 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:53:27,690 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:53:27,690 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:53:27,691 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:53:27,691 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:53:27,691 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:53:27,691 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:53:27,692 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:53:27,692 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:54:19,005 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 16:54:19,172 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:54:19,174 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:54:19,174 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:54:19,202 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:54:19,203 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:54:19,204 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:54:19,204 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:54:19,205 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:54:19,205 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:54:19,206 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:54:19,206 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:54:19,206 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:54:19,208 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:54:19,208 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:54:19,209 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:54:19,209 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:54:19,211 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:54:19,211 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:54:19,212 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:54:19,212 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:54:19,213 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:54:19,213 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:54:19,220 | INFO | hackthon_support_agent.BaseService | [PLANNING] Starting planning phase
2025-11-11 16:54:19,220 | INFO | hackthon_support_agent.BaseService | [PLANNING] Plan created: 3 focus areas
2025-11-11 16:54:19,312 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:54:19,313 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:54:19,313 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:54:19,314 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:54:19,314 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:54:19,315 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:54:19,315 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:54:19,315 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:54:19,315 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:54:19,316 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:54:19,316 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:54:19,316 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:54:19,317 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:54:19,318 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:54:19,318 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:54:19,318 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:54:19,319 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:54:19,319 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:54:19,320 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:54:19,320 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:54:19,320 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:54:19,320 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:54:19,325 | INFO | hackthon_support_agent.BaseService | [CACHE] Creating context cache
2025-11-11 16:54:19,325 | WARNING | hackthon_support_agent.BaseService | [CACHE] Failed to create real cache: cannot import name 'genai' from 'google' (unknown location)
2025-11-11 16:54:19,325 | WARNING | hackthon_support_agent.BaseService | [CACHE] Falling back to mock cache (no token savings)
2025-11-11 16:54:19,325 | INFO | hackthon_support_agent.BaseService | [CACHE] Cache created: projects/test_project_001/caches/1762847659, TTL: 60min
2025-11-11 16:54:19,326 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:54:19,328 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:54:19,328 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:54:19,329 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:54:19,329 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:54:19,331 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:54:19,331 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:54:19,333 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:54:19,333 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:54:19,334 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:54:19,334 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:54:19,334 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:54:19,336 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:54:19,337 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:54:19,338 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:54:19,338 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:54:19,338 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:54:19,338 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:54:19,339 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:54:19,339 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:54:19,340 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:54:19,340 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:54:19,346 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Starting parallel extraction
2025-11-11 16:54:19,346 | INFO | hackthon_support_agent.BaseService | [PARALLEL] Processing 2 focus areas in parallel
2025-11-11 16:54:19,346 | INFO | hackthon_support_agent.BaseService | [MAP_REDUCE] Starting map-reduce extraction for 認証
2025-11-11 16:54:19,347 | INFO | hackthon_support_agent.BaseService | [MAP_REDUCE] Document too small, using single extraction
2025-11-11 16:54:32,675 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 3 functions using Pydantic
2025-11-11 16:54:32,675 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURE] Starting parallel structuring
2025-11-11 16:54:32,675 | INFO | hackthon_support_agent.BaseService | [MAP_REDUCE] Starting map-reduce extraction for データ管理
2025-11-11 16:54:32,675 | INFO | hackthon_support_agent.BaseService | [MAP_REDUCE] Document too small, using single extraction
2025-11-11 16:54:39,883 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 3 functions using Pydantic
2025-11-11 16:54:39,883 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURE] Starting parallel structuring
2025-11-11 16:54:45,123 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 3 functions
2025-11-11 16:54:45,124 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 3}
2025-11-11 16:54:45,198 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 3 functions
2025-11-11 16:54:45,198 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'auth': 2, 'data': 1}
2025-11-11 16:54:45,817 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 3 functions
2025-11-11 16:54:45,817 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 3}
2025-11-11 16:54:46,090 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 3 functions
2025-11-11 16:54:46,090 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'auth': 2, 'data': 1}
2025-11-11 16:54:46,785 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 3 dependencies
2025-11-11 16:54:46,785 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 3}
2025-11-11 16:54:46,785 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURE] Parallel structuring completed
2025-11-11 16:54:46,785 | INFO | hackthon_support_agent.BaseService | [PARALLEL_VALIDATE] Starting parallel validation
2025-11-11 16:54:54,169 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 3 dependencies
2025-11-11 16:54:54,170 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 3}
2025-11-11 16:54:54,170 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURE] Parallel structuring completed
2025-11-11 16:54:54,170 | INFO | hackthon_support_agent.BaseService | [PARALLEL_VALIDATE] Starting parallel validation
2025-11-11 16:55:00,873 | INFO | hackthon_support_agent.BaseService | [VALIDATE_EXTRACT] Validation score: 1.0, needs_revision: False
2025-11-11 16:55:01,035 | INFO | hackthon_support_agent.BaseService | [VALIDATE_CATEGORIZE] Validation score: 1.0, needs_revision: False
2025-11-11 16:55:01,838 | INFO | hackthon_support_agent.BaseService | [VALIDATE_CATEGORIZE] Validation score: 1.0, needs_revision: False
2025-11-11 16:55:05,274 | INFO | hackthon_support_agent.BaseService | [VALIDATE_EXTRACT] Validation score: 0.95, needs_revision: False
2025-11-11 16:55:05,274 | INFO | hackthon_support_agent.BaseService | [VALIDATE_DEPENDENCY] Validation score: 1.0, needs_revision: False
2025-11-11 16:55:06,009 | INFO | hackthon_support_agent.BaseService | [VALIDATE_DEPENDENCY] Validation score: 1.0, needs_revision: False
2025-11-11 16:55:06,093 | INFO | hackthon_support_agent.BaseService | [VALIDATE_PRIORITY] Validation score: 0.9, needs_revision: False
2025-11-11 16:55:06,093 | INFO | hackthon_support_agent.BaseService | [PARALLEL_VALIDATE] Parallel validation completed
2025-11-11 16:55:06,093 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] データ管理 completed in 33.42s
2025-11-11 16:55:17,708 | INFO | hackthon_support_agent.BaseService | [VALIDATE_PRIORITY] Validation score: 0.85, needs_revision: True
2025-11-11 16:55:17,709 | INFO | hackthon_support_agent.BaseService | [PARALLEL_VALIDATE] Parallel validation completed
2025-11-11 16:55:17,709 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] 認証 completed in 58.36s
2025-11-11 16:55:17,710 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Completed: 2 areas processed in parallel
2025-11-11 16:55:17,711 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:55:17,713 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:55:17,713 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:55:17,715 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:55:17,715 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:55:17,715 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:55:17,715 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:55:17,716 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:55:17,716 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:55:17,717 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:55:17,717 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:55:17,717 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:55:17,718 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:55:17,718 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:55:17,719 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:55:17,719 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:55:17,719 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:55:17,719 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:55:17,720 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:55:17,720 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:55:17,720 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:55:17,720 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:55:17,725 | INFO | hackthon_support_agent.BaseService | [MERGE] Merging results from all focus areas
2025-11-11 16:55:17,725 | INFO | hackthon_support_agent.BaseService | [MERGE] Merged: 3 unique functions
2025-11-11 16:55:17,726 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:55:17,727 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:55:17,727 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:55:17,728 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:55:17,728 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:55:17,729 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:55:17,729 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:55:17,729 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:55:17,729 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:55:17,730 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:55:17,730 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:55:17,730 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:55:17,731 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:55:17,731 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:55:17,733 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:55:17,733 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:55:17,734 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:55:17,734 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:55:17,734 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:55:17,734 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:55:17,735 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:55:17,735 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:55:17,740 | INFO | hackthon_support_agent.BaseService | [FINAL_VALIDATION] Starting final validation
2025-11-11 16:55:37,405 | INFO | hackthon_support_agent.BaseService | [FINAL_VALIDATION] Judgment: APPROVE
2025-11-11 16:55:37,412 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:55:37,414 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:55:37,414 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:55:37,415 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:55:37,415 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:55:37,416 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:55:37,416 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:55:37,416 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:55:37,416 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:55:37,417 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:55:37,417 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:55:37,417 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:55:37,418 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:55:37,418 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:55:37,419 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:55:37,419 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:55:37,419 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:55:37,419 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:55:37,420 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:55:37,420 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:55:37,421 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:55:37,421 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:55:37,426 | INFO | hackthon_support_agent.BaseService | [PERSISTENCE] Saving to database
2025-11-11 16:55:37,426 | ERROR | hackthon_support_agent.BaseService | [PERSISTENCE] Persistence failed: FunctionStructuringPipeline._save_to_database() got an unexpected keyword argument 'final_data'
2025-11-11 16:55:37,432 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:55:37,434 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:55:37,434 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:55:37,435 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:55:37,435 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:55:37,435 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:55:37,435 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:55:37,436 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:55:37,436 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:55:37,437 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:55:37,437 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:55:37,437 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:55:37,438 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:55:37,438 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:55:37,439 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:55:37,439 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:55:37,439 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:55:37,439 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:55:37,440 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:55:37,440 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:55:37,440 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:55:37,440 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:55:37,446 | INFO | hackthon_support_agent.BaseService | [COVERAGE] Analyzing coverage
2025-11-11 16:55:37,446 | INFO | hackthon_support_agent.BaseService | [COVERAGE] Coverage: 5.0%, Status: continue
2025-11-11 16:55:37,447 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:55:37,448 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:55:37,448 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:55:37,449 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:55:37,449 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:55:37,450 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:55:37,450 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:55:37,450 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:55:37,450 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:55:37,451 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:55:37,451 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:55:37,451 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:55:37,452 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:55:37,452 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:55:37,453 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:55:37,453 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:55:37,453 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:55:37,454 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:55:37,454 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:55:37,454 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:55:37,455 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:55:37,455 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:55:37,460 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:55:37,461 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:55:37,461 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:55:37,462 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:55:37,462 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:55:37,463 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:55:37,463 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:55:37,463 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:55:37,463 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:55:37,464 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:55:37,464 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:55:37,464 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:55:37,465 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:55:37,465 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:55:37,466 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:55:37,466 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:55:37,466 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:55:37,466 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:55:37,467 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:55:37,467 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:55:37,467 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:55:37,467 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:55:37,473 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:55:37,474 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:55:37,474 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:55:37,475 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:55:37,475 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:55:37,475 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:55:37,476 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:55:37,476 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:55:37,476 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:55:37,477 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:55:37,477 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:55:37,477 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:55:37,478 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:55:37,478 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:55:37,479 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:55:37,479 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:55:37,480 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:55:37,480 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:55:37,480 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:55:37,481 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:55:37,481 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:55:37,481 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:55:37,487 | INFO | hackthon_support_agent.BaseService | [COVERAGE_DECISION] Max iterations reached, ending workflow
2025-11-11 16:55:37,488 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:55:37,490 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:55:37,490 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:55:37,491 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:55:37,491 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:55:37,491 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:55:37,491 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:55:37,492 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:55:37,492 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:55:37,492 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:55:37,493 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:55:37,493 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:55:37,494 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:55:37,494 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:55:37,495 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:55:37,495 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:55:37,495 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:55:37,495 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:55:37,496 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:55:37,496 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:55:37,496 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:55:37,496 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:55:37,501 | INFO | hackthon_support_agent.BaseService | [PARALLEL] Processing 2 focus areas in parallel
2025-11-11 16:55:37,501 | INFO | hackthon_support_agent.BaseService | [MAP_REDUCE] Starting map-reduce extraction for 認証
2025-11-11 16:55:37,501 | INFO | hackthon_support_agent.BaseService | [MAP_REDUCE] Document too small, using single extraction
2025-11-11 16:55:49,030 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 3 functions using Pydantic
2025-11-11 16:55:49,031 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURE] Starting parallel structuring
2025-11-11 16:55:49,031 | INFO | hackthon_support_agent.BaseService | [MAP_REDUCE] Starting map-reduce extraction for データ管理
2025-11-11 16:55:49,031 | INFO | hackthon_support_agent.BaseService | [MAP_REDUCE] Document too small, using single extraction
2025-11-11 16:56:26,580 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 25 functions using Pydantic
2025-11-11 16:56:26,581 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURE] Starting parallel structuring
2025-11-11 16:56:32,159 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 3 functions
2025-11-11 16:56:32,159 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 3}
2025-11-11 16:56:32,312 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 3 functions
2025-11-11 16:56:32,313 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'auth': 2, 'data': 1}
2025-11-11 16:56:43,404 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 25 functions
2025-11-11 16:56:43,404 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 25}
2025-11-11 16:56:43,585 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 3 dependencies
2025-11-11 16:56:43,586 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 3}
2025-11-11 16:56:43,586 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURE] Parallel structuring completed
2025-11-11 16:56:43,586 | INFO | hackthon_support_agent.BaseService | [PARALLEL_VALIDATE] Starting parallel validation
2025-11-11 16:56:46,761 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 25 functions
2025-11-11 16:56:46,763 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'ui': 6, 'api': 4, 'logic': 4, 'auth': 4, 'data': 4, 'deployment': 3}
2025-11-11 16:56:55,791 | INFO | hackthon_support_agent.BaseService | [VALIDATE_PRIORITY] Validation score: 1.0, needs_revision: False
2025-11-11 16:56:57,393 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 64 dependencies
2025-11-11 16:56:57,394 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 47, 'relates': 7, 'blocks': 10}
2025-11-11 16:56:57,394 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURE] Parallel structuring completed
2025-11-11 16:56:57,394 | INFO | hackthon_support_agent.BaseService | [PARALLEL_VALIDATE] Starting parallel validation
2025-11-11 16:56:58,806 | INFO | hackthon_support_agent.BaseService | [VALIDATE_DEPENDENCY] Validation score: 0.7, needs_revision: True
2025-11-11 16:57:05,807 | INFO | hackthon_support_agent.BaseService | [VALIDATE_CATEGORIZE] Validation score: 0.85, needs_revision: True
2025-11-11 16:57:05,808 | INFO | hackthon_support_agent.BaseService | [VALIDATE_EXTRACT] Validation score: 0.75, needs_revision: True
2025-11-11 16:57:05,809 | INFO | hackthon_support_agent.BaseService | [PARALLEL_VALIDATE] Parallel validation completed
2025-11-11 16:57:05,809 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] 認証 completed in 88.31s
2025-11-11 16:57:07,792 | INFO | hackthon_support_agent.BaseService | [VALIDATE_EXTRACT] Validation score: 0.98, needs_revision: False
2025-11-11 16:57:10,132 | INFO | hackthon_support_agent.BaseService | [VALIDATE_CATEGORIZE] Validation score: 1.0, needs_revision: False
2025-11-11 16:57:21,927 | INFO | hackthon_support_agent.BaseService | [VALIDATE_PRIORITY] Validation score: 0.6, needs_revision: True
2025-11-11 16:57:25,486 | INFO | hackthon_support_agent.BaseService | [VALIDATE_DEPENDENCY] Validation score: 0.35, needs_revision: True
2025-11-11 16:57:25,487 | INFO | hackthon_support_agent.BaseService | [PARALLEL_VALIDATE] Parallel validation completed
2025-11-11 16:57:25,487 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] データ管理 completed in 96.46s
2025-11-11 16:57:25,490 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:57:25,493 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:57:25,493 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:57:25,496 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:57:25,496 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:57:25,497 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:57:25,497 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:57:25,498 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:57:25,498 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:57:25,498 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:57:25,499 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:57:25,499 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:57:25,500 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:57:25,500 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:57:25,501 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:57:25,501 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:57:25,501 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:57:25,501 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:57:25,502 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:57:25,502 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:57:25,502 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:57:25,502 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:57:25,508 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURE] Starting parallel structuring
2025-11-11 16:57:32,409 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 0 dependencies
2025-11-11 16:57:32,409 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {}
2025-11-11 16:57:34,991 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 1 functions
2025-11-11 16:57:34,991 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'auth': 1}
2025-11-11 16:57:34,991 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 1 functions
2025-11-11 16:57:34,991 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 1}
2025-11-11 16:57:34,992 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURE] Parallel structuring completed
2025-11-11 16:57:35,026 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:57:35,027 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:57:35,027 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:57:35,028 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:57:35,028 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:57:35,029 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:57:35,029 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:57:35,030 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:57:35,030 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:57:35,030 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:57:35,030 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:57:35,030 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:57:35,032 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:57:35,032 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:57:35,032 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:57:35,032 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:57:35,033 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:57:35,033 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:57:35,034 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:57:35,034 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:57:35,035 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:57:35,035 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:57:35,046 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:57:35,047 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:57:35,047 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:57:35,048 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:57:35,048 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:57:35,049 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:57:35,049 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:57:35,050 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:57:35,050 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:57:35,050 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:57:35,050 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:57:35,050 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:57:35,052 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:57:35,052 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:57:35,052 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:57:35,053 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:57:35,053 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:57:35,053 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:57:35,054 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:57:35,054 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:57:35,054 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:57:35,054 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:57:35,066 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:57:35,067 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:57:35,067 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:57:35,068 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:57:35,068 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:57:35,069 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:57:35,069 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:57:35,070 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:57:35,070 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:57:35,070 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:57:35,070 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:57:35,070 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:57:35,072 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:57:35,072 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:57:35,072 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:57:35,072 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:57:35,073 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:57:35,073 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:57:35,073 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:57:35,073 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:57:35,074 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:57:35,074 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:57:35,079 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:57:35,081 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:57:35,081 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:57:35,081 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:57:35,081 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:57:35,082 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:57:35,082 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:57:35,082 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:57:35,083 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:57:35,083 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:57:35,083 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:57:35,083 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:57:35,085 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:57:35,085 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:57:35,085 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:57:35,085 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:57:35,086 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:57:35,086 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:57:35,086 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:57:35,087 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:57:35,087 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:57:35,087 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:57:35,092 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:57:35,094 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:57:35,094 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:57:35,094 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:57:35,094 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:57:35,095 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:57:35,095 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:57:35,096 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:57:35,096 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:57:35,096 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:57:35,096 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:57:35,096 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:57:35,098 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:57:35,098 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:57:35,098 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:57:35,098 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:57:35,099 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:57:35,099 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:57:35,101 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:57:35,101 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:57:35,101 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:57:35,101 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:57:35,106 | INFO | hackthon_support_agent.BaseService | [MAP_REDUCE] Starting map-reduce extraction for 認証
2025-11-11 16:57:35,106 | INFO | hackthon_support_agent.BaseService | [MAP_REDUCE] Document too small, using single extraction
2025-11-11 16:57:43,784 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 1 functions using Pydantic
2025-11-11 16:57:43,816 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:57:43,818 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:57:43,818 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:57:43,819 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:57:43,819 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:57:43,820 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:57:43,820 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:57:43,821 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:57:43,821 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:57:43,821 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:57:43,821 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:57:43,822 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:57:43,823 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:57:43,823 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:57:43,824 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:57:43,824 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:57:43,824 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:57:43,824 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:57:43,825 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:57:43,825 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:57:43,826 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:57:43,826 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:57:43,830 | INFO | hackthon_support_agent.BaseService | [MAP_REDUCE] Starting map-reduce extraction for 全体
2025-11-11 16:58:10,441 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 10 functions using Pydantic
2025-11-11 16:58:19,715 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 15 functions using Pydantic
2025-11-11 16:58:24,325 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 20 functions using Pydantic
2025-11-11 16:58:24,326 | INFO | hackthon_support_agent.BaseService | [MAP_REDUCE] Extracted 34 unique functions from 3 chunks
2025-11-11 16:58:24,357 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:58:24,362 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:58:24,362 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:58:24,366 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:58:24,366 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:58:24,367 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:58:24,367 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:58:24,368 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:58:24,368 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:58:24,368 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:58:24,368 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:58:24,368 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:58:24,370 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:58:24,370 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:58:24,371 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:58:24,371 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:58:24,373 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:58:24,373 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:58:24,374 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:58:24,374 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:58:24,375 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:58:24,376 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:58:24,464 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:58:24,465 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:58:24,465 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:58:24,465 | WARNING | hackthon_support_agent.BaseService | GOOGLE_API_KEY is not set
2025-11-11 16:58:33,432 | ERROR | hackthon_support_agent.BaseService | Failed to load LLM (provider=google, model=gemini-2.5-flash)
Traceback (most recent call last):
  File "/Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/base_service.py", line 107, in _load_llm
    llm = ChatGoogleGenerativeAI(
          ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/akatuki/.pyenv/versions/3.12.7/lib/python3.12/site-packages/langchain_google_genai/chat_models.py", line 1531, in __init__
    super().__init__(**kwargs)
  File "/Users/akatuki/.pyenv/versions/3.12.7/lib/python3.12/site-packages/langchain_core/load/serializable.py", line 115, in __init__
    super().__init__(*args, **kwargs)
  File "/Users/akatuki/.pyenv/versions/3.12.7/lib/python3.12/site-packages/pydantic/main.py", line 214, in __init__
    validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/akatuki/.pyenv/versions/3.12.7/lib/python3.12/site-packages/langchain_google_genai/chat_models.py", line 1592, in validate_environment
    self.client = genaix.build_generative_service(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/akatuki/.pyenv/versions/3.12.7/lib/python3.12/site-packages/langchain_google_genai/_genai_extension.py", line 286, in build_generative_service
    return v1betaGenerativeServiceClient(**config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/akatuki/.pyenv/versions/3.12.7/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py", line 698, in __init__
    self._transport = transport_init(
                      ^^^^^^^^^^^^^^^
  File "/Users/akatuki/.pyenv/versions/3.12.7/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/grpc.py", line 234, in __init__
    super().__init__(
  File "/Users/akatuki/.pyenv/versions/3.12.7/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/base.py", line 104, in __init__
    credentials, _ = google.auth.default(
                     ^^^^^^^^^^^^^^^^^^^^
  File "/Users/akatuki/.pyenv/versions/3.12.7/lib/python3.12/site-packages/google/auth/_default.py", line 719, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
2025-11-11 16:58:33,575 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:58:33,576 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:58:33,576 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:58:33,577 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:58:33,577 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:58:33,578 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:58:33,578 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:58:33,578 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:58:33,578 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:58:33,579 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:58:33,579 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:58:33,579 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:58:33,580 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:58:33,581 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:58:33,581 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:58:33,581 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:58:33,582 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:58:33,582 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:58:33,582 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:58:33,582 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:58:33,583 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:58:33,583 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:58:33,587 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURE] Starting parallel structuring
2025-11-11 16:58:43,973 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 5 functions
2025-11-11 16:58:43,974 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'auth': 5}
2025-11-11 16:58:46,228 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 5 functions
2025-11-11 16:58:46,228 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 1, 'Should': 1, 'Could': 2, 'Wont': 1}
2025-11-11 16:58:52,713 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 5 dependencies
2025-11-11 16:58:52,713 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 2, 'relates': 2, 'blocks': 1}
2025-11-11 16:58:52,713 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURE] Parallel structuring completed
2025-11-11 16:58:52,721 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:58:52,724 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:58:52,724 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:58:52,726 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:58:52,726 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:58:52,727 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:58:52,727 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:58:52,728 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:58:52,728 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:58:52,729 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:58:52,729 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:58:52,729 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:58:52,730 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 16:58:52,730 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:58:52,731 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:58:52,731 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:58:52,732 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:58:52,732 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:58:52,732 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:58:52,733 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:58:52,733 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:58:52,733 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 08:06:10,605 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 08:06:13,877 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 08:07:16,666 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-11-11 08:07:16,669 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 08:07:16,669 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 08:07:16,698 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 08:07:16,698 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 08:07:16,700 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 08:07:16,700 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 08:07:16,701 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 08:07:16,701 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 08:07:16,702 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 08:07:16,702 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-11-11 08:07:16,702 | DEBUG | hackthon_support_agent.QuestionService | Generating questions for project_id: b005274e-3a55-41dd-86fa-9bcdb08fe40c with idea_prompt: プロジェクトタイトル: オンライン学習プラットフォーム
プロジェクトアイディア: 学生の学力と得意不得意に合わせたAIを用いた動的な課題作成サービス
期間: 2025-11-11 〜 2025-12-11 17:06
2025-11-11 08:07:16,702 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-11-11 08:07:31,693 | INFO | hackthon_support_agent.QuestionService | Generated 6 questions for project_id: b005274e-3a55-41dd-86fa-9bcdb08fe40c
2025-11-11 08:07:31,720 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-11-11 08:07:31,722 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 08:07:31,723 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 08:07:31,728 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 08:07:31,728 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 08:07:31,730 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 08:07:31,730 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 08:07:31,737 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 08:07:31,738 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 08:07:31,740 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 08:07:31,740 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-11-11 08:08:03,944 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-11-11 08:08:03,949 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 08:08:03,950 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 08:08:03,961 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 08:08:03,961 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 08:08:03,964 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 08:08:03,964 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 08:08:03,965 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 08:08:03,966 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 08:08:03,967 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 08:08:03,967 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-11-11 08:08:04,041 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.generate_summary_document'
2025-11-11 08:08:17,474 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-11-11 08:08:17,477 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 08:08:17,478 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 08:08:17,480 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 08:08:17,480 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 08:08:17,481 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 08:08:17,481 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 08:08:17,482 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 08:08:17,483 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 08:08:17,484 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 08:08:17,484 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-11-11 08:08:36,369 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-11-11 08:08:36,375 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 08:08:36,376 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 08:08:36,387 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 08:08:36,388 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 08:08:36,390 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 08:08:36,390 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 08:08:36,392 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 08:08:36,392 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 08:08:36,394 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 08:08:36,395 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-11-11 08:08:36,404 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-11-11 08:08:57,791 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-11-11 08:08:57,795 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 08:08:57,796 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 08:08:57,801 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 08:08:57,801 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 08:08:57,803 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 08:08:57,804 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 08:08:57,805 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 08:08:57,806 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 08:08:57,807 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 08:08:57,807 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-11-11 08:08:57,996 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: b005274e-3a55-41dd-86fa-9bcdb08fe40c
2025-11-11 08:08:58,002 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.evaluate_specification'
2025-11-11 08:08:59,607 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-11-11 08:08:59,609 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 08:08:59,609 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 08:08:59,610 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 08:08:59,610 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 08:08:59,612 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 08:08:59,612 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 08:08:59,614 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 08:08:59,614 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 08:08:59,615 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 08:08:59,615 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-11-11 08:08:59,652 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: b005274e-3a55-41dd-86fa-9bcdb08fe40c
2025-11-11 08:08:59,655 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.evaluate_specification'
2025-11-11 08:09:10,472 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-11-11 08:09:10,475 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 08:09:10,476 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 08:09:10,484 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 08:09:10,485 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 08:09:10,487 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 08:09:10,487 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 08:09:10,488 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 08:09:10,488 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 08:09:10,490 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 08:09:10,490 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-11-11 08:09:10,530 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: b005274e-3a55-41dd-86fa-9bcdb08fe40c
2025-11-11 08:09:10,549 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.evaluate_specification'
2025-11-11 08:10:55,046 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 08:11:06,912 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 08:11:16,061 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 08:11:46,310 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 08:23:45,890 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-11-11 08:23:45,897 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 08:23:45,897 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 08:23:45,937 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 08:23:45,937 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 08:23:45,940 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 08:23:45,940 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 08:23:45,942 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 08:23:45,942 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 08:23:45,944 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 08:23:45,944 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-11-11 08:23:46,012 | INFO | hackthon_support_agent.SummaryService | 既存仕様書を検出。差分ベースで更新します。
2025-11-11 08:23:46,017 | INFO | hackthon_support_agent.SummaryService | 差分検出: 手動編集=False, 新規Q&A=5件
2025-11-11 08:23:46,018 | INFO | hackthon_support_agent.SummaryService | 新規キャッシュを作成: b005274e-3a55-41dd-86fa-9bcdb08fe40c
2025-11-11 08:23:46,268 | ERROR | hackthon_support_agent.SummaryService | キャッシュ使用中にエラー: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'Cached content is too small. total_token_count=778, min_total_token_count=4096', 'status': 'INVALID_ARGUMENT'}}
2025-11-11 08:23:46,268 | INFO | hackthon_support_agent.SummaryService | フォールバック: キャッシュなしで生成
2025-11-11 08:23:55,420 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: b005274e-3a55-41dd-86fa-9bcdb08fe40c
2025-11-11 08:23:55,429 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.evaluate_specification'
2025-11-11 08:24:18,448 | INFO | hackthon_support_agent.SummaryService | 不足情報から追加Q&Aを生成: 【ユーザー要件】ユーザーは普段、どのような時間帯に、どのくらいの頻度で学習を行いますか？また、どこで...
2025-11-11 08:24:18,451 | INFO | hackthon_support_agent.SummaryService | 不足情報から追加Q&Aを生成: 【非機能要件】AIによる課題生成の処理速度はどの程度が求められますか？（例：数秒以内、即時など）また...
2025-11-11 08:24:18,451 | INFO | hackthon_support_agent.SummaryService | 不足情報から追加Q&Aを生成: 【非機能要件】ユーザーの学習データや個人情報（学年、得意不得意、解答履歴など）はどのように保護されま...
2025-11-11 08:24:18,452 | INFO | hackthon_support_agent.SummaryService | 不足情報から追加Q&Aを生成: 【非機能要件】システム障害が発生した場合の対応フローや、データバックアップの頻度・方法について教えて...
2025-11-11 08:24:18,453 | INFO | hackthon_support_agent.SummaryService | 不足情報から追加Q&Aを生成: 【技術要件】AIが学生の学力や得意不得意を判断し、課題を生成する際に、どのような機械学習モデルやアル...
2025-11-11 08:24:18,476 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-11-11 08:24:18,480 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 08:24:18,481 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 08:24:18,488 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 08:24:18,489 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 08:24:18,491 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 08:24:18,491 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 08:24:18,493 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 08:24:18,493 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 08:24:18,494 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 08:24:18,495 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-11-11 08:24:18,501 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-11-11 08:25:24,072 | DEBUG | hackthon_support_agent.FunctionService | Initializing BaseService (provider=google)
2025-11-11 08:25:24,076 | INFO | hackthon_support_agent.FunctionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 08:25:24,076 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 08:25:24,082 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 08:25:24,082 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 08:25:24,083 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 08:25:24,084 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 08:25:24,086 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 08:25:24,086 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 08:25:24,087 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 08:25:24,087 | DEBUG | hackthon_support_agent.FunctionService | LLMs initialized
2025-11-11 08:25:24,087 | DEBUG | hackthon_support_agent.FunctionService | Generating functional requirements for project_id: b005274e-3a55-41dd-86fa-9bcdb08fe40c
2025-11-11 08:25:24,090 | DEBUG | hackthon_support_agent.FunctionService | Fetching prompt 'function_service.generate_functional_requirements'
2025-11-11 08:25:55,829 | DEBUG | hackthon_support_agent.FunctionService | Saving functional requirements to project document: b005274e-3a55-41dd-86fa-9bcdb08fe40c
2025-11-11 08:29:37,421 | DEBUG | hackthon_support_agent.AIDocumentService | Initializing BaseService (provider=google)
2025-11-11 08:29:37,426 | INFO | hackthon_support_agent.AIDocumentService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 08:29:37,426 | DEBUG | hackthon_support_agent.AIDocumentService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 08:29:37,433 | INFO | hackthon_support_agent.AIDocumentService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 08:29:37,434 | DEBUG | hackthon_support_agent.AIDocumentService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 08:29:37,443 | INFO | hackthon_support_agent.AIDocumentService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 08:29:37,443 | DEBUG | hackthon_support_agent.AIDocumentService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 08:29:37,445 | INFO | hackthon_support_agent.AIDocumentService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 08:29:37,445 | DEBUG | hackthon_support_agent.AIDocumentService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 08:29:37,446 | INFO | hackthon_support_agent.AIDocumentService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 08:29:37,446 | DEBUG | hackthon_support_agent.AIDocumentService | LLMs initialized
2025-11-11 08:31:12,088 | WARNING | hackthon_support_agent.AIDocumentService | JSONパースエラー (試行 1/2): Got invalid JSON object. Error: Invalid \escape: line 5 column 5227 (char 18031)
For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE 
2025-11-11 08:32:37,507 | DEBUG | hackthon_support_agent.AIDocumentService | Initializing BaseService (provider=google)
2025-11-11 08:32:37,514 | INFO | hackthon_support_agent.AIDocumentService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 08:32:37,514 | DEBUG | hackthon_support_agent.AIDocumentService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 08:32:37,523 | INFO | hackthon_support_agent.AIDocumentService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 08:32:37,523 | DEBUG | hackthon_support_agent.AIDocumentService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 08:32:37,525 | INFO | hackthon_support_agent.AIDocumentService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 08:32:37,526 | DEBUG | hackthon_support_agent.AIDocumentService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 08:32:37,528 | INFO | hackthon_support_agent.AIDocumentService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 08:32:37,529 | DEBUG | hackthon_support_agent.AIDocumentService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 08:32:37,531 | INFO | hackthon_support_agent.AIDocumentService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 08:32:37,531 | DEBUG | hackthon_support_agent.AIDocumentService | LLMs initialized
2025-11-11 08:33:51,944 | DEBUG | hackthon_support_agent.AIDocumentService | Initializing BaseService (provider=google)
2025-11-11 08:33:51,955 | INFO | hackthon_support_agent.AIDocumentService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 08:33:51,956 | DEBUG | hackthon_support_agent.AIDocumentService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 08:33:52,000 | INFO | hackthon_support_agent.AIDocumentService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 08:33:52,002 | DEBUG | hackthon_support_agent.AIDocumentService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 08:33:52,007 | INFO | hackthon_support_agent.AIDocumentService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 08:33:52,008 | DEBUG | hackthon_support_agent.AIDocumentService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 08:33:52,012 | INFO | hackthon_support_agent.AIDocumentService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 08:33:52,013 | DEBUG | hackthon_support_agent.AIDocumentService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 08:33:52,016 | INFO | hackthon_support_agent.AIDocumentService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 08:33:52,016 | DEBUG | hackthon_support_agent.AIDocumentService | LLMs initialized
2025-11-11 08:35:10,534 | DEBUG | hackthon_support_agent.AIDocumentService | Initializing BaseService (provider=google)
2025-11-11 08:35:10,542 | INFO | hackthon_support_agent.AIDocumentService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 08:35:10,542 | DEBUG | hackthon_support_agent.AIDocumentService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 08:35:10,557 | INFO | hackthon_support_agent.AIDocumentService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 08:35:10,557 | DEBUG | hackthon_support_agent.AIDocumentService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 08:35:10,559 | INFO | hackthon_support_agent.AIDocumentService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 08:35:10,560 | DEBUG | hackthon_support_agent.AIDocumentService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 08:35:10,562 | INFO | hackthon_support_agent.AIDocumentService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 08:35:10,563 | DEBUG | hackthon_support_agent.AIDocumentService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 08:35:10,565 | INFO | hackthon_support_agent.AIDocumentService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 08:35:10,566 | DEBUG | hackthon_support_agent.AIDocumentService | LLMs initialized
2025-11-11 08:36:35,652 | WARNING | hackthon_support_agent.AIDocumentService | JSONパースエラー (試行 1/2): Got invalid JSON object. Error: Invalid \escape: line 5 column 7651 (char 19254)
For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE 
2025-11-11 08:37:55,859 | WARNING | hackthon_support_agent.AIDocumentService | JSONパースエラー (試行 2/2): Got invalid JSON object. Error: Invalid \escape: line 5 column 5191 (char 14729)
For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE 
2025-11-11 08:37:55,861 | ERROR | hackthon_support_agent.AIDocumentService | JSONパース失敗。フォールバックモードで再試行
2025-11-11 08:37:55,862 | INFO | hackthon_support_agent.AIDocumentService | フォールバックモード: カテゴリごとに個別生成開始
2025-11-11 08:38:20,251 | INFO | hackthon_support_agent.AIDocumentService | カテゴリ 'environment' 生成完了
2025-11-11 08:39:02,243 | INFO | hackthon_support_agent.AIDocumentService | カテゴリ 'front_end' 生成完了
2025-11-11 08:39:39,289 | INFO | hackthon_support_agent.AIDocumentService | カテゴリ 'back_end' 生成完了
2025-11-11 08:40:18,819 | INFO | hackthon_support_agent.AIDocumentService | カテゴリ 'database' 生成完了
2025-11-11 08:40:41,846 | INFO | hackthon_support_agent.AIDocumentService | カテゴリ 'deployment' 生成完了
2025-11-11 08:41:11,328 | INFO | hackthon_support_agent.AIDocumentService | カテゴリ 'ai_design' 生成完了
2025-11-11 08:41:11,414 | DEBUG | hackthon_support_agent.AIDocumentService | Initializing BaseService (provider=google)
2025-11-11 08:41:11,420 | INFO | hackthon_support_agent.AIDocumentService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 08:41:11,421 | DEBUG | hackthon_support_agent.AIDocumentService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 08:41:11,446 | INFO | hackthon_support_agent.AIDocumentService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 08:41:11,446 | DEBUG | hackthon_support_agent.AIDocumentService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 08:41:11,456 | INFO | hackthon_support_agent.AIDocumentService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 08:41:11,460 | DEBUG | hackthon_support_agent.AIDocumentService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 08:41:11,463 | INFO | hackthon_support_agent.AIDocumentService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 08:41:11,464 | DEBUG | hackthon_support_agent.AIDocumentService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 08:41:11,467 | INFO | hackthon_support_agent.AIDocumentService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 08:41:11,468 | DEBUG | hackthon_support_agent.AIDocumentService | LLMs initialized
2025-11-11 08:42:28,020 | WARNING | hackthon_support_agent.AIDocumentService | JSONパースエラー (試行 1/2): Got invalid JSON object. Error: Invalid \escape: line 5 column 2181 (char 12878)
For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE 
2025-11-11 08:43:29,005 | DEBUG | hackthon_support_agent.AIDocumentService | Initializing BaseService (provider=google)
2025-11-11 08:43:29,020 | INFO | hackthon_support_agent.AIDocumentService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 08:43:29,024 | DEBUG | hackthon_support_agent.AIDocumentService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 08:43:29,047 | INFO | hackthon_support_agent.AIDocumentService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 08:43:29,051 | DEBUG | hackthon_support_agent.AIDocumentService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 08:43:29,062 | INFO | hackthon_support_agent.AIDocumentService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 08:43:29,063 | DEBUG | hackthon_support_agent.AIDocumentService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 08:43:29,065 | INFO | hackthon_support_agent.AIDocumentService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 08:43:29,066 | DEBUG | hackthon_support_agent.AIDocumentService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 08:43:29,069 | INFO | hackthon_support_agent.AIDocumentService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 08:43:29,070 | DEBUG | hackthon_support_agent.AIDocumentService | LLMs initialized
2025-11-11 08:44:47,912 | DEBUG | hackthon_support_agent.AIDocumentService | Initializing BaseService (provider=google)
2025-11-11 08:44:47,916 | INFO | hackthon_support_agent.AIDocumentService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 08:44:47,916 | DEBUG | hackthon_support_agent.AIDocumentService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 08:44:47,922 | INFO | hackthon_support_agent.AIDocumentService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 08:44:47,922 | DEBUG | hackthon_support_agent.AIDocumentService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 08:44:47,924 | INFO | hackthon_support_agent.AIDocumentService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 08:44:47,925 | DEBUG | hackthon_support_agent.AIDocumentService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 08:44:47,927 | INFO | hackthon_support_agent.AIDocumentService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 08:44:47,928 | DEBUG | hackthon_support_agent.AIDocumentService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 08:44:47,930 | INFO | hackthon_support_agent.AIDocumentService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 08:44:47,930 | DEBUG | hackthon_support_agent.AIDocumentService | LLMs initialized
2025-11-11 08:47:25,222 | WARNING | hackthon_support_agent.AIDocumentService | JSONパースエラー (試行 1/2): Got invalid JSON object. Error: Invalid \escape: line 5 column 10736 (char 23917)
For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE 
2025-11-11 08:49:01,262 | WARNING | hackthon_support_agent.AIDocumentService | JSONパースエラー (試行 2/2): Got invalid JSON object. Error: Invalid \escape: line 5 column 3052 (char 17104)
For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE 
2025-11-11 08:49:01,265 | ERROR | hackthon_support_agent.AIDocumentService | JSONパース失敗。フォールバックモードで再試行
2025-11-11 08:49:01,266 | INFO | hackthon_support_agent.AIDocumentService | フォールバックモード: カテゴリごとに個別生成開始
2025-11-11 08:49:20,815 | INFO | hackthon_support_agent.AIDocumentService | カテゴリ 'environment' 生成完了
2025-11-11 08:49:51,020 | INFO | hackthon_support_agent.AIDocumentService | カテゴリ 'front_end' 生成完了
2025-11-11 08:50:22,754 | INFO | hackthon_support_agent.AIDocumentService | カテゴリ 'back_end' 生成完了
2025-11-11 08:51:03,971 | INFO | hackthon_support_agent.AIDocumentService | カテゴリ 'database' 生成完了
2025-11-11 08:51:33,604 | INFO | hackthon_support_agent.AIDocumentService | カテゴリ 'deployment' 生成完了
2025-11-11 08:52:06,684 | INFO | hackthon_support_agent.AIDocumentService | カテゴリ 'ai_design' 生成完了
2025-11-11 08:52:06,720 | DEBUG | hackthon_support_agent.AIDocumentService | Initializing BaseService (provider=google)
2025-11-11 08:52:06,723 | INFO | hackthon_support_agent.AIDocumentService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 08:52:06,723 | DEBUG | hackthon_support_agent.AIDocumentService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 08:52:06,744 | INFO | hackthon_support_agent.AIDocumentService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 08:52:06,744 | DEBUG | hackthon_support_agent.AIDocumentService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 08:52:06,747 | INFO | hackthon_support_agent.AIDocumentService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 08:52:06,747 | DEBUG | hackthon_support_agent.AIDocumentService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 08:52:06,749 | INFO | hackthon_support_agent.AIDocumentService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 08:52:06,750 | DEBUG | hackthon_support_agent.AIDocumentService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 08:52:06,751 | INFO | hackthon_support_agent.AIDocumentService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 08:52:06,751 | DEBUG | hackthon_support_agent.AIDocumentService | LLMs initialized
2025-11-11 09:25:58,142 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 09:26:13,569 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 09:38:45,158 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-11-11 09:38:45,165 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 09:38:45,165 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:38:45,229 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:38:45,230 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:38:45,233 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:38:45,233 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:38:45,236 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:38:45,236 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 09:38:45,238 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 09:38:45,238 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-11-11 09:38:45,240 | DEBUG | hackthon_support_agent.QuestionService | Generating questions for project_id: fb298f0a-8931-417c-a5db-24152bf66c50 with idea_prompt: プロジェクトタイトル: オンライン学習プラットフォーム
プロジェクトアイディア: 学生の学力と得意不得意に合わせたAIを用いた動的な課題作成サービス
期間: 2025-11-11 〜 2025-12-11 18:38
2025-11-11 09:38:45,240 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-11-11 09:38:58,613 | INFO | hackthon_support_agent.QuestionService | Generated 8 questions for project_id: fb298f0a-8931-417c-a5db-24152bf66c50
2025-11-11 09:38:58,635 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-11-11 09:38:58,639 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 09:38:58,639 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:38:58,660 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:38:58,660 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:38:58,664 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:38:58,665 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:38:58,692 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:38:58,694 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 09:38:58,705 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 09:38:58,705 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-11-11 09:39:09,031 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-11-11 09:39:09,036 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 09:39:09,037 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:39:09,057 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:39:09,057 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:39:09,063 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:39:09,064 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:39:09,066 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:39:09,067 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 09:39:09,073 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 09:39:09,074 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-11-11 09:39:09,190 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.generate_summary_document'
2025-11-11 09:39:22,366 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-11-11 09:39:22,369 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 09:39:22,370 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:39:22,372 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:39:22,373 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:39:22,374 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:39:22,374 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:39:22,378 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:39:22,378 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 09:39:22,384 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 09:39:22,386 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-11-11 09:39:25,173 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-11-11 09:39:25,181 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 09:39:25,183 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:39:25,201 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:39:25,206 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:39:25,228 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:39:25,235 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:39:25,240 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:39:25,240 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 09:39:25,262 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 09:39:25,264 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-11-11 09:39:25,277 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-11-11 09:39:40,705 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-11-11 09:39:40,714 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 09:39:40,715 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:39:40,721 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:39:40,722 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:39:40,726 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:39:40,730 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:39:40,736 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:39:40,737 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 09:39:40,742 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 09:39:40,743 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-11-11 09:39:40,899 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: fb298f0a-8931-417c-a5db-24152bf66c50
2025-11-11 09:39:40,914 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.evaluate_specification'
2025-11-11 09:39:41,783 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-11-11 09:39:41,785 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 09:39:41,786 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:39:41,789 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:39:41,790 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:39:41,792 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:39:41,792 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:39:41,795 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:39:41,796 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 09:39:41,798 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 09:39:41,799 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-11-11 09:39:41,846 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: fb298f0a-8931-417c-a5db-24152bf66c50
2025-11-11 09:39:41,850 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.evaluate_specification'
2025-11-11 09:39:50,925 | DEBUG | hackthon_support_agent.FunctionService | Initializing BaseService (provider=google)
2025-11-11 09:39:50,929 | INFO | hackthon_support_agent.FunctionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 09:39:50,931 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:39:50,970 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:39:50,972 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:39:50,997 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:39:51,002 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:39:51,021 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:39:51,024 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 09:39:51,037 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 09:39:51,038 | DEBUG | hackthon_support_agent.FunctionService | LLMs initialized
2025-11-11 09:39:51,040 | DEBUG | hackthon_support_agent.FunctionService | Generating functional requirements for project_id: fb298f0a-8931-417c-a5db-24152bf66c50
2025-11-11 09:39:51,061 | DEBUG | hackthon_support_agent.FunctionService | Fetching prompt 'function_service.generate_functional_requirements'
2025-11-11 09:40:52,070 | DEBUG | hackthon_support_agent.FunctionService | Generating clarification questions for 2 low-confidence requirements
2025-11-11 09:40:52,072 | DEBUG | hackthon_support_agent.FunctionService | Fetching prompt 'function_service.generate_clarification_questions'
2025-11-11 09:41:09,590 | DEBUG | hackthon_support_agent.FunctionService | Saving functional requirements to project document: fb298f0a-8931-417c-a5db-24152bf66c50
2025-11-11 09:41:09,689 | DEBUG | hackthon_support_agent.FunctionService | Saving 6 clarification questions to database
2025-11-11 09:41:38,764 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 09:41:38,767 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 09:41:38,767 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:41:38,795 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:41:38,797 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:41:38,799 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:41:38,799 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:41:38,804 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:41:38,804 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 09:41:38,806 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 09:41:38,807 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 09:41:38,807 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 09:41:38,810 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 09:41:38,811 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:41:38,813 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:41:38,813 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:41:38,815 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:41:38,815 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:41:38,816 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:41:38,816 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 09:41:38,819 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 09:41:38,819 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 09:42:31,945 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 09:42:31,951 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 09:42:31,951 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:42:31,972 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:42:31,972 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:42:31,979 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:42:31,980 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:42:31,983 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:42:31,984 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 09:42:31,988 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 09:42:31,988 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 09:42:31,989 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 09:42:31,993 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 09:42:31,993 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:42:31,996 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:42:31,997 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:42:32,002 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:42:32,002 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:42:32,007 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:42:32,008 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 09:42:32,014 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 09:42:32,014 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 09:42:40,781 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 09:42:40,790 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 09:42:40,790 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:42:40,835 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:42:40,836 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:42:40,847 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:42:40,848 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:42:40,862 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:42:40,865 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 09:42:40,880 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 09:42:40,891 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 09:42:40,896 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 09:42:40,917 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 09:42:40,921 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:42:40,937 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:42:40,938 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:42:40,943 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:42:40,944 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:42:40,947 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:42:40,947 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 09:42:40,950 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 09:42:40,951 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 18:43:34,219 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 18:43:34,348 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 18:43:34,350 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 18:43:34,350 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 18:43:34,373 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 18:43:34,373 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 18:43:34,374 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 18:43:34,374 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 18:43:34,375 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 18:43:34,377 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 18:43:34,378 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 18:43:34,378 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 18:43:34,378 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 18:43:34,380 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 18:43:34,380 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 18:43:34,381 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 18:43:34,381 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 18:43:34,381 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 18:43:34,381 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 18:43:34,382 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 18:43:34,384 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 18:43:34,385 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 18:43:34,385 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 09:43:41,367 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 09:43:41,508 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 09:43:41,511 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:43:41,561 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:43:41,562 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:43:41,569 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:43:41,570 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:43:41,575 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:43:41,577 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 09:43:41,581 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 09:43:41,582 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 09:43:41,582 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 09:43:41,590 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 09:43:41,595 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:43:41,660 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:43:41,662 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:43:41,666 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:43:41,667 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:43:41,679 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:43:41,679 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 09:43:41,685 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 09:43:41,686 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 09:44:11,642 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 09:44:13,729 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 09:44:13,736 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 09:44:13,737 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:44:13,761 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:44:13,761 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:44:13,766 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:44:13,767 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:44:13,770 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:44:13,771 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 09:44:13,776 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 09:44:13,777 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 09:44:13,777 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 09:44:13,782 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 09:44:13,783 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:44:13,786 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:44:13,788 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:44:13,794 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:44:13,794 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:44:13,797 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:44:13,798 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 09:44:13,804 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 09:44:13,805 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 09:44:13,815 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Fetching context for project: fb298f0a-8931-417c-a5db-24152bf66c50
2025-11-11 09:44:13,829 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Starting workflow for project: fb298f0a-8931-417c-a5db-24152bf66c50
2025-11-11 09:44:13,830 | ERROR | hackthon_support_agent.BaseService | [WORKFLOW] Workflow failed: Checkpointer requires one or more of the following 'configurable' keys: thread_id, checkpoint_ns, checkpoint_id
2025-11-11 09:44:20,667 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 09:44:20,673 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 09:44:20,673 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:44:20,678 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:44:20,679 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:44:20,681 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:44:20,682 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:44:20,685 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:44:20,685 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 09:44:20,687 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 09:44:20,688 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 09:44:20,689 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 09:44:20,692 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 09:44:20,693 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:44:20,696 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:44:20,697 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:44:20,702 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:44:20,703 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:44:20,706 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:44:20,707 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 09:44:20,711 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 09:44:20,712 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 09:44:20,724 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Fetching context for project: fb298f0a-8931-417c-a5db-24152bf66c50
2025-11-11 09:44:20,744 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Starting workflow for project: fb298f0a-8931-417c-a5db-24152bf66c50
2025-11-11 09:44:20,746 | ERROR | hackthon_support_agent.BaseService | [WORKFLOW] Workflow failed: Checkpointer requires one or more of the following 'configurable' keys: thread_id, checkpoint_ns, checkpoint_id
2025-11-11 18:44:25,107 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 18:44:25,241 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 18:44:25,242 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 18:44:25,243 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 18:44:25,266 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 18:44:25,266 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 18:44:25,267 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 18:44:25,267 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 18:44:25,268 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 18:44:25,268 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 18:44:25,268 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 18:44:25,269 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 18:44:25,269 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 18:44:25,270 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /Users/akatuki/HackathonAgent/hackathon-support-agent/back/services/prompts.toml
2025-11-11 18:44:25,270 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 18:44:25,271 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 18:44:25,271 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 18:44:25,271 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 18:44:25,271 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 18:44:25,272 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 18:44:25,272 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 18:44:25,272 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 18:44:25,273 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 18:44:25,278 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Fetching context for project: fb298f0a-8931-417c-a5db-24152bf66c50
2025-11-11 18:44:27,534 | ERROR | hackthon_support_agent.BaseService | [WORKFLOW] Failed to process project fb298f0a-8931-417c-a5db-24152bf66c50: (psycopg2.OperationalError) could not translate host name "db" to address: nodename nor servname provided, or not known

(Background on this error at: https://sqlalche.me/e/20/e3q8)
2025-11-11 09:44:50,391 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 09:44:50,439 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 09:44:50,440 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:44:50,495 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:44:50,503 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:44:50,559 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:44:50,561 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:44:50,581 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:44:50,582 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 09:44:50,597 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 09:44:50,600 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 09:44:50,600 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 09:44:50,614 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 09:44:50,616 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:44:50,621 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:44:50,622 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:44:50,627 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:44:50,627 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:44:50,637 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:44:50,640 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 09:44:50,645 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 09:44:50,646 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 09:44:50,666 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Fetching context for project: fb298f0a-8931-417c-a5db-24152bf66c50
2025-11-11 09:44:50,690 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Starting workflow for project: fb298f0a-8931-417c-a5db-24152bf66c50
2025-11-11 09:44:50,693 | ERROR | hackthon_support_agent.BaseService | [WORKFLOW] Workflow failed: Checkpointer requires one or more of the following 'configurable' keys: thread_id, checkpoint_ns, checkpoint_id
2025-11-11 09:44:52,294 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 09:44:52,298 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 09:44:52,298 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:44:52,302 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:44:52,302 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:44:52,305 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:44:52,305 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:44:52,308 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:44:52,308 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 09:44:52,310 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 09:44:52,310 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 09:44:52,311 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 09:44:52,314 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 09:44:52,314 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:44:52,316 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:44:52,317 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:44:52,319 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:44:52,320 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:44:52,323 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:44:52,323 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 09:44:52,326 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 09:44:52,327 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 09:44:52,334 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Fetching context for project: fb298f0a-8931-417c-a5db-24152bf66c50
2025-11-11 09:44:52,344 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Starting workflow for project: fb298f0a-8931-417c-a5db-24152bf66c50
2025-11-11 09:44:52,345 | ERROR | hackthon_support_agent.BaseService | [WORKFLOW] Workflow failed: Checkpointer requires one or more of the following 'configurable' keys: thread_id, checkpoint_ns, checkpoint_id
2025-11-11 09:45:40,834 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 09:45:43,127 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 09:45:43,132 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 09:45:43,134 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:45:43,157 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:45:43,158 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:45:43,160 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:45:43,161 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:45:43,164 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:45:43,164 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 09:45:43,166 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 09:45:43,166 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 09:45:43,167 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 09:45:43,169 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 09:45:43,170 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:45:43,172 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:45:43,172 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:45:43,174 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:45:43,175 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:45:43,176 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:45:43,176 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 09:45:43,179 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 09:45:43,180 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 09:45:43,188 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Fetching context for project: fb298f0a-8931-417c-a5db-24152bf66c50
2025-11-11 09:45:43,202 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Starting workflow for project: fb298f0a-8931-417c-a5db-24152bf66c50
2025-11-11 09:45:43,208 | INFO | hackthon_support_agent.BaseService | [PLANNING] Starting planning phase
2025-11-11 09:45:43,209 | INFO | hackthon_support_agent.BaseService | [PLANNING] Plan created: 3 focus areas
2025-11-11 09:45:43,210 | INFO | hackthon_support_agent.BaseService | [CACHE] Creating context cache
2025-11-11 09:45:43,280 | WARNING | hackthon_support_agent.BaseService | [CACHE] Failed to create real cache: Caches.create() got an unexpected keyword argument 'contents'
2025-11-11 09:45:43,281 | WARNING | hackthon_support_agent.BaseService | [CACHE] Falling back to mock cache (no token savings)
2025-11-11 09:45:43,282 | INFO | hackthon_support_agent.BaseService | [CACHE] Cache created: projects/fb298f0a-8931-417c-a5db-24152bf66c50/caches/1762854343, TTL: 60min
2025-11-11 09:45:43,284 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Starting parallel extraction
2025-11-11 09:45:43,285 | INFO | hackthon_support_agent.BaseService | [PARALLEL] Processing 3 focus areas in parallel
2025-11-11 09:45:43,285 | INFO | hackthon_support_agent.BaseService | [MAP_REDUCE] Starting map-reduce extraction for 認証・権限
2025-11-11 09:45:43,286 | INFO | hackthon_support_agent.BaseService | [MAP_REDUCE] Starting map-reduce extraction for データ管理
2025-11-11 09:45:43,286 | INFO | hackthon_support_agent.BaseService | [MAP_REDUCE] Starting map-reduce extraction for UI・画面
2025-11-11 09:45:49,270 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 09:45:49,275 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 09:45:49,276 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:45:49,290 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:45:49,291 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:45:49,293 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:45:49,294 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:45:49,298 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:45:49,298 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 09:45:49,302 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 09:45:49,303 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 09:45:49,304 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 09:45:49,307 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 09:45:49,307 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:45:49,310 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:45:49,310 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:45:49,314 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:45:49,314 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:45:49,318 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:45:49,319 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 09:45:49,322 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 09:45:49,323 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 09:45:49,518 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Fetching context for project: fb298f0a-8931-417c-a5db-24152bf66c50
2025-11-11 09:45:49,547 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Starting workflow for project: fb298f0a-8931-417c-a5db-24152bf66c50
2025-11-11 09:45:49,563 | INFO | hackthon_support_agent.BaseService | [PLANNING] Starting planning phase
2025-11-11 09:45:49,565 | INFO | hackthon_support_agent.BaseService | [PLANNING] Plan created: 3 focus areas
2025-11-11 09:45:49,571 | INFO | hackthon_support_agent.BaseService | [CACHE] Creating context cache
2025-11-11 09:45:49,719 | WARNING | hackthon_support_agent.BaseService | [CACHE] Failed to create real cache: Caches.create() got an unexpected keyword argument 'contents'
2025-11-11 09:45:49,721 | WARNING | hackthon_support_agent.BaseService | [CACHE] Falling back to mock cache (no token savings)
2025-11-11 09:45:49,727 | INFO | hackthon_support_agent.BaseService | [CACHE] Cache created: projects/fb298f0a-8931-417c-a5db-24152bf66c50/caches/1762854349, TTL: 60min
2025-11-11 09:45:49,736 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Starting parallel extraction
2025-11-11 09:45:49,744 | INFO | hackthon_support_agent.BaseService | [PARALLEL] Processing 3 focus areas in parallel
2025-11-11 09:45:49,745 | INFO | hackthon_support_agent.BaseService | [MAP_REDUCE] Starting map-reduce extraction for 認証・権限
2025-11-11 09:45:49,749 | INFO | hackthon_support_agent.BaseService | [MAP_REDUCE] Starting map-reduce extraction for データ管理
2025-11-11 09:45:49,751 | INFO | hackthon_support_agent.BaseService | [MAP_REDUCE] Starting map-reduce extraction for UI・画面
2025-11-11 09:46:01,384 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 18 functions using Pydantic
2025-11-11 09:46:02,073 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 19 functions using Pydantic
2025-11-11 09:46:07,754 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 22 functions using Pydantic
2025-11-11 09:46:09,707 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 16 functions using Pydantic
2025-11-11 09:46:10,294 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 19 functions using Pydantic
2025-11-11 09:46:13,742 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 25 functions using Pydantic
2025-11-11 09:46:14,470 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 25 functions using Pydantic
2025-11-11 09:46:16,211 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 23 functions using Pydantic
2025-11-11 09:46:17,057 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 21 functions using Pydantic
2025-11-11 09:46:17,060 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 25 functions using Pydantic
2025-11-11 09:46:17,063 | INFO | hackthon_support_agent.BaseService | [MAP_REDUCE] Extracted 60 unique functions from 3 chunks
2025-11-11 09:46:17,066 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURE] Starting parallel structuring
2025-11-11 09:46:17,068 | INFO | hackthon_support_agent.BaseService | [MAP_REDUCE] Extracted 64 unique functions from 3 chunks
2025-11-11 09:46:17,088 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURE] Starting parallel structuring
2025-11-11 09:46:17,513 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 17 functions using Pydantic
2025-11-11 09:46:17,515 | INFO | hackthon_support_agent.BaseService | [MAP_REDUCE] Extracted 55 unique functions from 3 chunks
2025-11-11 09:46:17,516 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURE] Starting parallel structuring
2025-11-11 09:46:19,991 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 17 functions using Pydantic
2025-11-11 09:46:20,214 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 19 functions using Pydantic
2025-11-11 09:46:21,373 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 23 functions using Pydantic
2025-11-11 09:46:22,202 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 21 functions using Pydantic
2025-11-11 09:46:24,577 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 24 functions using Pydantic
2025-11-11 09:46:24,579 | INFO | hackthon_support_agent.BaseService | [MAP_REDUCE] Extracted 68 unique functions from 3 chunks
2025-11-11 09:46:24,579 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURE] Starting parallel structuring
2025-11-11 09:46:26,901 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 23 functions using Pydantic
2025-11-11 09:46:26,903 | INFO | hackthon_support_agent.BaseService | [MAP_REDUCE] Extracted 65 unique functions from 3 chunks
2025-11-11 09:46:26,903 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURE] Starting parallel structuring
2025-11-11 09:46:39,629 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 23 functions using Pydantic
2025-11-11 09:46:39,636 | INFO | hackthon_support_agent.BaseService | [MAP_REDUCE] Extracted 67 unique functions from 3 chunks
2025-11-11 09:46:39,637 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURE] Starting parallel structuring
2025-11-11 09:46:44,614 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 64 functions
2025-11-11 09:46:44,615 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'ui': 18, 'api': 12, 'logic': 14, 'data': 16, 'auth': 4}
2025-11-11 09:47:01,702 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 60 functions
2025-11-11 09:47:01,705 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 26, 'Should': 25, 'Could': 9}
2025-11-11 09:47:01,823 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 64 functions
2025-11-11 09:47:01,824 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 33, 'Should': 24, 'Could': 7}
2025-11-11 09:47:03,011 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 55 functions
2025-11-11 09:47:03,011 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 30, 'Should': 14, 'Could': 11}
2025-11-11 09:47:03,646 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 55 functions
2025-11-11 09:47:03,647 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'ui': 10, 'data': 18, 'logic': 17, 'api': 6, 'auth': 4}
2025-11-11 09:47:05,678 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 68 functions
2025-11-11 09:47:05,679 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'ui': 12, 'api': 18, 'logic': 18, 'data': 14, 'auth': 6}
2025-11-11 09:47:07,683 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 65 functions
2025-11-11 09:47:07,684 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'ui': 19, 'api': 15, 'logic': 11, 'data': 16, 'auth': 4}
2025-11-11 09:47:08,349 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 60 functions
2025-11-11 09:47:08,349 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'ui': 13, 'api': 6, 'logic': 13, 'data': 22, 'auth': 6}
2025-11-11 09:47:10,423 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 86 dependencies
2025-11-11 09:47:10,424 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 24, 'blocks': 35, 'relates': 27}
2025-11-11 09:47:16,137 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 67 functions
2025-11-11 09:47:16,140 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'ui': 15, 'api': 13, 'logic': 14, 'data': 21, 'auth': 4}
2025-11-11 09:47:16,807 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 78 dependencies
2025-11-11 09:47:16,809 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 39, 'blocks': 30, 'relates': 9}
2025-11-11 09:47:16,811 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURE] Parallel structuring completed
2025-11-11 09:47:16,811 | INFO | hackthon_support_agent.BaseService | [PARALLEL_VALIDATE] Starting parallel validation
2025-11-11 09:47:18,389 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 68 functions
2025-11-11 09:47:18,389 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 35, 'Should': 24, 'Could': 9}
2025-11-11 09:47:19,706 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 67 dependencies
2025-11-11 09:47:19,707 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 42, 'relates': 8, 'blocks': 17}
2025-11-11 09:47:19,709 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURE] Parallel structuring completed
2025-11-11 09:47:19,711 | INFO | hackthon_support_agent.BaseService | [PARALLEL_VALIDATE] Starting parallel validation
2025-11-11 09:47:20,155 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 09:47:20,160 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 09:47:20,161 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:47:20,173 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:47:20,175 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:47:20,182 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:47:20,183 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:47:20,188 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:47:20,189 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 09:47:20,192 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 09:47:20,193 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 09:47:20,194 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 09:47:20,200 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 09:47:20,202 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:47:20,207 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:47:20,208 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:47:20,216 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:47:20,218 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:47:20,235 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:47:20,237 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 09:47:20,246 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 09:47:20,247 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 09:47:20,271 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Fetching context for project: fb298f0a-8931-417c-a5db-24152bf66c50
2025-11-11 09:47:20,292 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Starting workflow for project: fb298f0a-8931-417c-a5db-24152bf66c50
2025-11-11 09:47:20,304 | INFO | hackthon_support_agent.BaseService | [PLANNING] Starting planning phase
2025-11-11 09:47:20,306 | INFO | hackthon_support_agent.BaseService | [PLANNING] Plan created: 3 focus areas
2025-11-11 09:47:20,309 | INFO | hackthon_support_agent.BaseService | [CACHE] Creating context cache
2025-11-11 09:47:20,546 | WARNING | hackthon_support_agent.BaseService | [CACHE] Failed to create real cache: Caches.create() got an unexpected keyword argument 'contents'
2025-11-11 09:47:20,567 | WARNING | hackthon_support_agent.BaseService | [CACHE] Falling back to mock cache (no token savings)
2025-11-11 09:47:20,571 | INFO | hackthon_support_agent.BaseService | [CACHE] Cache created: projects/fb298f0a-8931-417c-a5db-24152bf66c50/caches/1762854440, TTL: 60min
2025-11-11 09:47:20,576 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Starting parallel extraction
2025-11-11 09:47:20,579 | INFO | hackthon_support_agent.BaseService | [PARALLEL] Processing 3 focus areas in parallel
2025-11-11 09:47:20,580 | INFO | hackthon_support_agent.BaseService | [MAP_REDUCE] Starting map-reduce extraction for 認証・権限
2025-11-11 09:47:20,581 | INFO | hackthon_support_agent.BaseService | [MAP_REDUCE] Starting map-reduce extraction for データ管理
2025-11-11 09:47:20,582 | INFO | hackthon_support_agent.BaseService | [MAP_REDUCE] Starting map-reduce extraction for UI・画面
2025-11-11 09:47:22,591 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 140 dependencies
2025-11-11 09:47:22,591 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 69, 'blocks': 39, 'relates': 32}
2025-11-11 09:47:22,592 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURE] Parallel structuring completed
2025-11-11 09:47:22,592 | INFO | hackthon_support_agent.BaseService | [PARALLEL_VALIDATE] Starting parallel validation
2025-11-11 09:47:24,743 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 65 functions
2025-11-11 09:47:24,744 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 45, 'Should': 18, 'Could': 2}
2025-11-11 09:47:24,745 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURE] Parallel structuring completed
2025-11-11 09:47:24,746 | INFO | hackthon_support_agent.BaseService | [PARALLEL_VALIDATE] Starting parallel validation
2025-11-11 09:47:25,295 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 77 dependencies
2025-11-11 09:47:25,296 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 44, 'blocks': 25, 'relates': 8}
2025-11-11 09:47:25,297 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURE] Parallel structuring completed
2025-11-11 09:47:25,297 | INFO | hackthon_support_agent.BaseService | [PARALLEL_VALIDATE] Starting parallel validation
2025-11-11 09:47:30,585 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 67 functions
2025-11-11 09:47:30,587 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 45, 'Should': 22}
2025-11-11 09:47:31,909 | INFO | hackthon_support_agent.BaseService | [VALIDATE_EXTRACT] Validation score: 0.95, needs_revision: False
2025-11-11 09:47:39,711 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 68 dependencies
2025-11-11 09:47:39,713 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 60, 'blocks': 5, 'relates': 3}
2025-11-11 09:47:39,717 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURE] Parallel structuring completed
2025-11-11 09:47:39,720 | INFO | hackthon_support_agent.BaseService | [PARALLEL_VALIDATE] Starting parallel validation
2025-11-11 09:47:40,841 | INFO | hackthon_support_agent.BaseService | [VALIDATE_PRIORITY] Validation score: 0.35, needs_revision: True
2025-11-11 09:47:41,546 | INFO | hackthon_support_agent.BaseService | [VALIDATE_PRIORITY] Validation score: 0.4, needs_revision: True
2025-11-11 09:47:42,311 | INFO | hackthon_support_agent.BaseService | [VALIDATE_PRIORITY] Validation score: 0.3, needs_revision: True
2025-11-11 09:47:43,840 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 21 functions using Pydantic
2025-11-11 09:47:45,315 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 19 functions using Pydantic
2025-11-11 09:47:45,333 | INFO | hackthon_support_agent.BaseService | [VALIDATE_PRIORITY] Validation score: 0.6, needs_revision: True
2025-11-11 09:47:45,502 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 09:47:45,506 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 09:47:45,508 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:47:45,527 | INFO | hackthon_support_agent.BaseService | [VALIDATE_DEPENDENCY] Validation score: 0.85, needs_revision: True
2025-11-11 09:47:45,534 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:47:45,536 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:47:45,540 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:47:45,541 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:47:45,547 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:47:45,548 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 09:47:45,555 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 09:47:45,555 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 09:47:45,556 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 09:47:45,561 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 09:47:45,562 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:47:45,568 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:47:45,570 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:47:45,575 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:47:45,579 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:47:45,585 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:47:45,586 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 09:47:45,590 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 09:47:45,591 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 09:47:45,606 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Fetching context for project: fb298f0a-8931-417c-a5db-24152bf66c50
2025-11-11 09:47:45,624 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Starting workflow for project: fb298f0a-8931-417c-a5db-24152bf66c50
2025-11-11 09:47:45,630 | INFO | hackthon_support_agent.BaseService | [PLANNING] Starting planning phase
2025-11-11 09:47:45,631 | INFO | hackthon_support_agent.BaseService | [PLANNING] Plan created: 3 focus areas
2025-11-11 09:47:45,632 | INFO | hackthon_support_agent.BaseService | [CACHE] Creating context cache
2025-11-11 09:47:45,712 | WARNING | hackthon_support_agent.BaseService | [CACHE] Failed to create real cache: Caches.create() got an unexpected keyword argument 'contents'
2025-11-11 09:47:45,713 | WARNING | hackthon_support_agent.BaseService | [CACHE] Falling back to mock cache (no token savings)
2025-11-11 09:47:45,716 | INFO | hackthon_support_agent.BaseService | [CACHE] Cache created: projects/fb298f0a-8931-417c-a5db-24152bf66c50/caches/1762854465, TTL: 60min
2025-11-11 09:47:45,720 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Starting parallel extraction
2025-11-11 09:47:45,722 | INFO | hackthon_support_agent.BaseService | [PARALLEL] Processing 3 focus areas in parallel
2025-11-11 09:47:45,722 | INFO | hackthon_support_agent.BaseService | [MAP_REDUCE] Starting map-reduce extraction for 認証・権限
2025-11-11 09:47:45,723 | INFO | hackthon_support_agent.BaseService | [MAP_REDUCE] Starting map-reduce extraction for データ管理
2025-11-11 09:47:45,725 | INFO | hackthon_support_agent.BaseService | [MAP_REDUCE] Starting map-reduce extraction for UI・画面
2025-11-11 09:47:46,234 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 21 functions using Pydantic
2025-11-11 09:47:46,235 | INFO | hackthon_support_agent.BaseService | [VALIDATE_CATEGORIZE] Validation score: 0.88, needs_revision: True
2025-11-11 09:47:47,796 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 18 functions using Pydantic
2025-11-11 09:47:47,949 | INFO | hackthon_support_agent.BaseService | [VALIDATE_DEPENDENCY] Validation score: 0.85, needs_revision: True
2025-11-11 09:47:48,445 | INFO | hackthon_support_agent.BaseService | [VALIDATE_EXTRACT] Validation score: 0.7, needs_revision: True
2025-11-11 09:47:50,266 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 24 functions using Pydantic
2025-11-11 09:47:50,335 | INFO | hackthon_support_agent.BaseService | [VALIDATE_PRIORITY] Validation score: 0.3, needs_revision: True
2025-11-11 09:47:50,735 | INFO | hackthon_support_agent.BaseService | [VALIDATE_CATEGORIZE] Validation score: 1.0, needs_revision: False
2025-11-11 09:47:50,736 | INFO | hackthon_support_agent.BaseService | [PARALLEL_VALIDATE] Parallel validation completed
2025-11-11 09:47:50,737 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] 認証・権限 completed in 127.45s
2025-11-11 09:47:51,288 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 22 functions using Pydantic
2025-11-11 09:47:51,547 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 26 functions using Pydantic
2025-11-11 09:47:51,548 | INFO | hackthon_support_agent.BaseService | [MAP_REDUCE] Extracted 67 unique functions from 3 chunks
2025-11-11 09:47:51,549 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURE] Starting parallel structuring
2025-11-11 09:47:51,895 | INFO | hackthon_support_agent.BaseService | [VALIDATE_EXTRACT] Validation score: 0.6, needs_revision: True
2025-11-11 09:47:52,500 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 24 functions using Pydantic
2025-11-11 09:47:52,506 | INFO | hackthon_support_agent.BaseService | [MAP_REDUCE] Extracted 69 unique functions from 3 chunks
2025-11-11 09:47:52,508 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURE] Starting parallel structuring
2025-11-11 09:47:52,604 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 09:47:52,608 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 09:47:52,609 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:47:52,628 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:47:52,628 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:47:52,632 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:47:52,633 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:47:52,637 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:47:52,637 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 09:47:52,640 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 09:47:52,640 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 09:47:52,641 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 09:47:52,645 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 09:47:52,645 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:47:52,649 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:47:52,650 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:47:52,653 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:47:52,653 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:47:52,656 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:47:52,656 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 09:47:52,659 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 09:47:52,660 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 09:47:52,673 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Fetching context for project: fb298f0a-8931-417c-a5db-24152bf66c50
2025-11-11 09:47:52,689 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Starting workflow for project: fb298f0a-8931-417c-a5db-24152bf66c50
2025-11-11 09:47:52,695 | INFO | hackthon_support_agent.BaseService | [PLANNING] Starting planning phase
2025-11-11 09:47:52,695 | INFO | hackthon_support_agent.BaseService | [PLANNING] Plan created: 3 focus areas
2025-11-11 09:47:52,699 | INFO | hackthon_support_agent.BaseService | [CACHE] Creating context cache
2025-11-11 09:47:52,992 | WARNING | hackthon_support_agent.BaseService | [CACHE] Failed to create real cache: Caches.create() got an unexpected keyword argument 'contents'
2025-11-11 09:47:52,993 | WARNING | hackthon_support_agent.BaseService | [CACHE] Falling back to mock cache (no token savings)
2025-11-11 09:47:52,996 | INFO | hackthon_support_agent.BaseService | [CACHE] Cache created: projects/fb298f0a-8931-417c-a5db-24152bf66c50/caches/1762854472, TTL: 60min
2025-11-11 09:47:53,000 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Starting parallel extraction
2025-11-11 09:47:53,003 | INFO | hackthon_support_agent.BaseService | [PARALLEL] Processing 3 focus areas in parallel
2025-11-11 09:47:53,004 | INFO | hackthon_support_agent.BaseService | [MAP_REDUCE] Starting map-reduce extraction for 認証・権限
2025-11-11 09:47:53,005 | INFO | hackthon_support_agent.BaseService | [MAP_REDUCE] Starting map-reduce extraction for データ管理
2025-11-11 09:47:53,012 | INFO | hackthon_support_agent.BaseService | [MAP_REDUCE] Starting map-reduce extraction for UI・画面
2025-11-11 09:47:55,284 | INFO | hackthon_support_agent.BaseService | [VALIDATE_EXTRACT] Validation score: 0.75, needs_revision: True
2025-11-11 09:47:56,984 | INFO | hackthon_support_agent.BaseService | [VALIDATE_DEPENDENCY] Validation score: 0.89, needs_revision: True
2025-11-11 09:47:56,985 | INFO | hackthon_support_agent.BaseService | [PARALLEL_VALIDATE] Parallel validation completed
2025-11-11 09:47:56,986 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] UI・画面 completed in 127.23s
2025-11-11 09:47:57,975 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 09:47:57,981 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 09:47:57,982 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:47:57,998 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:47:58,000 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:47:58,007 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:47:58,008 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:47:58,014 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:47:58,015 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 09:47:58,020 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 09:47:58,020 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 09:47:58,022 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 09:47:58,025 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 09:47:58,026 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:47:58,033 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:47:58,035 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:47:58,045 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:47:58,047 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:47:58,055 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:47:58,056 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 09:47:58,063 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 09:47:58,065 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 09:47:58,176 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Fetching context for project: fb298f0a-8931-417c-a5db-24152bf66c50
2025-11-11 09:47:58,186 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 21 functions using Pydantic
2025-11-11 09:47:58,206 | INFO | hackthon_support_agent.BaseService | [MAP_REDUCE] Extracted 60 unique functions from 3 chunks
2025-11-11 09:47:58,208 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURE] Starting parallel structuring
2025-11-11 09:47:58,341 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Starting workflow for project: fb298f0a-8931-417c-a5db-24152bf66c50
2025-11-11 09:47:58,348 | INFO | hackthon_support_agent.BaseService | [PLANNING] Starting planning phase
2025-11-11 09:47:58,348 | INFO | hackthon_support_agent.BaseService | [PLANNING] Plan created: 3 focus areas
2025-11-11 09:47:58,352 | INFO | hackthon_support_agent.BaseService | [CACHE] Creating context cache
2025-11-11 09:47:58,421 | WARNING | hackthon_support_agent.BaseService | [CACHE] Failed to create real cache: Caches.create() got an unexpected keyword argument 'contents'
2025-11-11 09:47:58,421 | WARNING | hackthon_support_agent.BaseService | [CACHE] Falling back to mock cache (no token savings)
2025-11-11 09:47:58,423 | INFO | hackthon_support_agent.BaseService | [CACHE] Cache created: projects/fb298f0a-8931-417c-a5db-24152bf66c50/caches/1762854478, TTL: 60min
2025-11-11 09:47:58,425 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Starting parallel extraction
2025-11-11 09:47:58,427 | INFO | hackthon_support_agent.BaseService | [PARALLEL] Processing 3 focus areas in parallel
2025-11-11 09:47:58,430 | INFO | hackthon_support_agent.BaseService | [MAP_REDUCE] Starting map-reduce extraction for 認証・権限
2025-11-11 09:47:58,431 | INFO | hackthon_support_agent.BaseService | [MAP_REDUCE] Starting map-reduce extraction for データ管理
2025-11-11 09:47:58,433 | INFO | hackthon_support_agent.BaseService | [MAP_REDUCE] Starting map-reduce extraction for UI・画面
2025-11-11 09:48:00,077 | INFO | hackthon_support_agent.BaseService | [VALIDATE_CATEGORIZE] Validation score: 1.0, needs_revision: False
2025-11-11 09:48:00,604 | INFO | hackthon_support_agent.BaseService | [VALIDATE_CATEGORIZE] Validation score: 0.98, needs_revision: True
2025-11-11 09:48:04,948 | INFO | hackthon_support_agent.BaseService | [VALIDATE_CATEGORIZE] Validation score: 1.0, needs_revision: False
2025-11-11 09:48:04,950 | INFO | hackthon_support_agent.BaseService | [PARALLEL_VALIDATE] Parallel validation completed
2025-11-11 09:48:04,950 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] データ管理 completed in 141.66s
2025-11-11 09:48:08,340 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 19 functions using Pydantic
2025-11-11 09:48:09,084 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 20 functions using Pydantic
2025-11-11 09:48:09,501 | INFO | hackthon_support_agent.BaseService | [VALIDATE_EXTRACT] Validation score: 0.85, needs_revision: True
2025-11-11 09:48:11,209 | INFO | hackthon_support_agent.BaseService | [VALIDATE_DEPENDENCY] Validation score: 0.3, needs_revision: True
2025-11-11 09:48:11,210 | INFO | hackthon_support_agent.BaseService | [PARALLEL_VALIDATE] Parallel validation completed
2025-11-11 09:48:11,211 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] データ管理 completed in 141.46s
2025-11-11 09:48:11,659 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 17 functions using Pydantic
2025-11-11 09:48:12,118 | INFO | hackthon_support_agent.BaseService | [VALIDATE_CATEGORIZE] Validation score: 0.72, needs_revision: True
2025-11-11 09:48:12,282 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 19 functions using Pydantic
2025-11-11 09:48:12,449 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 25 functions using Pydantic
2025-11-11 09:48:12,450 | INFO | hackthon_support_agent.BaseService | [MAP_REDUCE] Extracted 64 unique functions from 3 chunks
2025-11-11 09:48:12,451 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURE] Starting parallel structuring
2025-11-11 09:48:12,539 | INFO | hackthon_support_agent.BaseService | [VALIDATE_PRIORITY] Validation score: 0.25, needs_revision: False
2025-11-11 09:48:12,628 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 23 functions using Pydantic
2025-11-11 09:48:12,959 | INFO | hackthon_support_agent.BaseService | [VALIDATE_EXTRACT] Validation score: 0.6, needs_revision: True
2025-11-11 09:48:17,327 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 18 functions using Pydantic
2025-11-11 09:48:17,584 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 25 functions using Pydantic
2025-11-11 09:48:17,906 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 20 functions using Pydantic
2025-11-11 09:48:17,936 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 26 functions using Pydantic
2025-11-11 09:48:18,384 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 25 functions using Pydantic
2025-11-11 09:48:18,729 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 16 functions using Pydantic
2025-11-11 09:48:19,521 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 19 functions using Pydantic
2025-11-11 09:48:20,231 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 19 functions using Pydantic
2025-11-11 09:48:20,888 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 24 functions using Pydantic
2025-11-11 09:48:20,889 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 16 functions using Pydantic
2025-11-11 09:48:20,890 | INFO | hackthon_support_agent.BaseService | [MAP_REDUCE] Extracted 64 unique functions from 3 chunks
2025-11-11 09:48:20,891 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURE] Starting parallel structuring
2025-11-11 09:48:22,712 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 22 functions using Pydantic
2025-11-11 09:48:23,258 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 21 functions using Pydantic
2025-11-11 09:48:23,259 | INFO | hackthon_support_agent.BaseService | [MAP_REDUCE] Extracted 59 unique functions from 3 chunks
2025-11-11 09:48:23,260 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURE] Starting parallel structuring
2025-11-11 09:48:24,935 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 60 functions
2025-11-11 09:48:24,936 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'ui': 10, 'api': 9, 'data': 24, 'logic': 12, 'auth': 5}
2025-11-11 09:48:25,510 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 22 functions using Pydantic
2025-11-11 09:48:25,511 | INFO | hackthon_support_agent.BaseService | [MAP_REDUCE] Extracted 63 unique functions from 3 chunks
2025-11-11 09:48:25,512 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURE] Starting parallel structuring
2025-11-11 09:48:26,145 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 25 functions using Pydantic
2025-11-11 09:48:27,055 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 67 functions
2025-11-11 09:48:27,069 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'ui': 20, 'api': 12, 'logic': 12, 'auth': 5, 'data': 18}
2025-11-11 09:48:27,524 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 23 functions using Pydantic
2025-11-11 09:48:28,864 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 25 functions using Pydantic
2025-11-11 09:48:30,780 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 18 functions using Pydantic
2025-11-11 09:48:30,781 | INFO | hackthon_support_agent.BaseService | [MAP_REDUCE] Extracted 62 unique functions from 3 chunks
2025-11-11 09:48:30,782 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURE] Starting parallel structuring
2025-11-11 09:48:30,965 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 19 functions using Pydantic
2025-11-11 09:48:30,967 | INFO | hackthon_support_agent.BaseService | [MAP_REDUCE] Extracted 62 unique functions from 3 chunks
2025-11-11 09:48:30,968 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURE] Starting parallel structuring
2025-11-11 09:48:31,446 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 18 functions using Pydantic
2025-11-11 09:48:31,448 | INFO | hackthon_support_agent.BaseService | [MAP_REDUCE] Extracted 63 unique functions from 3 chunks
2025-11-11 09:48:31,449 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURE] Starting parallel structuring
2025-11-11 09:48:31,625 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 22 functions using Pydantic
2025-11-11 09:48:31,627 | INFO | hackthon_support_agent.BaseService | [MAP_REDUCE] Extracted 65 unique functions from 3 chunks
2025-11-11 09:48:31,628 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURE] Starting parallel structuring
2025-11-11 09:48:32,247 | INFO | hackthon_support_agent.BaseService | [VALIDATE_DEPENDENCY] Validation score: 0.65, needs_revision: True
2025-11-11 09:48:32,249 | INFO | hackthon_support_agent.BaseService | [PARALLEL_VALIDATE] Parallel validation completed
2025-11-11 09:48:32,249 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] UI・画面 completed in 168.96s
2025-11-11 09:48:32,256 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Completed: 3 areas processed in parallel
2025-11-11 09:48:32,261 | INFO | hackthon_support_agent.BaseService | [MERGE] Merging results from all focus areas
2025-11-11 09:48:32,264 | INFO | hackthon_support_agent.BaseService | [MERGE] Merged: 145 unique functions
2025-11-11 09:48:32,268 | INFO | hackthon_support_agent.BaseService | [FINAL_VALIDATION] Starting final validation
2025-11-11 09:48:36,924 | ERROR | hackthon_support_agent.BaseService | Function extraction failed: 1 validation error for FunctionExtractionOutput
functions.20.description
  String should have at least 50 characters [type=string_too_short, input_value='学生の氏名、学年...ンも配置するUI。', input_type=str]
    For further information visit https://errors.pydantic.dev/2.12/v/string_too_short
2025-11-11 09:48:36,929 | INFO | hackthon_support_agent.BaseService | [MAP_REDUCE] Extracted 44 unique functions from 3 chunks
2025-11-11 09:48:36,930 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURE] Starting parallel structuring
2025-11-11 09:48:43,892 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 69 functions
2025-11-11 09:48:43,893 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 28, 'Should': 32, 'Could': 9}
2025-11-11 09:48:46,892 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 67 functions
2025-11-11 09:48:46,893 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 34, 'Wont': 5, 'Should': 13, 'Could': 15}
2025-11-11 09:48:46,967 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 60 functions
2025-11-11 09:48:46,967 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 27, 'Should': 28, 'Could': 5}
2025-11-11 09:48:47,837 | INFO | hackthon_support_agent.BaseService | [FINAL_VALIDATION] Judgment: APPROVE
2025-11-11 09:48:47,847 | INFO | hackthon_support_agent.BaseService | [PERSISTENCE] Saving to database
2025-11-11 09:48:47,848 | ERROR | hackthon_support_agent.BaseService | [PERSISTENCE] Persistence failed: FunctionStructuringPipeline._save_to_database() got an unexpected keyword argument 'final_data'
2025-11-11 09:48:47,849 | INFO | hackthon_support_agent.BaseService | [COVERAGE] Analyzing coverage
2025-11-11 09:48:47,852 | INFO | hackthon_support_agent.BaseService | [COVERAGE] Coverage: 100.0%, Status: complete
2025-11-11 09:48:47,858 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Workflow completed in 184.66s
2025-11-11 09:48:47,919 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 09:48:47,921 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 09:48:47,921 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:48:47,928 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:48:47,929 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:48:47,931 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:48:47,932 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:48:47,934 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:48:47,935 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 09:48:47,938 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 09:48:47,938 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 09:48:47,938 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 09:48:47,941 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 09:48:47,941 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:48:47,943 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:48:47,943 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:48:47,947 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:48:47,948 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:48:47,949 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:48:47,950 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 09:48:47,952 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 09:48:47,952 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 09:48:47,960 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Fetching context for project: fb298f0a-8931-417c-a5db-24152bf66c50
2025-11-11 09:48:47,968 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Starting workflow for project: fb298f0a-8931-417c-a5db-24152bf66c50
2025-11-11 09:48:47,974 | INFO | hackthon_support_agent.BaseService | [PLANNING] Starting planning phase
2025-11-11 09:48:47,974 | INFO | hackthon_support_agent.BaseService | [PLANNING] Plan created: 3 focus areas
2025-11-11 09:48:47,975 | INFO | hackthon_support_agent.BaseService | [CACHE] Creating context cache
2025-11-11 09:48:48,018 | WARNING | hackthon_support_agent.BaseService | [CACHE] Failed to create real cache: Caches.create() got an unexpected keyword argument 'contents'
2025-11-11 09:48:48,018 | WARNING | hackthon_support_agent.BaseService | [CACHE] Falling back to mock cache (no token savings)
2025-11-11 09:48:48,020 | INFO | hackthon_support_agent.BaseService | [CACHE] Cache created: projects/fb298f0a-8931-417c-a5db-24152bf66c50/caches/1762854528, TTL: 60min
2025-11-11 09:48:48,022 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Starting parallel extraction
2025-11-11 09:48:48,024 | INFO | hackthon_support_agent.BaseService | [PARALLEL] Processing 3 focus areas in parallel
2025-11-11 09:48:48,024 | INFO | hackthon_support_agent.BaseService | [MAP_REDUCE] Starting map-reduce extraction for 認証・権限
2025-11-11 09:48:48,025 | INFO | hackthon_support_agent.BaseService | [MAP_REDUCE] Starting map-reduce extraction for データ管理
2025-11-11 09:48:48,025 | INFO | hackthon_support_agent.BaseService | [MAP_REDUCE] Starting map-reduce extraction for UI・画面
2025-11-11 09:48:48,399 | INFO | hackthon_support_agent.BaseService | [VALIDATE_DEPENDENCY] Validation score: 0.5, needs_revision: True
2025-11-11 09:48:48,400 | INFO | hackthon_support_agent.BaseService | [PARALLEL_VALIDATE] Parallel validation completed
2025-11-11 09:48:48,401 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] 認証・権限 completed in 178.66s
2025-11-11 09:48:48,407 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Completed: 3 areas processed in parallel
2025-11-11 09:48:48,409 | INFO | hackthon_support_agent.BaseService | [MERGE] Merging results from all focus areas
2025-11-11 09:48:48,412 | INFO | hackthon_support_agent.BaseService | [MERGE] Merged: 171 unique functions
2025-11-11 09:48:48,415 | INFO | hackthon_support_agent.BaseService | [FINAL_VALIDATION] Starting final validation
2025-11-11 09:48:52,308 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 69 functions
2025-11-11 09:48:52,310 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'ui': 20, 'api': 12, 'logic': 12, 'data': 21, 'auth': 4}
2025-11-11 09:48:56,574 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 59 functions
2025-11-11 09:48:56,576 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'ui': 10, 'api': 15, 'logic': 12, 'data': 17, 'auth': 5}
2025-11-11 09:48:58,604 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 64 functions
2025-11-11 09:48:58,605 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'ui': 17, 'api': 13, 'logic': 14, 'data': 16, 'auth': 4}
2025-11-11 09:49:02,734 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 64 functions
2025-11-11 09:49:02,744 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 27, 'Should': 26, 'Could': 11}
2025-11-11 09:49:04,296 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 59 functions
2025-11-11 09:49:04,298 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 30, 'Should': 24, 'Could': 5}
2025-11-11 09:49:04,302 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 63 functions
2025-11-11 09:49:04,304 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'ui': 18, 'api': 13, 'data': 18, 'logic': 10, 'auth': 4}
2025-11-11 09:49:04,679 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 178 dependencies
2025-11-11 09:49:04,680 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 93, 'relates': 70, 'blocks': 15}
2025-11-11 09:49:04,681 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURE] Parallel structuring completed
2025-11-11 09:49:04,682 | INFO | hackthon_support_agent.BaseService | [PARALLEL_VALIDATE] Starting parallel validation
2025-11-11 09:49:06,616 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 64 functions
2025-11-11 09:49:06,617 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'ui': 16, 'api': 11, 'data': 19, 'logic': 13, 'auth': 5}
2025-11-11 09:49:07,719 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 62 functions
2025-11-11 09:49:07,720 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 34, 'Should': 28}
2025-11-11 09:49:08,378 | INFO | hackthon_support_agent.BaseService | [FINAL_VALIDATION] Judgment: APPROVE
2025-11-11 09:49:08,385 | INFO | hackthon_support_agent.BaseService | [PERSISTENCE] Saving to database
2025-11-11 09:49:08,386 | ERROR | hackthon_support_agent.BaseService | [PERSISTENCE] Persistence failed: FunctionStructuringPipeline._save_to_database() got an unexpected keyword argument 'final_data'
2025-11-11 09:49:08,390 | INFO | hackthon_support_agent.BaseService | [COVERAGE] Analyzing coverage
2025-11-11 09:49:08,391 | INFO | hackthon_support_agent.BaseService | [COVERAGE] Coverage: 100.0%, Status: complete
2025-11-11 09:49:08,396 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Workflow completed in 198.85s
2025-11-11 09:49:08,418 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 09:49:08,421 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 09:49:08,422 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:49:08,430 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:49:08,431 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:49:08,434 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:49:08,434 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:49:08,438 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:49:08,438 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 09:49:08,442 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 09:49:08,442 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 09:49:08,443 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 09:49:08,446 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 09:49:08,447 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:49:08,449 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:49:08,450 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:49:08,452 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:49:08,452 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 09:49:08,454 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 09:49:08,455 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 09:49:08,457 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 09:49:08,457 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 09:49:08,469 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Fetching context for project: fb298f0a-8931-417c-a5db-24152bf66c50
2025-11-11 09:49:08,489 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Starting workflow for project: fb298f0a-8931-417c-a5db-24152bf66c50
2025-11-11 09:49:08,493 | INFO | hackthon_support_agent.BaseService | [PLANNING] Starting planning phase
2025-11-11 09:49:08,493 | INFO | hackthon_support_agent.BaseService | [PLANNING] Plan created: 3 focus areas
2025-11-11 09:49:08,495 | INFO | hackthon_support_agent.BaseService | [CACHE] Creating context cache
2025-11-11 09:49:08,566 | WARNING | hackthon_support_agent.BaseService | [CACHE] Failed to create real cache: Caches.create() got an unexpected keyword argument 'contents'
2025-11-11 09:49:08,569 | WARNING | hackthon_support_agent.BaseService | [CACHE] Falling back to mock cache (no token savings)
2025-11-11 09:49:08,597 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 63 functions
2025-11-11 09:49:08,600 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'ui': 10, 'api': 17, 'logic': 14, 'data': 18, 'auth': 4}
2025-11-11 09:49:08,597 | INFO | hackthon_support_agent.BaseService | [CACHE] Cache created: projects/fb298f0a-8931-417c-a5db-24152bf66c50/caches/1762854548, TTL: 60min
2025-11-11 09:49:08,605 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Starting parallel extraction
2025-11-11 09:49:08,608 | INFO | hackthon_support_agent.BaseService | [PARALLEL] Processing 3 focus areas in parallel
2025-11-11 09:49:08,609 | INFO | hackthon_support_agent.BaseService | [MAP_REDUCE] Starting map-reduce extraction for 認証・権限
2025-11-11 09:49:08,610 | INFO | hackthon_support_agent.BaseService | [MAP_REDUCE] Starting map-reduce extraction for データ管理
2025-11-11 09:49:08,611 | INFO | hackthon_support_agent.BaseService | [MAP_REDUCE] Starting map-reduce extraction for UI・画面
2025-11-11 09:49:09,153 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 76 dependencies
2025-11-11 09:49:09,153 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 45, 'blocks': 18, 'relates': 13}
2025-11-11 09:49:09,154 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURE] Parallel structuring completed
2025-11-11 09:49:09,154 | INFO | hackthon_support_agent.BaseService | [PARALLEL_VALIDATE] Starting parallel validation
2025-11-11 09:49:09,380 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 137 dependencies
2025-11-11 09:49:09,381 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 43, 'blocks': 33, 'relates': 61}
2025-11-11 09:49:09,382 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURE] Parallel structuring completed
2025-11-11 09:49:09,382 | INFO | hackthon_support_agent.BaseService | [PARALLEL_VALIDATE] Starting parallel validation
2025-11-11 09:49:09,402 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 23 functions using Pydantic
2025-11-11 09:49:09,769 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 44 functions
2025-11-11 09:49:09,770 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 18, 'Should': 15, 'Could': 11}
2025-11-11 09:49:12,761 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 17 functions using Pydantic
2025-11-11 09:49:13,021 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 64 functions
2025-11-11 09:49:13,022 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 41, 'Should': 15, 'Could': 8}
2025-11-11 09:49:13,301 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 63 functions
2025-11-11 09:49:13,302 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 29, 'Should': 28, 'Could': 6}
2025-11-11 09:49:13,641 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 20 functions using Pydantic
2025-11-11 09:49:13,943 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 19 functions using Pydantic
2025-11-11 09:49:14,096 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 44 functions
2025-11-11 09:49:14,097 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'api': 5, 'data': 17, 'logic': 10, 'ui': 8, 'auth': 4}
2025-11-11 09:49:15,760 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 19 functions using Pydantic
2025-11-11 09:49:15,764 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 65 functions
2025-11-11 09:49:15,765 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 33, 'Should': 30, 'Could': 2}
2025-11-11 09:49:17,668 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 62 functions
2025-11-11 09:49:17,669 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 45, 'Should': 17}
2025-11-11 09:49:19,206 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 19 functions using Pydantic
2025-11-11 09:49:19,211 | INFO | hackthon_support_agent.BaseService | [MAP_REDUCE] Extracted 61 unique functions from 3 chunks
2025-11-11 09:49:19,214 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURE] Starting parallel structuring
2025-11-11 09:49:20,339 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 62 functions
2025-11-11 09:49:20,340 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'ui': 13, 'api': 15, 'logic': 14, 'data': 16, 'auth': 4}
2025-11-11 09:49:22,672 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 91 dependencies
2025-11-11 09:49:22,673 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'blocks': 2, 'requires': 71, 'relates': 18}
2025-11-11 09:49:22,674 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURE] Parallel structuring completed
2025-11-11 09:49:22,675 | INFO | hackthon_support_agent.BaseService | [PARALLEL_VALIDATE] Starting parallel validation
2025-11-11 09:49:26,118 | INFO | hackthon_support_agent.BaseService | [VALIDATE_PRIORITY] Validation score: 0.3, needs_revision: True
2025-11-11 09:49:26,777 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 20 functions using Pydantic
2025-11-11 09:49:26,794 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 21 functions using Pydantic
2025-11-11 09:49:26,975 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 20 functions using Pydantic
2025-11-11 09:49:26,976 | INFO | hackthon_support_agent.BaseService | [MAP_REDUCE] Extracted 56 unique functions from 3 chunks
2025-11-11 09:49:26,977 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURE] Starting parallel structuring
2025-11-11 09:49:27,600 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 62 functions
2025-11-11 09:49:27,603 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 23 functions using Pydantic
2025-11-11 09:49:27,603 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'ui': 11, 'api': 15, 'logic': 14, 'data': 18, 'auth': 4}
2025-11-11 09:49:27,605 | INFO | hackthon_support_agent.BaseService | [MAP_REDUCE] Extracted 64 unique functions from 3 chunks
2025-11-11 09:49:27,607 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURE] Starting parallel structuring
2025-11-11 09:49:28,298 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 20 functions using Pydantic
2025-11-11 09:49:29,138 | INFO | hackthon_support_agent.BaseService | [VALIDATE_PRIORITY] Validation score: 0.4, needs_revision: True
2025-11-11 09:49:30,182 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 22 functions using Pydantic
2025-11-11 09:49:31,258 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 17 functions using Pydantic
2025-11-11 09:49:32,933 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 53 dependencies
2025-11-11 09:49:32,934 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'blocks': 4, 'requires': 35, 'relates': 14}
2025-11-11 09:49:32,936 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURE] Parallel structuring completed
2025-11-11 09:49:32,937 | INFO | hackthon_support_agent.BaseService | [PARALLEL_VALIDATE] Starting parallel validation
2025-11-11 09:49:33,197 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 125 dependencies
2025-11-11 09:49:33,198 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'blocks': 32, 'relates': 54, 'requires': 39}
2025-11-11 09:49:33,199 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURE] Parallel structuring completed
2025-11-11 09:49:33,199 | INFO | hackthon_support_agent.BaseService | [PARALLEL_VALIDATE] Starting parallel validation
2025-11-11 09:49:33,581 | INFO | hackthon_support_agent.BaseService | [VALIDATE_EXTRACT] Validation score: 0.65, needs_revision: True
2025-11-11 09:49:33,702 | INFO | hackthon_support_agent.BaseService | [VALIDATE_PRIORITY] Validation score: 0.5, needs_revision: True
2025-11-11 09:49:35,812 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 65 functions
2025-11-11 09:49:35,813 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'ui': 14, 'api': 14, 'data': 22, 'logic': 11, 'auth': 4}
2025-11-11 09:49:36,422 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 189 dependencies
2025-11-11 09:49:36,423 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 72, 'blocks': 62, 'relates': 55}
2025-11-11 09:49:36,424 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURE] Parallel structuring completed
2025-11-11 09:49:36,425 | INFO | hackthon_support_agent.BaseService | [PARALLEL_VALIDATE] Starting parallel validation
2025-11-11 09:49:36,440 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 17 functions using Pydantic
2025-11-11 09:49:37,439 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 151 dependencies
2025-11-11 09:49:37,439 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 88, 'relates': 7, 'blocks': 56}
2025-11-11 09:49:37,512 | INFO | hackthon_support_agent.BaseService | [VALIDATE_EXTRACT] Validation score: 0.65, needs_revision: True
2025-11-11 09:49:37,656 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 63 functions
2025-11-11 09:49:37,656 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 25, 'Should': 26, 'Could': 12}
2025-11-11 09:49:37,657 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURE] Parallel structuring completed
2025-11-11 09:49:37,657 | INFO | hackthon_support_agent.BaseService | [PARALLEL_VALIDATE] Starting parallel validation
2025-11-11 09:49:37,830 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 25 functions using Pydantic
2025-11-11 09:49:37,831 | INFO | hackthon_support_agent.BaseService | [MAP_REDUCE] Extracted 62 unique functions from 3 chunks
2025-11-11 09:49:37,832 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURE] Starting parallel structuring
2025-11-11 09:49:39,949 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 20 functions using Pydantic
2025-11-11 09:49:40,308 | INFO | hackthon_support_agent.BaseService | [VALIDATE_EXTRACT] Validation score: 0.55, needs_revision: True
2025-11-11 09:49:40,929 | INFO | hackthon_support_agent.BaseService | [VALIDATE_CATEGORIZE] Validation score: 1.0, needs_revision: False
2025-11-11 09:49:40,950 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 94 dependencies
2025-11-11 09:49:40,951 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 47, 'blocks': 27, 'relates': 20}
2025-11-11 09:49:40,952 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURE] Parallel structuring completed
2025-11-11 09:49:40,958 | INFO | hackthon_support_agent.BaseService | [PARALLEL_VALIDATE] Starting parallel validation
2025-11-11 09:49:41,435 | INFO | hackthon_support_agent.BaseService | [VALIDATE_CATEGORIZE] Validation score: 1.0, needs_revision: False
2025-11-11 09:49:45,667 | INFO | hackthon_support_agent.BaseService | [VALIDATE_EXTRACT] Validation score: 0.75, needs_revision: True
2025-11-11 09:49:46,816 | INFO | hackthon_support_agent.BaseService | [VALIDATE_PRIORITY] Validation score: 0.3, needs_revision: True
2025-11-11 09:49:48,757 | ERROR | hackthon_support_agent.BaseService | Function extraction failed: 1 validation error for FunctionExtractionOutput
functions.21.description
  String should have at least 50 characters [type=string_too_short, input_value='学生が中断した課...ンポーネント。', input_type=str]
    For further information visit https://errors.pydantic.dev/2.12/v/string_too_short
2025-11-11 09:49:48,760 | INFO | hackthon_support_agent.BaseService | [MAP_REDUCE] Extracted 42 unique functions from 3 chunks
2025-11-11 09:49:48,760 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURE] Starting parallel structuring
2025-11-11 09:49:49,759 | INFO | hackthon_support_agent.BaseService | [VALIDATE_CATEGORIZE] Validation score: 1.0, needs_revision: False
2025-11-11 09:49:52,517 | INFO | hackthon_support_agent.BaseService | [VALIDATE_PRIORITY] Validation score: 0.4, needs_revision: True
2025-11-11 09:49:53,825 | INFO | hackthon_support_agent.BaseService | [VALIDATE_PRIORITY] Validation score: 0.6, needs_revision: True
2025-11-11 09:49:53,876 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 19 functions using Pydantic
2025-11-11 09:49:53,878 | INFO | hackthon_support_agent.BaseService | [MAP_REDUCE] Extracted 56 unique functions from 3 chunks
2025-11-11 09:49:53,878 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURE] Starting parallel structuring
2025-11-11 09:49:54,374 | INFO | hackthon_support_agent.BaseService | [VALIDATE_PRIORITY] Validation score: 0.45, needs_revision: True
2025-11-11 09:49:55,465 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 123 dependencies
2025-11-11 09:49:55,467 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'blocks': 40, 'relates': 47, 'requires': 36}
2025-11-11 09:49:55,469 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURE] Parallel structuring completed
2025-11-11 09:49:55,469 | INFO | hackthon_support_agent.BaseService | [PARALLEL_VALIDATE] Starting parallel validation
2025-11-11 09:49:56,133 | INFO | hackthon_support_agent.BaseService | [VALIDATE_CATEGORIZE] Validation score: 0.6, needs_revision: True
2025-11-11 09:49:58,338 | INFO | hackthon_support_agent.BaseService | [VALIDATE_DEPENDENCY] Validation score: 0.5, needs_revision: True
2025-11-11 09:49:58,340 | INFO | hackthon_support_agent.BaseService | [PARALLEL_VALIDATE] Parallel validation completed
2025-11-11 09:49:58,341 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] データ管理 completed in 157.76s
2025-11-11 09:49:58,355 | INFO | hackthon_support_agent.BaseService | [VALIDATE_PRIORITY] Validation score: 0.45, needs_revision: True
2025-11-11 09:49:59,130 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 61 functions
2025-11-11 09:49:59,131 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'ui': 11, 'api': 18, 'logic': 13, 'data': 15, 'auth': 4}
2025-11-11 09:50:00,351 | INFO | hackthon_support_agent.BaseService | [VALIDATE_EXTRACT] Validation score: 0.6, needs_revision: True
2025-11-11 09:50:00,666 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 56 functions
2025-11-11 09:50:00,667 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'ui': 8, 'api': 11, 'logic': 15, 'data': 18, 'auth': 4}
2025-11-11 09:50:01,508 | INFO | hackthon_support_agent.BaseService | [VALIDATE_EXTRACT] Validation score: 0.7, needs_revision: True
2025-11-11 09:50:01,715 | INFO | hackthon_support_agent.BaseService | [VALIDATE_EXTRACT] Validation score: 0.75, needs_revision: True
2025-11-11 09:50:01,825 | INFO | hackthon_support_agent.BaseService | [VALIDATE_PRIORITY] Validation score: 0.5, needs_revision: True
2025-11-11 09:50:01,920 | INFO | hackthon_support_agent.BaseService | [VALIDATE_EXTRACT] Validation score: 0.95, needs_revision: False
2025-11-11 09:50:02,018 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 56 functions
2025-11-11 09:50:02,019 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 27, 'Should': 24, 'Could': 5}
2025-11-11 09:50:02,429 | INFO | hackthon_support_agent.BaseService | [VALIDATE_EXTRACT] Validation score: 0.55, needs_revision: True
2025-11-11 09:50:03,278 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 61 functions
2025-11-11 09:50:03,282 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 27, 'Should': 25, 'Could': 9}
2025-11-11 09:50:06,080 | INFO | hackthon_support_agent.BaseService | [VALIDATE_CATEGORIZE] Validation score: 0.636, needs_revision: True
2025-11-11 09:50:08,675 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 64 functions
2025-11-11 09:50:08,676 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'ui': 16, 'api': 12, 'logic': 13, 'data': 19, 'auth': 4}
2025-11-11 09:50:09,380 | INFO | hackthon_support_agent.BaseService | [VALIDATE_PRIORITY] Validation score: 0.3, needs_revision: True
2025-11-11 09:50:10,850 | INFO | hackthon_support_agent.BaseService | [VALIDATE_DEPENDENCY] Validation score: 0.44, needs_revision: True
2025-11-11 09:50:10,852 | INFO | hackthon_support_agent.BaseService | [PARALLEL_VALIDATE] Parallel validation completed
2025-11-11 09:50:10,852 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] 認証・権限 completed in 145.13s
2025-11-11 09:50:13,150 | INFO | hackthon_support_agent.BaseService | [VALIDATE_CATEGORIZE] Validation score: 1.0, needs_revision: False
2025-11-11 09:50:14,276 | INFO | hackthon_support_agent.BaseService | [VALIDATE_CATEGORIZE] Validation score: 0.6, needs_revision: True
2025-11-11 09:50:17,080 | INFO | hackthon_support_agent.BaseService | [VALIDATE_DEPENDENCY] Validation score: 0.55, needs_revision: True
2025-11-11 09:50:17,086 | INFO | hackthon_support_agent.BaseService | [PARALLEL_VALIDATE] Parallel validation completed
2025-11-11 09:50:17,086 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] データ管理 completed in 138.65s
2025-11-11 09:50:17,293 | INFO | hackthon_support_agent.BaseService | [VALIDATE_CATEGORIZE] Validation score: 0.73, needs_revision: True
2025-11-11 09:50:18,098 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 64 functions
2025-11-11 09:50:18,099 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 33, 'Should': 22, 'Could': 9}
2025-11-11 09:50:18,639 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 171 dependencies
2025-11-11 09:50:18,641 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 78, 'relates': 31, 'blocks': 62}
2025-11-11 09:50:18,645 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURE] Parallel structuring completed
2025-11-11 09:50:18,646 | INFO | hackthon_support_agent.BaseService | [PARALLEL_VALIDATE] Starting parallel validation
2025-11-11 09:50:19,204 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 56 functions
2025-11-11 09:50:19,205 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'ui': 9, 'data': 23, 'logic': 14, 'api': 6, 'auth': 4}
2025-11-11 09:50:20,057 | INFO | hackthon_support_agent.BaseService | [VALIDATE_DEPENDENCY] Validation score: 0.4, needs_revision: True
2025-11-11 09:50:22,394 | INFO | hackthon_support_agent.BaseService | [VALIDATE_CATEGORIZE] Validation score: 0.71, needs_revision: True
2025-11-11 09:50:23,622 | INFO | hackthon_support_agent.BaseService | [VALIDATE_DEPENDENCY] Validation score: 0.9, needs_revision: False
2025-11-11 09:50:23,623 | INFO | hackthon_support_agent.BaseService | [PARALLEL_VALIDATE] Parallel validation completed
2025-11-11 09:50:23,624 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] UI・画面 completed in 150.61s
2025-11-11 09:50:24,312 | INFO | hackthon_support_agent.BaseService | [VALIDATE_CATEGORIZE] Validation score: 0.71, needs_revision: True
2025-11-11 09:50:24,314 | INFO | hackthon_support_agent.BaseService | [PARALLEL_VALIDATE] Parallel validation completed
2025-11-11 09:50:24,314 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] データ管理 completed in 158.59s
2025-11-11 09:50:26,954 | INFO | hackthon_support_agent.BaseService | [VALIDATE_DEPENDENCY] Validation score: 0.7, needs_revision: True
2025-11-11 09:50:26,955 | INFO | hackthon_support_agent.BaseService | [PARALLEL_VALIDATE] Parallel validation completed
2025-11-11 09:50:26,956 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] 認証・権限 completed in 186.38s
2025-11-11 09:50:28,768 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 56 functions
2025-11-11 09:50:28,768 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 46, 'Should': 7, 'Could': 3}
2025-11-11 09:50:31,794 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 42 functions
2025-11-11 09:50:31,795 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'data': 16, 'logic': 9, 'api': 9, 'ui': 3, 'auth': 5}
2025-11-11 09:50:32,122 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 69 dependencies
2025-11-11 09:50:32,123 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 40, 'blocks': 23, 'relates': 6}
2025-11-11 09:50:32,123 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURE] Parallel structuring completed
2025-11-11 09:50:32,124 | INFO | hackthon_support_agent.BaseService | [PARALLEL_VALIDATE] Starting parallel validation
2025-11-11 09:50:33,264 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 148 dependencies
2025-11-11 09:50:33,265 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'relates': 28, 'requires': 87, 'blocks': 33}
2025-11-11 09:50:36,005 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 60 dependencies
2025-11-11 09:50:36,006 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 45, 'relates': 12, 'blocks': 3}
2025-11-11 09:50:37,322 | INFO | hackthon_support_agent.BaseService | [VALIDATE_DEPENDENCY] Validation score: 0.76, needs_revision: True
2025-11-11 09:50:37,323 | INFO | hackthon_support_agent.BaseService | [PARALLEL_VALIDATE] Parallel validation completed
2025-11-11 09:50:37,324 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] UI・画面 completed in 158.89s
2025-11-11 09:50:37,579 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 42 functions
2025-11-11 09:50:37,579 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 28, 'Should': 12, 'Could': 2}
2025-11-11 09:50:37,580 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURE] Parallel structuring completed
2025-11-11 09:50:37,580 | INFO | hackthon_support_agent.BaseService | [PARALLEL_VALIDATE] Starting parallel validation
2025-11-11 09:50:38,402 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 62 functions
2025-11-11 09:50:38,403 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'ui': 17, 'data': 21, 'api': 7, 'logic': 13, 'auth': 4}
2025-11-11 09:50:39,069 | INFO | hackthon_support_agent.BaseService | [VALIDATE_EXTRACT] Validation score: 0.8, needs_revision: True
2025-11-11 09:50:40,013 | INFO | hackthon_support_agent.BaseService | [VALIDATE_PRIORITY] Validation score: 0.6, needs_revision: True
2025-11-11 09:50:44,795 | INFO | hackthon_support_agent.BaseService | [VALIDATE_DEPENDENCY] Validation score: 0.55, needs_revision: True
2025-11-11 09:50:44,909 | INFO | hackthon_support_agent.BaseService | [VALIDATE_CATEGORIZE] Validation score: 1.0, needs_revision: False
2025-11-11 09:50:47,499 | INFO | hackthon_support_agent.BaseService | [VALIDATE_EXTRACT] Validation score: 0.65, needs_revision: True
2025-11-11 09:50:47,501 | INFO | hackthon_support_agent.BaseService | [PARALLEL_VALIDATE] Parallel validation completed
2025-11-11 09:50:47,501 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] 認証・権限 completed in 169.07s
2025-11-11 09:50:47,507 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Completed: 3 areas processed in parallel
2025-11-11 09:50:47,513 | INFO | hackthon_support_agent.BaseService | [MERGE] Merging results from all focus areas
2025-11-11 09:50:47,513 | INFO | hackthon_support_agent.BaseService | [MERGE] Merged: 135 unique functions
2025-11-11 09:50:47,516 | INFO | hackthon_support_agent.BaseService | [FINAL_VALIDATION] Starting final validation
2025-11-11 09:50:49,555 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 62 functions
2025-11-11 09:50:49,556 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 31, 'Should': 25, 'Could': 6}
2025-11-11 09:50:49,560 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURE] Parallel structuring completed
2025-11-11 09:50:49,561 | INFO | hackthon_support_agent.BaseService | [PARALLEL_VALIDATE] Starting parallel validation
2025-11-11 09:50:51,158 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 200 dependencies
2025-11-11 09:50:51,160 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 61, 'relates': 125, 'blocks': 14}
2025-11-11 09:50:51,161 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURE] Parallel structuring completed
2025-11-11 09:50:51,161 | INFO | hackthon_support_agent.BaseService | [PARALLEL_VALIDATE] Starting parallel validation
2025-11-11 09:50:56,000 | INFO | hackthon_support_agent.BaseService | [VALIDATE_DEPENDENCY] Validation score: 0.4, needs_revision: True
2025-11-11 09:50:56,001 | INFO | hackthon_support_agent.BaseService | [PARALLEL_VALIDATE] Parallel validation completed
2025-11-11 09:50:56,002 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] データ管理 completed in 183.00s
2025-11-11 09:50:56,503 | INFO | hackthon_support_agent.BaseService | [VALIDATE_PRIORITY] Validation score: 0.6, needs_revision: True
2025-11-11 09:50:59,070 | INFO | hackthon_support_agent.BaseService | [VALIDATE_EXTRACT] Validation score: 0.85, needs_revision: True
2025-11-11 09:51:02,120 | INFO | hackthon_support_agent.BaseService | [VALIDATE_EXTRACT] Validation score: 0.9, needs_revision: False
2025-11-11 09:51:03,057 | INFO | hackthon_support_agent.BaseService | [VALIDATE_PRIORITY] Validation score: 0.6, needs_revision: True
2025-11-11 09:51:03,224 | INFO | hackthon_support_agent.BaseService | [VALIDATE_EXTRACT] Validation score: 0.95, needs_revision: False
2025-11-11 09:51:04,045 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 84 dependencies
2025-11-11 09:51:04,046 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 21, 'relates': 23, 'blocks': 40}
2025-11-11 09:51:04,047 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURE] Parallel structuring completed
2025-11-11 09:51:04,047 | INFO | hackthon_support_agent.BaseService | [PARALLEL_VALIDATE] Starting parallel validation
2025-11-11 09:51:04,266 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 187 dependencies
2025-11-11 09:51:04,267 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'relates': 9, 'requires': 88, 'blocks': 90}
2025-11-11 09:51:04,268 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURE] Parallel structuring completed
2025-11-11 09:51:04,268 | INFO | hackthon_support_agent.BaseService | [PARALLEL_VALIDATE] Starting parallel validation
2025-11-11 09:51:08,652 | INFO | hackthon_support_agent.BaseService | [VALIDATE_CATEGORIZE] Validation score: 1.0, needs_revision: False
2025-11-11 09:51:10,805 | INFO | hackthon_support_agent.BaseService | [VALIDATE_PRIORITY] Validation score: 0.65, needs_revision: True
2025-11-11 09:51:11,141 | INFO | hackthon_support_agent.BaseService | [VALIDATE_DEPENDENCY] Validation score: 0.4, needs_revision: True
2025-11-11 09:51:13,888 | INFO | hackthon_support_agent.BaseService | [FINAL_VALIDATION] Judgment: REVISE_NEEDED
2025-11-11 09:51:13,896 | INFO | hackthon_support_agent.BaseService | [PERSISTENCE] Saving to database
2025-11-11 09:51:13,897 | ERROR | hackthon_support_agent.BaseService | [PERSISTENCE] Persistence failed: FunctionStructuringPipeline._save_to_database() got an unexpected keyword argument 'final_data'
2025-11-11 09:51:13,901 | INFO | hackthon_support_agent.BaseService | [COVERAGE] Analyzing coverage
2025-11-11 09:51:13,902 | INFO | hackthon_support_agent.BaseService | [COVERAGE] Coverage: 100.0%, Status: complete
2025-11-11 09:51:13,905 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Workflow completed in 195.56s
2025-11-11 09:51:15,613 | INFO | hackthon_support_agent.BaseService | [VALIDATE_PRIORITY] Validation score: 0.45, needs_revision: True
2025-11-11 09:51:17,208 | INFO | hackthon_support_agent.BaseService | [VALIDATE_CATEGORIZE] Validation score: 0.73, needs_revision: True
2025-11-11 09:51:17,211 | INFO | hackthon_support_agent.BaseService | [PARALLEL_VALIDATE] Parallel validation completed
2025-11-11 09:51:17,215 | INFO | hackthon_support_agent.BaseService | [VALIDATE_EXTRACT] Validation score: 0.75, needs_revision: True
2025-11-11 09:51:17,215 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] UI・画面 completed in 211.49s
2025-11-11 09:51:17,224 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Completed: 3 areas processed in parallel
2025-11-11 09:51:17,228 | INFO | hackthon_support_agent.BaseService | [MERGE] Merging results from all focus areas
2025-11-11 09:51:17,233 | INFO | hackthon_support_agent.BaseService | [MERGE] Merged: 160 unique functions
2025-11-11 09:51:17,237 | INFO | hackthon_support_agent.BaseService | [FINAL_VALIDATION] Starting final validation
2025-11-11 09:51:25,175 | INFO | hackthon_support_agent.BaseService | [VALIDATE_PRIORITY] Validation score: 0.3, needs_revision: True
2025-11-11 09:51:26,534 | INFO | hackthon_support_agent.BaseService | [VALIDATE_EXTRACT] Validation score: 0.85, needs_revision: True
2025-11-11 09:51:26,801 | INFO | hackthon_support_agent.BaseService | [VALIDATE_PRIORITY] Validation score: 0.4, needs_revision: True
2025-11-11 09:51:26,894 | INFO | hackthon_support_agent.BaseService | [VALIDATE_CATEGORIZE] Validation score: 1.0, needs_revision: False
2025-11-11 10:08:35,302 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 10:08:37,872 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 10:11:12,327 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 10:11:25,318 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 10:11:32,167 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 10:11:39,188 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 10:11:47,055 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 10:12:08,143 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 10:12:10,707 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 10:16:19,956 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 10:16:45,478 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 10:16:47,624 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 10:29:24,709 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 10:29:24,714 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 10:29:24,715 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 10:29:24,734 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 10:29:24,735 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 10:29:24,737 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 10:29:24,738 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 10:29:24,740 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 10:29:24,741 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 10:29:24,742 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 10:29:24,743 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 10:29:24,754 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Fetching context for project: fb298f0a-8931-417c-a5db-24152bf66c50
2025-11-11 10:29:24,764 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Starting workflow for project: fb298f0a-8931-417c-a5db-24152bf66c50
2025-11-11 10:29:24,775 | INFO | hackthon_support_agent.BaseService | [PLANNING] Starting planning phase
2025-11-11 10:29:24,775 | INFO | hackthon_support_agent.BaseService | [PLANNING] Plan created with 3 focus areas
2025-11-11 10:29:24,777 | INFO | hackthon_support_agent.BaseService | [CACHE] Creating context cache
2025-11-11 10:29:24,777 | INFO | hackthon_support_agent.BaseService | [CACHE] Context cache prepared (not yet implemented)
2025-11-11 10:29:24,780 | ERROR | hackthon_support_agent.BaseService | [WORKFLOW] Workflow failed: No synchronous function provided to "parallel_extraction".
Either initialize with a synchronous function or invoke via the async API (ainvoke, astream, etc.)
2025-11-11 10:29:36,009 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 10:29:37,376 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 10:29:37,379 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 10:29:37,380 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 10:29:37,407 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 10:29:37,407 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 10:29:37,409 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 10:29:37,409 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 10:29:37,411 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 10:29:37,411 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 10:29:37,413 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 10:29:37,413 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 10:29:37,423 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Fetching context for project: fb298f0a-8931-417c-a5db-24152bf66c50
2025-11-11 10:29:37,427 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Starting workflow for project: fb298f0a-8931-417c-a5db-24152bf66c50
2025-11-11 10:29:37,432 | INFO | hackthon_support_agent.BaseService | [PLANNING] Starting planning phase
2025-11-11 10:29:37,433 | INFO | hackthon_support_agent.BaseService | [PLANNING] Plan created with 3 focus areas
2025-11-11 10:29:37,434 | INFO | hackthon_support_agent.BaseService | [CACHE] Creating context cache
2025-11-11 10:29:37,434 | INFO | hackthon_support_agent.BaseService | [CACHE] Context cache prepared (not yet implemented)
2025-11-11 10:29:37,436 | ERROR | hackthon_support_agent.BaseService | [WORKFLOW] Workflow failed: No synchronous function provided to "parallel_extraction".
Either initialize with a synchronous function or invoke via the async API (ainvoke, astream, etc.)
2025-11-11 10:30:41,308 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 10:33:43,137 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 10:35:12,159 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 10:38:18,441 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 10:40:31,622 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 10:41:59,554 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 10:43:32,231 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 10:45:46,081 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 10:46:05,909 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 10:46:35,928 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 10:48:22,627 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 10:49:20,688 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 10:50:02,439 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 10:51:26,665 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 10:51:49,375 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 10:52:06,344 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 10:52:32,230 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 10:52:38,485 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 10:52:44,756 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 10:52:50,247 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 11:07:41,908 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 11:07:41,913 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 11:07:41,914 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 11:07:41,934 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 11:07:41,935 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 11:07:41,938 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 11:07:41,939 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 11:07:41,940 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 11:07:41,940 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 11:07:41,942 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 11:07:41,942 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 11:07:42,033 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Fetching context for project: fb298f0a-8931-417c-a5db-24152bf66c50
2025-11-11 11:07:42,039 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Starting workflow for project: fb298f0a-8931-417c-a5db-24152bf66c50
2025-11-11 11:07:42,046 | INFO | hackthon_support_agent.BaseService | [PLANNING] Starting planning phase
2025-11-11 11:07:42,046 | INFO | hackthon_support_agent.BaseService | [PLANNING] Plan created with 3 focus areas
2025-11-11 11:07:42,048 | INFO | hackthon_support_agent.BaseService | [CACHE] Creating context cache
2025-11-11 11:07:42,527 | ERROR | hackthon_support_agent.BaseService | [CACHE] Cache creation failed: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'Cached content is too small. total_token_count=3593, min_total_token_count=4096', 'status': 'INVALID_ARGUMENT'}}
2025-11-11 11:07:42,530 | ERROR | hackthon_support_agent.BaseService | [WORKFLOW] Workflow failed: No synchronous function provided to "parallel_extraction".
Either initialize with a synchronous function or invoke via the async API (ainvoke, astream, etc.)
2025-11-11 11:07:43,185 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 11:07:43,188 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 11:07:43,188 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 11:07:43,191 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 11:07:43,192 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 11:07:43,193 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 11:07:43,193 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 11:07:43,195 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 11:07:43,196 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 11:07:43,197 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 11:07:43,197 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 11:07:43,243 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Fetching context for project: fb298f0a-8931-417c-a5db-24152bf66c50
2025-11-11 11:07:43,246 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Starting workflow for project: fb298f0a-8931-417c-a5db-24152bf66c50
2025-11-11 11:07:43,248 | INFO | hackthon_support_agent.BaseService | [PLANNING] Starting planning phase
2025-11-11 11:07:43,248 | INFO | hackthon_support_agent.BaseService | [PLANNING] Plan created with 3 focus areas
2025-11-11 11:07:43,249 | INFO | hackthon_support_agent.BaseService | [CACHE] Creating context cache
2025-11-11 11:07:43,532 | ERROR | hackthon_support_agent.BaseService | [CACHE] Cache creation failed: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'Cached content is too small. total_token_count=3593, min_total_token_count=4096', 'status': 'INVALID_ARGUMENT'}}
2025-11-11 11:07:43,536 | ERROR | hackthon_support_agent.BaseService | [WORKFLOW] Workflow failed: No synchronous function provided to "parallel_extraction".
Either initialize with a synchronous function or invoke via the async API (ainvoke, astream, etc.)
2025-11-11 11:07:45,485 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 11:07:45,489 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 11:07:45,489 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 11:07:45,497 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 11:07:45,498 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 11:07:45,499 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 11:07:45,500 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 11:07:45,501 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 11:07:45,501 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 11:07:45,503 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 11:07:45,504 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 11:07:45,550 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Fetching context for project: fb298f0a-8931-417c-a5db-24152bf66c50
2025-11-11 11:07:45,552 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Starting workflow for project: fb298f0a-8931-417c-a5db-24152bf66c50
2025-11-11 11:07:45,554 | INFO | hackthon_support_agent.BaseService | [PLANNING] Starting planning phase
2025-11-11 11:07:45,555 | INFO | hackthon_support_agent.BaseService | [PLANNING] Plan created with 3 focus areas
2025-11-11 11:07:45,557 | INFO | hackthon_support_agent.BaseService | [CACHE] Creating context cache
2025-11-11 11:07:46,073 | ERROR | hackthon_support_agent.BaseService | [CACHE] Cache creation failed: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'Cached content is too small. total_token_count=3593, min_total_token_count=4096', 'status': 'INVALID_ARGUMENT'}}
2025-11-11 11:07:46,075 | ERROR | hackthon_support_agent.BaseService | [WORKFLOW] Workflow failed: No synchronous function provided to "parallel_extraction".
Either initialize with a synchronous function or invoke via the async API (ainvoke, astream, etc.)
2025-11-11 11:33:11,928 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 11:33:11,941 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 11:33:11,942 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 11:33:12,002 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 11:33:12,002 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 11:33:12,006 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 11:33:12,006 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 11:33:12,011 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 11:33:12,012 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 11:33:12,017 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 11:33:12,018 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 11:33:12,186 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Fetching context for project: fb298f0a-8931-417c-a5db-24152bf66c50
2025-11-11 11:33:12,195 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Starting workflow for project: fb298f0a-8931-417c-a5db-24152bf66c50
2025-11-11 11:33:12,214 | INFO | hackthon_support_agent.BaseService | [PLANNING] Starting planning phase
2025-11-11 11:33:12,215 | INFO | hackthon_support_agent.BaseService | [PLANNING] Plan created with 3 focus areas
2025-11-11 11:33:12,219 | INFO | hackthon_support_agent.BaseService | [CACHE] Creating context cache
2025-11-11 11:33:12,809 | ERROR | hackthon_support_agent.BaseService | [CACHE] Cache creation failed: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'Cached content is too small. total_token_count=3593, min_total_token_count=4096', 'status': 'INVALID_ARGUMENT'}}
2025-11-11 11:33:12,812 | ERROR | hackthon_support_agent.BaseService | [WORKFLOW] Workflow failed: No synchronous function provided to "parallel_extraction".
Either initialize with a synchronous function or invoke via the async API (ainvoke, astream, etc.)
2025-11-11 11:33:25,920 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 11:33:25,928 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 11:33:25,929 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 11:33:25,945 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 11:33:25,946 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 11:33:25,954 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 11:33:25,954 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 11:33:25,964 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 11:33:25,964 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 11:33:25,971 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 11:33:25,971 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 11:33:26,078 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Fetching context for project: fb298f0a-8931-417c-a5db-24152bf66c50
2025-11-11 11:33:26,084 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Starting workflow for project: fb298f0a-8931-417c-a5db-24152bf66c50
2025-11-11 11:33:26,091 | INFO | hackthon_support_agent.BaseService | [PLANNING] Starting planning phase
2025-11-11 11:33:26,092 | INFO | hackthon_support_agent.BaseService | [PLANNING] Plan created with 3 focus areas
2025-11-11 11:33:26,095 | INFO | hackthon_support_agent.BaseService | [CACHE] Creating context cache
2025-11-11 11:33:26,551 | ERROR | hackthon_support_agent.BaseService | [CACHE] Cache creation failed: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'Cached content is too small. total_token_count=3593, min_total_token_count=4096', 'status': 'INVALID_ARGUMENT'}}
2025-11-11 11:33:26,555 | ERROR | hackthon_support_agent.BaseService | [WORKFLOW] Workflow failed: No synchronous function provided to "parallel_extraction".
Either initialize with a synchronous function or invoke via the async API (ainvoke, astream, etc.)
2025-11-11 11:34:58,089 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 11:34:58,103 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 11:34:58,104 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 11:34:58,151 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 11:34:58,152 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 11:34:58,163 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 11:34:58,164 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 11:34:58,169 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 11:34:58,169 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 11:34:58,172 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 11:34:58,173 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 11:34:58,305 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Fetching context for project: fb298f0a-8931-417c-a5db-24152bf66c50
2025-11-11 11:34:58,309 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Starting workflow for project: fb298f0a-8931-417c-a5db-24152bf66c50
2025-11-11 11:34:58,315 | INFO | hackthon_support_agent.BaseService | [PLANNING] Starting planning phase
2025-11-11 11:34:58,316 | INFO | hackthon_support_agent.BaseService | [PLANNING] Plan created with 3 focus areas
2025-11-11 11:34:58,317 | INFO | hackthon_support_agent.BaseService | [CACHE] Creating context cache
2025-11-11 11:34:58,883 | ERROR | hackthon_support_agent.BaseService | [CACHE] Cache creation failed: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'Cached content is too small. total_token_count=3593, min_total_token_count=4096', 'status': 'INVALID_ARGUMENT'}}
2025-11-11 11:34:58,885 | ERROR | hackthon_support_agent.BaseService | [WORKFLOW] Workflow failed: No synchronous function provided to "parallel_extraction".
Either initialize with a synchronous function or invoke via the async API (ainvoke, astream, etc.)
2025-11-11 11:37:54,888 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 11:37:54,893 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 11:37:54,893 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 11:37:55,018 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 11:37:55,019 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 11:37:55,023 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 11:37:55,024 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 11:37:55,025 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 11:37:55,026 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 11:37:55,029 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 11:37:55,030 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 11:37:55,097 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Fetching context for project: fb298f0a-8931-417c-a5db-24152bf66c50
2025-11-11 11:37:55,101 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Starting workflow for project: fb298f0a-8931-417c-a5db-24152bf66c50
2025-11-11 11:37:55,118 | INFO | hackthon_support_agent.BaseService | [PLANNING] Starting planning phase
2025-11-11 11:37:55,119 | INFO | hackthon_support_agent.BaseService | [PLANNING] Plan created with 3 focus areas
2025-11-11 11:37:55,122 | INFO | hackthon_support_agent.BaseService | [CACHE] Creating context cache
2025-11-11 11:37:55,358 | ERROR | hackthon_support_agent.BaseService | [CACHE] Cache creation failed: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'Cached content is too small. total_token_count=3593, min_total_token_count=4096', 'status': 'INVALID_ARGUMENT'}}
2025-11-11 11:37:55,362 | ERROR | hackthon_support_agent.BaseService | [WORKFLOW] Workflow failed: No synchronous function provided to "parallel_extraction".
Either initialize with a synchronous function or invoke via the async API (ainvoke, astream, etc.)
2025-11-11 12:19:53,170 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 12:20:13,577 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 12:29:06,877 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 12:29:06,885 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 12:29:06,893 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 12:29:06,894 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 12:29:06,900 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 12:29:06,902 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 12:29:06,906 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 12:29:06,920 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 12:29:06,921 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 12:29:06,941 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 12:29:06,942 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 12:29:06,942 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 12:29:06,941 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 12:29:06,944 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 12:29:06,945 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 12:29:06,946 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 12:29:06,946 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 12:29:06,949 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 12:29:06,955 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 12:29:06,957 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 12:29:06,957 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 12:29:06,958 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 12:29:06,959 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 12:29:06,964 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 12:29:06,970 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 12:29:06,969 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 12:29:06,967 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 12:29:06,973 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 12:29:06,974 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 12:29:06,974 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 12:29:06,975 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 12:29:06,983 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 12:29:06,985 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 12:29:07,158 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Fetching context for project: fb298f0a-8931-417c-a5db-24152bf66c50
2025-11-11 12:29:07,163 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Fetching context for project: fb298f0a-8931-417c-a5db-24152bf66c50
2025-11-11 12:29:07,172 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Fetching context for project: fb298f0a-8931-417c-a5db-24152bf66c50
2025-11-11 12:29:07,176 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Starting workflow for project: fb298f0a-8931-417c-a5db-24152bf66c50
2025-11-11 12:29:07,177 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Starting workflow for project: fb298f0a-8931-417c-a5db-24152bf66c50
2025-11-11 12:29:07,184 | INFO | hackthon_support_agent.BaseService | [PLANNING] Starting planning phase
2025-11-11 12:29:07,186 | INFO | hackthon_support_agent.BaseService | [PLANNING] Plan created with 3 focus areas
2025-11-11 12:29:07,187 | INFO | hackthon_support_agent.BaseService | [PLANNING] Starting planning phase
2025-11-11 12:29:07,190 | INFO | hackthon_support_agent.BaseService | [CACHE] Creating context cache
2025-11-11 12:29:07,190 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Starting workflow for project: fb298f0a-8931-417c-a5db-24152bf66c50
2025-11-11 12:29:07,191 | INFO | hackthon_support_agent.BaseService | [PLANNING] Plan created with 3 focus areas
2025-11-11 12:29:07,198 | INFO | hackthon_support_agent.BaseService | [PLANNING] Starting planning phase
2025-11-11 12:29:07,199 | INFO | hackthon_support_agent.BaseService | [CACHE] Creating context cache
2025-11-11 12:29:07,200 | INFO | hackthon_support_agent.BaseService | [PLANNING] Plan created with 3 focus areas
2025-11-11 12:29:07,205 | INFO | hackthon_support_agent.BaseService | [CACHE] Creating context cache
2025-11-11 12:29:07,736 | ERROR | hackthon_support_agent.BaseService | [CACHE] Cache creation failed: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'Cached content is too small. total_token_count=3715, min_total_token_count=4096', 'status': 'INVALID_ARGUMENT'}}
2025-11-11 12:29:07,737 | ERROR | hackthon_support_agent.BaseService | [CACHE] Cache creation failed: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'Cached content is too small. total_token_count=3715, min_total_token_count=4096', 'status': 'INVALID_ARGUMENT'}}
2025-11-11 12:29:07,740 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Starting parallel extraction
2025-11-11 12:29:07,742 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Starting parallel extraction
2025-11-11 12:29:07,743 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: データ・モデル
2025-11-11 12:29:07,743 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: データ・モデル
2025-11-11 12:29:07,759 | ERROR | hackthon_support_agent.BaseService | [CACHE] Cache creation failed: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'Cached content is too small. total_token_count=3715, min_total_token_count=4096', 'status': 'INVALID_ARGUMENT'}}
2025-11-11 12:29:07,770 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Starting parallel extraction
2025-11-11 12:29:07,770 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: データ・モデル
2025-11-11 12:29:21,956 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 12:29:21,963 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 12:29:21,964 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 12:29:21,966 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 12:29:21,966 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 12:29:21,968 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 12:29:21,968 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 12:29:21,971 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 12:29:21,972 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 12:29:21,974 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 12:29:21,974 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 12:29:22,046 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Fetching context for project: fb298f0a-8931-417c-a5db-24152bf66c50
2025-11-11 12:29:22,049 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Starting workflow for project: fb298f0a-8931-417c-a5db-24152bf66c50
2025-11-11 12:29:22,052 | INFO | hackthon_support_agent.BaseService | [PLANNING] Starting planning phase
2025-11-11 12:29:22,052 | INFO | hackthon_support_agent.BaseService | [PLANNING] Plan created with 3 focus areas
2025-11-11 12:29:22,053 | INFO | hackthon_support_agent.BaseService | [CACHE] Creating context cache
2025-11-11 12:29:22,922 | ERROR | hackthon_support_agent.BaseService | [CACHE] Cache creation failed: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'Cached content is too small. total_token_count=3715, min_total_token_count=4096', 'status': 'INVALID_ARGUMENT'}}
2025-11-11 12:29:22,924 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Starting parallel extraction
2025-11-11 12:29:22,925 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: データ・モデル
2025-11-11 12:29:33,785 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 21 functions using LangChain
2025-11-11 12:29:36,257 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 12:29:36,269 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 12:29:36,270 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 12:29:36,287 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 12:29:36,288 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 12:29:36,292 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 12:29:36,292 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 12:29:36,299 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 12:29:36,300 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 12:29:36,307 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 12:29:36,308 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 12:29:36,409 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Fetching context for project: fb298f0a-8931-417c-a5db-24152bf66c50
2025-11-11 12:29:36,413 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Starting workflow for project: fb298f0a-8931-417c-a5db-24152bf66c50
2025-11-11 12:29:36,419 | INFO | hackthon_support_agent.BaseService | [PLANNING] Starting planning phase
2025-11-11 12:29:36,420 | INFO | hackthon_support_agent.BaseService | [PLANNING] Plan created with 3 focus areas
2025-11-11 12:29:36,423 | INFO | hackthon_support_agent.BaseService | [CACHE] Creating context cache
2025-11-11 12:29:36,665 | ERROR | hackthon_support_agent.BaseService | [CACHE] Cache creation failed: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'Cached content is too small. total_token_count=3715, min_total_token_count=4096', 'status': 'INVALID_ARGUMENT'}}
2025-11-11 12:29:36,668 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Starting parallel extraction
2025-11-11 12:29:36,669 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: データ・モデル
2025-11-11 12:29:46,186 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 12:29:46,191 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 12:29:46,192 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 12:29:46,195 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 12:29:46,195 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 12:29:46,200 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 12:29:46,200 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 12:29:46,204 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 12:29:46,205 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 12:29:46,211 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 12:29:46,212 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 12:29:46,286 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Fetching context for project: fb298f0a-8931-417c-a5db-24152bf66c50
2025-11-11 12:29:46,293 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Starting workflow for project: fb298f0a-8931-417c-a5db-24152bf66c50
2025-11-11 12:29:46,297 | INFO | hackthon_support_agent.BaseService | [PLANNING] Starting planning phase
2025-11-11 12:29:46,298 | INFO | hackthon_support_agent.BaseService | [PLANNING] Plan created with 3 focus areas
2025-11-11 12:29:46,300 | INFO | hackthon_support_agent.BaseService | [CACHE] Creating context cache
2025-11-11 12:29:46,525 | ERROR | hackthon_support_agent.BaseService | [CACHE] Cache creation failed: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'Cached content is too small. total_token_count=3715, min_total_token_count=4096', 'status': 'INVALID_ARGUMENT'}}
2025-11-11 12:29:46,527 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Starting parallel extraction
2025-11-11 12:29:46,527 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: データ・モデル
2025-11-11 12:29:55,814 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 21 functions
2025-11-11 12:29:55,816 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'logic': 8, 'ui': 5, 'data': 5, 'auth': 3}
2025-11-11 12:30:02,966 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 28 functions using LangChain
2025-11-11 12:30:07,051 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 23 functions using LangChain
2025-11-11 12:30:18,895 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 21 functions
2025-11-11 12:30:18,897 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 15, 'Should': 3, 'Could': 3}
2025-11-11 12:30:22,587 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 23 functions
2025-11-11 12:30:22,587 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'ui': 7, 'api': 4, 'logic': 2, 'data': 7, 'auth': 3}
2025-11-11 12:30:22,919 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 23 functions using LangChain
2025-11-11 12:30:31,630 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 24 functions using LangChain
2025-11-11 12:30:31,720 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 28 functions
2025-11-11 12:30:31,721 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'ui': 7, 'api': 6, 'logic': 5, 'data': 7, 'auth': 3}
2025-11-11 12:30:32,272 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 23 functions using LangChain
2025-11-11 12:30:47,393 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 24 functions
2025-11-11 12:30:47,394 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'ui': 8, 'logic': 6, 'data': 7, 'auth': 3}
2025-11-11 12:30:47,986 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 23 functions
2025-11-11 12:30:47,987 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'ui': 7, 'logic': 6, 'data': 7, 'auth': 3}
2025-11-11 12:30:48,319 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 23 functions
2025-11-11 12:30:48,320 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 12, 'Should': 10, 'Could': 1}
2025-11-11 12:30:52,411 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 23 functions
2025-11-11 12:30:52,411 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'ui': 7, 'logic': 5, 'api': 1, 'data': 7, 'auth': 3}
2025-11-11 12:30:52,730 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 71 dependencies
2025-11-11 12:30:52,731 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 39, 'relates': 32}
2025-11-11 12:30:52,732 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] データ・モデル completed in 104.97s - 71 dependencies
2025-11-11 12:30:52,732 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: API・バックエンド
2025-11-11 12:31:06,422 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 45 dependencies
2025-11-11 12:31:06,425 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 24, 'relates': 7, 'blocks': 14}
2025-11-11 12:31:06,425 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] データ・モデル completed in 118.68s - 45 dependencies
2025-11-11 12:31:06,426 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: API・バックエンド
2025-11-11 12:31:07,088 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 28 functions
2025-11-11 12:31:07,089 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 14, 'Should': 9, 'Could': 5}
2025-11-11 12:31:10,280 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 24 functions
2025-11-11 12:31:10,281 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 11, 'Should': 9, 'Could': 4}
2025-11-11 12:31:17,650 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 23 functions
2025-11-11 12:31:17,651 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 11, 'Should': 8, 'Could': 4}
2025-11-11 12:31:19,480 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 23 functions
2025-11-11 12:31:19,481 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 18, 'Should': 3, 'Could': 2}
2025-11-11 12:31:34,641 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 45 dependencies
2025-11-11 12:31:34,643 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 29, 'relates': 12, 'blocks': 4}
2025-11-11 12:31:34,644 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] データ・モデル completed in 146.87s - 45 dependencies
2025-11-11 12:31:34,644 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: API・バックエンド
2025-11-11 12:31:36,751 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 79 dependencies
2025-11-11 12:31:36,752 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 28, 'relates': 9, 'blocks': 42}
2025-11-11 12:31:36,753 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] データ・モデル completed in 110.23s - 79 dependencies
2025-11-11 12:31:36,753 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: API・バックエンド
2025-11-11 12:31:56,000 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 25 functions using LangChain
2025-11-11 12:32:00,431 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 51 dependencies
2025-11-11 12:32:00,432 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 40, 'blocks': 9, 'relates': 2}
2025-11-11 12:32:00,432 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] データ・モデル completed in 157.51s - 51 dependencies
2025-11-11 12:32:00,433 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: API・バックエンド
2025-11-11 12:32:02,141 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 25 functions using LangChain
2025-11-11 12:32:11,486 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 25 functions
2025-11-11 12:32:11,487 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'ui': 7, 'api': 3, 'logic': 5, 'data': 7, 'auth': 3}
2025-11-11 12:32:19,472 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 76 dependencies
2025-11-11 12:32:19,473 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 33, 'blocks': 39, 'relates': 4}
2025-11-11 12:32:19,474 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] データ・モデル completed in 162.80s - 76 dependencies
2025-11-11 12:32:19,474 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: API・バックエンド
2025-11-11 12:32:23,651 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 25 functions
2025-11-11 12:32:23,652 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'ui': 7, 'api': 5, 'logic': 3, 'data': 7, 'auth': 3}
2025-11-11 12:32:41,573 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 25 functions
2025-11-11 12:32:41,577 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 22 functions using LangChain
2025-11-11 12:32:41,579 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 15, 'Should': 10}
2025-11-11 12:32:43,557 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 25 functions
2025-11-11 12:32:43,557 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 14, 'Should': 11}
2025-11-11 12:32:55,955 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 22 functions
2025-11-11 12:32:55,957 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'ui': 6, 'logic': 6, 'data': 7, 'auth': 3}
2025-11-11 12:32:59,328 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 24 functions using LangChain
2025-11-11 12:33:08,231 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 23 functions using LangChain
2025-11-11 12:33:11,653 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 49 dependencies
2025-11-11 12:33:11,654 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'relates': 24, 'blocks': 8, 'requires': 17}
2025-11-11 12:33:11,655 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] API・バックエンド completed in 125.23s - 49 dependencies
2025-11-11 12:33:11,655 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: UI・画面
2025-11-11 12:33:16,602 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 23 functions using LangChain
2025-11-11 12:33:17,537 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 24 functions
2025-11-11 12:33:17,538 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'ui': 6, 'api': 6, 'logic': 4, 'data': 7, 'auth': 1}
2025-11-11 12:33:17,552 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 22 functions
2025-11-11 12:33:17,552 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 11, 'Should': 9, 'Could': 2}
2025-11-11 12:33:30,809 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 23 functions
2025-11-11 12:33:30,811 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'ui': 9, 'api': 3, 'logic': 5, 'data': 3, 'auth': 3}
2025-11-11 12:33:34,371 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 23 functions
2025-11-11 12:33:34,372 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'ui': 6, 'api': 2, 'logic': 5, 'data': 7, 'auth': 3}
2025-11-11 12:33:35,757 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 60 dependencies
2025-11-11 12:33:35,758 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 42, 'blocks': 5, 'relates': 13}
2025-11-11 12:33:35,759 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] API・バックエンド completed in 163.03s - 60 dependencies
2025-11-11 12:33:35,760 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: UI・画面
2025-11-11 12:33:36,050 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 42 dependencies
2025-11-11 12:33:36,051 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 32, 'relates': 9, 'blocks': 1}
2025-11-11 12:33:36,052 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] API・バックエンド completed in 121.41s - 42 dependencies
2025-11-11 12:33:36,053 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: UI・画面
2025-11-11 12:33:40,549 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 24 functions
2025-11-11 12:33:40,551 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 17, 'Should': 7}
2025-11-11 12:33:55,259 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 23 functions
2025-11-11 12:33:55,260 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 14, 'Should': 7, 'Could': 2}
2025-11-11 12:33:58,492 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 23 functions
2025-11-11 12:33:58,492 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 13, 'Should': 10}
2025-11-11 12:34:20,293 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 50 dependencies
2025-11-11 12:34:20,303 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 26, 'relates': 19, 'blocks': 5}
2025-11-11 12:34:20,310 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] API・バックエンド completed in 163.56s - 50 dependencies
2025-11-11 12:34:20,313 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: UI・画面
2025-11-11 12:34:22,925 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 46 dependencies
2025-11-11 12:34:22,925 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 22, 'blocks': 10, 'relates': 14}
2025-11-11 12:34:22,926 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] API・バックエンド completed in 142.49s - 46 dependencies
2025-11-11 12:34:22,926 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: UI・画面
2025-11-11 12:34:24,889 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 23 functions using LangChain
2025-11-11 12:34:32,641 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 22 functions using LangChain
2025-11-11 12:34:32,872 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 50 dependencies
2025-11-11 12:34:32,873 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 34, 'blocks': 14, 'relates': 2}
2025-11-11 12:34:32,873 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] API・バックエンド completed in 133.40s - 50 dependencies
2025-11-11 12:34:32,874 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: UI・画面
2025-11-11 12:34:48,179 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 22 functions
2025-11-11 12:34:48,187 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'ui': 6, 'logic': 2, 'api': 4, 'data': 7, 'auth': 3}
2025-11-11 12:34:48,761 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 23 functions using LangChain
2025-11-11 12:34:53,066 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 23 functions
2025-11-11 12:34:53,067 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'ui': 7, 'logic': 5, 'api': 1, 'data': 7, 'auth': 3}
2025-11-11 12:35:05,801 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 23 functions
2025-11-11 12:35:05,804 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'ui': 9, 'logic': 3, 'api': 3, 'data': 7, 'auth': 1}
2025-11-11 12:35:12,075 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 22 functions
2025-11-11 12:35:12,075 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 13, 'Should': 8, 'Could': 1}
2025-11-11 12:35:14,466 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 25 functions using LangChain
2025-11-11 12:35:20,105 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 23 functions
2025-11-11 12:35:20,106 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 19, 'Should': 4}
2025-11-11 12:35:20,159 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 28 functions using LangChain
2025-11-11 12:35:29,911 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 25 functions
2025-11-11 12:35:29,913 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'ui': 7, 'api': 5, 'logic': 3, 'data': 7, 'auth': 3}
2025-11-11 12:35:30,084 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 25 functions using LangChain
2025-11-11 12:35:34,480 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 23 functions
2025-11-11 12:35:34,480 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 20, 'Should': 3}
2025-11-11 12:35:43,197 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 25 functions
2025-11-11 12:35:43,200 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'ui': 6, 'api': 3, 'logic': 6, 'data': 7, 'auth': 3}
2025-11-11 12:35:49,068 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 28 functions
2025-11-11 12:35:49,069 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'ui': 7, 'api': 3, 'logic': 7, 'data': 7, 'auth': 4}
2025-11-11 12:35:51,315 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 25 functions
2025-11-11 12:35:51,315 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 13, 'Should': 12}
2025-11-11 12:35:58,310 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 78 dependencies
2025-11-11 12:35:58,311 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 26, 'blocks': 48, 'relates': 4}
2025-11-11 12:35:58,312 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] UI・画面 completed in 142.26s - 78 dependencies
2025-11-11 12:35:58,313 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Completed: 3 areas processed
2025-11-11 12:35:58,320 | INFO | hackthon_support_agent.BaseService | [MERGE] Merging results from all focus areas
2025-11-11 12:35:58,321 | INFO | hackthon_support_agent.BaseService | [MERGE] Merged: 64 unique functions, 165 dependencies
2025-11-11 12:35:58,324 | INFO | hackthon_support_agent.BaseService | [PERSISTENCE] Saving to database
2025-11-11 12:35:58,392 | ERROR | hackthon_support_agent.BaseService | [PERSISTENCE] Persistence failed: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "function_dependencies_from_function_id_to_function_id_key"
DETAIL:  Key (from_function_id, to_function_id)=(90c1df29-2847-41d2-b0fb-8facc3387c8b, 987ca2e9-161f-482e-905d-25ea076041a7) already exists.

[SQL: INSERT INTO function_dependencies (id, from_function_id, to_function_id, dependency_type) VALUES (%(id__0)s::UUID, %(from_function_id__0)s::UUID, %(to_function_id__0)s::UUID, %(dependency_type__0)s), (%(id__1)s::UUID, %(from_function_id__1)s::UUID, % ... 17620 characters truncated ... 4)s::UUID, %(from_function_id__164)s::UUID, %(to_function_id__164)s::UUID, %(dependency_type__164)s)]
[parameters: {'id__0': UUID('efcb0591-f6b7-4f01-989a-c906eba37291'), 'dependency_type__0': 'requires', 'to_function_id__0': '316994fe-59a2-4b1d-9df9-b3264cfba2ed', 'from_function_id__0': 'fbcd57a3-7153-454b-ba69-0cca4491efeb', 'id__1': UUID('defd696d-c072-46b0-a832-3ebb10e72e4c'), 'dependency_type__1': 'requires', 'to_function_id__1': 'e73e3dc9-6283-4687-9eed-bc8c7348e3d3', 'from_function_id__1': '316994fe-59a2-4b1d-9df9-b3264cfba2ed', 'id__2': UUID('883bdc8d-66f1-411b-b318-110d98106523'), 'dependency_type__2': 'relates', 'to_function_id__2': '6e248969-4806-4b9e-adb4-a19cc485614e', 'from_function_id__2': '316994fe-59a2-4b1d-9df9-b3264cfba2ed', 'id__3': UUID('7ff3c16c-57b1-451f-9dc6-0e357a28b782'), 'dependency_type__3': 'requires', 'to_function_id__3': 'b628971b-514d-427b-ba96-e40442272f63', 'from_function_id__3': '706120dd-43a3-4821-947c-8e3d88e2cf57', 'id__4': UUID('8e7f8350-a253-4a2c-8897-c3e9b950da93'), 'dependency_type__4': 'requires', 'to_function_id__4': 'fabb1011-3b7c-4c72-9f5d-4722dad7a581', 'from_function_id__4': '706120dd-43a3-4821-947c-8e3d88e2cf57', 'id__5': UUID('c51ec884-9683-4ac8-8aaa-90e91684cfb2'), 'dependency_type__5': 'requires', 'to_function_id__5': '2a388313-4210-419b-9900-7ed7ffa8ffcc', 'from_function_id__5': 'fabb1011-3b7c-4c72-9f5d-4722dad7a581', 'id__6': UUID('598e83f6-ad72-4e08-b489-d1c76a963151'), 'dependency_type__6': 'relates', 'to_function_id__6': '6e248969-4806-4b9e-adb4-a19cc485614e', 'from_function_id__6': 'fabb1011-3b7c-4c72-9f5d-4722dad7a581', 'id__7': UUID('c55f3b0b-fe43-4d3c-b5e2-85ec391df739'), 'dependency_type__7': 'requires', 'to_function_id__7': 'fe88329a-ce19-4b24-a9fb-d4b15e943fd3', 'from_function_id__7': 'edca1a79-6d6e-4fb7-8633-cf6ef32c31f4', 'id__8': UUID('d2eae6cf-0252-4f21-b299-34dd05a25bbe'), 'dependency_type__8': 'requires', 'to_function_id__8': '0c093398-0e5c-4180-b5c3-870b30370650', 'from_function_id__8': '7d1f9427-23b2-4c4c-bc5f-27052f89e8c1', 'id__9': UUID('b4648618-afb7-4fb0-a38c-840a8256354e'), 'dependency_type__9': 'requires', 'to_function_id__9': '20149503-435a-4849-9f98-dabdac7946d3', 'from_function_id__9': '7d1f9427-23b2-4c4c-bc5f-27052f89e8c1', 'id__10': UUID('fcfba8f1-37fe-44ce-bdc1-f42ef1687603'), 'dependency_type__10': 'requires', 'to_function_id__10': '2d1a3802-6870-424e-bda1-1c323adb3154', 'from_function_id__10': '7d1f9427-23b2-4c4c-bc5f-27052f89e8c1', 'id__11': UUID('75dfbb10-f0c5-4793-9072-c2eb519fa27c'), 'dependency_type__11': 'relates', 'to_function_id__11': '987ca2e9-161f-482e-905d-25ea076041a7', 'from_function_id__11': '90c1df29-2847-41d2-b0fb-8facc3387c8b', 'id__12': UUID('b6d9aae2-15cb-4781-bd65-63c826b60148'), 'dependency_type__12': 'requires' ... 560 parameters truncated ... 'to_function_id__152': '309a9b95-7916-4fb9-9924-135b4f4b8aa2', 'from_function_id__152': '4896a88b-5b50-451e-b1ab-6c03324fdf53', 'id__153': UUID('b3e0b0d1-c0db-46c3-a7cf-8d649a3e5671'), 'dependency_type__153': 'blocks', 'to_function_id__153': '20d0d944-a5c4-4d81-92d1-5c932d91a766', 'from_function_id__153': '4896a88b-5b50-451e-b1ab-6c03324fdf53', 'id__154': UUID('c3411f0b-ab72-4bcd-ae51-d1ad80d23822'), 'dependency_type__154': 'blocks', 'to_function_id__154': '54d4f7b5-0fe5-4971-a967-34eb07ec37e6', 'from_function_id__154': '4896a88b-5b50-451e-b1ab-6c03324fdf53', 'id__155': UUID('789d8de3-ac38-4bd9-bfb6-2cc41b4af494'), 'dependency_type__155': 'blocks', 'to_function_id__155': '20d0d944-a5c4-4d81-92d1-5c932d91a766', 'from_function_id__155': '4a04240c-3f27-4847-b73b-3c3ddee41a92', 'id__156': UUID('6b20e10c-7230-4f58-9f61-b5c70e0e72af'), 'dependency_type__156': 'blocks', 'to_function_id__156': '54d4f7b5-0fe5-4971-a967-34eb07ec37e6', 'from_function_id__156': '4a04240c-3f27-4847-b73b-3c3ddee41a92', 'id__157': UUID('0836fb68-0aed-41ce-a7ba-0caae28b3001'), 'dependency_type__157': 'blocks', 'to_function_id__157': '9e79ec8d-8dda-42c8-96a7-7c5a649165e2', 'from_function_id__157': '2ed82d9c-9671-4322-806f-94d9b4421a93', 'id__158': UUID('f2eea4d8-44f2-4eb8-8ec1-4c0b39caff0b'), 'dependency_type__158': 'blocks', 'to_function_id__158': '20d0d944-a5c4-4d81-92d1-5c932d91a766', 'from_function_id__158': '2ed82d9c-9671-4322-806f-94d9b4421a93', 'id__159': UUID('f03fc6d0-1162-4ff3-8385-2ac74a79ac66'), 'dependency_type__159': 'blocks', 'to_function_id__159': '54d4f7b5-0fe5-4971-a967-34eb07ec37e6', 'from_function_id__159': '2ed82d9c-9671-4322-806f-94d9b4421a93', 'id__160': UUID('df0c5fdf-5554-4917-912a-dd3c5aa7872d'), 'dependency_type__160': 'blocks', 'to_function_id__160': 'a0b2174c-5269-450d-aa8b-ed46b1bdc88a', 'from_function_id__160': '2ed82d9c-9671-4322-806f-94d9b4421a93', 'id__161': UUID('e2d33918-fef0-4922-a3e5-8fc48824d5e6'), 'dependency_type__161': 'blocks', 'to_function_id__161': '8e5f33b5-c935-4f81-a5e3-5133506a6b50', 'from_function_id__161': '8dfbcf96-da8a-4c29-afe7-3b3bbb75b0b6', 'id__162': UUID('ae207509-c4e1-4fad-8ba2-16b988bf58d9'), 'dependency_type__162': 'blocks', 'to_function_id__162': 'b9621633-9d11-4b87-a5eb-026688be3a9e', 'from_function_id__162': '8dfbcf96-da8a-4c29-afe7-3b3bbb75b0b6', 'id__163': UUID('4d7bdc10-5640-4d7e-b393-c83220979c60'), 'dependency_type__163': 'blocks', 'to_function_id__163': '309a9b95-7916-4fb9-9924-135b4f4b8aa2', 'from_function_id__163': '72276efb-6088-4621-a50f-6830f3c322e9', 'id__164': UUID('dd380a98-45ab-48b1-8742-e6824547f2ad'), 'dependency_type__164': 'relates', 'to_function_id__164': '75bf5a6f-0966-4b45-a4d0-6b89744be3e9', 'from_function_id__164': '3625b709-d865-4b41-947a-7a81e2b4f791'}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
2025-11-11 12:35:58,394 | INFO | hackthon_support_agent.BaseService | [COVERAGE] Analyzing coverage
2025-11-11 12:36:05,352 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 25 functions
2025-11-11 12:36:05,354 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 13, 'Should': 12}
2025-11-11 12:36:06,416 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 28 functions
2025-11-11 12:36:06,417 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 22, 'Should': 6}
2025-11-11 12:36:09,896 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 95 dependencies
2025-11-11 12:36:09,897 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'relates': 12, 'requires': 42, 'blocks': 41}
2025-11-11 12:36:09,897 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] UI・画面 completed in 154.14s - 95 dependencies
2025-11-11 12:36:09,898 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Completed: 3 areas processed
2025-11-11 12:36:09,900 | INFO | hackthon_support_agent.BaseService | [MERGE] Merging results from all focus areas
2025-11-11 12:36:09,902 | INFO | hackthon_support_agent.BaseService | [MERGE] Merged: 63 unique functions, 226 dependencies
2025-11-11 12:36:09,904 | INFO | hackthon_support_agent.BaseService | [PERSISTENCE] Saving to database
2025-11-11 12:36:09,950 | ERROR | hackthon_support_agent.BaseService | [PERSISTENCE] Persistence failed: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "function_dependencies_from_function_id_to_function_id_key"
DETAIL:  Key (from_function_id, to_function_id)=(f5f8b19d-8017-4f08-aabc-dea5dc4b8f38, 88a285a6-ebcb-4cd1-a4c2-d9d76fdaccf3) already exists.

[SQL: INSERT INTO function_dependencies (id, from_function_id, to_function_id, dependency_type) VALUES (%(id__0)s::UUID, %(from_function_id__0)s::UUID, %(to_function_id__0)s::UUID, %(dependency_type__0)s), (%(id__1)s::UUID, %(from_function_id__1)s::UUID, % ... 24391 characters truncated ... 5)s::UUID, %(from_function_id__225)s::UUID, %(to_function_id__225)s::UUID, %(dependency_type__225)s)]
[parameters: {'id__0': UUID('ecce3d4f-2e35-4a91-a648-e60c83605fd8'), 'dependency_type__0': 'requires', 'to_function_id__0': 'd4dd8fb2-5194-4a34-a347-fda28d3295ba', 'from_function_id__0': '57ef1f53-2ee8-4539-8897-e306e2623241', 'id__1': UUID('8c474826-a78b-4c81-9231-d93d60d80feb'), 'dependency_type__1': 'relates', 'to_function_id__1': 'd4b86024-e508-4853-9cbd-35cc87117940', 'from_function_id__1': '57ef1f53-2ee8-4539-8897-e306e2623241', 'id__2': UUID('bbd9c79f-6556-4bbf-bfdd-3381a32039b1'), 'dependency_type__2': 'relates', 'to_function_id__2': 'fc61eff0-ea0f-4970-8b27-2fa51b41f99d', 'from_function_id__2': '57ef1f53-2ee8-4539-8897-e306e2623241', 'id__3': UUID('d4eed26b-3ac1-471a-9672-81d9fda71d9a'), 'dependency_type__3': 'requires', 'to_function_id__3': '6ab2ea00-6d82-4055-90c8-a6da0d7b3d9c', 'from_function_id__3': '57ef1f53-2ee8-4539-8897-e306e2623241', 'id__4': UUID('52d8b32b-01b9-4e9a-b363-d30b36f2216d'), 'dependency_type__4': 'requires', 'to_function_id__4': '9c60c8d9-9e97-455f-b142-90bf675746fd', 'from_function_id__4': '58159819-1b08-4d9c-a295-1ba64d36b672', 'id__5': UUID('6ddc843b-207b-4dd7-938f-eb8f4a5281d5'), 'dependency_type__5': 'requires', 'to_function_id__5': '9901a482-b9c2-4c17-b1a8-dbfad00a7dc8', 'from_function_id__5': '58159819-1b08-4d9c-a295-1ba64d36b672', 'id__6': UUID('58a4f1d9-1290-4a72-85b2-06486522ed50'), 'dependency_type__6': 'relates', 'to_function_id__6': 'd4b86024-e508-4853-9cbd-35cc87117940', 'from_function_id__6': '58159819-1b08-4d9c-a295-1ba64d36b672', 'id__7': UUID('a1ad4b2e-493b-444e-b29e-333bb5805855'), 'dependency_type__7': 'relates', 'to_function_id__7': 'b4281272-f756-4454-b32e-6fa33ed50b57', 'from_function_id__7': '58159819-1b08-4d9c-a295-1ba64d36b672', 'id__8': UUID('a1c60668-3e6d-4fb0-955b-80db7866ebd7'), 'dependency_type__8': 'requires', 'to_function_id__8': '4c6b5b00-cb02-4c7d-8b1c-ab1c85a1f7c4', 'from_function_id__8': '88a285a6-ebcb-4cd1-a4c2-d9d76fdaccf3', 'id__9': UUID('10111829-fcc4-49ae-935a-513b567509e2'), 'dependency_type__9': 'relates', 'to_function_id__9': 'af70fb3b-0038-4a7c-b615-0122e1339634', 'from_function_id__9': '88a285a6-ebcb-4cd1-a4c2-d9d76fdaccf3', 'id__10': UUID('7b325580-2acb-4b8f-8ec4-f9bbe09078ec'), 'dependency_type__10': 'relates', 'to_function_id__10': '1c1c4c36-3852-4abd-ae20-a0124e0ee02f', 'from_function_id__10': '88a285a6-ebcb-4cd1-a4c2-d9d76fdaccf3', 'id__11': UUID('6c9b9809-09a0-4d42-9f43-ba14a3d1f748'), 'dependency_type__11': 'requires', 'to_function_id__11': 'af3eeaa4-dac5-4439-b73b-f4437b64e943', 'from_function_id__11': 'f5f8b19d-8017-4f08-aabc-dea5dc4b8f38', 'id__12': UUID('629df7b7-5a9c-4e48-996c-1acb9bc5822a'), 'dependency_type__12': 'requires' ... 804 parameters truncated ... 'to_function_id__213': '7d3472ae-dce6-4954-9a7f-49c887cd2831', 'from_function_id__213': '3b66e306-f168-4d2d-ae37-8e928578542b', 'id__214': UUID('b2f6fe1a-bf01-4ad6-ad23-01b958778d27'), 'dependency_type__214': 'requires', 'to_function_id__214': 'fd0e445d-49d7-4f3a-853a-7eb628b8a473', 'from_function_id__214': 'cf7a33ba-3def-4551-b78b-aeb1c17622c1', 'id__215': UUID('84b66271-9b9f-46ff-b65c-d131b0f3e576'), 'dependency_type__215': 'blocks', 'to_function_id__215': '6ab2ea00-6d82-4055-90c8-a6da0d7b3d9c', 'from_function_id__215': 'cf7a33ba-3def-4551-b78b-aeb1c17622c1', 'id__216': UUID('f36a6b42-d78e-47f9-874f-eb21b21545a7'), 'dependency_type__216': 'blocks', 'to_function_id__216': '29d031df-0e09-44e1-a890-b289b9f73678', 'from_function_id__216': '6ab2ea00-6d82-4055-90c8-a6da0d7b3d9c', 'id__217': UUID('881ad35d-97ae-47db-b556-fb6de0d51249'), 'dependency_type__217': 'blocks', 'to_function_id__217': '9331b3ac-9b52-40b3-a038-38a394d90b69', 'from_function_id__217': '6ab2ea00-6d82-4055-90c8-a6da0d7b3d9c', 'id__218': UUID('50bbc024-f646-4851-b58e-562c290dfd4e'), 'dependency_type__218': 'blocks', 'to_function_id__218': '88a285a6-ebcb-4cd1-a4c2-d9d76fdaccf3', 'from_function_id__218': '6ab2ea00-6d82-4055-90c8-a6da0d7b3d9c', 'id__219': UUID('bcc3ef1c-e49a-467c-87e1-0bfcb0e18898'), 'dependency_type__219': 'blocks', 'to_function_id__219': 'f5f8b19d-8017-4f08-aabc-dea5dc4b8f38', 'from_function_id__219': '6ab2ea00-6d82-4055-90c8-a6da0d7b3d9c', 'id__220': UUID('1e6839cf-649d-49ae-ad2c-4a7aeb0b929b'), 'dependency_type__220': 'blocks', 'to_function_id__220': 'e4e0f563-5efb-4136-9de8-3a8e36be1b37', 'from_function_id__220': '6ab2ea00-6d82-4055-90c8-a6da0d7b3d9c', 'id__221': UUID('e9232375-2096-4c34-9f13-a1e950c6a59c'), 'dependency_type__221': 'blocks', 'to_function_id__221': 'e7533a07-905c-43ca-bc82-4f6cf0169424', 'from_function_id__221': '6ab2ea00-6d82-4055-90c8-a6da0d7b3d9c', 'id__222': UUID('c1854cff-0ff0-4cdf-ab65-7c0d59859eeb'), 'dependency_type__222': 'blocks', 'to_function_id__222': '7d3472ae-dce6-4954-9a7f-49c887cd2831', 'from_function_id__222': '6ab2ea00-6d82-4055-90c8-a6da0d7b3d9c', 'id__223': UUID('86ab35b9-7c04-416a-9780-3db2d4e6a769'), 'dependency_type__223': 'relates', 'to_function_id__223': '3b302843-e588-4f58-b26c-de7d15c9ef9c', 'from_function_id__223': '6ab2ea00-6d82-4055-90c8-a6da0d7b3d9c', 'id__224': UUID('5366899e-62af-4333-9cda-a0282040e156'), 'dependency_type__224': 'relates', 'to_function_id__224': '6ab2ea00-6d82-4055-90c8-a6da0d7b3d9c', 'from_function_id__224': '3b302843-e588-4f58-b26c-de7d15c9ef9c', 'id__225': UUID('48da4296-1a61-4b37-ad28-7c5c09213bf4'), 'dependency_type__225': 'relates', 'to_function_id__225': 'fd0e445d-49d7-4f3a-853a-7eb628b8a473', 'from_function_id__225': '3b302843-e588-4f58-b26c-de7d15c9ef9c'}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
2025-11-11 12:36:09,952 | INFO | hackthon_support_agent.BaseService | [COVERAGE] Analyzing coverage
2025-11-11 12:36:21,628 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 57 dependencies
2025-11-11 12:36:21,630 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 26, 'blocks': 26, 'relates': 5}
2025-11-11 12:36:21,631 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] UI・画面 completed in 189.98s - 57 dependencies
2025-11-11 12:36:21,631 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Completed: 3 areas processed
2025-11-11 12:36:21,636 | INFO | hackthon_support_agent.BaseService | [MERGE] Merging results from all focus areas
2025-11-11 12:36:21,636 | INFO | hackthon_support_agent.BaseService | [MERGE] Merged: 65 unique functions, 151 dependencies
2025-11-11 12:36:21,638 | INFO | hackthon_support_agent.BaseService | [PERSISTENCE] Saving to database
2025-11-11 12:36:21,688 | INFO | hackthon_support_agent.BaseService | [PERSISTENCE] Saved 65 functions and 151 dependencies to DB
2025-11-11 12:36:21,689 | INFO | hackthon_support_agent.BaseService | [COVERAGE] Analyzing coverage
2025-11-11 12:36:27,474 | ERROR | hackthon_support_agent.BaseService | Coverage analysis failed: 1 validation error for CoverageAnalysis
iteration_count
  Input should be greater than or equal to 1 [type=greater_than_equal, input_value=0, input_type=int]
    For further information visit https://errors.pydantic.dev/2.12/v/greater_than_equal
2025-11-11 12:36:27,474 | INFO | hackthon_support_agent.BaseService | [COVERAGE] Coverage: 100.0%, Status: complete
2025-11-11 12:36:27,475 | INFO | hackthon_support_agent.BaseService | [COVERAGE_DECISION] Coverage sufficient, completing
2025-11-11 12:36:27,481 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Workflow completed in 440.30s
2025-11-11 12:36:28,363 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 48 dependencies
2025-11-11 12:36:28,364 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 38, 'relates': 9, 'blocks': 1}
2025-11-11 12:36:28,364 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] UI・画面 completed in 125.44s - 48 dependencies
2025-11-11 12:36:28,364 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Completed: 3 areas processed
2025-11-11 12:36:28,366 | INFO | hackthon_support_agent.BaseService | [MERGE] Merging results from all focus areas
2025-11-11 12:36:28,367 | INFO | hackthon_support_agent.BaseService | [MERGE] Merged: 61 unique functions, 145 dependencies
2025-11-11 12:36:28,368 | INFO | hackthon_support_agent.BaseService | [PERSISTENCE] Saving to database
2025-11-11 12:36:28,372 | ERROR | hackthon_support_agent.BaseService | [PERSISTENCE] Persistence failed: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "structured_functions_project_id_function_code_key"
DETAIL:  Key (project_id, function_code)=(fb298f0a-8931-417c-a5db-24152bf66c50, F001) already exists.

[SQL: INSERT INTO structured_functions (function_id, project_id, function_code, function_name, description, category, priority, source_doc_id, extraction_confidence, order_index) VALUES (%(function_id)s::UUID, %(project_id)s::UUID, %(function_code)s, %(function_name)s, %(description)s, %(category)s, %(priority)s, %(source_doc_id)s::UUID, %(extraction_confidence)s, %(order_index)s) RETURNING structured_functions.created_at]
[parameters: {'function_id': UUID('1f6e648d-4fde-42b2-8777-1a664a22039d'), 'project_id': 'fb298f0a-8931-417c-a5db-24152bf66c50', 'function_code': 'F001', 'function_name': '診断テスト受講', 'description': '学生が診断テストを開始し、複数の問題に解答を入力、完了後に結果をシステムに送信する一連のUIフローと、その解答データを保存しAI分析に利用可能にするバックエンドAPIを実装する。', 'category': 'ui', 'priority': 'Must', 'source_doc_id': None, 'extraction_confidence': 0.8, 'order_index': 1}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
2025-11-11 12:36:28,374 | INFO | hackthon_support_agent.BaseService | [COVERAGE] Analyzing coverage
2025-11-11 12:36:34,209 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 45 dependencies
2025-11-11 12:36:34,210 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 38, 'relates': 2, 'blocks': 5}
2025-11-11 12:36:34,212 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] UI・画面 completed in 121.34s - 45 dependencies
2025-11-11 12:36:34,213 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Completed: 3 areas processed
2025-11-11 12:36:34,220 | INFO | hackthon_support_agent.BaseService | [MERGE] Merging results from all focus areas
2025-11-11 12:36:34,222 | INFO | hackthon_support_agent.BaseService | [MERGE] Merged: 57 unique functions, 171 dependencies
2025-11-11 12:36:34,225 | INFO | hackthon_support_agent.BaseService | [PERSISTENCE] Saving to database
2025-11-11 12:36:34,255 | ERROR | hackthon_support_agent.BaseService | [PERSISTENCE] Persistence failed: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "structured_functions_project_id_function_code_key"
DETAIL:  Key (project_id, function_code)=(fb298f0a-8931-417c-a5db-24152bf66c50, F001) already exists.

[SQL: INSERT INTO structured_functions (function_id, project_id, function_code, function_name, description, category, priority, source_doc_id, extraction_confidence, order_index) VALUES (%(function_id)s::UUID, %(project_id)s::UUID, %(function_code)s, %(function_name)s, %(description)s, %(category)s, %(priority)s, %(source_doc_id)s::UUID, %(extraction_confidence)s, %(order_index)s) RETURNING structured_functions.created_at]
[parameters: {'function_id': UUID('4fb46b84-bfa2-4309-a695-d07bd174a8f4'), 'project_id': 'fb298f0a-8931-417c-a5db-24152bf66c50', 'function_code': 'F001', 'function_name': '診断テスト受講・結果送信', 'description': '学生が診断テストを開始し、複数の問題に解答を入力、完了後にその結果をシステムに送信する一連のUIとAPI連携を実装する。これにはテストの開始画面、問題表示画面、解答入力UI、および結果送信API呼び出しが含まれる。', 'category': 'ui', 'priority': 'Must', 'source_doc_id': None, 'extraction_confidence': 0.8, 'order_index': 1}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
2025-11-11 12:36:34,258 | INFO | hackthon_support_agent.BaseService | [COVERAGE] Analyzing coverage
2025-11-11 12:36:41,530 | ERROR | hackthon_support_agent.BaseService | Coverage analysis failed: 1 validation error for CoverageAnalysis
iteration_count
  Input should be greater than or equal to 1 [type=greater_than_equal, input_value=0, input_type=int]
    For further information visit https://errors.pydantic.dev/2.12/v/greater_than_equal
2025-11-11 12:36:41,533 | INFO | hackthon_support_agent.BaseService | [COVERAGE] Coverage: 100.0%, Status: complete
2025-11-11 12:36:41,534 | INFO | hackthon_support_agent.BaseService | [COVERAGE_DECISION] Coverage sufficient, completing
2025-11-11 12:36:41,540 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Workflow completed in 454.36s
2025-11-11 12:36:47,667 | ERROR | hackthon_support_agent.BaseService | Coverage analysis failed: 1 validation error for CoverageAnalysis
iteration_count
  Input should be greater than or equal to 1 [type=greater_than_equal, input_value=0, input_type=int]
    For further information visit https://errors.pydantic.dev/2.12/v/greater_than_equal
2025-11-11 12:36:47,668 | INFO | hackthon_support_agent.BaseService | [COVERAGE] Coverage: 100.0%, Status: complete
2025-11-11 12:36:47,671 | INFO | hackthon_support_agent.BaseService | [COVERAGE_DECISION] Coverage sufficient, completing
2025-11-11 12:36:47,680 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Workflow completed in 460.49s
2025-11-11 12:36:49,439 | ERROR | hackthon_support_agent.BaseService | Coverage analysis failed: 1 validation error for CoverageAnalysis
iteration_count
  Input should be greater than or equal to 1 [type=greater_than_equal, input_value=0, input_type=int]
    For further information visit https://errors.pydantic.dev/2.12/v/greater_than_equal
2025-11-11 12:36:49,440 | INFO | hackthon_support_agent.BaseService | [COVERAGE] Coverage: 100.0%, Status: complete
2025-11-11 12:36:49,441 | INFO | hackthon_support_agent.BaseService | [COVERAGE_DECISION] Coverage sufficient, completing
2025-11-11 12:36:49,445 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Workflow completed in 433.03s
2025-11-11 12:36:51,350 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 41 dependencies
2025-11-11 12:36:51,351 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'blocks': 29, 'requires': 9, 'relates': 3}
2025-11-11 12:36:51,352 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] UI・画面 completed in 151.04s - 41 dependencies
2025-11-11 12:36:51,352 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Completed: 3 areas processed
2025-11-11 12:36:51,356 | INFO | hackthon_support_agent.BaseService | [MERGE] Merging results from all focus areas
2025-11-11 12:36:51,359 | INFO | hackthon_support_agent.BaseService | [MERGE] Merged: 68 unique functions, 170 dependencies
2025-11-11 12:36:51,364 | INFO | hackthon_support_agent.BaseService | [PERSISTENCE] Saving to database
2025-11-11 12:36:51,373 | ERROR | hackthon_support_agent.BaseService | [PERSISTENCE] Persistence failed: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "structured_functions_project_id_function_code_key"
DETAIL:  Key (project_id, function_code)=(fb298f0a-8931-417c-a5db-24152bf66c50, F001) already exists.

[SQL: INSERT INTO structured_functions (function_id, project_id, function_code, function_name, description, category, priority, source_doc_id, extraction_confidence, order_index) VALUES (%(function_id)s::UUID, %(project_id)s::UUID, %(function_code)s, %(function_name)s, %(description)s, %(category)s, %(priority)s, %(source_doc_id)s::UUID, %(extraction_confidence)s, %(order_index)s) RETURNING structured_functions.created_at]
[parameters: {'function_id': UUID('5d922867-bfe4-4a69-93e4-53c1b1547d75'), 'project_id': 'fb298f0a-8931-417c-a5db-24152bf66c50', 'function_code': 'F001', 'function_name': '診断テスト受講UI', 'description': '学生が診断テストの開始をトリガーし、複数の問題で構成されるテストに解答を入力し、完了後に結果をシステムに送信するまでの一連のUI操作を提供する。システムはテスト結果をAI分析に利用できる状態にする。', 'category': 'ui', 'priority': 'Must', 'source_doc_id': None, 'extraction_confidence': 0.8, 'order_index': 1}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
2025-11-11 12:36:51,377 | INFO | hackthon_support_agent.BaseService | [COVERAGE] Analyzing coverage
2025-11-11 12:36:52,607 | ERROR | hackthon_support_agent.BaseService | Coverage analysis failed: 1 validation error for CoverageAnalysis
iteration_count
  Input should be greater than or equal to 1 [type=greater_than_equal, input_value=0, input_type=int]
    For further information visit https://errors.pydantic.dev/2.12/v/greater_than_equal
2025-11-11 12:36:52,608 | INFO | hackthon_support_agent.BaseService | [COVERAGE] Coverage: 100.0%, Status: complete
2025-11-11 12:36:52,609 | INFO | hackthon_support_agent.BaseService | [COVERAGE_DECISION] Coverage sufficient, completing
2025-11-11 12:36:52,613 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Workflow completed in 450.56s
2025-11-11 12:37:15,322 | ERROR | hackthon_support_agent.BaseService | Coverage analysis failed: 1 validation error for CoverageAnalysis
iteration_count
  Input should be greater than or equal to 1 [type=greater_than_equal, input_value=0, input_type=int]
    For further information visit https://errors.pydantic.dev/2.12/v/greater_than_equal
2025-11-11 12:37:15,325 | INFO | hackthon_support_agent.BaseService | [COVERAGE] Coverage: 100.0%, Status: complete
2025-11-11 12:37:15,327 | INFO | hackthon_support_agent.BaseService | [COVERAGE_DECISION] Coverage sufficient, completing
2025-11-11 12:37:15,334 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Workflow completed in 449.04s
2025-11-11 13:07:43,068 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 13:08:11,803 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 13:12:32,184 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 13:13:03,504 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 13:14:22,269 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 13:14:42,512 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 13:48:39,538 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-11-11 13:48:39,545 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 13:48:39,545 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 13:48:39,614 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 13:48:39,615 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 13:48:39,616 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 13:48:39,616 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 13:48:39,617 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 13:48:39,618 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 13:48:39,619 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 13:48:39,619 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-11-11 13:48:39,619 | DEBUG | hackthon_support_agent.QuestionService | Generating questions for project_id: 28a69af2-ae3b-46d8-a818-20bdbc089974 with idea_prompt: プロジェクトタイトル: オンライン学習プラットフォーム
プロジェクトアイディア: 学生の学力と得意不得意に合わせたAIを用いた動的な課題作成サービス
期間: 2025-11-11 〜 2025-12-11 22:48
2025-11-11 13:48:39,620 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-11-11 13:56:49,131 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 13:56:52,152 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 13:59:00,451 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-11-11 13:59:00,454 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 13:59:00,454 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 13:59:00,488 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 13:59:00,488 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 13:59:00,490 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 13:59:00,491 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 13:59:00,492 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 13:59:00,493 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 13:59:00,494 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 13:59:00,494 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-11-11 13:59:00,494 | DEBUG | hackthon_support_agent.QuestionService | Generating questions for project_id: f1657f06-e4c4-4b31-871e-aafedbbbc73a with idea_prompt: プロジェクトタイトル: オンライン学習プラットフォーム
プロジェクトアイディア: 学生の学力と得意不得意に合わせたAIを用いた動的な課題作成サービス
期間: 2025-11-11 〜 2025-12-11 22:57
2025-11-11 13:59:00,495 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-11-11 13:59:16,095 | INFO | hackthon_support_agent.QuestionService | Generated 8 questions for project_id: f1657f06-e4c4-4b31-871e-aafedbbbc73a
2025-11-11 13:59:16,118 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-11-11 13:59:16,120 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 13:59:16,121 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 13:59:16,127 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 13:59:16,127 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 13:59:16,129 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 13:59:16,129 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 13:59:16,131 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 13:59:16,131 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 13:59:16,133 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 13:59:16,133 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-11-11 13:59:20,504 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-11-11 13:59:20,507 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 13:59:20,507 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 13:59:20,511 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 13:59:20,511 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 13:59:20,514 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 13:59:20,514 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 13:59:20,516 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 13:59:20,517 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 13:59:20,519 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 13:59:20,519 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-11-11 13:59:20,590 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.generate_summary_document'
2025-11-11 13:59:33,647 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-11-11 13:59:33,651 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 13:59:33,652 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 13:59:33,661 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 13:59:33,661 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 13:59:33,663 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 13:59:33,663 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 13:59:33,664 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 13:59:33,665 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 13:59:33,666 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 13:59:33,666 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-11-11 13:59:55,125 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-11-11 13:59:55,128 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 13:59:55,128 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 13:59:55,135 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 13:59:55,136 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 13:59:55,137 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 13:59:55,137 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 13:59:55,138 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 13:59:55,138 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 13:59:55,140 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 13:59:55,140 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-11-11 13:59:55,147 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-11-11 14:00:37,824 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-11-11 14:00:37,833 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 14:00:37,836 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:00:37,858 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:00:37,858 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:00:37,860 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:00:37,861 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:00:37,864 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:00:37,865 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 14:00:37,866 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 14:00:37,866 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-11-11 14:00:37,928 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: f1657f06-e4c4-4b31-871e-aafedbbbc73a
2025-11-11 14:00:37,933 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.evaluate_specification'
2025-11-11 14:00:38,859 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-11-11 14:00:38,863 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 14:00:38,863 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:00:38,865 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:00:38,866 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:00:38,868 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:00:38,868 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:00:38,869 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:00:38,870 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 14:00:38,871 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 14:00:38,871 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-11-11 14:00:38,911 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: f1657f06-e4c4-4b31-871e-aafedbbbc73a
2025-11-11 14:00:38,913 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.evaluate_specification'
2025-11-11 14:02:10,801 | DEBUG | hackthon_support_agent.FunctionService | Initializing BaseService (provider=google)
2025-11-11 14:02:10,805 | INFO | hackthon_support_agent.FunctionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 14:02:10,805 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:02:10,812 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:02:10,813 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:02:10,814 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:02:10,815 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:02:10,816 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:02:10,820 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 14:02:10,821 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 14:02:10,822 | DEBUG | hackthon_support_agent.FunctionService | LLMs initialized
2025-11-11 14:02:10,822 | DEBUG | hackthon_support_agent.FunctionService | Generating functional requirements for project_id: f1657f06-e4c4-4b31-871e-aafedbbbc73a
2025-11-11 14:02:10,825 | DEBUG | hackthon_support_agent.FunctionService | Fetching prompt 'function_service.generate_functional_requirements'
2025-11-11 14:03:08,295 | DEBUG | hackthon_support_agent.FunctionService | Saving functional requirements to project document: f1657f06-e4c4-4b31-871e-aafedbbbc73a
2025-11-11 14:04:33,933 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 14:04:33,939 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 14:04:33,939 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:04:33,949 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:04:33,950 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:04:33,952 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:04:33,952 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:04:33,954 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:04:33,954 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 14:04:33,955 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 14:04:33,955 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 14:04:34,011 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Fetching context for project: f1657f06-e4c4-4b31-871e-aafedbbbc73a
2025-11-11 14:04:34,013 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Starting workflow for project: f1657f06-e4c4-4b31-871e-aafedbbbc73a
2025-11-11 14:04:34,017 | INFO | hackthon_support_agent.BaseService | [PLANNING] Starting planning phase
2025-11-11 14:04:34,017 | INFO | hackthon_support_agent.BaseService | [PLANNING] Plan created with 3 focus areas
2025-11-11 14:04:34,019 | INFO | hackthon_support_agent.BaseService | [CACHE] Creating context cache
2025-11-11 14:04:34,210 | ERROR | hackthon_support_agent.BaseService | [CACHE] Cache creation failed: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'Cached content is too small. total_token_count=3989, min_total_token_count=4096', 'status': 'INVALID_ARGUMENT'}}
2025-11-11 14:04:34,212 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Starting parallel extraction
2025-11-11 14:04:34,212 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: データ・モデル
2025-11-11 14:04:34,212 | ERROR | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] Error in データ・モデル: 'NoneType' object has no attribute 'get'
2025-11-11 14:04:34,212 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: API・バックエンド
2025-11-11 14:04:34,213 | ERROR | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] Error in API・バックエンド: 'NoneType' object has no attribute 'get'
2025-11-11 14:04:34,213 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: UI・画面
2025-11-11 14:04:34,213 | ERROR | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] Error in UI・画面: 'NoneType' object has no attribute 'get'
2025-11-11 14:04:34,213 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Completed: 3 areas processed
2025-11-11 14:04:34,214 | INFO | hackthon_support_agent.BaseService | [MERGE] Merging results from all focus areas
2025-11-11 14:04:34,214 | INFO | hackthon_support_agent.BaseService | [MERGE] Merged: 0 unique functions, 0 dependencies
2025-11-11 14:04:34,215 | INFO | hackthon_support_agent.BaseService | [VALIDATION] Starting validation
2025-11-11 14:04:34,221 | ERROR | hackthon_support_agent.BaseService | Validation failed: "Input to ChatPromptTemplate is missing variables {'actual_count'}.  Expected: ['actual_count', 'dependencies_summary', 'dependency_count', 'end_date', 'function_count', 'functions_summary', 'idea', 'iteration_count', 'start_date', 'title'] Received: ['title', 'idea', 'start_date', 'end_date', 'function_count', 'functions_summary', 'dependency_count', 'dependencies_summary', 'iteration_count']\nNote: if you intended {actual_count} to be part of the string and not a variable, please escape it with double curly braces like: '{{actual_count}}'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT "
2025-11-11 14:04:34,221 | INFO | hackthon_support_agent.BaseService | [VALIDATION] Status: PASS, Issues: 0
2025-11-11 14:04:34,221 | INFO | hackthon_support_agent.BaseService | [VALIDATION_DECISION] Validation passed, proceeding to persistence
2025-11-11 14:04:34,222 | INFO | hackthon_support_agent.BaseService | [PERSISTENCE] Saving to database
2025-11-11 14:04:34,223 | INFO | hackthon_support_agent.BaseService | [PERSISTENCE] Saved 0 functions and 0 dependencies to DB
2025-11-11 14:04:34,224 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Workflow completed in 0.21s
2025-11-11 14:05:00,819 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 14:05:00,823 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 14:05:00,824 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:05:00,832 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:05:00,833 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:05:00,835 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:05:00,836 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:05:00,838 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:05:00,839 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 14:05:00,841 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 14:05:00,841 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 14:05:00,910 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Fetching context for project: f1657f06-e4c4-4b31-871e-aafedbbbc73a
2025-11-11 14:05:00,913 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Starting workflow for project: f1657f06-e4c4-4b31-871e-aafedbbbc73a
2025-11-11 14:05:00,917 | INFO | hackthon_support_agent.BaseService | [PLANNING] Starting planning phase
2025-11-11 14:05:00,917 | INFO | hackthon_support_agent.BaseService | [PLANNING] Plan created with 3 focus areas
2025-11-11 14:05:00,918 | INFO | hackthon_support_agent.BaseService | [CACHE] Creating context cache
2025-11-11 14:05:02,492 | ERROR | hackthon_support_agent.BaseService | [CACHE] Cache creation failed: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'Cached content is too small. total_token_count=3989, min_total_token_count=4096', 'status': 'INVALID_ARGUMENT'}}
2025-11-11 14:05:02,496 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Starting parallel extraction
2025-11-11 14:05:02,496 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: データ・モデル
2025-11-11 14:05:02,497 | ERROR | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] Error in データ・モデル: 'NoneType' object has no attribute 'get'
2025-11-11 14:05:02,497 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: API・バックエンド
2025-11-11 14:05:02,497 | ERROR | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] Error in API・バックエンド: 'NoneType' object has no attribute 'get'
2025-11-11 14:05:02,498 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: UI・画面
2025-11-11 14:05:02,498 | ERROR | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] Error in UI・画面: 'NoneType' object has no attribute 'get'
2025-11-11 14:05:02,498 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Completed: 3 areas processed
2025-11-11 14:05:02,501 | INFO | hackthon_support_agent.BaseService | [MERGE] Merging results from all focus areas
2025-11-11 14:05:02,501 | INFO | hackthon_support_agent.BaseService | [MERGE] Merged: 0 unique functions, 0 dependencies
2025-11-11 14:05:02,502 | INFO | hackthon_support_agent.BaseService | [VALIDATION] Starting validation
2025-11-11 14:05:02,515 | ERROR | hackthon_support_agent.BaseService | Validation failed: "Input to ChatPromptTemplate is missing variables {'actual_count'}.  Expected: ['actual_count', 'dependencies_summary', 'dependency_count', 'end_date', 'function_count', 'functions_summary', 'idea', 'iteration_count', 'start_date', 'title'] Received: ['title', 'idea', 'start_date', 'end_date', 'function_count', 'functions_summary', 'dependency_count', 'dependencies_summary', 'iteration_count']\nNote: if you intended {actual_count} to be part of the string and not a variable, please escape it with double curly braces like: '{{actual_count}}'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT "
2025-11-11 14:05:02,516 | INFO | hackthon_support_agent.BaseService | [VALIDATION] Status: PASS, Issues: 0
2025-11-11 14:05:02,517 | INFO | hackthon_support_agent.BaseService | [VALIDATION_DECISION] Validation passed, proceeding to persistence
2025-11-11 14:05:02,519 | INFO | hackthon_support_agent.BaseService | [PERSISTENCE] Saving to database
2025-11-11 14:05:02,520 | INFO | hackthon_support_agent.BaseService | [PERSISTENCE] Saved 0 functions and 0 dependencies to DB
2025-11-11 14:05:02,522 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Workflow completed in 1.61s
2025-11-11 14:06:06,657 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 14:06:22,262 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 14:06:28,095 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 14:06:28,108 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 14:06:28,108 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:06:28,128 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:06:28,129 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:06:28,131 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:06:28,131 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:06:28,133 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:06:28,133 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 14:06:28,136 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 14:06:28,136 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 14:06:28,216 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Fetching context for project: f1657f06-e4c4-4b31-871e-aafedbbbc73a
2025-11-11 14:06:28,221 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Starting workflow for project: f1657f06-e4c4-4b31-871e-aafedbbbc73a
2025-11-11 14:06:28,224 | INFO | hackthon_support_agent.BaseService | [PLANNING] Starting planning phase
2025-11-11 14:06:28,225 | INFO | hackthon_support_agent.BaseService | [PLANNING] Plan created with 3 focus areas
2025-11-11 14:06:28,227 | INFO | hackthon_support_agent.BaseService | [CACHE] Creating context cache
2025-11-11 14:06:29,591 | ERROR | hackthon_support_agent.BaseService | [CACHE] Cache creation failed: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'Cached content is too small. total_token_count=3989, min_total_token_count=4096', 'status': 'INVALID_ARGUMENT'}}
2025-11-11 14:06:29,594 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Starting parallel extraction
2025-11-11 14:06:29,595 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: データ・モデル
2025-11-11 14:06:29,595 | ERROR | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] Error in データ・モデル: 'NoneType' object has no attribute 'get'
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/function_structuring_workflow.py", line 274, in _process_focus_area_async
    "retry_instruction": state.get("final_validation", {}).get("retry_instruction", "")
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'get'
2025-11-11 14:06:29,596 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: API・バックエンド
2025-11-11 14:06:29,597 | ERROR | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] Error in API・バックエンド: 'NoneType' object has no attribute 'get'
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/function_structuring_workflow.py", line 274, in _process_focus_area_async
    "retry_instruction": state.get("final_validation", {}).get("retry_instruction", "")
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'get'
2025-11-11 14:06:29,598 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: UI・画面
2025-11-11 14:06:29,599 | ERROR | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] Error in UI・画面: 'NoneType' object has no attribute 'get'
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/function_structuring_workflow.py", line 274, in _process_focus_area_async
    "retry_instruction": state.get("final_validation", {}).get("retry_instruction", "")
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'get'
2025-11-11 14:06:29,599 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Completed: 3 areas processed
2025-11-11 14:06:29,602 | INFO | hackthon_support_agent.BaseService | [MERGE] Merging results from all focus areas
2025-11-11 14:06:29,602 | INFO | hackthon_support_agent.BaseService | [MERGE] Merged: 0 unique functions, 0 dependencies
2025-11-11 14:06:29,604 | INFO | hackthon_support_agent.BaseService | [VALIDATION] Starting validation
2025-11-11 14:06:34,111 | INFO | hackthon_support_agent.BaseService | [VALIDATION] Status: REJECT, Issues: 1
2025-11-11 14:06:34,113 | WARNING | hackthon_support_agent.BaseService | [VALIDATION] REJECT - Retry instruction: 機能が一つも抽出されていません。プロジェクトのアイデア「オンライン学習プラットフォーム」に基づき、15-25個の主要な機能を抽出してください。
2025-11-11 14:06:34,115 | INFO | hackthon_support_agent.BaseService | [VALIDATION_DECISION] Validation rejected (iteration 0/3), retrying extraction
2025-11-11 14:06:34,120 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Starting parallel extraction
2025-11-11 14:06:34,120 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: データ・モデル
2025-11-11 14:07:04,065 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 21 functions using LangChain
2025-11-11 14:07:15,090 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 14:07:15,094 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 14:07:15,094 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:07:15,103 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:07:15,104 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:07:15,106 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:07:15,107 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:07:15,109 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:07:15,110 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 14:07:15,116 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 14:07:15,117 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 14:07:15,194 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Fetching context for project: f1657f06-e4c4-4b31-871e-aafedbbbc73a
2025-11-11 14:07:15,197 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Starting workflow for project: f1657f06-e4c4-4b31-871e-aafedbbbc73a
2025-11-11 14:07:15,202 | INFO | hackthon_support_agent.BaseService | [PLANNING] Starting planning phase
2025-11-11 14:07:15,202 | INFO | hackthon_support_agent.BaseService | [PLANNING] Plan created with 3 focus areas
2025-11-11 14:07:15,203 | INFO | hackthon_support_agent.BaseService | [CACHE] Creating context cache
2025-11-11 14:07:16,323 | ERROR | hackthon_support_agent.BaseService | [CACHE] Cache creation failed: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'Cached content is too small. total_token_count=3989, min_total_token_count=4096', 'status': 'INVALID_ARGUMENT'}}
2025-11-11 14:07:16,327 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Starting parallel extraction
2025-11-11 14:07:16,328 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: データ・モデル
2025-11-11 14:07:16,328 | ERROR | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] Error in データ・モデル: 'NoneType' object has no attribute 'get'
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/function_structuring_workflow.py", line 274, in _process_focus_area_async
    "retry_instruction": state.get("final_validation", {}).get("retry_instruction", "")
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'get'
2025-11-11 14:07:16,330 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: API・バックエンド
2025-11-11 14:07:16,330 | ERROR | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] Error in API・バックエンド: 'NoneType' object has no attribute 'get'
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/function_structuring_workflow.py", line 274, in _process_focus_area_async
    "retry_instruction": state.get("final_validation", {}).get("retry_instruction", "")
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'get'
2025-11-11 14:07:16,331 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: UI・画面
2025-11-11 14:07:16,332 | ERROR | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] Error in UI・画面: 'NoneType' object has no attribute 'get'
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/function_structuring_workflow.py", line 274, in _process_focus_area_async
    "retry_instruction": state.get("final_validation", {}).get("retry_instruction", "")
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'get'
2025-11-11 14:07:16,333 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Completed: 3 areas processed
2025-11-11 14:07:16,336 | INFO | hackthon_support_agent.BaseService | [MERGE] Merging results from all focus areas
2025-11-11 14:07:16,337 | INFO | hackthon_support_agent.BaseService | [MERGE] Merged: 0 unique functions, 0 dependencies
2025-11-11 14:07:16,339 | INFO | hackthon_support_agent.BaseService | [VALIDATION] Starting validation
2025-11-11 14:07:24,465 | INFO | hackthon_support_agent.BaseService | [VALIDATION] Status: REJECT, Issues: 1
2025-11-11 14:07:24,467 | WARNING | hackthon_support_agent.BaseService | [VALIDATION] REJECT - Retry instruction: 機能が一つも抽出されていません。ハッカソンの要件を満たすためには、15〜25個の機能を抽出する必要があります。プロジェクトのアイデア（学生の学力と得意不得意に合わせたAIを用いた動的な課題作成サービス）に基づき、適切な粒度（例: 「ユーザー認証機能」、「AIによる課題生成機能」、「学習進捗管理機能」など）で機能を具体的にリストアップしてください。各機能には、descriptionとして100文字以
2025-11-11 14:07:24,469 | INFO | hackthon_support_agent.BaseService | [VALIDATION_DECISION] Validation rejected (iteration 0/3), retrying extraction
2025-11-11 14:07:24,473 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Starting parallel extraction
2025-11-11 14:07:24,473 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: データ・モデル
2025-11-11 14:07:34,935 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 21 functions
2025-11-11 14:07:34,936 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'auth': 4, 'ui': 5, 'logic': 7, 'data': 5}
2025-11-11 14:07:53,202 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 21 functions using LangChain
2025-11-11 14:07:56,215 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 14:07:59,129 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 14:08:29,641 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 14:08:29,646 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 14:08:29,648 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:08:29,668 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:08:29,669 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:08:29,676 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:08:29,676 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:08:29,678 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:08:29,679 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 14:08:29,682 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 14:08:29,685 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 14:08:29,774 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Fetching context for project: f1657f06-e4c4-4b31-871e-aafedbbbc73a
2025-11-11 14:08:29,779 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Starting workflow for project: f1657f06-e4c4-4b31-871e-aafedbbbc73a
2025-11-11 14:08:29,784 | INFO | hackthon_support_agent.BaseService | [PLANNING] Starting planning phase
2025-11-11 14:08:29,785 | INFO | hackthon_support_agent.BaseService | [PLANNING] Plan created with 3 focus areas
2025-11-11 14:08:29,787 | INFO | hackthon_support_agent.BaseService | [CACHE] Creating context cache
2025-11-11 14:08:30,025 | ERROR | hackthon_support_agent.BaseService | [CACHE] Cache creation failed: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'Cached content is too small. total_token_count=3989, min_total_token_count=4096', 'status': 'INVALID_ARGUMENT'}}
2025-11-11 14:08:30,026 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Starting parallel extraction
2025-11-11 14:08:30,026 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: データ・モデル
2025-11-11 14:08:30,027 | ERROR | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] Error in データ・モデル: 'NoneType' object has no attribute 'get'
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/function_structuring_workflow.py", line 274, in _process_focus_area_async
    "retry_instruction": state.get("final_validation", {}).get("retry_instruction", "")
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'get'
2025-11-11 14:08:30,027 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: API・バックエンド
2025-11-11 14:08:30,028 | ERROR | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] Error in API・バックエンド: 'NoneType' object has no attribute 'get'
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/function_structuring_workflow.py", line 274, in _process_focus_area_async
    "retry_instruction": state.get("final_validation", {}).get("retry_instruction", "")
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'get'
2025-11-11 14:08:30,028 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: UI・画面
2025-11-11 14:08:30,028 | ERROR | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] Error in UI・画面: 'NoneType' object has no attribute 'get'
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/function_structuring_workflow.py", line 274, in _process_focus_area_async
    "retry_instruction": state.get("final_validation", {}).get("retry_instruction", "")
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'get'
2025-11-11 14:08:30,029 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Completed: 3 areas processed
2025-11-11 14:08:30,031 | INFO | hackthon_support_agent.BaseService | [MERGE] Merging results from all focus areas
2025-11-11 14:08:30,032 | INFO | hackthon_support_agent.BaseService | [MERGE] Merged: 0 unique functions, 0 dependencies
2025-11-11 14:08:30,033 | INFO | hackthon_support_agent.BaseService | [VALIDATION] Starting validation
2025-11-11 14:08:35,181 | INFO | hackthon_support_agent.BaseService | [VALIDATION] Status: REJECT, Issues: 1
2025-11-11 14:08:35,182 | WARNING | hackthon_support_agent.BaseService | [VALIDATION] REJECT - Retry instruction: 機能が全く抽出されていません。プロジェクトのアイデアに基づき、15〜25個の機能を具体的に抽出してください。
2025-11-11 14:08:35,182 | INFO | hackthon_support_agent.BaseService | [VALIDATION_DECISION] Validation rejected (iteration 0/3), retrying extraction
2025-11-11 14:08:35,185 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Starting parallel extraction
2025-11-11 14:08:35,185 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: データ・モデル
2025-11-11 14:09:14,534 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 14:09:14,541 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 14:09:14,542 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:09:14,561 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:09:14,562 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:09:14,566 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:09:14,566 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:09:14,573 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:09:14,574 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 14:09:14,578 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 14:09:14,579 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 14:09:14,923 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Fetching context for project: f1657f06-e4c4-4b31-871e-aafedbbbc73a
2025-11-11 14:09:14,931 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Starting workflow for project: f1657f06-e4c4-4b31-871e-aafedbbbc73a
2025-11-11 14:09:14,939 | INFO | hackthon_support_agent.BaseService | [PLANNING] Starting planning phase
2025-11-11 14:09:14,940 | INFO | hackthon_support_agent.BaseService | [PLANNING] Plan created with 3 focus areas
2025-11-11 14:09:14,943 | INFO | hackthon_support_agent.BaseService | [CACHE] Creating context cache
2025-11-11 14:09:15,198 | ERROR | hackthon_support_agent.BaseService | [CACHE] Cache creation failed: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'Cached content is too small. total_token_count=3989, min_total_token_count=4096', 'status': 'INVALID_ARGUMENT'}}
2025-11-11 14:09:15,201 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Starting parallel extraction
2025-11-11 14:09:15,202 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: データ・モデル
2025-11-11 14:09:15,203 | ERROR | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] Error in データ・モデル: 'NoneType' object has no attribute 'get'
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/function_structuring_workflow.py", line 274, in _process_focus_area_async
    "retry_instruction": state.get("final_validation", {}).get("retry_instruction", "")
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'get'
2025-11-11 14:09:15,204 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: API・バックエンド
2025-11-11 14:09:15,205 | ERROR | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] Error in API・バックエンド: 'NoneType' object has no attribute 'get'
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/function_structuring_workflow.py", line 274, in _process_focus_area_async
    "retry_instruction": state.get("final_validation", {}).get("retry_instruction", "")
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'get'
2025-11-11 14:09:15,206 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: UI・画面
2025-11-11 14:09:15,207 | ERROR | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] Error in UI・画面: 'NoneType' object has no attribute 'get'
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/function_structuring_workflow.py", line 274, in _process_focus_area_async
    "retry_instruction": state.get("final_validation", {}).get("retry_instruction", "")
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'get'
2025-11-11 14:09:15,208 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Completed: 3 areas processed
2025-11-11 14:09:15,212 | INFO | hackthon_support_agent.BaseService | [MERGE] Merging results from all focus areas
2025-11-11 14:09:15,212 | INFO | hackthon_support_agent.BaseService | [MERGE] Merged: 0 unique functions, 0 dependencies
2025-11-11 14:09:15,214 | INFO | hackthon_support_agent.BaseService | [VALIDATION] Starting validation
2025-11-11 14:09:19,601 | INFO | hackthon_support_agent.BaseService | [VALIDATION] Status: REJECT, Issues: 1
2025-11-11 14:09:19,602 | WARNING | hackthon_support_agent.BaseService | [VALIDATION] REJECT - Retry instruction: 機能が全く抽出されていません。プロジェクトのアイデアに基づき、必要な機能を抽出してください。推奨機能数は15-25個です。
2025-11-11 14:09:19,602 | INFO | hackthon_support_agent.BaseService | [VALIDATION_DECISION] Validation rejected (iteration 0/3), retrying extraction
2025-11-11 14:09:19,603 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Starting parallel extraction
2025-11-11 14:09:19,604 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: データ・モデル
2025-11-11 14:09:22,590 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 21 functions using LangChain
2025-11-11 14:09:55,290 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 21 functions
2025-11-11 14:09:55,293 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'auth': 4, 'ui': 5, 'logic': 7, 'data': 5}
2025-11-11 14:09:56,675 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 21 functions using LangChain
2025-11-11 14:10:19,813 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 21 functions
2025-11-11 14:10:19,814 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 20, 'Should': 1}
2025-11-11 14:10:28,318 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 21 functions
2025-11-11 14:10:28,320 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'auth': 4, 'ui': 5, 'logic': 7, 'data': 5}
2025-11-11 14:10:46,646 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 62 dependencies
2025-11-11 14:10:46,653 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 33, 'blocks': 9, 'relates': 20}
2025-11-11 14:10:46,655 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] データ・モデル completed in 131.47s - 21 functions, 62 dependencies
2025-11-11 14:10:46,656 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: API・バックエンド
2025-11-11 14:11:07,804 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 21 functions
2025-11-11 14:11:07,807 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 20, 'Should': 1}
2025-11-11 14:11:16,162 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 21 functions using LangChain
2025-11-11 14:11:51,072 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 21 functions
2025-11-11 14:11:51,075 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'auth': 4, 'ui': 5, 'logic': 7, 'data': 5}
2025-11-11 14:12:08,423 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 71 dependencies
2025-11-11 14:12:08,425 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 30, 'blocks': 26, 'relates': 15}
2025-11-11 14:12:08,425 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] データ・モデル completed in 168.82s - 21 functions, 71 dependencies
2025-11-11 14:12:08,426 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: API・バックエンド
2025-11-11 14:12:13,586 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 14:12:13,593 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 14:12:13,594 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:12:13,626 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:12:13,626 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:12:13,630 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:12:13,631 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:12:13,638 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:12:13,639 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 14:12:13,644 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 14:12:13,645 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 14:12:13,837 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Fetching context for project: f1657f06-e4c4-4b31-871e-aafedbbbc73a
2025-11-11 14:12:13,885 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Starting workflow for project: f1657f06-e4c4-4b31-871e-aafedbbbc73a
2025-11-11 14:12:13,897 | INFO | hackthon_support_agent.BaseService | [PLANNING] Starting planning phase
2025-11-11 14:12:13,897 | INFO | hackthon_support_agent.BaseService | [PLANNING] Plan created with 3 focus areas
2025-11-11 14:12:13,899 | INFO | hackthon_support_agent.BaseService | [CACHE] Creating context cache
2025-11-11 14:12:14,220 | ERROR | hackthon_support_agent.BaseService | [CACHE] Cache creation failed: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'Cached content is too small. total_token_count=3989, min_total_token_count=4096', 'status': 'INVALID_ARGUMENT'}}
2025-11-11 14:12:14,223 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Starting parallel extraction
2025-11-11 14:12:14,224 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: データ・モデル
2025-11-11 14:12:14,227 | ERROR | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] Error in データ・モデル: 'NoneType' object has no attribute 'get'
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/function_structuring_workflow.py", line 274, in _process_focus_area_async
    "retry_instruction": state.get("final_validation", {}).get("retry_instruction", "")
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'get'
2025-11-11 14:12:14,228 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: API・バックエンド
2025-11-11 14:12:14,228 | ERROR | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] Error in API・バックエンド: 'NoneType' object has no attribute 'get'
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/function_structuring_workflow.py", line 274, in _process_focus_area_async
    "retry_instruction": state.get("final_validation", {}).get("retry_instruction", "")
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'get'
2025-11-11 14:12:14,230 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: UI・画面
2025-11-11 14:12:14,230 | ERROR | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] Error in UI・画面: 'NoneType' object has no attribute 'get'
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/function_structuring_workflow.py", line 274, in _process_focus_area_async
    "retry_instruction": state.get("final_validation", {}).get("retry_instruction", "")
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'get'
2025-11-11 14:12:14,231 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Completed: 3 areas processed
2025-11-11 14:12:14,234 | INFO | hackthon_support_agent.BaseService | [MERGE] Merging results from all focus areas
2025-11-11 14:12:14,238 | INFO | hackthon_support_agent.BaseService | [MERGE] Merged: 0 unique functions, 0 dependencies
2025-11-11 14:12:14,243 | INFO | hackthon_support_agent.BaseService | [VALIDATION] Starting validation
2025-11-11 14:12:14,655 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 14:12:14,662 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 14:12:14,663 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:12:14,667 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:12:14,668 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:12:14,675 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:12:14,677 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:12:14,680 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:12:14,681 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 14:12:14,686 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 14:12:14,687 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 14:12:14,698 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 21 functions
2025-11-11 14:12:14,706 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 16, 'Should': 4, 'Could': 1}
2025-11-11 14:12:14,832 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Fetching context for project: f1657f06-e4c4-4b31-871e-aafedbbbc73a
2025-11-11 14:12:14,846 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Starting workflow for project: f1657f06-e4c4-4b31-871e-aafedbbbc73a
2025-11-11 14:12:14,853 | INFO | hackthon_support_agent.BaseService | [PLANNING] Starting planning phase
2025-11-11 14:12:14,854 | INFO | hackthon_support_agent.BaseService | [PLANNING] Plan created with 3 focus areas
2025-11-11 14:12:14,860 | INFO | hackthon_support_agent.BaseService | [CACHE] Creating context cache
2025-11-11 14:12:15,103 | ERROR | hackthon_support_agent.BaseService | [CACHE] Cache creation failed: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'Cached content is too small. total_token_count=3989, min_total_token_count=4096', 'status': 'INVALID_ARGUMENT'}}
2025-11-11 14:12:15,108 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Starting parallel extraction
2025-11-11 14:12:15,110 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: データ・モデル
2025-11-11 14:12:15,111 | ERROR | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] Error in データ・モデル: 'NoneType' object has no attribute 'get'
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/function_structuring_workflow.py", line 274, in _process_focus_area_async
    "retry_instruction": state.get("final_validation", {}).get("retry_instruction", "")
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'get'
2025-11-11 14:12:15,112 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: API・バックエンド
2025-11-11 14:12:15,114 | ERROR | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] Error in API・バックエンド: 'NoneType' object has no attribute 'get'
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/function_structuring_workflow.py", line 274, in _process_focus_area_async
    "retry_instruction": state.get("final_validation", {}).get("retry_instruction", "")
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'get'
2025-11-11 14:12:15,119 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: UI・画面
2025-11-11 14:12:15,123 | ERROR | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] Error in UI・画面: 'NoneType' object has no attribute 'get'
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/function_structuring_workflow.py", line 274, in _process_focus_area_async
    "retry_instruction": state.get("final_validation", {}).get("retry_instruction", "")
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'get'
2025-11-11 14:12:15,127 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Completed: 3 areas processed
2025-11-11 14:12:15,137 | INFO | hackthon_support_agent.BaseService | [MERGE] Merging results from all focus areas
2025-11-11 14:12:15,140 | INFO | hackthon_support_agent.BaseService | [MERGE] Merged: 0 unique functions, 0 dependencies
2025-11-11 14:12:15,145 | INFO | hackthon_support_agent.BaseService | [VALIDATION] Starting validation
2025-11-11 14:12:21,879 | INFO | hackthon_support_agent.BaseService | [VALIDATION] Status: REJECT, Issues: 1
2025-11-11 14:12:21,880 | WARNING | hackthon_support_agent.BaseService | [VALIDATION] REJECT - Retry instruction: 機能が全く抽出されていません。まずはプロジェクトアイデアに基づき、15〜25個の具体的な機能を抽出してください。
2025-11-11 14:12:21,881 | INFO | hackthon_support_agent.BaseService | [VALIDATION_DECISION] Validation rejected (iteration 0/3), retrying extraction
2025-11-11 14:12:21,886 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Starting parallel extraction
2025-11-11 14:12:21,887 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: データ・モデル
2025-11-11 14:12:23,305 | INFO | hackthon_support_agent.BaseService | [VALIDATION] Status: REJECT, Issues: 1
2025-11-11 14:12:23,306 | WARNING | hackthon_support_agent.BaseService | [VALIDATION] REJECT - Retry instruction: 機能が全く抽出されていません。オンライン学習プラットフォームのアイデアに基づき、15〜25個の主要な機能を具体的に抽出してください。
2025-11-11 14:12:23,307 | INFO | hackthon_support_agent.BaseService | [VALIDATION_DECISION] Validation rejected (iteration 0/3), retrying extraction
2025-11-11 14:12:23,309 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Starting parallel extraction
2025-11-11 14:12:23,310 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: データ・モデル
2025-11-11 14:12:28,935 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 14:12:28,943 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 14:12:28,944 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:12:28,973 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:12:28,973 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:12:28,978 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:12:28,978 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:12:28,981 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:12:28,982 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 14:12:28,987 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 14:12:28,988 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 14:12:29,081 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Fetching context for project: f1657f06-e4c4-4b31-871e-aafedbbbc73a
2025-11-11 14:12:29,086 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Starting workflow for project: f1657f06-e4c4-4b31-871e-aafedbbbc73a
2025-11-11 14:12:29,094 | INFO | hackthon_support_agent.BaseService | [PLANNING] Starting planning phase
2025-11-11 14:12:29,095 | INFO | hackthon_support_agent.BaseService | [PLANNING] Plan created with 3 focus areas
2025-11-11 14:12:29,096 | INFO | hackthon_support_agent.BaseService | [CACHE] Creating context cache
2025-11-11 14:12:29,444 | ERROR | hackthon_support_agent.BaseService | [CACHE] Cache creation failed: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'Cached content is too small. total_token_count=3989, min_total_token_count=4096', 'status': 'INVALID_ARGUMENT'}}
2025-11-11 14:12:29,448 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Starting parallel extraction
2025-11-11 14:12:29,448 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: データ・モデル
2025-11-11 14:12:29,451 | ERROR | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] Error in データ・モデル: 'NoneType' object has no attribute 'get'
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/function_structuring_workflow.py", line 274, in _process_focus_area_async
    "retry_instruction": state.get("final_validation", {}).get("retry_instruction", "")
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'get'
2025-11-11 14:12:29,453 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: API・バックエンド
2025-11-11 14:12:29,454 | ERROR | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] Error in API・バックエンド: 'NoneType' object has no attribute 'get'
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/function_structuring_workflow.py", line 274, in _process_focus_area_async
    "retry_instruction": state.get("final_validation", {}).get("retry_instruction", "")
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'get'
2025-11-11 14:12:29,457 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: UI・画面
2025-11-11 14:12:29,460 | ERROR | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] Error in UI・画面: 'NoneType' object has no attribute 'get'
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/function_structuring_workflow.py", line 274, in _process_focus_area_async
    "retry_instruction": state.get("final_validation", {}).get("retry_instruction", "")
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'get'
2025-11-11 14:12:29,462 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Completed: 3 areas processed
2025-11-11 14:12:29,469 | INFO | hackthon_support_agent.BaseService | [MERGE] Merging results from all focus areas
2025-11-11 14:12:29,470 | INFO | hackthon_support_agent.BaseService | [MERGE] Merged: 0 unique functions, 0 dependencies
2025-11-11 14:12:29,472 | INFO | hackthon_support_agent.BaseService | [VALIDATION] Starting validation
2025-11-11 14:12:34,497 | INFO | hackthon_support_agent.BaseService | [VALIDATION] Status: REJECT, Issues: 1
2025-11-11 14:12:34,497 | WARNING | hackthon_support_agent.BaseService | [VALIDATION] REJECT - Retry instruction: 機能が一つも抽出されていません。プロジェクトのアイデア「オンライン学習プラットフォーム」に基づき、学生の学力と得意不得意に合わせたAIを用いた動的な課題作成サービスを実現するための機能を15〜25個抽出してください。
2025-11-11 14:12:34,498 | INFO | hackthon_support_agent.BaseService | [VALIDATION_DECISION] Validation rejected (iteration 0/3), retrying extraction
2025-11-11 14:12:34,502 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Starting parallel extraction
2025-11-11 14:12:34,503 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: データ・モデル
2025-11-11 14:12:35,979 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 14:12:36,003 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 14:12:36,005 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:12:36,022 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:12:36,022 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:12:36,050 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:12:36,055 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:12:36,061 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:12:36,063 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 14:12:36,070 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 14:12:36,071 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 14:12:36,479 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Fetching context for project: f1657f06-e4c4-4b31-871e-aafedbbbc73a
2025-11-11 14:12:36,486 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Starting workflow for project: f1657f06-e4c4-4b31-871e-aafedbbbc73a
2025-11-11 14:12:36,495 | INFO | hackthon_support_agent.BaseService | [PLANNING] Starting planning phase
2025-11-11 14:12:36,496 | INFO | hackthon_support_agent.BaseService | [PLANNING] Plan created with 3 focus areas
2025-11-11 14:12:36,498 | INFO | hackthon_support_agent.BaseService | [CACHE] Creating context cache
2025-11-11 14:12:37,233 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 62 dependencies
2025-11-11 14:12:37,233 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 33, 'relates': 16, 'blocks': 13}
2025-11-11 14:12:37,234 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] API・バックエンド completed in 110.58s - 21 functions, 62 dependencies
2025-11-11 14:12:37,234 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: UI・画面
2025-11-11 14:12:37,774 | ERROR | hackthon_support_agent.BaseService | [CACHE] Cache creation failed: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'Cached content is too small. total_token_count=3989, min_total_token_count=4096', 'status': 'INVALID_ARGUMENT'}}
2025-11-11 14:12:37,777 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Starting parallel extraction
2025-11-11 14:12:37,778 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: データ・モデル
2025-11-11 14:12:37,778 | ERROR | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] Error in データ・モデル: 'NoneType' object has no attribute 'get'
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/function_structuring_workflow.py", line 274, in _process_focus_area_async
    "retry_instruction": state.get("final_validation", {}).get("retry_instruction", "")
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'get'
2025-11-11 14:12:37,779 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: API・バックエンド
2025-11-11 14:12:37,780 | ERROR | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] Error in API・バックエンド: 'NoneType' object has no attribute 'get'
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/function_structuring_workflow.py", line 274, in _process_focus_area_async
    "retry_instruction": state.get("final_validation", {}).get("retry_instruction", "")
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'get'
2025-11-11 14:12:37,780 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: UI・画面
2025-11-11 14:12:37,781 | ERROR | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] Error in UI・画面: 'NoneType' object has no attribute 'get'
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/function_structuring_workflow.py", line 274, in _process_focus_area_async
    "retry_instruction": state.get("final_validation", {}).get("retry_instruction", "")
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'get'
2025-11-11 14:12:37,781 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Completed: 3 areas processed
2025-11-11 14:12:37,784 | INFO | hackthon_support_agent.BaseService | [MERGE] Merging results from all focus areas
2025-11-11 14:12:37,785 | INFO | hackthon_support_agent.BaseService | [MERGE] Merged: 0 unique functions, 0 dependencies
2025-11-11 14:12:37,786 | INFO | hackthon_support_agent.BaseService | [VALIDATION] Starting validation
2025-11-11 14:12:39,803 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 21 functions using LangChain
2025-11-11 14:12:42,403 | INFO | hackthon_support_agent.BaseService | [VALIDATION] Status: REJECT, Issues: 1
2025-11-11 14:12:42,404 | WARNING | hackthon_support_agent.BaseService | [VALIDATION] REJECT - Retry instruction: 機能が全く抽出されていません。プロジェクトのアイデア（学生の学力と得意不得意に合わせたAIを用いた動的な課題作成サービス）に基づき、必要な機能を具体的にリストアップしてください。推奨機能数は15-25個です。
2025-11-11 14:12:42,405 | INFO | hackthon_support_agent.BaseService | [VALIDATION_DECISION] Validation rejected (iteration 0/3), retrying extraction
2025-11-11 14:12:42,410 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Starting parallel extraction
2025-11-11 14:12:42,411 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: データ・モデル
2025-11-11 14:12:50,849 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 21 functions using LangChain
2025-11-11 14:12:56,001 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 21 functions
2025-11-11 14:12:56,003 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'auth': 4, 'ui': 5, 'logic': 7, 'data': 5}
2025-11-11 14:13:00,109 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 21 functions using LangChain
2025-11-11 14:13:04,642 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 21 functions using LangChain
2025-11-11 14:13:06,873 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 21 functions using LangChain
2025-11-11 14:13:16,219 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 21 functions
2025-11-11 14:13:16,221 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'auth': 4, 'ui': 5, 'logic': 7, 'data': 5}
2025-11-11 14:13:17,079 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 21 functions using LangChain
2025-11-11 14:13:18,309 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 21 functions
2025-11-11 14:13:18,309 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'auth': 4, 'ui': 5, 'logic': 7, 'data': 5}
2025-11-11 14:13:25,360 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 21 functions
2025-11-11 14:13:25,360 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 18, 'Should': 2, 'Could': 1}
2025-11-11 14:13:33,805 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 21 functions
2025-11-11 14:13:33,806 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'auth': 4, 'ui': 5, 'logic': 6, 'api': 2, 'data': 4}
2025-11-11 14:13:38,470 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 21 functions
2025-11-11 14:13:38,471 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'auth': 4, 'ui': 5, 'logic': 7, 'data': 5}
2025-11-11 14:13:41,125 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 21 functions
2025-11-11 14:13:41,126 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 20, 'Could': 1}
2025-11-11 14:13:41,136 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 21 functions
2025-11-11 14:13:41,137 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 18, 'Should': 2, 'Could': 1}
2025-11-11 14:13:43,284 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 21 functions
2025-11-11 14:13:43,284 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'auth': 4, 'ui': 5, 'logic': 7, 'data': 5}
2025-11-11 14:13:59,147 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 21 functions
2025-11-11 14:13:59,148 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 16, 'Should': 5}
2025-11-11 14:14:06,880 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 21 functions
2025-11-11 14:14:06,881 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 18, 'Should': 3}
2025-11-11 14:14:09,908 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 45 dependencies
2025-11-11 14:14:09,909 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 26, 'blocks': 19}
2025-11-11 14:14:09,909 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] データ・モデル completed in 95.41s - 21 functions, 45 dependencies
2025-11-11 14:14:09,910 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: API・バックエンド
2025-11-11 14:14:15,728 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 49 dependencies
2025-11-11 14:14:15,728 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 35, 'relates': 3, 'blocks': 11}
2025-11-11 14:14:15,729 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] API・バックエンド completed in 127.30s - 21 functions, 49 dependencies
2025-11-11 14:14:15,729 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: UI・画面
2025-11-11 14:14:23,923 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 21 functions
2025-11-11 14:14:23,924 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 16, 'Should': 4, 'Could': 1}
2025-11-11 14:14:25,634 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 64 dependencies
2025-11-11 14:14:25,635 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 28, 'relates': 30, 'blocks': 6}
2025-11-11 14:14:25,635 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] UI・画面 completed in 108.40s - 21 functions, 64 dependencies
2025-11-11 14:14:25,636 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Completed: 3 areas processed
2025-11-11 14:14:25,640 | INFO | hackthon_support_agent.BaseService | [MERGE] Merging results from all focus areas
2025-11-11 14:14:25,642 | INFO | hackthon_support_agent.BaseService | [MERGE] Merged: 47 unique functions, 188 dependencies
2025-11-11 14:14:25,644 | INFO | hackthon_support_agent.BaseService | [VALIDATION] Starting validation
2025-11-11 14:14:42,914 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 21 functions using LangChain
2025-11-11 14:14:43,526 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 48 dependencies
2025-11-11 14:14:43,527 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 32, 'relates': 6, 'blocks': 10}
2025-11-11 14:14:43,527 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] データ・モデル completed in 140.22s - 21 functions, 48 dependencies
2025-11-11 14:14:43,528 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: API・バックエンド
2025-11-11 14:14:44,841 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 74 dependencies
2025-11-11 14:14:44,842 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 34, 'relates': 26, 'blocks': 14}
2025-11-11 14:14:44,842 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] データ・モデル completed in 142.95s - 21 functions, 74 dependencies
2025-11-11 14:14:44,843 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: API・バックエンド
2025-11-11 14:14:52,711 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 21 functions using LangChain
2025-11-11 14:14:53,441 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 66 dependencies
2025-11-11 14:14:53,442 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 26, 'relates': 25, 'blocks': 15}
2025-11-11 14:14:53,442 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] データ・モデル completed in 131.03s - 21 functions, 66 dependencies
2025-11-11 14:14:53,442 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: API・バックエンド
2025-11-11 14:15:07,592 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 21 functions
2025-11-11 14:15:07,593 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'auth': 4, 'ui': 5, 'logic': 7, 'api': 1, 'data': 4}
2025-11-11 14:15:10,094 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 21 functions using LangChain
2025-11-11 14:15:11,114 | INFO | hackthon_support_agent.BaseService | [VALIDATION] Status: REJECT, Issues: 2
2025-11-11 14:15:11,116 | WARNING | hackthon_support_agent.BaseService | [VALIDATION] REJECT - Retry instruction: 機能数が47個と多すぎます。15-25個に収まるように機能を統合してください。特に、以下の例のように、UI、API、ビジネスロジック、CRUD操作を一つの上位機能として再定義することを検討してください。
- 「ユーザー登録機能」「ユーザーログイン機能」「ユーザー認証API」「セッション管理API」「ユーザー情報CRUD機能」を「ユーザー認証・アカウント管理機能」として統合。
- 「初期診断テスト実
2025-11-11 14:15:11,119 | INFO | hackthon_support_agent.BaseService | [VALIDATION_DECISION] Validation rejected (iteration 0/3), retrying extraction
2025-11-11 14:15:11,128 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Starting parallel extraction
2025-11-11 14:15:11,129 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: データ・モデル
2025-11-11 14:15:17,651 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 21 functions using LangChain
2025-11-11 14:15:26,450 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 21 functions
2025-11-11 14:15:26,452 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'auth': 4, 'ui': 5, 'logic': 7, 'data': 5}
2025-11-11 14:15:33,834 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 14:15:36,440 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 14:36:39,185 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 14:36:41,656 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 14:38:05,986 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-11-11 14:38:05,990 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 14:38:05,990 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:38:06,013 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:38:06,013 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:38:06,015 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:38:06,015 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:38:06,016 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:38:06,016 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 14:38:06,023 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 14:38:06,023 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-11-11 14:38:06,023 | DEBUG | hackthon_support_agent.QuestionService | Generating questions for project_id: 448799f3-692a-42d4-8b6b-c14b00cd586f with idea_prompt: プロジェクトタイトル: オンライン学習プラットフォーム
プロジェクトアイディア: 学生の学力と得意不得意に合わせたAIを用いた動的な課題作成サービス
期間: 2025-11-11 〜 2025-12-11 23:37
2025-11-11 14:38:06,024 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-11-11 14:38:21,426 | INFO | hackthon_support_agent.QuestionService | Generated 6 questions for project_id: 448799f3-692a-42d4-8b6b-c14b00cd586f
2025-11-11 14:38:21,445 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-11-11 14:38:21,448 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 14:38:21,448 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:38:21,454 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:38:21,455 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:38:21,456 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:38:21,457 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:38:21,460 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:38:21,461 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 14:38:21,462 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 14:38:21,462 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-11-11 14:38:25,207 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-11-11 14:38:25,210 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 14:38:25,211 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:38:25,215 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:38:25,215 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:38:25,218 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:38:25,219 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:38:25,221 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:38:25,221 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 14:38:25,223 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 14:38:25,224 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-11-11 14:38:25,305 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.generate_summary_document'
2025-11-11 14:38:37,365 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-11-11 14:38:37,368 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 14:38:37,369 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:38:37,374 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:38:37,375 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:38:37,376 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:38:37,377 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:38:37,379 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:38:37,380 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 14:38:37,381 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 14:38:37,381 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-11-11 14:39:04,382 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-11-11 14:39:04,387 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 14:39:04,387 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:39:04,398 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:39:04,399 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:39:04,400 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:39:04,400 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:39:04,405 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:39:04,406 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 14:39:04,407 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 14:39:04,407 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-11-11 14:39:04,416 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-11-11 14:39:24,952 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-11-11 14:39:24,956 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 14:39:24,956 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:39:24,962 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:39:24,962 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:39:24,964 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:39:24,964 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:39:24,966 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:39:24,966 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 14:39:24,969 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 14:39:24,969 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-11-11 14:39:25,011 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: 448799f3-692a-42d4-8b6b-c14b00cd586f
2025-11-11 14:39:25,016 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.evaluate_specification'
2025-11-11 14:39:26,030 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-11-11 14:39:26,032 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 14:39:26,032 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:39:26,033 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:39:26,034 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:39:26,037 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:39:26,037 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:39:26,040 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:39:26,041 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 14:39:26,043 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 14:39:26,044 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-11-11 14:39:26,099 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: 448799f3-692a-42d4-8b6b-c14b00cd586f
2025-11-11 14:39:26,104 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.evaluate_specification'
2025-11-11 14:39:33,269 | DEBUG | hackthon_support_agent.FunctionService | Initializing BaseService (provider=google)
2025-11-11 14:39:33,272 | INFO | hackthon_support_agent.FunctionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 14:39:33,272 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:39:33,277 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:39:33,278 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:39:33,280 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:39:33,281 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:39:33,283 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:39:33,283 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 14:39:33,286 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 14:39:33,286 | DEBUG | hackthon_support_agent.FunctionService | LLMs initialized
2025-11-11 14:39:33,287 | DEBUG | hackthon_support_agent.FunctionService | Generating functional requirements for project_id: 448799f3-692a-42d4-8b6b-c14b00cd586f
2025-11-11 14:39:33,292 | DEBUG | hackthon_support_agent.FunctionService | Fetching prompt 'function_service.generate_functional_requirements'
2025-11-11 14:40:46,372 | DEBUG | hackthon_support_agent.FunctionService | Saving functional requirements to project document: 448799f3-692a-42d4-8b6b-c14b00cd586f
2025-11-11 14:43:33,403 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 14:43:33,406 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 14:43:33,407 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:43:33,413 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:43:33,413 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:43:33,414 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:43:33,414 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:43:33,417 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:43:33,418 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 14:43:33,420 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 14:43:33,420 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 14:43:33,485 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Fetching context for project: 448799f3-692a-42d4-8b6b-c14b00cd586f
2025-11-11 14:43:33,489 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Starting workflow for project: 448799f3-692a-42d4-8b6b-c14b00cd586f
2025-11-11 14:43:33,496 | INFO | hackthon_support_agent.BaseService | [PLANNING] Starting planning phase
2025-11-11 14:43:33,497 | INFO | hackthon_support_agent.BaseService | [PLANNING] Plan created with 3 focus areas
2025-11-11 14:43:33,498 | INFO | hackthon_support_agent.BaseService | [CACHE] Creating context cache
2025-11-11 14:43:33,780 | ERROR | hackthon_support_agent.BaseService | [CACHE] Cache creation failed: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'Cached content is too small. total_token_count=3977, min_total_token_count=4096', 'status': 'INVALID_ARGUMENT'}}
2025-11-11 14:43:33,787 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Starting parallel extraction
2025-11-11 14:43:33,788 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: データ・モデル
2025-11-11 14:43:33,788 | ERROR | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] Error in データ・モデル: 'NoneType' object has no attribute 'get'
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/function_structuring_workflow.py", line 274, in _process_focus_area_async
    "retry_instruction": state.get("final_validation", {}).get("retry_instruction", "")
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'get'
2025-11-11 14:43:33,789 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: API・バックエンド
2025-11-11 14:43:33,790 | ERROR | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] Error in API・バックエンド: 'NoneType' object has no attribute 'get'
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/function_structuring_workflow.py", line 274, in _process_focus_area_async
    "retry_instruction": state.get("final_validation", {}).get("retry_instruction", "")
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'get'
2025-11-11 14:43:33,791 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: UI・画面
2025-11-11 14:43:33,791 | ERROR | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] Error in UI・画面: 'NoneType' object has no attribute 'get'
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/function_structuring_workflow.py", line 274, in _process_focus_area_async
    "retry_instruction": state.get("final_validation", {}).get("retry_instruction", "")
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'get'
2025-11-11 14:43:33,792 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Completed: 3 areas processed
2025-11-11 14:43:33,793 | INFO | hackthon_support_agent.BaseService | [MERGE] Merging results from all focus areas
2025-11-11 14:43:33,793 | INFO | hackthon_support_agent.BaseService | [MERGE] Merged: 0 unique functions, 0 dependencies
2025-11-11 14:43:33,794 | INFO | hackthon_support_agent.BaseService | [VALIDATION] Starting validation
2025-11-11 14:43:38,804 | INFO | hackthon_support_agent.BaseService | [VALIDATION] Status: REJECT, Issues: 1
2025-11-11 14:43:38,805 | WARNING | hackthon_support_agent.BaseService | [VALIDATION] REJECT - Retry instruction: 機能が0個です。オンライン学習プラットフォームのアイデアに基づき、15〜25個の機能を具体的に抽出してください。例えば、「ユーザー登録・ログイン機能」、「AIによる課題生成機能」、「学習履歴管理機能」など、MVPに必要な機能を洗い出しましょう。
2025-11-11 14:43:38,806 | INFO | hackthon_support_agent.BaseService | [VALIDATION_DECISION] Validation rejected (iteration 0/3), retrying extraction
2025-11-11 14:43:38,807 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Starting parallel extraction
2025-11-11 14:43:38,807 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: データ・モデル
2025-11-11 14:44:00,837 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 14:44:00,844 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 14:44:00,845 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:44:00,868 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:44:00,869 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:44:00,877 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:44:00,878 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:44:00,882 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:44:00,882 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 14:44:00,888 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 14:44:00,889 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 14:44:01,014 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Fetching context for project: 448799f3-692a-42d4-8b6b-c14b00cd586f
2025-11-11 14:44:01,022 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Starting workflow for project: 448799f3-692a-42d4-8b6b-c14b00cd586f
2025-11-11 14:44:01,029 | INFO | hackthon_support_agent.BaseService | [PLANNING] Starting planning phase
2025-11-11 14:44:01,030 | INFO | hackthon_support_agent.BaseService | [PLANNING] Plan created with 3 focus areas
2025-11-11 14:44:01,031 | INFO | hackthon_support_agent.BaseService | [CACHE] Creating context cache
2025-11-11 14:44:01,398 | ERROR | hackthon_support_agent.BaseService | [CACHE] Cache creation failed: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'Cached content is too small. total_token_count=3977, min_total_token_count=4096', 'status': 'INVALID_ARGUMENT'}}
2025-11-11 14:44:01,403 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Starting parallel extraction
2025-11-11 14:44:01,404 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: データ・モデル
2025-11-11 14:44:01,405 | ERROR | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] Error in データ・モデル: 'NoneType' object has no attribute 'get'
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/function_structuring_workflow.py", line 274, in _process_focus_area_async
    "retry_instruction": state.get("final_validation", {}).get("retry_instruction", "")
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'get'
2025-11-11 14:44:01,406 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: API・バックエンド
2025-11-11 14:44:01,407 | ERROR | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] Error in API・バックエンド: 'NoneType' object has no attribute 'get'
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/function_structuring_workflow.py", line 274, in _process_focus_area_async
    "retry_instruction": state.get("final_validation", {}).get("retry_instruction", "")
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'get'
2025-11-11 14:44:01,408 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: UI・画面
2025-11-11 14:44:01,409 | ERROR | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] Error in UI・画面: 'NoneType' object has no attribute 'get'
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/function_structuring_workflow.py", line 274, in _process_focus_area_async
    "retry_instruction": state.get("final_validation", {}).get("retry_instruction", "")
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'get'
2025-11-11 14:44:01,411 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Completed: 3 areas processed
2025-11-11 14:44:01,413 | INFO | hackthon_support_agent.BaseService | [MERGE] Merging results from all focus areas
2025-11-11 14:44:01,414 | INFO | hackthon_support_agent.BaseService | [MERGE] Merged: 0 unique functions, 0 dependencies
2025-11-11 14:44:01,422 | INFO | hackthon_support_agent.BaseService | [VALIDATION] Starting validation
2025-11-11 14:44:07,023 | INFO | hackthon_support_agent.BaseService | [VALIDATION] Status: REJECT, Issues: 1
2025-11-11 14:44:07,025 | WARNING | hackthon_support_agent.BaseService | [VALIDATION] REJECT - Retry instruction: 機能が一つも抽出されていません。プロジェクトのアイデアに基づき、必要な機能を抽出してください。推奨機能数は15-25個です。
2025-11-11 14:44:07,026 | INFO | hackthon_support_agent.BaseService | [VALIDATION_DECISION] Validation rejected (iteration 0/3), retrying extraction
2025-11-11 14:44:07,029 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Starting parallel extraction
2025-11-11 14:44:07,030 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: データ・モデル
2025-11-11 14:44:10,900 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 14:44:10,914 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 14:44:10,915 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:44:11,001 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:44:11,002 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:44:11,007 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:44:11,008 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:44:11,011 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:44:11,011 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 14:44:11,015 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 14:44:11,015 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 14:44:11,092 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Fetching context for project: 448799f3-692a-42d4-8b6b-c14b00cd586f
2025-11-11 14:44:11,095 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Starting workflow for project: 448799f3-692a-42d4-8b6b-c14b00cd586f
2025-11-11 14:44:11,100 | INFO | hackthon_support_agent.BaseService | [PLANNING] Starting planning phase
2025-11-11 14:44:11,100 | INFO | hackthon_support_agent.BaseService | [PLANNING] Plan created with 3 focus areas
2025-11-11 14:44:11,101 | INFO | hackthon_support_agent.BaseService | [CACHE] Creating context cache
2025-11-11 14:44:11,469 | ERROR | hackthon_support_agent.BaseService | [CACHE] Cache creation failed: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'Cached content is too small. total_token_count=3977, min_total_token_count=4096', 'status': 'INVALID_ARGUMENT'}}
2025-11-11 14:44:11,485 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Starting parallel extraction
2025-11-11 14:44:11,488 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: データ・モデル
2025-11-11 14:44:11,490 | ERROR | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] Error in データ・モデル: 'NoneType' object has no attribute 'get'
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/function_structuring_workflow.py", line 274, in _process_focus_area_async
    "retry_instruction": state.get("final_validation", {}).get("retry_instruction", "")
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'get'
2025-11-11 14:44:11,492 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: API・バックエンド
2025-11-11 14:44:11,493 | ERROR | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] Error in API・バックエンド: 'NoneType' object has no attribute 'get'
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/function_structuring_workflow.py", line 274, in _process_focus_area_async
    "retry_instruction": state.get("final_validation", {}).get("retry_instruction", "")
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'get'
2025-11-11 14:44:11,495 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: UI・画面
2025-11-11 14:44:11,497 | ERROR | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] Error in UI・画面: 'NoneType' object has no attribute 'get'
Traceback (most recent call last):
  File "/workspaces/hackathon_support_agent/back/services/function_structuring_workflow.py", line 274, in _process_focus_area_async
    "retry_instruction": state.get("final_validation", {}).get("retry_instruction", "")
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'get'
2025-11-11 14:44:11,499 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Completed: 3 areas processed
2025-11-11 14:44:11,502 | INFO | hackthon_support_agent.BaseService | [MERGE] Merging results from all focus areas
2025-11-11 14:44:11,503 | INFO | hackthon_support_agent.BaseService | [MERGE] Merged: 0 unique functions, 0 dependencies
2025-11-11 14:44:11,507 | INFO | hackthon_support_agent.BaseService | [VALIDATION] Starting validation
2025-11-11 14:44:15,952 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 21 functions using LangChain
2025-11-11 14:44:17,475 | INFO | hackthon_support_agent.BaseService | [VALIDATION] Status: REJECT, Issues: 1
2025-11-11 14:44:17,475 | WARNING | hackthon_support_agent.BaseService | [VALIDATION] REJECT - Retry instruction: 機能が全く抽出されていません。プロジェクトアイデア「学生の学力と得意不得意に合わせたAIを用いた動的な課題作成サービス」に基づき、15〜25個の具体的な機能を抽出してください。例えば、「AIによる学力診断機能」「個別最適化された課題生成機能」「学習進捗トラッキング機能」などです。
2025-11-11 14:44:17,476 | INFO | hackthon_support_agent.BaseService | [VALIDATION_DECISION] Validation rejected (iteration 0/3), retrying extraction
2025-11-11 14:44:17,478 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Starting parallel extraction
2025-11-11 14:44:17,478 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: データ・モデル
2025-11-11 14:44:43,577 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 21 functions using LangChain
2025-11-11 14:44:47,055 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 20 functions using LangChain
2025-11-11 14:44:59,550 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 21 functions
2025-11-11 14:44:59,551 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'auth': 4, 'ui': 7, 'logic': 5, 'data': 5}
2025-11-11 14:45:03,388 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 21 functions
2025-11-11 14:45:03,389 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'auth': 4, 'ui': 5, 'logic': 7, 'data': 5}
2025-11-11 14:45:15,397 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 20 functions
2025-11-11 14:45:15,399 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'auth': 4, 'ui': 7, 'logic': 5, 'data': 4}
2025-11-11 14:45:27,848 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 21 functions
2025-11-11 14:45:27,849 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 18, 'Should': 3}
2025-11-11 14:45:32,230 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 21 functions
2025-11-11 14:45:32,231 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 18, 'Should': 2, 'Could': 1}
2025-11-11 14:45:39,683 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 20 functions
2025-11-11 14:45:39,684 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 18, 'Should': 2}
2025-11-11 14:46:03,783 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 67 dependencies
2025-11-11 14:46:03,785 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 32, 'relates': 33, 'blocks': 2}
2025-11-11 14:46:03,785 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] データ・モデル completed in 106.31s - 21 functions, 67 dependencies
2025-11-11 14:46:03,786 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: API・バックエンド
2025-11-11 14:46:04,516 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 37 dependencies
2025-11-11 14:46:04,516 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 30, 'blocks': 2, 'relates': 5}
2025-11-11 14:46:04,517 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] データ・モデル completed in 145.71s - 21 functions, 37 dependencies
2025-11-11 14:46:04,518 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: API・バックエンド
2025-11-11 14:46:17,237 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 85 dependencies
2025-11-11 14:46:17,239 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 45, 'relates': 22, 'blocks': 18}
2025-11-11 14:46:17,240 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] データ・モデル completed in 130.21s - 20 functions, 85 dependencies
2025-11-11 14:46:17,242 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: API・バックエンド
2025-11-11 14:46:34,094 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 21 functions using LangChain
2025-11-11 14:46:38,801 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 21 functions using LangChain
2025-11-11 14:46:41,254 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 21 functions using LangChain
2025-11-11 14:47:00,352 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 21 functions
2025-11-11 14:47:00,354 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'auth': 4, 'ui': 7, 'logic': 5, 'data': 5}
2025-11-11 14:47:06,747 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 21 functions
2025-11-11 14:47:06,748 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'auth': 4, 'ui': 8, 'logic': 4, 'data': 5}
2025-11-11 14:47:08,841 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 21 functions
2025-11-11 14:47:08,842 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'auth': 4, 'ui': 8, 'logic': 4, 'data': 5}
2025-11-11 14:47:26,019 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 21 functions
2025-11-11 14:47:26,022 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 16, 'Should': 5}
2025-11-11 14:47:33,893 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 21 functions
2025-11-11 14:47:33,894 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 18, 'Should': 3}
2025-11-11 14:47:36,467 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 21 functions
2025-11-11 14:47:36,467 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 19, 'Should': 2}
2025-11-11 14:48:08,626 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 92 dependencies
2025-11-11 14:48:08,628 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 46, 'relates': 45, 'blocks': 1}
2025-11-11 14:48:08,629 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] API・バックエンド completed in 124.84s - 21 functions, 92 dependencies
2025-11-11 14:48:08,629 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: UI・画面
2025-11-11 14:48:34,058 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 54 dependencies
2025-11-11 14:48:34,062 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 34, 'blocks': 11, 'relates': 9}
2025-11-11 14:48:34,063 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] API・バックエンド completed in 149.55s - 21 functions, 54 dependencies
2025-11-11 14:48:34,065 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: UI・画面
2025-11-11 14:48:39,312 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 21 functions using LangChain
2025-11-11 14:48:43,012 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 82 dependencies
2025-11-11 14:48:43,014 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 20, 'blocks': 9, 'relates': 53}
2025-11-11 14:48:43,015 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] API・バックエンド completed in 145.77s - 21 functions, 82 dependencies
2025-11-11 14:48:43,016 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: UI・画面
2025-11-11 14:49:02,597 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 21 functions
2025-11-11 14:49:02,599 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'auth': 4, 'ui': 7, 'logic': 5, 'data': 5}
2025-11-11 14:49:10,455 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 21 functions using LangChain
2025-11-11 14:49:13,332 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 21 functions using LangChain
2025-11-11 14:49:22,063 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 21 functions
2025-11-11 14:49:22,064 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 20, 'Should': 1}
2025-11-11 14:49:37,920 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 21 functions
2025-11-11 14:49:37,923 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'auth': 4, 'ui': 7, 'logic': 5, 'data': 5}
2025-11-11 14:49:41,791 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 21 functions
2025-11-11 14:49:41,793 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'auth': 4, 'ui': 6, 'logic': 6, 'data': 5}
2025-11-11 14:49:58,670 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 47 dependencies
2025-11-11 14:49:58,674 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 36, 'blocks': 9, 'relates': 2}
2025-11-11 14:49:58,674 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] UI・画面 completed in 110.04s - 21 functions, 47 dependencies
2025-11-11 14:49:58,675 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Completed: 3 areas processed
2025-11-11 14:49:58,682 | INFO | hackthon_support_agent.BaseService | [MERGE] Merging results from all focus areas
2025-11-11 14:49:58,683 | INFO | hackthon_support_agent.BaseService | [MERGE] Merged: 54 unique functions, 206 dependencies
2025-11-11 14:49:58,688 | INFO | hackthon_support_agent.BaseService | [VALIDATION] Starting validation
2025-11-11 14:50:04,141 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 21 functions
2025-11-11 14:50:04,141 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 18, 'Should': 3}
2025-11-11 14:50:13,661 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 21 functions
2025-11-11 14:50:13,666 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 19, 'Should': 2}
2025-11-11 14:50:47,837 | INFO | hackthon_support_agent.BaseService | [VALIDATION] Status: REJECT, Issues: 3
2025-11-11 14:50:47,838 | WARNING | hackthon_support_agent.BaseService | [VALIDATION] REJECT - Retry instruction: 機能数が30個と、推奨される15-25個の範囲を超えています。また、多くの機能で重複や類似が見られます。
以下の点を修正してください:
1.  **機能の統合と粒度の調整**: 以下の重複または類似する機能を統合し、単一の明確な機能として再定義してください。これにより、機能数を推奨範囲に収め、各機能の責務を明確にしてください。
    *   `ユーザーアカウント登録機能` と `アカウント登録機
2025-11-11 14:50:47,841 | INFO | hackthon_support_agent.BaseService | [VALIDATION_DECISION] Validation rejected (iteration 0/3), retrying extraction
2025-11-11 14:50:47,849 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Starting parallel extraction
2025-11-11 14:50:47,850 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: データ・モデル
2025-11-11 14:50:55,006 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 84 dependencies
2025-11-11 14:50:55,006 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 65, 'relates': 18, 'blocks': 1}
2025-11-11 14:50:55,007 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] UI・画面 completed in 140.94s - 21 functions, 84 dependencies
2025-11-11 14:50:55,007 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Completed: 3 areas processed
2025-11-11 14:50:55,013 | INFO | hackthon_support_agent.BaseService | [MERGE] Merging results from all focus areas
2025-11-11 14:50:55,014 | INFO | hackthon_support_agent.BaseService | [MERGE] Merged: 53 unique functions, 175 dependencies
2025-11-11 14:50:55,014 | INFO | hackthon_support_agent.BaseService | [VALIDATION] Starting validation
2025-11-11 14:51:08,365 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 14:51:12,397 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 14:53:38,960 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-11-11 14:53:38,966 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 14:53:38,966 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:53:38,996 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:53:38,997 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:53:38,999 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:53:39,000 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:53:39,001 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:53:39,002 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 14:53:39,007 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 14:53:39,007 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-11-11 14:53:39,008 | DEBUG | hackthon_support_agent.QuestionService | Generating questions for project_id: 35fa8b5e-6f47-4b3c-9c57-48625e9af0fa with idea_prompt: プロジェクトタイトル: オンライン学習プラットフォーム
プロジェクトアイディア: 学生の学力と得意不得意に合わせたAIを用いた動的な課題作成サービス
期間: 2025-11-11 〜 2025-12-11 23:50
2025-11-11 14:53:39,008 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-11-11 14:53:53,803 | INFO | hackthon_support_agent.QuestionService | Generated 5 questions for project_id: 35fa8b5e-6f47-4b3c-9c57-48625e9af0fa
2025-11-11 14:53:53,815 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-11-11 14:53:53,818 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 14:53:53,818 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:53:53,823 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:53:53,823 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:53:53,825 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:53:53,825 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:53:53,827 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:53:53,828 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 14:53:53,831 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 14:53:53,831 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-11-11 14:54:06,154 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-11-11 14:54:06,159 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 14:54:06,160 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:54:06,175 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:54:06,175 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:54:06,179 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:54:06,179 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:54:06,182 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:54:06,183 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 14:54:06,186 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 14:54:06,187 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-11-11 14:54:06,313 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.generate_summary_document'
2025-11-11 14:54:20,031 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-11-11 14:54:20,034 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 14:54:20,035 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:54:20,036 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:54:20,036 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:54:20,037 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:54:20,038 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:54:20,039 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:54:20,039 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 14:54:20,040 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 14:54:20,040 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-11-11 14:54:20,971 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-11-11 14:54:20,975 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 14:54:20,975 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:54:20,982 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:54:20,983 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:54:20,985 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:54:20,985 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:54:20,987 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:54:20,988 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 14:54:20,989 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 14:54:20,989 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-11-11 14:54:21,003 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-11-11 14:54:38,938 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-11-11 14:54:38,947 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 14:54:38,948 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:54:38,961 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:54:38,961 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:54:38,965 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:54:38,966 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:54:38,994 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:54:38,995 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 14:54:39,005 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 14:54:39,007 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-11-11 14:54:39,074 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: 35fa8b5e-6f47-4b3c-9c57-48625e9af0fa
2025-11-11 14:54:39,080 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.evaluate_specification'
2025-11-11 14:54:40,013 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-11-11 14:54:40,021 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 14:54:40,022 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:54:40,027 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:54:40,028 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:54:40,034 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:54:40,035 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:54:40,040 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:54:40,040 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 14:54:40,043 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 14:54:40,043 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-11-11 14:54:40,099 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: 35fa8b5e-6f47-4b3c-9c57-48625e9af0fa
2025-11-11 14:54:40,102 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.evaluate_specification'
2025-11-11 14:56:59,533 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 14:58:22,513 | DEBUG | hackthon_support_agent.FunctionService | Initializing BaseService (provider=google)
2025-11-11 14:58:22,522 | INFO | hackthon_support_agent.FunctionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 14:58:22,523 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:58:22,561 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:58:22,563 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:58:22,565 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:58:22,566 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 14:58:22,568 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 14:58:22,569 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 14:58:22,571 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 14:58:22,571 | DEBUG | hackthon_support_agent.FunctionService | LLMs initialized
2025-11-11 14:58:22,571 | DEBUG | hackthon_support_agent.FunctionService | Generating functional requirements for project_id: 35fa8b5e-6f47-4b3c-9c57-48625e9af0fa
2025-11-11 14:58:22,577 | DEBUG | hackthon_support_agent.FunctionService | Fetching prompt 'function_service.generate_functional_requirements'
2025-11-11 14:58:53,290 | DEBUG | hackthon_support_agent.FunctionService | Saving functional requirements to project document: 35fa8b5e-6f47-4b3c-9c57-48625e9af0fa
2025-11-11 15:00:25,347 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 15:00:25,355 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 15:00:25,355 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 15:00:25,368 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 15:00:25,369 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 15:00:25,372 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 15:00:25,373 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 15:00:25,374 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 15:00:25,375 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 15:00:25,378 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 15:00:25,378 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 15:00:25,553 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Fetching context for project: 35fa8b5e-6f47-4b3c-9c57-48625e9af0fa
2025-11-11 15:00:25,582 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Starting workflow for project: 35fa8b5e-6f47-4b3c-9c57-48625e9af0fa
2025-11-11 15:00:25,596 | INFO | hackthon_support_agent.BaseService | [PLANNING] Starting planning phase
2025-11-11 15:00:25,597 | INFO | hackthon_support_agent.BaseService | [PLANNING] Plan created with 3 focus areas
2025-11-11 15:00:25,607 | INFO | hackthon_support_agent.BaseService | [CACHE] Creating context cache
2025-11-11 15:00:25,908 | ERROR | hackthon_support_agent.BaseService | [CACHE] Cache creation failed: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'Cached content is too small. total_token_count=3405, min_total_token_count=4096', 'status': 'INVALID_ARGUMENT'}}
2025-11-11 15:00:25,916 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Starting parallel extraction
2025-11-11 15:00:25,922 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: データ・モデル
2025-11-11 15:00:40,856 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 5 functions using LangChain
2025-11-11 15:00:48,719 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 5 functions
2025-11-11 15:00:48,721 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'data': 5}
2025-11-11 15:00:59,510 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 5 functions
2025-11-11 15:00:59,512 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 5}
2025-11-11 15:01:19,001 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 6 dependencies
2025-11-11 15:01:19,002 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 6}
2025-11-11 15:01:19,003 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] データ・モデル completed in 53.07s - 5 functions, 6 dependencies
2025-11-11 15:01:19,004 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: API・バックエンド
2025-11-11 15:01:39,244 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 15:01:39,262 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 15:01:39,263 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 15:01:39,279 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 15:01:39,281 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 15:01:39,286 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 15:01:39,286 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 15:01:39,290 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 15:01:39,291 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 15:01:39,294 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 15:01:39,295 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 15:01:39,392 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Fetching context for project: 35fa8b5e-6f47-4b3c-9c57-48625e9af0fa
2025-11-11 15:01:39,397 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Starting workflow for project: 35fa8b5e-6f47-4b3c-9c57-48625e9af0fa
2025-11-11 15:01:39,403 | INFO | hackthon_support_agent.BaseService | [PLANNING] Starting planning phase
2025-11-11 15:01:39,404 | INFO | hackthon_support_agent.BaseService | [PLANNING] Plan created with 3 focus areas
2025-11-11 15:01:39,405 | INFO | hackthon_support_agent.BaseService | [CACHE] Creating context cache
2025-11-11 15:01:39,637 | ERROR | hackthon_support_agent.BaseService | [CACHE] Cache creation failed: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'Cached content is too small. total_token_count=3405, min_total_token_count=4096', 'status': 'INVALID_ARGUMENT'}}
2025-11-11 15:01:39,640 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Starting parallel extraction
2025-11-11 15:01:39,640 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: データ・モデル
2025-11-11 15:01:43,407 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 15:01:43,414 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 15:01:43,415 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 15:01:43,421 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 15:01:43,422 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 15:01:43,427 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 15:01:43,427 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 15:01:43,431 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 15:01:43,432 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 15:01:43,437 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 15:01:43,438 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 15:01:43,510 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Fetching context for project: 35fa8b5e-6f47-4b3c-9c57-48625e9af0fa
2025-11-11 15:01:43,514 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Starting workflow for project: 35fa8b5e-6f47-4b3c-9c57-48625e9af0fa
2025-11-11 15:01:43,518 | INFO | hackthon_support_agent.BaseService | [PLANNING] Starting planning phase
2025-11-11 15:01:43,518 | INFO | hackthon_support_agent.BaseService | [PLANNING] Plan created with 3 focus areas
2025-11-11 15:01:43,519 | INFO | hackthon_support_agent.BaseService | [CACHE] Creating context cache
2025-11-11 15:01:43,780 | ERROR | hackthon_support_agent.BaseService | [CACHE] Cache creation failed: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'Cached content is too small. total_token_count=3405, min_total_token_count=4096', 'status': 'INVALID_ARGUMENT'}}
2025-11-11 15:01:43,784 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Starting parallel extraction
2025-11-11 15:01:43,785 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: データ・モデル
2025-11-11 15:01:47,859 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 8 functions using LangChain
2025-11-11 15:01:53,814 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 5 functions using LangChain
2025-11-11 15:01:53,929 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 5 functions using LangChain
2025-11-11 15:01:59,517 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 8 functions
2025-11-11 15:01:59,519 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'auth': 1, 'data': 4, 'logic': 3}
2025-11-11 15:02:01,091 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 5 functions
2025-11-11 15:02:01,092 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'data': 5}
2025-11-11 15:02:01,881 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 15:02:01,887 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 15:02:01,887 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 15:02:01,899 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 15:02:01,900 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 15:02:01,903 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 15:02:01,903 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 15:02:01,905 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 15:02:01,906 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 15:02:01,909 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 15:02:01,910 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 15:02:01,987 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Fetching context for project: 35fa8b5e-6f47-4b3c-9c57-48625e9af0fa
2025-11-11 15:02:01,997 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Starting workflow for project: 35fa8b5e-6f47-4b3c-9c57-48625e9af0fa
2025-11-11 15:02:02,003 | INFO | hackthon_support_agent.BaseService | [PLANNING] Starting planning phase
2025-11-11 15:02:02,004 | INFO | hackthon_support_agent.BaseService | [PLANNING] Plan created with 3 focus areas
2025-11-11 15:02:02,007 | INFO | hackthon_support_agent.BaseService | [CACHE] Creating context cache
2025-11-11 15:02:02,242 | ERROR | hackthon_support_agent.BaseService | [CACHE] Cache creation failed: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'Cached content is too small. total_token_count=3405, min_total_token_count=4096', 'status': 'INVALID_ARGUMENT'}}
2025-11-11 15:02:02,249 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Starting parallel extraction
2025-11-11 15:02:02,250 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: データ・モデル
2025-11-11 15:02:02,898 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 5 functions
2025-11-11 15:02:02,899 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'data': 5}
2025-11-11 15:02:12,714 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 5 functions using LangChain
2025-11-11 15:02:12,727 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 8 functions
2025-11-11 15:02:12,728 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 8}
2025-11-11 15:02:16,361 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 5 functions
2025-11-11 15:02:16,363 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 5}
2025-11-11 15:02:16,697 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 5 functions
2025-11-11 15:02:16,698 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 5}
2025-11-11 15:02:20,789 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 15:02:20,795 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 15:02:20,796 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 15:02:20,822 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 15:02:20,823 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 15:02:20,829 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 15:02:20,830 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 15:02:20,838 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 15:02:20,838 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 15:02:20,846 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 15:02:20,847 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 15:02:20,976 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Fetching context for project: 35fa8b5e-6f47-4b3c-9c57-48625e9af0fa
2025-11-11 15:02:20,981 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Starting workflow for project: 35fa8b5e-6f47-4b3c-9c57-48625e9af0fa
2025-11-11 15:02:20,986 | INFO | hackthon_support_agent.BaseService | [PLANNING] Starting planning phase
2025-11-11 15:02:20,987 | INFO | hackthon_support_agent.BaseService | [PLANNING] Plan created with 3 focus areas
2025-11-11 15:02:20,988 | INFO | hackthon_support_agent.BaseService | [CACHE] Creating context cache
2025-11-11 15:02:21,211 | ERROR | hackthon_support_agent.BaseService | [CACHE] Cache creation failed: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'Cached content is too small. total_token_count=3405, min_total_token_count=4096', 'status': 'INVALID_ARGUMENT'}}
2025-11-11 15:02:21,214 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Starting parallel extraction
2025-11-11 15:02:21,215 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: データ・モデル
2025-11-11 15:02:22,264 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 5 functions
2025-11-11 15:02:22,265 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'data': 5}
2025-11-11 15:02:28,405 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 15:02:28,410 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 15:02:28,411 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 15:02:28,420 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 15:02:28,420 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 15:02:28,423 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 15:02:28,423 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 15:02:28,427 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 15:02:28,428 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 15:02:28,431 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 15:02:28,432 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 15:02:28,513 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Fetching context for project: 35fa8b5e-6f47-4b3c-9c57-48625e9af0fa
2025-11-11 15:02:28,517 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Starting workflow for project: 35fa8b5e-6f47-4b3c-9c57-48625e9af0fa
2025-11-11 15:02:28,521 | INFO | hackthon_support_agent.BaseService | [PLANNING] Starting planning phase
2025-11-11 15:02:28,521 | INFO | hackthon_support_agent.BaseService | [PLANNING] Plan created with 3 focus areas
2025-11-11 15:02:28,523 | INFO | hackthon_support_agent.BaseService | [CACHE] Creating context cache
2025-11-11 15:02:28,755 | ERROR | hackthon_support_agent.BaseService | [CACHE] Cache creation failed: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'Cached content is too small. total_token_count=3405, min_total_token_count=4096', 'status': 'INVALID_ARGUMENT'}}
2025-11-11 15:02:28,757 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Starting parallel extraction
2025-11-11 15:02:28,758 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: データ・モデル
2025-11-11 15:02:29,464 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 6 dependencies
2025-11-11 15:02:29,465 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 3, 'relates': 3}
2025-11-11 15:02:29,466 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] データ・モデル completed in 45.68s - 5 functions, 6 dependencies
2025-11-11 15:02:29,467 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: API・バックエンド
2025-11-11 15:02:33,680 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 5 functions using LangChain
2025-11-11 15:02:33,705 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 5 functions
2025-11-11 15:02:33,705 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 5}
2025-11-11 15:02:37,743 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 6 dependencies
2025-11-11 15:02:37,745 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 3, 'relates': 3}
2025-11-11 15:02:37,746 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] データ・モデル completed in 58.10s - 5 functions, 6 dependencies
2025-11-11 15:02:37,746 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: API・バックエンド
2025-11-11 15:02:40,236 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 5 functions using LangChain
2025-11-11 15:02:42,269 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 10 dependencies
2025-11-11 15:02:42,270 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 10}
2025-11-11 15:02:42,271 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] API・バックエンド completed in 83.27s - 8 functions, 10 dependencies
2025-11-11 15:02:42,271 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: UI・画面
2025-11-11 15:02:42,565 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 5 functions
2025-11-11 15:02:42,566 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'data': 5}
2025-11-11 15:02:45,789 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 5 dependencies
2025-11-11 15:02:45,790 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 5}
2025-11-11 15:02:45,791 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] データ・モデル completed in 43.54s - 5 functions, 5 dependencies
2025-11-11 15:02:45,793 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: API・バックエンド
2025-11-11 15:02:46,145 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 5 functions
2025-11-11 15:02:46,146 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'data': 5}
2025-11-11 15:02:52,733 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 6 functions using LangChain
2025-11-11 15:02:52,799 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 5 functions
2025-11-11 15:02:52,800 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 5}
2025-11-11 15:03:00,821 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 5 functions
2025-11-11 15:03:00,821 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 5}
2025-11-11 15:03:04,689 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 6 functions
2025-11-11 15:03:04,689 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'auth': 1, 'data': 3, 'logic': 2}
2025-11-11 15:03:04,704 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 7 functions using LangChain
2025-11-11 15:03:07,808 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 6 dependencies
2025-11-11 15:03:07,810 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 3, 'relates': 3}
2025-11-11 15:03:07,810 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] データ・モデル completed in 46.59s - 5 functions, 6 dependencies
2025-11-11 15:03:07,811 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: API・バックエンド
2025-11-11 15:03:12,610 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 7 functions
2025-11-11 15:03:12,611 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'ui': 7}
2025-11-11 15:03:18,108 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 6 functions
2025-11-11 15:03:18,109 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 5, 'Could': 1}
2025-11-11 15:03:18,635 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 6 dependencies
2025-11-11 15:03:18,636 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 4, 'relates': 2}
2025-11-11 15:03:18,636 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] データ・モデル completed in 49.88s - 5 functions, 6 dependencies
2025-11-11 15:03:18,637 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: API・バックエンド
2025-11-11 15:03:18,841 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 8 functions using LangChain
2025-11-11 15:03:21,872 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 8 functions using LangChain
2025-11-11 15:03:28,723 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 7 functions
2025-11-11 15:03:28,726 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 4, 'Should': 3}
2025-11-11 15:03:32,664 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 8 functions
2025-11-11 15:03:32,666 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'auth': 1, 'logic': 3, 'data': 4}
2025-11-11 15:03:33,552 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 7 functions using LangChain
2025-11-11 15:03:35,750 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 11 dependencies
2025-11-11 15:03:35,751 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 9, 'relates': 2}
2025-11-11 15:03:35,751 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] API・バックエンド completed in 66.28s - 6 functions, 11 dependencies
2025-11-11 15:03:35,752 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: UI・画面
2025-11-11 15:03:37,617 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 8 functions
2025-11-11 15:03:37,619 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'auth': 1, 'logic': 3, 'data': 4}
2025-11-11 15:03:42,956 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 7 functions
2025-11-11 15:03:42,957 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'auth': 1, 'logic': 3, 'data': 3}
2025-11-11 15:03:46,401 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 7 functions using LangChain
2025-11-11 15:03:49,497 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 9 dependencies
2025-11-11 15:03:49,499 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'blocks': 6, 'relates': 3}
2025-11-11 15:03:49,500 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] UI・画面 completed in 67.23s - 7 functions, 9 dependencies
2025-11-11 15:03:49,501 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Completed: 3 areas processed
2025-11-11 15:03:49,507 | INFO | hackthon_support_agent.BaseService | [MERGE] Merging results from all focus areas
2025-11-11 15:03:49,508 | INFO | hackthon_support_agent.BaseService | [MERGE] Merged: 20 unique functions, 25 dependencies
2025-11-11 15:03:49,510 | INFO | hackthon_support_agent.BaseService | [VALIDATION] Starting validation
2025-11-11 15:03:50,139 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 7 functions using LangChain
2025-11-11 15:03:58,213 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 8 functions
2025-11-11 15:03:58,214 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 8}
2025-11-11 15:03:58,266 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 7 functions
2025-11-11 15:03:58,267 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'auth': 2, 'logic': 3, 'data': 2}
2025-11-11 15:03:59,658 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 8 functions
2025-11-11 15:03:59,659 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 8}
2025-11-11 15:03:59,699 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 7 functions
2025-11-11 15:03:59,699 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'ui': 7}
2025-11-11 15:04:10,662 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 7 functions
2025-11-11 15:04:10,663 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 7}
2025-11-11 15:04:13,200 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 7 functions
2025-11-11 15:04:13,200 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 5, 'Should': 2}
2025-11-11 15:04:13,627 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 7 functions
2025-11-11 15:04:13,628 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 4, 'Should': 1, 'Could': 2}
2025-11-11 15:04:14,087 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 9 dependencies
2025-11-11 15:04:14,088 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 6, 'relates': 2, 'blocks': 1}
2025-11-11 15:04:14,088 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] API・バックエンド completed in 88.29s - 8 functions, 9 dependencies
2025-11-11 15:04:14,089 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: UI・画面
2025-11-11 15:04:15,604 | INFO | hackthon_support_agent.BaseService | [VALIDATION] Status: REJECT, Issues: 2
2025-11-11 15:04:15,606 | WARNING | hackthon_support_agent.BaseService | [VALIDATION] REJECT - Retry instruction: 循環依存が2箇所検出されました。システム設計の複雑性を軽減し、各機能の独立性を高めるため、以下の依存関係を見直してください。

1.  **AIモデル・設定データ管理、学習履歴データ管理、問題データ管理間の循環依存:**
    *   `問題データ管理` が `AIモデル・設定データ管理` を `requires` する依存関係を見直してください。問題データ自体はAIモデルの設定に直接依存するの
2025-11-11 15:04:15,610 | INFO | hackthon_support_agent.BaseService | [VALIDATION_DECISION] Validation rejected (iteration 0/3), retrying extraction
2025-11-11 15:04:15,619 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Starting parallel extraction
2025-11-11 15:04:15,620 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: データ・モデル
2025-11-11 15:04:23,934 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 10 dependencies
2025-11-11 15:04:23,936 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 10}
2025-11-11 15:04:23,937 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] API・バックエンド completed in 106.19s - 8 functions, 10 dependencies
2025-11-11 15:04:23,937 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: UI・画面
2025-11-11 15:04:25,294 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 8 dependencies
2025-11-11 15:04:25,295 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'blocks': 1, 'requires': 2, 'relates': 5}
2025-11-11 15:04:25,295 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] UI・画面 completed in 49.54s - 7 functions, 8 dependencies
2025-11-11 15:04:25,296 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Completed: 3 areas processed
2025-11-11 15:04:25,299 | INFO | hackthon_support_agent.BaseService | [MERGE] Merging results from all focus areas
2025-11-11 15:04:25,302 | INFO | hackthon_support_agent.BaseService | [MERGE] Merged: 18 unique functions, 25 dependencies
2025-11-11 15:04:25,304 | INFO | hackthon_support_agent.BaseService | [VALIDATION] Starting validation
2025-11-11 15:04:28,698 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 11 dependencies
2025-11-11 15:04:28,698 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 10, 'relates': 1}
2025-11-11 15:04:28,701 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] API・バックエンド completed in 80.89s - 7 functions, 11 dependencies
2025-11-11 15:04:28,702 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: UI・画面
2025-11-11 15:04:34,845 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 7 functions using LangChain
2025-11-11 15:04:37,869 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 5 functions using LangChain
2025-11-11 15:04:43,510 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 8 functions using LangChain
2025-11-11 15:04:43,799 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 10 dependencies
2025-11-11 15:04:43,800 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 10}
2025-11-11 15:04:43,801 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] API・バックエンド completed in 85.16s - 7 functions, 10 dependencies
2025-11-11 15:04:43,801 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: UI・画面
2025-11-11 15:04:46,117 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 7 functions
2025-11-11 15:04:46,119 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'ui': 7}
2025-11-11 15:04:47,153 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 6 functions using LangChain
2025-11-11 15:04:53,842 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 5 functions
2025-11-11 15:04:53,843 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'data': 5}
2025-11-11 15:04:55,843 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 8 functions
2025-11-11 15:04:55,844 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'ui': 8}
2025-11-11 15:04:57,853 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 6 functions
2025-11-11 15:04:57,854 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'ui': 6}
2025-11-11 15:04:58,857 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 7 functions
2025-11-11 15:04:58,858 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 4, 'Should': 2, 'Could': 1}
2025-11-11 15:04:59,022 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 7 functions using LangChain
2025-11-11 15:04:59,577 | INFO | hackthon_support_agent.BaseService | [VALIDATION] Status: REJECT, Issues: 1
2025-11-11 15:04:59,577 | WARNING | hackthon_support_agent.BaseService | [VALIDATION] REJECT - Retry instruction: 循環依存が検出されました。学習履歴データ管理、問題データ管理、AIモデル・設定データ管理の間の依存関係を見直し、循環を解消してください。例えば、AIモデル・設定データ管理が学習履歴データ管理に直接依存するのではなく、学習履歴データ管理からAIモデル・設定データ管理を参照する形にするなど、一方向の依存関係になるように設計を修正してください。
2025-11-11 15:04:59,579 | INFO | hackthon_support_agent.BaseService | [VALIDATION_DECISION] Validation rejected (iteration 0/3), retrying extraction
2025-11-11 15:04:59,588 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Starting parallel extraction
2025-11-11 15:04:59,588 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: データ・モデル
2025-11-11 15:05:10,569 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 5 functions
2025-11-11 15:05:10,570 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 4, 'Should': 1}
2025-11-11 15:05:11,655 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 7 functions
2025-11-11 15:05:11,656 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'ui': 7}
2025-11-11 15:05:12,182 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 8 functions
2025-11-11 15:05:12,184 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 5, 'Should': 3}
2025-11-11 15:05:15,658 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 6 functions
2025-11-11 15:05:15,659 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 4, 'Should': 2}
2025-11-11 15:05:16,717 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 14 dependencies
2025-11-11 15:05:16,718 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'blocks': 9, 'relates': 5}
2025-11-11 15:05:16,719 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] UI・画面 completed in 62.63s - 7 functions, 14 dependencies
2025-11-11 15:05:16,719 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Completed: 3 areas processed
2025-11-11 15:05:16,726 | INFO | hackthon_support_agent.BaseService | [MERGE] Merging results from all focus areas
2025-11-11 15:05:16,728 | INFO | hackthon_support_agent.BaseService | [MERGE] Merged: 20 unique functions, 28 dependencies
2025-11-11 15:05:16,731 | INFO | hackthon_support_agent.BaseService | [VALIDATION] Starting validation
2025-11-11 15:05:17,333 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 5 functions using LangChain
2025-11-11 15:05:25,958 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 5 functions
2025-11-11 15:05:25,959 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'data': 5}
2025-11-11 15:05:27,324 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 7 functions
2025-11-11 15:05:27,325 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 4, 'Should': 3}
2025-11-11 15:05:31,190 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 6 dependencies
2025-11-11 15:05:31,191 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 4, 'relates': 2}
2025-11-11 15:05:31,192 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] データ・モデル completed in 75.57s - 5 functions, 6 dependencies
2025-11-11 15:05:31,192 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: API・バックエンド
2025-11-11 15:05:33,800 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 30 dependencies
2025-11-11 15:05:33,801 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'blocks': 12, 'requires': 8, 'relates': 10}
2025-11-11 15:05:33,801 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] UI・画面 completed in 69.86s - 8 functions, 30 dependencies
2025-11-11 15:05:33,802 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Completed: 3 areas processed
2025-11-11 15:05:33,804 | INFO | hackthon_support_agent.BaseService | [MERGE] Merging results from all focus areas
2025-11-11 15:05:33,805 | INFO | hackthon_support_agent.BaseService | [MERGE] Merged: 21 unique functions, 46 dependencies
2025-11-11 15:05:33,808 | INFO | hackthon_support_agent.BaseService | [VALIDATION] Starting validation
2025-11-11 15:05:34,931 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 5 functions
2025-11-11 15:05:34,933 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 5}
2025-11-11 15:05:37,168 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 8 dependencies
2025-11-11 15:05:37,168 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 3, 'relates': 5}
2025-11-11 15:05:37,169 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] UI・画面 completed in 68.47s - 6 functions, 8 dependencies
2025-11-11 15:05:37,169 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Completed: 3 areas processed
2025-11-11 15:05:37,171 | INFO | hackthon_support_agent.BaseService | [MERGE] Merging results from all focus areas
2025-11-11 15:05:37,172 | INFO | hackthon_support_agent.BaseService | [MERGE] Merged: 18 unique functions, 25 dependencies
2025-11-11 15:05:37,175 | INFO | hackthon_support_agent.BaseService | [VALIDATION] Starting validation
2025-11-11 15:05:46,310 | INFO | hackthon_support_agent.BaseService | [VALIDATION] Status: REJECT, Issues: 1
2025-11-11 15:05:46,313 | WARNING | hackthon_support_agent.BaseService | [VALIDATION] REJECT - Retry instruction: descriptionの平均文字数が87.86文字であり、推奨の100文字を下回っています。各機能のdescriptionをより詳細に記述し、平均文字数が100文字以上になるように修正してください。
2025-11-11 15:05:46,315 | INFO | hackthon_support_agent.BaseService | [VALIDATION_DECISION] Validation rejected (iteration 0/3), retrying extraction
2025-11-11 15:05:46,322 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Starting parallel extraction
2025-11-11 15:05:46,322 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: データ・モデル
2025-11-11 15:05:48,979 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 5 dependencies
2025-11-11 15:05:48,980 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 5}
2025-11-11 15:05:48,981 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] データ・モデル completed in 49.39s - 5 functions, 5 dependencies
2025-11-11 15:05:48,983 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: API・バックエンド
2025-11-11 15:05:49,795 | INFO | hackthon_support_agent.BaseService | [VALIDATION] Status: REJECT, Issues: 1
2025-11-11 15:05:49,796 | WARNING | hackthon_support_agent.BaseService | [VALIDATION] REJECT - Retry instruction: 循環依存が検出されました。`AI学習状況分析ロジック` が `学習履歴データ記録API` を `requires` し、かつ `学習履歴データ記録API` が `AI学習状況分析ロジック` に `relates` しているため、循環依存が発生しています。`AI学習状況分析ロジック` は、`学習履歴データ記録API` が蓄積する「学習履歴データ」に依存するべきであり、APIそのものに直接依存するべき
2025-11-11 15:05:49,797 | INFO | hackthon_support_agent.BaseService | [VALIDATION_DECISION] Validation rejected (iteration 0/3), retrying extraction
2025-11-11 15:05:49,799 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Starting parallel extraction
2025-11-11 15:05:49,801 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: データ・モデル
2025-11-11 15:05:50,463 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 15 dependencies
2025-11-11 15:05:50,464 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 9, 'blocks': 1, 'relates': 5}
2025-11-11 15:05:50,467 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] UI・画面 completed in 66.66s - 7 functions, 15 dependencies
2025-11-11 15:05:50,467 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Completed: 3 areas processed
2025-11-11 15:05:50,472 | INFO | hackthon_support_agent.BaseService | [MERGE] Merging results from all focus areas
2025-11-11 15:05:50,472 | INFO | hackthon_support_agent.BaseService | [MERGE] Merged: 19 unique functions, 31 dependencies
2025-11-11 15:05:50,476 | INFO | hackthon_support_agent.BaseService | [VALIDATION] Starting validation
2025-11-11 15:05:59,788 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 6 functions using LangChain
2025-11-11 15:06:02,993 | INFO | hackthon_support_agent.BaseService | [VALIDATION] Status: REJECT, Issues: 1
2025-11-11 15:06:02,994 | WARNING | hackthon_support_agent.BaseService | [VALIDATION] REJECT - Retry instruction: 以下の循環依存を解消してください: 学習履歴データ管理機能 -> AIモデル・設定データ管理機能 -> 問題データ管理機能 -> 学習履歴データ管理機能。これらの機能間の依存関係を見直し、単一方向の依存になるように設計を変更してください。
2025-11-11 15:06:02,996 | INFO | hackthon_support_agent.BaseService | [VALIDATION_DECISION] Validation rejected (iteration 0/3), retrying extraction
2025-11-11 15:06:03,004 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Starting parallel extraction
2025-11-11 15:06:03,005 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: データ・モデル
2025-11-11 15:06:08,610 | INFO | hackthon_support_agent.BaseService | [VALIDATION] Status: REJECT, Issues: 1
2025-11-11 15:06:08,610 | WARNING | hackthon_support_agent.BaseService | [VALIDATION] REJECT - Retry instruction: 循環依存が検出されました。以下の機能間に循環依存があります: 'AI動的問題生成API' -> 'AI学習状況分析・推奨API' -> '回答処理・学習履歴記録API' -> 'AI動的問題生成API'。特に、'AI動的問題生成API'が'AI学習状況分析・推奨API'を直接'requires'している点が問題です。'AI動的問題生成API'は'AI学習状況分析・推奨API'の分析結果を利用する形
2025-11-11 15:06:08,612 | INFO | hackthon_support_agent.BaseService | [VALIDATION_DECISION] Validation rejected (iteration 0/3), retrying extraction
2025-11-11 15:06:08,617 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Starting parallel extraction
2025-11-11 15:06:08,617 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: データ・モデル
2025-11-11 15:06:10,816 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 6 functions using LangChain
2025-11-11 15:06:11,836 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 6 functions
2025-11-11 15:06:11,837 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'auth': 1, 'data': 3, 'logic': 2}
2025-11-11 15:06:13,513 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 5 functions using LangChain
2025-11-11 15:06:18,558 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 5 functions
2025-11-11 15:06:18,559 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'data': 5}
2025-11-11 15:06:19,517 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 5 functions using LangChain
2025-11-11 15:06:22,774 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 7 functions using LangChain
2025-11-11 15:06:23,944 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 6 functions
2025-11-11 15:06:23,945 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'data': 6}
2025-11-11 15:06:26,215 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 6 functions
2025-11-11 15:06:26,216 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 4, 'Should': 1, 'Wont': 1}
2025-11-11 15:06:27,654 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 5 functions
2025-11-11 15:06:27,655 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'data': 5}
2025-11-11 15:06:29,980 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 5 functions using LangChain
2025-11-11 15:06:33,581 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 6 functions
2025-11-11 15:06:33,584 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 6}
2025-11-11 15:06:33,658 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 5 functions
2025-11-11 15:06:33,659 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 5}
2025-11-11 15:06:34,977 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 7 functions
2025-11-11 15:06:34,981 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'auth': 1, 'data': 3, 'logic': 3}
2025-11-11 15:06:38,649 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 5 functions
2025-11-11 15:06:38,650 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'data': 5}
2025-11-11 15:06:39,716 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 5 functions
2025-11-11 15:06:39,717 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 5}
2025-11-11 15:06:43,849 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 12 dependencies
2025-11-11 15:06:43,851 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 10, 'relates': 2}
2025-11-11 15:06:43,853 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] API・バックエンド completed in 72.66s - 6 functions, 12 dependencies
2025-11-11 15:06:43,854 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: UI・画面
2025-11-11 15:06:47,815 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 7 dependencies
2025-11-11 15:06:47,816 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 7}
2025-11-11 15:06:47,818 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] データ・モデル completed in 58.02s - 6 functions, 7 dependencies
2025-11-11 15:06:47,818 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: API・バックエンド
2025-11-11 15:06:49,929 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 5 dependencies
2025-11-11 15:06:49,929 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 4, 'relates': 1}
2025-11-11 15:06:49,930 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] データ・モデル completed in 63.61s - 5 functions, 5 dependencies
2025-11-11 15:06:49,931 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: API・バックエンド
2025-11-11 15:06:50,338 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 5 functions
2025-11-11 15:06:50,339 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 5}
2025-11-11 15:06:51,766 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 8 dependencies
2025-11-11 15:06:51,767 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 7, 'relates': 1}
2025-11-11 15:06:51,768 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] データ・モデル completed in 43.15s - 5 functions, 8 dependencies
2025-11-11 15:06:51,768 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: API・バックエンド
2025-11-11 15:06:51,807 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 7 functions
2025-11-11 15:06:51,808 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 6, 'Should': 1}
2025-11-11 15:07:01,840 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 7 functions using LangChain
2025-11-11 15:07:01,958 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 5 dependencies
2025-11-11 15:07:01,959 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 4, 'relates': 1}
2025-11-11 15:07:01,960 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] データ・モデル completed in 58.95s - 5 functions, 5 dependencies
2025-11-11 15:07:01,961 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: API・バックエンド
2025-11-11 15:07:10,141 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 9 dependencies
2025-11-11 15:07:10,142 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 8, 'relates': 1}
2025-11-11 15:07:10,143 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] API・バックエンド completed in 81.16s - 7 functions, 9 dependencies
2025-11-11 15:07:10,144 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: UI・画面
2025-11-11 15:07:11,049 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 6 functions using LangChain
2025-11-11 15:07:12,258 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 7 functions
2025-11-11 15:07:12,259 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'auth': 1, 'ui': 6}
2025-11-11 15:07:17,360 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 7 functions using LangChain
2025-11-11 15:07:20,224 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 7 functions using LangChain
2025-11-11 15:07:23,601 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 6 functions
2025-11-11 15:07:23,602 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'auth': 1, 'logic': 3, 'data': 2}
2025-11-11 15:07:24,363 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 7 functions using LangChain
2025-11-11 15:07:25,486 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 7 functions
2025-11-11 15:07:25,487 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 4, 'Should': 3}
2025-11-11 15:07:29,577 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 7 functions
2025-11-11 15:07:29,579 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'auth': 1, 'data': 3, 'logic': 3}
2025-11-11 15:07:33,368 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 7 functions
2025-11-11 15:07:33,370 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'auth': 1, 'data': 4, 'logic': 2}
2025-11-11 15:07:34,364 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 7 functions using LangChain
2025-11-11 15:07:36,709 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 7 functions
2025-11-11 15:07:36,710 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'auth': 1, 'logic': 2, 'data': 4}
2025-11-11 15:07:39,414 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 6 functions
2025-11-11 15:07:39,415 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 5, 'Should': 1}
2025-11-11 15:07:41,743 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 7 functions
2025-11-11 15:07:41,744 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'ui': 7}
2025-11-11 15:07:43,920 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 7 functions
2025-11-11 15:07:43,920 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 7}
2025-11-11 15:07:45,676 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 12 dependencies
2025-11-11 15:07:45,678 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'blocks': 7, 'relates': 5}
2025-11-11 15:07:45,679 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] UI・画面 completed in 61.82s - 7 functions, 12 dependencies
2025-11-11 15:07:45,679 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Completed: 3 areas processed
2025-11-11 15:07:45,703 | INFO | hackthon_support_agent.BaseService | [MERGE] Merging results from all focus areas
2025-11-11 15:07:45,704 | INFO | hackthon_support_agent.BaseService | [MERGE] Merged: 18 unique functions, 30 dependencies
2025-11-11 15:07:45,706 | INFO | hackthon_support_agent.BaseService | [VALIDATION] Starting validation
2025-11-11 15:07:47,916 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 7 functions
2025-11-11 15:07:47,917 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 6, 'Could': 1}
2025-11-11 15:07:56,142 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 7 functions
2025-11-11 15:07:56,145 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 6, 'Should': 1}
2025-11-11 15:07:57,438 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 7 functions
2025-11-11 15:07:57,439 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 4, 'Should': 1, 'Could': 2}
2025-11-11 15:07:57,720 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 10 dependencies
2025-11-11 15:07:57,721 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 10}
2025-11-11 15:07:57,722 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] API・バックエンド completed in 67.79s - 6 functions, 10 dependencies
2025-11-11 15:07:57,724 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: UI・画面
2025-11-11 15:08:08,410 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 14 dependencies
2025-11-11 15:08:08,412 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 8, 'relates': 6}
2025-11-11 15:08:08,413 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] API・バックエンド completed in 76.64s - 7 functions, 14 dependencies
2025-11-11 15:08:08,414 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: UI・画面
2025-11-11 15:08:09,057 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 10 dependencies
2025-11-11 15:08:09,058 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 5, 'blocks': 2, 'relates': 3}
2025-11-11 15:08:09,059 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] API・バックエンド completed in 81.24s - 7 functions, 10 dependencies
2025-11-11 15:08:09,060 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: UI・画面
2025-11-11 15:08:14,141 | INFO | hackthon_support_agent.BaseService | [VALIDATION] Status: REJECT, Issues: 2
2025-11-11 15:08:14,142 | WARNING | hackthon_support_agent.BaseService | [VALIDATION] REJECT - Retry instruction: 以下の問題により、機能設計をREJECTします。

1.  **循環依存の解消**:
    *   `学習履歴データ管理` -> `問題データ管理` -> `AIモデル・設定データ管理` -> `学習履歴データ管理` という循環依存が検出されました。
    *   機能間の依存関係を見直し、この循環を解消してください。特に、`AIモデル・設定データ管理`が`学習履歴データ管理`に「relate
2025-11-11 15:08:14,145 | INFO | hackthon_support_agent.BaseService | [VALIDATION_DECISION] Validation rejected (iteration 0/3), retrying extraction
2025-11-11 15:08:14,154 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Starting parallel extraction
2025-11-11 15:08:14,155 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: データ・モデル
2025-11-11 15:08:14,912 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 11 dependencies
2025-11-11 15:08:14,913 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 10, 'relates': 1}
2025-11-11 15:08:14,913 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] API・バックエンド completed in 72.95s - 7 functions, 11 dependencies
2025-11-11 15:08:14,914 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: UI・画面
2025-11-11 15:08:15,589 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 21 dependencies
2025-11-11 15:08:15,590 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'blocks': 8, 'requires': 7, 'relates': 6}
2025-11-11 15:08:15,590 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] UI・画面 completed in 65.45s - 7 functions, 21 dependencies
2025-11-11 15:08:15,591 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Completed: 3 areas processed
2025-11-11 15:08:15,598 | INFO | hackthon_support_agent.BaseService | [MERGE] Merging results from all focus areas
2025-11-11 15:08:15,600 | INFO | hackthon_support_agent.BaseService | [MERGE] Merged: 19 unique functions, 35 dependencies
2025-11-11 15:08:15,602 | INFO | hackthon_support_agent.BaseService | [VALIDATION] Starting validation
2025-11-11 15:08:19,082 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 8 functions using LangChain
2025-11-11 15:08:27,775 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 8 functions using LangChain
2025-11-11 15:08:28,736 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 5 functions using LangChain
2025-11-11 15:08:29,609 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 8 functions using LangChain
2025-11-11 15:08:29,714 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 8 functions using LangChain
2025-11-11 15:08:36,063 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 8 functions
2025-11-11 15:08:36,066 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'ui': 8}
2025-11-11 15:08:36,164 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 8 functions
2025-11-11 15:08:36,165 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'ui': 8}
2025-11-11 15:08:36,367 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 8 functions
2025-11-11 15:08:36,368 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'ui': 8}
2025-11-11 15:08:39,020 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 5 functions
2025-11-11 15:08:39,021 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'data': 5}
2025-11-11 15:08:42,081 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 8 functions
2025-11-11 15:08:42,081 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'ui': 8}
2025-11-11 15:08:47,629 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 5 functions
2025-11-11 15:08:47,631 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 5}
2025-11-11 15:08:50,000 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 8 functions
2025-11-11 15:08:50,000 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 5, 'Should': 1, 'Could': 2}
2025-11-11 15:08:50,489 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 8 functions
2025-11-11 15:08:50,490 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 5, 'Should': 3}
2025-11-11 15:08:52,225 | INFO | hackthon_support_agent.BaseService | [VALIDATION] Status: PASS, Issues: 0
2025-11-11 15:08:52,228 | INFO | hackthon_support_agent.BaseService | [VALIDATION_DECISION] Validation passed, proceeding to persistence
2025-11-11 15:08:52,234 | INFO | hackthon_support_agent.BaseService | [PERSISTENCE] Saving to database
2025-11-11 15:08:52,288 | INFO | hackthon_support_agent.BaseService | [PERSISTENCE] Saved 19 functions and 35 dependencies to DB
2025-11-11 15:08:52,291 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Workflow completed in 428.78s
2025-11-11 15:08:55,671 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 8 functions
2025-11-11 15:08:55,672 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 5, 'Should': 3}
2025-11-11 15:08:56,787 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 8 functions
2025-11-11 15:08:56,788 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 5, 'Should': 3}
2025-11-11 15:09:03,052 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 5 dependencies
2025-11-11 15:09:03,053 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 4, 'relates': 1}
2025-11-11 15:09:03,054 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] データ・モデル completed in 48.90s - 5 functions, 5 dependencies
2025-11-11 15:09:03,054 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: API・バックエンド
2025-11-11 15:09:07,174 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 16 dependencies
2025-11-11 15:09:07,176 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'blocks': 3, 'requires': 3, 'relates': 10}
2025-11-11 15:09:07,177 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] UI・画面 completed in 69.45s - 8 functions, 16 dependencies
2025-11-11 15:09:07,178 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Completed: 3 areas processed
2025-11-11 15:09:07,182 | INFO | hackthon_support_agent.BaseService | [MERGE] Merging results from all focus areas
2025-11-11 15:09:07,184 | INFO | hackthon_support_agent.BaseService | [MERGE] Merged: 19 unique functions, 31 dependencies
2025-11-11 15:09:07,187 | INFO | hackthon_support_agent.BaseService | [VALIDATION] Starting validation
2025-11-11 15:09:15,278 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 17 dependencies
2025-11-11 15:09:15,279 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'blocks': 6, 'requires': 5, 'relates': 6}
2025-11-11 15:09:15,280 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] UI・画面 completed in 66.87s - 8 functions, 17 dependencies
2025-11-11 15:09:15,281 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Completed: 3 areas processed
2025-11-11 15:09:15,286 | INFO | hackthon_support_agent.BaseService | [MERGE] Merging results from all focus areas
2025-11-11 15:09:15,286 | INFO | hackthon_support_agent.BaseService | [MERGE] Merged: 20 unique functions, 39 dependencies
2025-11-11 15:09:15,289 | INFO | hackthon_support_agent.BaseService | [VALIDATION] Starting validation
2025-11-11 15:09:21,723 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 13 dependencies
2025-11-11 15:09:21,724 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'blocks': 5, 'relates': 4, 'requires': 4}
2025-11-11 15:09:21,725 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] UI・画面 completed in 72.66s - 8 functions, 13 dependencies
2025-11-11 15:09:21,726 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Completed: 3 areas processed
2025-11-11 15:09:21,731 | INFO | hackthon_support_agent.BaseService | [MERGE] Merging results from all focus areas
2025-11-11 15:09:21,732 | INFO | hackthon_support_agent.BaseService | [MERGE] Merged: 21 unique functions, 30 dependencies
2025-11-11 15:09:21,735 | INFO | hackthon_support_agent.BaseService | [VALIDATION] Starting validation
2025-11-11 15:09:30,640 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 6 functions using LangChain
2025-11-11 15:09:34,124 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 17 dependencies
2025-11-11 15:09:34,125 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'blocks': 8, 'relates': 6, 'requires': 3}
2025-11-11 15:09:34,126 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] UI・画面 completed in 79.21s - 8 functions, 17 dependencies
2025-11-11 15:09:34,127 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Completed: 3 areas processed
2025-11-11 15:09:34,159 | INFO | hackthon_support_agent.BaseService | [MERGE] Merging results from all focus areas
2025-11-11 15:09:34,161 | INFO | hackthon_support_agent.BaseService | [MERGE] Merged: 20 unique functions, 33 dependencies
2025-11-11 15:09:34,202 | INFO | hackthon_support_agent.BaseService | [VALIDATION] Starting validation
2025-11-11 15:09:35,247 | INFO | hackthon_support_agent.BaseService | [VALIDATION] Status: REJECT, Issues: 1
2025-11-11 15:09:35,248 | WARNING | hackthon_support_agent.BaseService | [VALIDATION] REJECT - Retry instruction: AIモデル・設定データ管理機能、学習履歴データ管理機能、問題データ管理機能の間に循環依存が検出されました。具体的には、`AIモデル・設定データ管理機能`が`学習履歴データ管理機能`に、`学習履歴データ管理機能`が`問題データ管理機能`に、そして`問題データ管理機能`が`AIモデル・設定データ管理機能`に依存しています。

この循環依存はシステムの結合度を高め、変更やテストを困難にする可能性がありま
2025-11-11 15:09:35,250 | INFO | hackthon_support_agent.BaseService | [VALIDATION_DECISION] Validation rejected (iteration 0/3), retrying extraction
2025-11-11 15:09:35,255 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Starting parallel extraction
2025-11-11 15:09:35,256 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: データ・モデル
2025-11-11 15:09:40,733 | INFO | hackthon_support_agent.BaseService | [VALIDATION] Status: PASS, Issues: 0
2025-11-11 15:09:40,735 | INFO | hackthon_support_agent.BaseService | [VALIDATION_DECISION] Validation passed, proceeding to persistence
2025-11-11 15:09:40,737 | INFO | hackthon_support_agent.BaseService | [PERSISTENCE] Saving to database
2025-11-11 15:09:40,758 | ERROR | hackthon_support_agent.BaseService | [PERSISTENCE] Persistence failed: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "structured_functions_project_id_function_code_key"
DETAIL:  Key (project_id, function_code)=(35fa8b5e-6f47-4b3c-9c57-48625e9af0fa, F001) already exists.

[SQL: INSERT INTO structured_functions (function_id, project_id, function_code, function_name, description, category, priority, source_doc_id, extraction_confidence, order_index) VALUES (%(function_id)s::UUID, %(project_id)s::UUID, %(function_code)s, %(function_name)s, %(description)s, %(category)s, %(priority)s, %(source_doc_id)s::UUID, %(extraction_confidence)s, %(order_index)s) RETURNING structured_functions.created_at]
[parameters: {'function_id': UUID('9846a396-574e-4e8a-88ca-21a52e5142da'), 'project_id': '35fa8b5e-6f47-4b3c-9c57-48625e9af0fa', 'function_code': 'F001', 'function_name': 'ユーザーデータ管理', 'description': 'ユーザーのアカウント情報(ID,メールアドレス,パスワードハッシュなど)およびプロフィール情報(学年,氏名など)を安全に保存,更新,削除できる機能。新規ユーザーの登録情報がデータベースに保存され、ログイン時の認証情報照合や、ユーザー情報の更新・削除が可能である。これにより、ユーザーは自身の情報を管理し、システムはユーザー認証とパーソナライズされたサービス提供の基盤を確保する。', 'category': 'data', 'priority': 'Must', 'source_doc_id': None, 'extraction_confidence': 0.8, 'order_index': 1}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
2025-11-11 15:09:40,762 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Workflow completed in 432.25s
2025-11-11 15:09:41,479 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 6 functions
2025-11-11 15:09:41,480 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'auth': 1, 'data': 2, 'logic': 3}
2025-11-11 15:09:49,308 | INFO | hackthon_support_agent.BaseService | [VALIDATION] Status: PASS, Issues: 0
2025-11-11 15:09:49,316 | INFO | hackthon_support_agent.BaseService | [VALIDATION_DECISION] Validation passed, proceeding to persistence
2025-11-11 15:09:49,327 | INFO | hackthon_support_agent.BaseService | [PERSISTENCE] Saving to database
2025-11-11 15:09:49,337 | ERROR | hackthon_support_agent.BaseService | [PERSISTENCE] Persistence failed: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "structured_functions_project_id_function_code_key"
DETAIL:  Key (project_id, function_code)=(35fa8b5e-6f47-4b3c-9c57-48625e9af0fa, F001) already exists.

[SQL: INSERT INTO structured_functions (function_id, project_id, function_code, function_name, description, category, priority, source_doc_id, extraction_confidence, order_index) VALUES (%(function_id)s::UUID, %(project_id)s::UUID, %(function_code)s, %(function_name)s, %(description)s, %(category)s, %(priority)s, %(source_doc_id)s::UUID, %(extraction_confidence)s, %(order_index)s) RETURNING structured_functions.created_at]
[parameters: {'function_id': UUID('476b55dc-080c-4900-ac86-117e01414248'), 'project_id': '35fa8b5e-6f47-4b3c-9c57-48625e9af0fa', 'function_code': 'F001', 'function_name': '学習履歴記録', 'description': 'ユーザーが問題を解答するたびに、その正誤、回答にかかった時間、学習した単元、学習進捗などの情報を詳細に抽出し、AI分析のためのデータとしてデータベースに永続的に蓄積する機能を提供する。具体的には、問題解答ごとにユーザーID, 問題ID, 回答内容, 正誤, 回答時間が記録され、特定の単元や学習セッションの開始・終了日時も記録される。', 'category': 'data', 'priority': 'Must', 'source_doc_id': None, 'extraction_confidence': 0.8, 'order_index': 1}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
2025-11-11 15:09:49,344 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Workflow completed in 467.35s
2025-11-11 15:09:50,295 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 5 functions using LangChain
2025-11-11 15:09:59,548 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 6 functions
2025-11-11 15:09:59,550 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 4, 'Could': 1, 'Wont': 1}
2025-11-11 15:10:02,677 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 5 functions
2025-11-11 15:10:02,677 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'data': 5}
2025-11-11 15:10:07,203 | INFO | hackthon_support_agent.BaseService | [VALIDATION] Status: REJECT, Issues: 1
2025-11-11 15:10:07,204 | WARNING | hackthon_support_agent.BaseService | [VALIDATION] REJECT - Retry instruction: statusがREJECTです。以下の問題が見つかりました:
- 循環依存: 「問題生成・解答処理API」と「学習履歴・状況分析API」の間に循環依存が見られます。

「問題生成・解答処理API」が「学習履歴・状況分析API」を`requires`し、一方で「学習履歴・状況分析API」が「問題生成・解答処理API」を`relates`しています。この依存関係を見直し、一方向の依存になるように設計を
2025-11-11 15:10:07,205 | INFO | hackthon_support_agent.BaseService | [VALIDATION_DECISION] Validation rejected (iteration 0/3), retrying extraction
2025-11-11 15:10:07,212 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Starting parallel extraction
2025-11-11 15:10:07,213 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: データ・モデル
2025-11-11 15:10:17,366 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 9 dependencies
2025-11-11 15:10:17,367 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 7, 'relates': 2}
2025-11-11 15:10:17,367 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] API・バックエンド completed in 74.31s - 6 functions, 9 dependencies
2025-11-11 15:10:17,368 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: UI・画面
2025-11-11 15:10:19,635 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 5 functions using LangChain
2025-11-11 15:10:21,591 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 5 functions
2025-11-11 15:10:21,594 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 5}
2025-11-11 15:10:28,620 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 5 functions
2025-11-11 15:10:28,622 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'data': 5}
2025-11-11 15:10:30,602 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 8 functions using LangChain
2025-11-11 15:10:36,712 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 6 dependencies
2025-11-11 15:10:36,714 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 2, 'relates': 4}
2025-11-11 15:10:36,715 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] データ・モデル completed in 61.46s - 5 functions, 6 dependencies
2025-11-11 15:10:36,715 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: API・バックエンド
2025-11-11 15:10:40,028 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 5 functions
2025-11-11 15:10:40,030 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 5}
2025-11-11 15:10:52,028 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 8 functions
2025-11-11 15:10:52,030 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'auth': 1, 'ui': 7}
2025-11-11 15:11:02,665 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 6 dependencies
2025-11-11 15:11:02,668 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 5, 'relates': 1}
2025-11-11 15:11:02,670 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] データ・モデル completed in 55.46s - 5 functions, 6 dependencies
2025-11-11 15:11:02,670 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: API・バックエンド
2025-11-11 15:11:05,480 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 8 functions
2025-11-11 15:11:05,482 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 5, 'Should': 3}
2025-11-11 15:11:09,754 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 8 functions using LangChain
2025-11-11 15:11:25,999 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 8 functions
2025-11-11 15:11:26,001 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'auth': 1, 'logic': 3, 'data': 4}
2025-11-11 15:11:26,776 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 7 functions using LangChain
2025-11-11 15:11:29,850 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 11 dependencies
2025-11-11 15:11:29,851 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'blocks': 7, 'relates': 3, 'requires': 1}
2025-11-11 15:11:29,851 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] UI・画面 completed in 72.48s - 8 functions, 11 dependencies
2025-11-11 15:11:29,852 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Completed: 3 areas processed
2025-11-11 15:11:29,859 | INFO | hackthon_support_agent.BaseService | [MERGE] Merging results from all focus areas
2025-11-11 15:11:29,860 | INFO | hackthon_support_agent.BaseService | [MERGE] Merged: 19 unique functions, 25 dependencies
2025-11-11 15:11:29,861 | INFO | hackthon_support_agent.BaseService | [VALIDATION] Starting validation
2025-11-11 15:11:40,642 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 7 functions
2025-11-11 15:11:40,643 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'auth': 1, 'data': 2, 'logic': 3, 'deployment': 1}
2025-11-11 15:11:46,762 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 8 functions
2025-11-11 15:11:46,765 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 7, 'Should': 1}
2025-11-11 15:11:55,683 | INFO | hackthon_support_agent.BaseService | [VALIDATION] Status: REJECT, Issues: 3
2025-11-11 15:11:55,685 | WARNING | hackthon_support_agent.BaseService | [VALIDATION] REJECT - Retry instruction: 機能構造に問題が見つかりました。以下の点を修正してください。

1. **循環依存の解消**: `四択問題解答画面`と`正誤判定表示画面`の間に循環依存が検出されました。依存関係を単方向にするか、機能を再設計してください。
2. **機能記述の具体化**: 機能の説明の平均文字数が95.57文字と、推奨される100文字を下回っています。特に以下の機能の説明をより詳細に記述してください: `正誤判定
2025-11-11 15:11:55,687 | INFO | hackthon_support_agent.BaseService | [VALIDATION_DECISION] Validation rejected (iteration 0/3), retrying extraction
2025-11-11 15:11:55,693 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Starting parallel extraction
2025-11-11 15:11:55,694 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: データ・モデル
2025-11-11 15:11:57,507 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 7 functions
2025-11-11 15:11:57,510 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 5, 'Should': 1, 'Could': 1}
2025-11-11 15:12:08,372 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 5 functions using LangChain
2025-11-11 15:12:10,013 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 9 dependencies
2025-11-11 15:12:10,014 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 9}
2025-11-11 15:12:10,015 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] API・バックエンド completed in 93.30s - 8 functions, 9 dependencies
2025-11-11 15:12:10,016 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: UI・画面
2025-11-11 15:12:16,001 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 5 functions
2025-11-11 15:12:16,002 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'data': 5}
2025-11-11 15:12:23,993 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 17 dependencies
2025-11-11 15:12:23,994 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 10, 'relates': 7}
2025-11-11 15:12:23,995 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] API・バックエンド completed in 81.32s - 7 functions, 17 dependencies
2025-11-11 15:12:23,995 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: UI・画面
2025-11-11 15:12:26,479 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 5 functions
2025-11-11 15:12:26,481 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 5}
2025-11-11 15:12:28,677 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 7 functions using LangChain
2025-11-11 15:12:36,591 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 4 dependencies
2025-11-11 15:12:36,591 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 4}
2025-11-11 15:12:36,592 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] データ・モデル completed in 40.90s - 5 functions, 4 dependencies
2025-11-11 15:12:36,593 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: API・バックエンド
2025-11-11 15:12:38,263 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 7 functions using LangChain
2025-11-11 15:12:42,168 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 7 functions
2025-11-11 15:12:42,168 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'ui': 7}
2025-11-11 15:12:50,793 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 7 functions
2025-11-11 15:12:50,795 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'ui': 7}
2025-11-11 15:12:59,258 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 7 functions
2025-11-11 15:12:59,259 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 4, 'Should': 3}
2025-11-11 15:13:04,851 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 7 functions
2025-11-11 15:13:04,852 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 4, 'Should': 1, 'Could': 2}
2025-11-11 15:13:11,676 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 8 functions using LangChain
2025-11-11 15:13:13,490 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 9 dependencies
2025-11-11 15:13:13,491 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'blocks': 8, 'requires': 1}
2025-11-11 15:13:13,492 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] UI・画面 completed in 63.48s - 7 functions, 9 dependencies
2025-11-11 15:13:13,492 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Completed: 3 areas processed
2025-11-11 15:13:13,501 | INFO | hackthon_support_agent.BaseService | [MERGE] Merging results from all focus areas
2025-11-11 15:13:13,502 | INFO | hackthon_support_agent.BaseService | [MERGE] Merged: 20 unique functions, 24 dependencies
2025-11-11 15:13:13,505 | INFO | hackthon_support_agent.BaseService | [VALIDATION] Starting validation
2025-11-11 15:13:25,172 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 17 dependencies
2025-11-11 15:13:25,174 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 4, 'blocks': 4, 'relates': 9}
2025-11-11 15:13:25,175 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] UI・画面 completed in 61.18s - 7 functions, 17 dependencies
2025-11-11 15:13:25,176 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Completed: 3 areas processed
2025-11-11 15:13:25,184 | INFO | hackthon_support_agent.BaseService | [MERGE] Merging results from all focus areas
2025-11-11 15:13:25,184 | INFO | hackthon_support_agent.BaseService | [MERGE] Merged: 19 unique functions, 40 dependencies
2025-11-11 15:13:25,187 | INFO | hackthon_support_agent.BaseService | [VALIDATION] Starting validation
2025-11-11 15:13:26,824 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 8 functions
2025-11-11 15:13:26,825 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'auth': 1, 'data': 4, 'logic': 3}
2025-11-11 15:13:42,964 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 8 functions
2025-11-11 15:13:42,965 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 7, 'Could': 1}
2025-11-11 15:13:45,865 | INFO | hackthon_support_agent.BaseService | [VALIDATION] Status: REJECT, Issues: 1
2025-11-11 15:13:45,867 | WARNING | hackthon_support_agent.BaseService | [VALIDATION] REJECT - Retry instruction: 循環依存が検出されました。以下の機能間の依存関係を見直し、一方向の依存関係に修正してください: 問題データCRUD と AIモデル・設定データ管理。
2025-11-11 15:13:45,870 | INFO | hackthon_support_agent.BaseService | [VALIDATION_DECISION] Validation rejected (iteration 0/3), retrying extraction
2025-11-11 15:13:45,894 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Starting parallel extraction
2025-11-11 15:13:45,895 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: データ・モデル
2025-11-11 15:13:48,592 | INFO | hackthon_support_agent.BaseService | [VALIDATION] Status: PASS, Issues: 0
2025-11-11 15:13:48,593 | INFO | hackthon_support_agent.BaseService | [VALIDATION_DECISION] Validation passed, proceeding to persistence
2025-11-11 15:13:48,595 | INFO | hackthon_support_agent.BaseService | [PERSISTENCE] Saving to database
2025-11-11 15:13:48,602 | ERROR | hackthon_support_agent.BaseService | [PERSISTENCE] Persistence failed: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "structured_functions_project_id_function_code_key"
DETAIL:  Key (project_id, function_code)=(35fa8b5e-6f47-4b3c-9c57-48625e9af0fa, F001) already exists.

[SQL: INSERT INTO structured_functions (function_id, project_id, function_code, function_name, description, category, priority, source_doc_id, extraction_confidence, order_index) VALUES (%(function_id)s::UUID, %(project_id)s::UUID, %(function_code)s, %(function_name)s, %(description)s, %(category)s, %(priority)s, %(source_doc_id)s::UUID, %(extraction_confidence)s, %(order_index)s) RETURNING structured_functions.created_at]
[parameters: {'function_id': UUID('d44fc685-18ee-47aa-9de5-d5a03cbbefcf'), 'project_id': '35fa8b5e-6f47-4b3c-9c57-48625e9af0fa', 'function_code': 'F001', 'function_name': 'ユーザーデータCRUD管理', 'description': 'ユーザーの新規登録時にアカウント情報（ID、メールアドレス、パスワードハッシュ）およびプロフィール情報（学年、氏名など）をデータベースに安全に保存する機能を提供する。また、ログイン時の認証情報照合、既存ユーザー情報の更新、および不要になったユーザー情報の削除といった一連のCRUD操作を管理するバックエンドAPIエンドポイント群と、それらを操作するための管理画面インターフェースを実装する。これにより、ユーザーの個人情報を一元的に管理し、システム全体で利用可能な状態に保つ。', 'category': 'data', 'priority': 'Must', 'source_doc_id': None, 'extraction_confidence': 0.8, 'order_index': 1}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
2025-11-11 15:13:48,606 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Workflow completed in 729.21s
2025-11-11 15:14:04,174 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 5 functions using LangChain
2025-11-11 15:14:04,567 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 15 dependencies
2025-11-11 15:14:04,567 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 12, 'relates': 3}
2025-11-11 15:14:04,568 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] API・バックエンド completed in 87.97s - 8 functions, 15 dependencies
2025-11-11 15:14:04,569 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: UI・画面
2025-11-11 15:14:19,021 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 5 functions
2025-11-11 15:14:19,022 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'data': 5}
2025-11-11 15:14:21,502 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 7 functions using LangChain
2025-11-11 15:45:03,242 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 15:45:07,260 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 15:45:20,295 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-11-11 15:45:20,298 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 15:45:20,299 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 15:45:20,323 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 15:45:20,324 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 15:45:20,326 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 15:45:20,326 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 15:45:20,328 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 15:45:20,329 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 15:45:20,331 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 15:45:20,331 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-11-11 15:45:20,331 | DEBUG | hackthon_support_agent.QuestionService | Generating questions for project_id: 53a1678d-be0d-4f55-a6b6-d8da5d897069 with idea_prompt: プロジェクトタイトル: オンライン学習プラットフォーム
プロジェクトアイディア: 学生の学力と得意不得意に合わせたAIを用いた動的な課題作成サービス
期間: 2025-11-11 〜 2025-12-11 00:44
2025-11-11 15:45:20,332 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-11-11 15:45:42,243 | INFO | hackthon_support_agent.QuestionService | Generated 7 questions for project_id: 53a1678d-be0d-4f55-a6b6-d8da5d897069
2025-11-11 15:45:42,450 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-11-11 15:45:42,472 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 15:45:42,484 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 15:45:42,547 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 15:45:42,548 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 15:45:42,551 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 15:45:42,551 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 15:45:42,554 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 15:45:42,555 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 15:45:42,558 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 15:45:42,559 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-11-11 15:45:48,085 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-11-11 15:45:48,088 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 15:45:48,089 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 15:45:48,095 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 15:45:48,096 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 15:45:48,098 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 15:45:48,099 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 15:45:48,101 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 15:45:48,101 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 15:45:48,103 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 15:45:48,103 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-11-11 15:45:48,232 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.generate_summary_document'
2025-11-11 15:46:05,516 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-11-11 15:46:05,520 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 15:46:05,520 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 15:46:05,528 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 15:46:05,529 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 15:46:05,532 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 15:46:05,533 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 15:46:05,535 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 15:46:05,536 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 15:46:05,539 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 15:46:05,540 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-11-11 15:46:06,758 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-11-11 15:46:06,763 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 15:46:06,765 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 15:46:06,768 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 15:46:06,768 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 15:46:06,780 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 15:46:06,783 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 15:46:06,799 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 15:46:06,800 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 15:46:06,804 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 15:46:06,805 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-11-11 15:46:06,829 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-11-11 15:46:21,461 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-11-11 15:46:21,464 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 15:46:21,465 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 15:46:21,469 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 15:46:21,470 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 15:46:21,472 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 15:46:21,472 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 15:46:21,475 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 15:46:21,476 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 15:46:21,478 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 15:46:21,478 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-11-11 15:46:21,525 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: 53a1678d-be0d-4f55-a6b6-d8da5d897069
2025-11-11 15:46:21,530 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.evaluate_specification'
2025-11-11 15:46:22,531 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-11-11 15:46:22,533 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 15:46:22,534 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 15:46:22,537 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 15:46:22,537 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 15:46:22,540 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 15:46:22,540 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 15:46:22,542 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 15:46:22,543 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 15:46:22,544 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 15:46:22,544 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-11-11 15:46:22,589 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: 53a1678d-be0d-4f55-a6b6-d8da5d897069
2025-11-11 15:46:22,591 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.evaluate_specification'
2025-11-11 15:46:45,105 | DEBUG | hackthon_support_agent.FunctionService | Initializing BaseService (provider=google)
2025-11-11 15:46:45,109 | INFO | hackthon_support_agent.FunctionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 15:46:45,109 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 15:46:45,116 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 15:46:45,117 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 15:46:45,119 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 15:46:45,120 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 15:46:45,122 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 15:46:45,123 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 15:46:45,124 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 15:46:45,124 | DEBUG | hackthon_support_agent.FunctionService | LLMs initialized
2025-11-11 15:46:45,125 | DEBUG | hackthon_support_agent.FunctionService | Generating functional requirements for project_id: 53a1678d-be0d-4f55-a6b6-d8da5d897069
2025-11-11 15:46:45,129 | DEBUG | hackthon_support_agent.FunctionService | Fetching prompt 'function_service.generate_functional_requirements'
2025-11-11 15:47:38,963 | DEBUG | hackthon_support_agent.FunctionService | Saving functional requirements to project document: 53a1678d-be0d-4f55-a6b6-d8da5d897069
2025-11-11 15:48:46,752 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 15:48:46,757 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 15:48:46,758 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 15:48:46,768 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 15:48:46,769 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 15:48:46,771 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 15:48:46,771 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 15:48:46,779 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 15:48:46,780 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 15:48:46,782 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 15:48:46,782 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 15:48:46,863 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Fetching context for project: 53a1678d-be0d-4f55-a6b6-d8da5d897069
2025-11-11 15:48:46,866 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Starting workflow for project: 53a1678d-be0d-4f55-a6b6-d8da5d897069
2025-11-11 15:48:46,871 | INFO | hackthon_support_agent.BaseService | [PLANNING] Starting planning phase
2025-11-11 15:48:46,871 | INFO | hackthon_support_agent.BaseService | [PLANNING] Plan created with 3 focus areas
2025-11-11 15:48:46,878 | INFO | hackthon_support_agent.BaseService | [CACHE] Creating context cache
2025-11-11 15:48:48,409 | INFO | hackthon_support_agent.BaseService | [CACHE] Context cache created: cachedContents/n3wcm4asw3w5fm939hyvmsk826m7ta2r2gsj1i2t
2025-11-11 15:48:48,413 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Starting parallel extraction
2025-11-11 15:48:48,414 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: データ・モデル
2025-11-11 15:48:54,851 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 6 functions using Cache
2025-11-11 15:48:54,852 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] データ・モデル completed in 6.44s - 6 functions extracted
2025-11-11 15:48:54,852 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: API・バックエンド
2025-11-11 15:49:03,657 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 7 functions using Cache
2025-11-11 15:49:03,658 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] API・バックエンド completed in 8.80s - 7 functions extracted
2025-11-11 15:49:03,658 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: UI・画面
2025-11-11 15:49:11,137 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 8 functions using Cache
2025-11-11 15:49:11,138 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] UI・画面 completed in 7.48s - 8 functions extracted
2025-11-11 15:49:11,138 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Completed: 3 areas processed
2025-11-11 15:49:11,142 | INFO | hackthon_support_agent.BaseService | [MERGE] Merging results from all focus areas
2025-11-11 15:49:11,143 | INFO | hackthon_support_agent.BaseService | [MERGE] Merged: 21 unique functions
2025-11-11 15:49:11,146 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURING] Starting parallel structuring
2025-11-11 15:49:30,428 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 21 functions
2025-11-11 15:49:30,430 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'data': 10, 'auth': 1, 'logic': 2, 'ui': 8}
2025-11-11 15:49:45,190 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 21 functions
2025-11-11 15:49:45,191 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 18, 'Should': 3}
2025-11-11 15:49:54,760 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 43 dependencies
2025-11-11 15:49:54,761 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 30, 'blocks': 7, 'relates': 6}
2025-11-11 15:49:54,762 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURING] Completed: 21 functions, 43 dependencies
2025-11-11 15:49:54,765 | INFO | hackthon_support_agent.BaseService | [PERSISTENCE] Saving to database
2025-11-11 15:49:54,801 | INFO | hackthon_support_agent.BaseService | [PERSISTENCE] Saved 21 functions and 43 dependencies to DB
2025-11-11 15:49:54,803 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Workflow completed in 67.94s
2025-11-11 16:08:35,763 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-11-11 16:08:35,770 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 16:08:35,771 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:08:35,802 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:08:35,803 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:08:35,804 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:08:35,804 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:08:35,806 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:08:35,806 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:08:35,807 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:08:35,808 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-11-11 16:08:35,808 | DEBUG | hackthon_support_agent.QuestionService | Generating questions for project_id: ef14fc35-dacd-498f-b068-e988648686bb with idea_prompt: プロジェクトタイトル: オンライン学習プラットフォーム
プロジェクトアイディア: 学生の学力と得意不得意に合わせたAIを用いた動的な課題作成サービス
期間: 2025-11-11 〜 2025-12-11 01:08
2025-11-11 16:08:35,808 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-11-11 16:08:48,305 | INFO | hackthon_support_agent.QuestionService | Generated 5 questions for project_id: ef14fc35-dacd-498f-b068-e988648686bb
2025-11-11 16:08:48,320 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-11-11 16:08:48,323 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 16:08:48,323 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:08:48,327 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:08:48,328 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:08:48,329 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:08:48,329 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:08:48,330 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:08:48,331 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:08:48,332 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:08:48,332 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-11-11 16:08:56,211 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-11-11 16:08:56,217 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 16:08:56,218 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:08:56,230 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:08:56,231 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:08:56,234 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:08:56,234 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:08:56,236 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:08:56,237 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:08:56,240 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:08:56,240 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-11-11 16:08:56,336 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.generate_summary_document'
2025-11-11 16:09:08,089 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-11-11 16:09:08,094 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 16:09:08,094 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:09:08,100 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:09:08,100 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:09:08,102 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:09:08,102 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:09:08,105 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:09:08,105 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:09:08,107 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:09:08,107 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-11-11 16:09:12,379 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-11-11 16:09:12,382 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 16:09:12,382 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:09:12,390 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:09:12,394 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:09:12,397 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:09:12,397 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:09:12,399 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:09:12,399 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:09:12,401 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:09:12,401 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-11-11 16:09:12,414 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-11-11 16:09:26,688 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-11-11 16:09:26,694 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 16:09:26,694 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:09:26,698 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:09:26,698 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:09:26,700 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:09:26,701 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:09:26,703 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:09:26,704 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:09:26,705 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:09:26,705 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-11-11 16:09:26,762 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: ef14fc35-dacd-498f-b068-e988648686bb
2025-11-11 16:09:26,767 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.evaluate_specification'
2025-11-11 16:09:27,729 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-11-11 16:09:27,734 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 16:09:27,734 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:09:27,736 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:09:27,736 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:09:27,738 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:09:27,739 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:09:27,741 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:09:27,741 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:09:27,742 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:09:27,742 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-11-11 16:09:27,785 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: ef14fc35-dacd-498f-b068-e988648686bb
2025-11-11 16:09:27,787 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.evaluate_specification'
2025-11-11 16:12:24,056 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-11-11 16:12:24,065 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 16:12:24,066 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:12:24,076 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:12:24,076 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:12:24,079 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:12:24,080 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:12:24,082 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:12:24,082 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:12:24,084 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:12:24,084 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-11-11 16:12:24,130 | INFO | hackthon_support_agent.SummaryService | 既存仕様書を検出。差分ベースで更新します。
2025-11-11 16:12:24,140 | INFO | hackthon_support_agent.SummaryService | 差分検出: 手動編集=False, 新規Q&A=5件
2025-11-11 16:12:24,141 | INFO | hackthon_support_agent.SummaryService | 新規キャッシュを作成: ef14fc35-dacd-498f-b068-e988648686bb
2025-11-11 16:12:24,332 | ERROR | hackthon_support_agent.SummaryService | キャッシュ使用中にエラー: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'Cached content is too small. total_token_count=780, min_total_token_count=4096', 'status': 'INVALID_ARGUMENT'}}
2025-11-11 16:12:24,332 | INFO | hackthon_support_agent.SummaryService | フォールバック: キャッシュなしで生成
2025-11-11 16:12:38,166 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: ef14fc35-dacd-498f-b068-e988648686bb
2025-11-11 16:12:38,170 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.evaluate_specification'
2025-11-11 16:12:55,623 | INFO | hackthon_support_agent.SummaryService | 不足情報から追加Q&Aを生成: 【ユーザー要件】メインユーザーである中学生・高校生は、どのようなデバイス（PC、タブレット、スマート...
2025-11-11 16:12:55,626 | INFO | hackthon_support_agent.SummaryService | 不足情報から追加Q&Aを生成: 【ユーザー要件】ユーザーは本プラットフォームをどのくらいの頻度で、一回あたりどれくらいの時間利用する...
2025-11-11 16:12:55,627 | INFO | hackthon_support_agent.SummaryService | 不足情報から追加Q&Aを生成: 【技術要件】AIが学生の学習状況（正答率、解答時間など）を分析し、次に提示する課題の難易度や分野を決...
2025-11-11 16:12:55,627 | INFO | hackthon_support_agent.SummaryService | 不足情報から追加Q&Aを生成: 【機能要件】本プラットフォームで提供する学習コンテンツは、具体的にどの教科、どの単元をカバーする予定...
2025-11-11 16:12:55,628 | INFO | hackthon_support_agent.SummaryService | 不足情報から追加Q&Aを生成: 【非機能要件】本プラットフォームのパフォーマンス（応答速度）、セキュリティ（個人情報保護、データ暗号...
2025-11-11 16:12:55,658 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-11-11 16:12:55,661 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 16:12:55,661 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:12:55,667 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:12:55,667 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:12:55,669 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:12:55,669 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:12:55,675 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:12:55,676 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:12:55,678 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:12:55,679 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-11-11 16:12:55,686 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-11-11 16:13:59,295 | DEBUG | hackthon_support_agent.FunctionService | Initializing BaseService (provider=google)
2025-11-11 16:13:59,308 | INFO | hackthon_support_agent.FunctionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 16:13:59,310 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:13:59,322 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:13:59,326 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:13:59,338 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:13:59,339 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:13:59,342 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:13:59,343 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:13:59,346 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:13:59,347 | DEBUG | hackthon_support_agent.FunctionService | LLMs initialized
2025-11-11 16:13:59,347 | DEBUG | hackthon_support_agent.FunctionService | Generating functional requirements for project_id: ef14fc35-dacd-498f-b068-e988648686bb
2025-11-11 16:13:59,352 | DEBUG | hackthon_support_agent.FunctionService | Fetching prompt 'function_service.generate_functional_requirements'
2025-11-11 16:14:47,125 | DEBUG | hackthon_support_agent.FunctionService | Generating clarification questions for 1 low-confidence requirements
2025-11-11 16:14:47,127 | DEBUG | hackthon_support_agent.FunctionService | Fetching prompt 'function_service.generate_clarification_questions'
2025-11-11 16:15:04,433 | DEBUG | hackthon_support_agent.FunctionService | Saving functional requirements to project document: ef14fc35-dacd-498f-b068-e988648686bb
2025-11-11 16:15:04,452 | DEBUG | hackthon_support_agent.FunctionService | Saving 5 clarification questions to database
2025-11-11 16:15:13,690 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:15:13,694 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 16:15:13,695 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:15:13,701 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:15:13,702 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:15:13,705 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:15:13,706 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:15:13,707 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:15:13,707 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:15:13,709 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:15:13,710 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:15:13,789 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Fetching context for project: ef14fc35-dacd-498f-b068-e988648686bb
2025-11-11 16:15:13,793 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Starting workflow for project: ef14fc35-dacd-498f-b068-e988648686bb
2025-11-11 16:15:13,799 | INFO | hackthon_support_agent.BaseService | [PLANNING] Starting planning phase
2025-11-11 16:15:13,800 | INFO | hackthon_support_agent.BaseService | [PLANNING] Plan created with 3 focus areas
2025-11-11 16:15:13,801 | INFO | hackthon_support_agent.BaseService | [CACHE] Creating context cache
2025-11-11 16:15:14,257 | ERROR | hackthon_support_agent.BaseService | [CACHE] Cache creation failed: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'Cached content is too small. total_token_count=4010, min_total_token_count=4096', 'status': 'INVALID_ARGUMENT'}}
2025-11-11 16:15:14,261 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Starting parallel extraction
2025-11-11 16:15:14,261 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: データ・モデル
2025-11-11 16:15:29,779 | DEBUG | hackthon_support_agent.FrameworkService | Initializing BaseService (provider=google)
2025-11-11 16:15:29,784 | INFO | hackthon_support_agent.FrameworkService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 16:15:29,785 | DEBUG | hackthon_support_agent.FrameworkService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:15:29,788 | INFO | hackthon_support_agent.FrameworkService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:15:29,788 | DEBUG | hackthon_support_agent.FrameworkService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:15:29,792 | INFO | hackthon_support_agent.FrameworkService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:15:29,792 | DEBUG | hackthon_support_agent.FrameworkService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:15:29,794 | INFO | hackthon_support_agent.FrameworkService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:15:29,795 | DEBUG | hackthon_support_agent.FrameworkService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:15:29,796 | INFO | hackthon_support_agent.FrameworkService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:15:29,797 | DEBUG | hackthon_support_agent.FrameworkService | LLMs initialized
2025-11-11 16:15:29,797 | DEBUG | hackthon_support_agent.FrameworkService | Fetching prompt 'framework_service.generate_simple_recommendations'
2025-11-11 16:15:29,864 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 6 functions using LangChain
2025-11-11 16:15:29,864 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] データ・モデル completed in 15.60s - 6 functions extracted
2025-11-11 16:15:29,864 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: API・バックエンド
2025-11-11 16:16:17,649 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 5 functions using LangChain
2025-11-11 16:16:17,651 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] API・バックエンド completed in 47.79s - 5 functions extracted
2025-11-11 16:16:17,651 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: UI・画面
2025-11-11 16:16:37,631 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 8 functions using LangChain
2025-11-11 16:16:37,632 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] UI・画面 completed in 19.98s - 8 functions extracted
2025-11-11 16:16:37,632 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Completed: 3 areas processed
2025-11-11 16:16:37,637 | INFO | hackthon_support_agent.BaseService | [MERGE] Merging results from all focus areas
2025-11-11 16:16:37,639 | INFO | hackthon_support_agent.BaseService | [MERGE] Merged: 19 unique functions
2025-11-11 16:16:37,641 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURING] Starting parallel structuring
2025-11-11 16:16:53,602 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 19 functions
2025-11-11 16:16:53,604 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'data': 7, 'auth': 1, 'logic': 2, 'api': 1, 'ui': 8}
2025-11-11 16:16:59,128 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 19 functions
2025-11-11 16:16:59,130 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 16, 'Could': 2, 'Should': 1}
2025-11-11 16:17:10,533 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 25 dependencies
2025-11-11 16:17:10,534 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 19, 'blocks': 4, 'relates': 2}
2025-11-11 16:17:10,535 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURING] Completed: 19 functions, 25 dependencies
2025-11-11 16:17:10,544 | INFO | hackthon_support_agent.BaseService | [PERSISTENCE] Saving to database
2025-11-11 16:17:10,576 | ERROR | hackthon_support_agent.BaseService | [PERSISTENCE] Persistence failed: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "function_dependencies_from_function_id_to_function_id_key"
DETAIL:  Key (from_function_id, to_function_id)=(256d62cf-6682-4875-a1fa-98b849fe120a, 1b035f28-2fbd-4504-abde-5c33e58eb700) already exists.

[SQL: INSERT INTO function_dependencies (id, from_function_id, to_function_id, dependency_type) VALUES (%(id__0)s::UUID, %(from_function_id__0)s::UUID, %(to_function_id__0)s::UUID, %(dependency_type__0)s), (%(id__1)s::UUID, %(from_function_id__1)s::UUID, % ... 2380 characters truncated ... __24)s::UUID, %(from_function_id__24)s::UUID, %(to_function_id__24)s::UUID, %(dependency_type__24)s)]
[parameters: {'to_function_id__0': 'c6d4beee-3906-44b2-bec9-84cec1eecf09', 'id__0': UUID('46bdb8ad-ff21-4c7d-856f-c2e5f816a1b9'), 'from_function_id__0': '772ebccd-204f-44c1-a872-2d0e239b3223', 'dependency_type__0': 'requires', 'to_function_id__1': 'c6d4beee-3906-44b2-bec9-84cec1eecf09', 'id__1': UUID('0ed6bc96-2261-4cf6-8bea-f56a8048c1c4'), 'from_function_id__1': 'baff5a09-2e16-46d6-8ea7-48573705038b', 'dependency_type__1': 'requires', 'to_function_id__2': 'c6d4beee-3906-44b2-bec9-84cec1eecf09', 'id__2': UUID('3dad9227-efe6-4ec6-8c9f-10097e2119c8'), 'from_function_id__2': 'df9b20ed-ad96-486d-b031-17576dbf1c87', 'dependency_type__2': 'requires', 'to_function_id__3': '489c5ebc-a619-4c99-bc14-23eca9087cb8', 'id__3': UUID('06a970d3-21e3-4574-994c-e4f876075d71'), 'from_function_id__3': '4fd781c8-4329-427b-8a26-8f7af8a042ba', 'dependency_type__3': 'requires', 'to_function_id__4': '489c5ebc-a619-4c99-bc14-23eca9087cb8', 'id__4': UUID('c81791ab-baf5-4a79-9cbe-362e7496b13a'), 'from_function_id__4': 'df9b20ed-ad96-486d-b031-17576dbf1c87', 'dependency_type__4': 'requires', 'to_function_id__5': '489c5ebc-a619-4c99-bc14-23eca9087cb8', 'id__5': UUID('9a48b2d6-ff2b-4659-bc2a-0a4c93736280'), 'from_function_id__5': 'baff5a09-2e16-46d6-8ea7-48573705038b', 'dependency_type__5': 'requires', 'to_function_id__6': '489c5ebc-a619-4c99-bc14-23eca9087cb8', 'id__6': UUID('baaebd97-0931-4229-8898-662788842066'), 'from_function_id__6': 'f50e98b0-3039-4784-bb0d-17ccf00be986', 'dependency_type__6': 'requires', 'to_function_id__7': '1b035f28-2fbd-4504-abde-5c33e58eb700', 'id__7': UUID('b29ae305-73d8-4d9e-b0c8-727cbe930d0b'), 'from_function_id__7': 'df9b20ed-ad96-486d-b031-17576dbf1c87', 'dependency_type__7': 'requires', 'to_function_id__8': '1b035f28-2fbd-4504-abde-5c33e58eb700', 'id__8': UUID('214b7b30-b7f0-4407-9a99-ece6468b2eb3'), 'from_function_id__8': '4fd781c8-4329-427b-8a26-8f7af8a042ba', 'dependency_type__8': 'requires', 'to_function_id__9': '1b035f28-2fbd-4504-abde-5c33e58eb700', 'id__9': UUID('393a485c-46ea-4d49-a59c-0c242c501ceb'), 'from_function_id__9': '256d62cf-6682-4875-a1fa-98b849fe120a', 'dependency_type__9': 'blocks', 'to_function_id__10': '90c86ecb-ea01-4d6f-8af4-31b36b78bc9e', 'id__10': UUID('d26a09ef-d4d8-475d-bd14-6f06fa04e2af'), 'from_function_id__10': '4fd781c8-4329-427b-8a26-8f7af8a042ba', 'dependency_type__10': 'requires', 'to_function_id__11': '90c86ecb-ea01-4d6f-8af4-31b36b78bc9e', 'id__11': UUID('14db0879-246c-4841-a2da-9fdb09216480'), 'from_function_id__11': '256d62cf-6682-4875-a1fa-98b849fe120a', 'dependency_type__11': 'blocks', 'to_function_id__12': 'f50e98b0-3039-4784-bb0d-17ccf00be986', 'id__12': UUID('6a43f7a9-5813-4b19-85bf-6e3b46eab14c'), 'from_function_id__12': 'df9b20ed-ad96-486d-b031-17576dbf1c87', 'dependency_type__12': 'requires', 'to_function_id__13': '1b035f28-2fbd-4504-abde-5c33e58eb700', 'id__13': UUID('5185d762-2440-48f0-b74c-4e8c4d531cac'), 'from_function_id__13': '256d62cf-6682-4875-a1fa-98b849fe120a', 'dependency_type__13': 'blocks', 'to_function_id__14': '90c86ecb-ea01-4d6f-8af4-31b36b78bc9e', 'id__14': UUID('ab080b08-7027-4233-acda-8301f1324bf7'), 'from_function_id__14': '256d62cf-6682-4875-a1fa-98b849fe120a', 'dependency_type__14': 'blocks', 'to_function_id__15': '772ebccd-204f-44c1-a872-2d0e239b3223', 'id__15': UUID('f4a6009f-a199-4c3d-9af9-b64cf8298597'), 'from_function_id__15': '352d11dd-e4d5-4ff4-a5ec-3a1fb7ba24ac', 'dependency_type__15': 'requires', 'to_function_id__16': '772ebccd-204f-44c1-a872-2d0e239b3223', 'id__16': UUID('35f2b072-4b4e-4a58-8c8b-a20e019932be'), 'from_function_id__16': '3b8b4ded-d04b-470a-961f-9170f4399e75', 'dependency_type__16': 'requires', 'to_function_id__17': 'df9b20ed-ad96-486d-b031-17576dbf1c87', 'id__17': UUID('e85c6f00-2139-46b7-a8ac-39c8d5e128f0'), 'from_function_id__17': '9acc32fb-da9a-43eb-82d8-25b311ffaf97', 'dependency_type__17': 'requires', 'to_function_id__18': 'df9b20ed-ad96-486d-b031-17576dbf1c87', 'id__18': UUID('f1c4214d-9148-42e7-bcfd-c362b3a79930'), 'from_function_id__18': 'a70f8c2f-f6c4-475f-a7df-838b5cee1318', 'dependency_type__18': 'requires', 'to_function_id__19': '014e2c16-d85a-4dfe-a0e7-db31aeeedf26', 'id__19': UUID('ab171383-1636-4ed1-a018-05f531a55b23'), 'from_function_id__19': '4fd781c8-4329-427b-8a26-8f7af8a042ba', 'dependency_type__19': 'requires', 'to_function_id__20': '4fd781c8-4329-427b-8a26-8f7af8a042ba', 'id__20': UUID('101351d4-9482-4643-88f6-57fc85f37b1d'), 'from_function_id__20': '8df5f1b8-3602-4d9b-85e3-3da7e4606937', 'dependency_type__20': 'relates', 'to_function_id__21': '4fd781c8-4329-427b-8a26-8f7af8a042ba', 'id__21': UUID('4e224d3a-e42e-493e-9a47-f7f78a8b5c80'), 'from_function_id__21': '21d20a1c-7b6d-4b5f-99e9-1ed54ed3cd76', 'dependency_type__21': 'requires', 'to_function_id__22': 'baff5a09-2e16-46d6-8ea7-48573705038b', 'id__22': UUID('1b3ee391-575d-4993-9306-91cecb0cc14a'), 'from_function_id__22': 'ee78433d-840f-4db1-8d65-6d884726e070', 'dependency_type__22': 'requires', 'to_function_id__23': 'baff5a09-2e16-46d6-8ea7-48573705038b', 'id__23': UUID('ba888d64-4bc7-407f-aee9-094c7dbf5e4d'), 'from_function_id__23': 'aacaa175-2fca-4181-ba60-22c234ae3023', 'dependency_type__23': 'requires', 'to_function_id__24': '014e2c16-d85a-4dfe-a0e7-db31aeeedf26', 'id__24': UUID('cd18fb4a-edd8-4569-aabe-25518b63e880'), 'from_function_id__24': '8df5f1b8-3602-4d9b-85e3-3da7e4606937', 'dependency_type__24': 'relates'}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
2025-11-11 16:17:10,584 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Workflow completed in 116.79s
2025-11-11 16:18:40,667 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:18:40,672 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 16:18:40,672 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:18:40,683 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:18:40,683 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:18:40,686 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:18:40,687 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:18:40,689 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:18:40,690 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:18:40,692 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:18:40,692 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:18:40,758 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Fetching context for project: ef14fc35-dacd-498f-b068-e988648686bb
2025-11-11 16:18:40,765 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Starting workflow for project: ef14fc35-dacd-498f-b068-e988648686bb
2025-11-11 16:18:40,769 | INFO | hackthon_support_agent.BaseService | [PLANNING] Starting planning phase
2025-11-11 16:18:40,770 | INFO | hackthon_support_agent.BaseService | [PLANNING] Plan created with 3 focus areas
2025-11-11 16:18:40,772 | INFO | hackthon_support_agent.BaseService | [CACHE] Creating context cache
2025-11-11 16:18:41,334 | ERROR | hackthon_support_agent.BaseService | [CACHE] Cache creation failed: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'Cached content is too small. total_token_count=4036, min_total_token_count=4096', 'status': 'INVALID_ARGUMENT'}}
2025-11-11 16:18:41,337 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Starting parallel extraction
2025-11-11 16:18:41,338 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: データ・モデル
2025-11-11 16:18:54,237 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 5 functions using LangChain
2025-11-11 16:18:54,239 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] データ・モデル completed in 12.90s - 5 functions extracted
2025-11-11 16:18:54,240 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: API・バックエンド
2025-11-11 16:19:55,686 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 7 functions using LangChain
2025-11-11 16:19:55,690 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] API・バックエンド completed in 61.45s - 7 functions extracted
2025-11-11 16:19:55,690 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: UI・画面
2025-11-11 16:20:16,526 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 7 functions using LangChain
2025-11-11 16:20:16,529 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] UI・画面 completed in 20.84s - 7 functions extracted
2025-11-11 16:20:16,529 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Completed: 3 areas processed
2025-11-11 16:20:16,535 | INFO | hackthon_support_agent.BaseService | [MERGE] Merging results from all focus areas
2025-11-11 16:20:16,536 | INFO | hackthon_support_agent.BaseService | [MERGE] Merged: 19 unique functions
2025-11-11 16:20:16,537 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURING] Starting parallel structuring
2025-11-11 16:20:33,869 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 19 functions
2025-11-11 16:20:33,870 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 17, 'Should': 1, 'Could': 1}
2025-11-11 16:20:36,791 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 19 functions
2025-11-11 16:20:36,792 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'data': 5, 'api': 5, 'auth': 1, 'logic': 1, 'ui': 7}
2025-11-11 16:20:54,361 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 30 dependencies
2025-11-11 16:20:54,363 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 21, 'relates': 9}
2025-11-11 16:20:54,365 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURING] Completed: 19 functions, 30 dependencies
2025-11-11 16:20:54,370 | INFO | hackthon_support_agent.BaseService | [PERSISTENCE] Saving to database
2025-11-11 16:20:54,393 | INFO | hackthon_support_agent.BaseService | [PERSISTENCE] Saved 19 functions and 30 dependencies to DB
2025-11-11 16:20:54,395 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Workflow completed in 133.63s
2025-11-11 16:21:12,898 | DEBUG | hackthon_support_agent.IntegratedTaskService | Initializing BaseService (provider=google)
2025-11-11 16:21:12,925 | INFO | hackthon_support_agent.IntegratedTaskService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 16:21:12,928 | DEBUG | hackthon_support_agent.IntegratedTaskService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:21:12,942 | INFO | hackthon_support_agent.IntegratedTaskService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:21:12,943 | DEBUG | hackthon_support_agent.IntegratedTaskService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:21:12,957 | INFO | hackthon_support_agent.IntegratedTaskService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:21:12,957 | DEBUG | hackthon_support_agent.IntegratedTaskService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:21:12,980 | INFO | hackthon_support_agent.IntegratedTaskService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:21:12,981 | DEBUG | hackthon_support_agent.IntegratedTaskService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:21:12,986 | INFO | hackthon_support_agent.IntegratedTaskService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:21:12,987 | DEBUG | hackthon_support_agent.IntegratedTaskService | LLMs initialized
2025-11-11 16:21:12,988 | DEBUG | hackthon_support_agent.TaskGenerationService | Initializing BaseService (provider=google)
2025-11-11 16:21:12,993 | INFO | hackthon_support_agent.TaskGenerationService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 16:21:12,994 | DEBUG | hackthon_support_agent.TaskGenerationService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:21:12,999 | INFO | hackthon_support_agent.TaskGenerationService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:21:13,000 | DEBUG | hackthon_support_agent.TaskGenerationService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:21:13,004 | INFO | hackthon_support_agent.TaskGenerationService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:21:13,005 | DEBUG | hackthon_support_agent.TaskGenerationService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:21:13,020 | INFO | hackthon_support_agent.TaskGenerationService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:21:13,021 | DEBUG | hackthon_support_agent.TaskGenerationService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:21:13,062 | INFO | hackthon_support_agent.TaskGenerationService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:21:13,062 | DEBUG | hackthon_support_agent.TaskGenerationService | LLMs initialized
2025-11-11 16:21:13,065 | DEBUG | hackthon_support_agent.TaskQualityEvaluationService | Initializing BaseService (provider=google)
2025-11-11 16:21:13,071 | INFO | hackthon_support_agent.TaskQualityEvaluationService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 16:21:13,071 | DEBUG | hackthon_support_agent.TaskQualityEvaluationService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:21:13,076 | INFO | hackthon_support_agent.TaskQualityEvaluationService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:21:13,077 | DEBUG | hackthon_support_agent.TaskQualityEvaluationService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:21:13,082 | INFO | hackthon_support_agent.TaskQualityEvaluationService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:21:13,083 | DEBUG | hackthon_support_agent.TaskQualityEvaluationService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:21:13,086 | INFO | hackthon_support_agent.TaskQualityEvaluationService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:21:13,086 | DEBUG | hackthon_support_agent.TaskQualityEvaluationService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:21:13,089 | INFO | hackthon_support_agent.TaskQualityEvaluationService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:21:13,090 | DEBUG | hackthon_support_agent.TaskQualityEvaluationService | LLMs initialized
2025-11-11 16:21:13,090 | DEBUG | hackthon_support_agent.LayerConsistencyEvaluator | Initializing BaseService (provider=google)
2025-11-11 16:21:13,094 | INFO | hackthon_support_agent.LayerConsistencyEvaluator | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 16:21:13,094 | DEBUG | hackthon_support_agent.LayerConsistencyEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:21:13,098 | INFO | hackthon_support_agent.LayerConsistencyEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:21:13,098 | DEBUG | hackthon_support_agent.LayerConsistencyEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:21:13,101 | INFO | hackthon_support_agent.LayerConsistencyEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:21:13,102 | DEBUG | hackthon_support_agent.LayerConsistencyEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:21:13,106 | INFO | hackthon_support_agent.LayerConsistencyEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:21:13,107 | DEBUG | hackthon_support_agent.LayerConsistencyEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:21:13,110 | INFO | hackthon_support_agent.LayerConsistencyEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:21:13,111 | DEBUG | hackthon_support_agent.LayerConsistencyEvaluator | LLMs initialized
2025-11-11 16:21:13,111 | DEBUG | hackthon_support_agent.DomainCompletenessEvaluator | Initializing BaseService (provider=google)
2025-11-11 16:21:13,115 | INFO | hackthon_support_agent.DomainCompletenessEvaluator | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 16:21:13,115 | DEBUG | hackthon_support_agent.DomainCompletenessEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:21:13,117 | INFO | hackthon_support_agent.DomainCompletenessEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:21:13,118 | DEBUG | hackthon_support_agent.DomainCompletenessEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:21:13,120 | INFO | hackthon_support_agent.DomainCompletenessEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:21:13,120 | DEBUG | hackthon_support_agent.DomainCompletenessEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:21:13,123 | INFO | hackthon_support_agent.DomainCompletenessEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:21:13,123 | DEBUG | hackthon_support_agent.DomainCompletenessEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:21:13,125 | INFO | hackthon_support_agent.DomainCompletenessEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:21:13,126 | DEBUG | hackthon_support_agent.DomainCompletenessEvaluator | LLMs initialized
2025-11-11 16:21:13,128 | DEBUG | hackthon_support_agent.TaskDependencyService | Initializing BaseService (provider=google)
2025-11-11 16:21:13,132 | INFO | hackthon_support_agent.TaskDependencyService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 16:21:13,134 | DEBUG | hackthon_support_agent.TaskDependencyService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:21:13,137 | INFO | hackthon_support_agent.TaskDependencyService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:21:13,138 | DEBUG | hackthon_support_agent.TaskDependencyService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:21:13,143 | INFO | hackthon_support_agent.TaskDependencyService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:21:13,144 | DEBUG | hackthon_support_agent.TaskDependencyService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:21:13,149 | INFO | hackthon_support_agent.TaskDependencyService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:21:13,149 | DEBUG | hackthon_support_agent.TaskDependencyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:21:13,162 | INFO | hackthon_support_agent.TaskDependencyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:21:13,162 | DEBUG | hackthon_support_agent.TaskDependencyService | LLMs initialized
2025-11-11 16:21:13,164 | DEBUG | hackthon_support_agent.TaskPositionService | Initializing BaseService (provider=google)
2025-11-11 16:21:13,167 | INFO | hackthon_support_agent.TaskPositionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 16:21:13,168 | DEBUG | hackthon_support_agent.TaskPositionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:21:13,173 | INFO | hackthon_support_agent.TaskPositionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:21:13,174 | DEBUG | hackthon_support_agent.TaskPositionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:21:13,176 | INFO | hackthon_support_agent.TaskPositionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:21:13,177 | DEBUG | hackthon_support_agent.TaskPositionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:21:13,179 | INFO | hackthon_support_agent.TaskPositionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:21:13,180 | DEBUG | hackthon_support_agent.TaskPositionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:21:13,182 | INFO | hackthon_support_agent.TaskPositionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:21:13,183 | DEBUG | hackthon_support_agent.TaskPositionService | LLMs initialized
2025-11-11 16:21:50,103 | INFO | hackthon_support_agent.TaskGenerationService | ✅ Batch batch_1: All tasks validated successfully on attempt 1
2025-11-11 16:22:15,781 | INFO | hackthon_support_agent.TaskGenerationService | ✅ Batch batch_2: All tasks validated successfully on attempt 1
2025-11-11 16:22:48,558 | INFO | hackthon_support_agent.TaskGenerationService | ✅ Batch batch_3: All tasks validated successfully on attempt 1
2025-11-11 16:23:06,000 | INFO | hackthon_support_agent.TaskGenerationService | ✅ Batch batch_4: All tasks validated successfully on attempt 1
2025-11-11 16:30:00,688 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 16:32:25,537 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-11-11 16:32:25,541 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 16:32:25,541 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:32:25,560 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:32:25,560 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:32:25,561 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:32:25,562 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:32:25,563 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:32:25,563 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:32:25,564 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:32:25,564 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-11-11 16:32:25,565 | DEBUG | hackthon_support_agent.QuestionService | Generating questions for project_id: fb67101d-f6c5-4b7a-8113-64327f099b30 with idea_prompt: プロジェクトタイトル: オンライン学習プラットフォーム
プロジェクトアイディア: 学生の学力と得意不得意に合わせたAIを用いた動的な課題作成サービス
期間: 2025-11-11 〜 2025-12-11 01:21
2025-11-11 16:32:25,565 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-11-11 16:32:40,772 | INFO | hackthon_support_agent.QuestionService | Generated 7 questions for project_id: fb67101d-f6c5-4b7a-8113-64327f099b30
2025-11-11 16:32:40,790 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-11-11 16:32:40,793 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 16:32:40,793 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:32:40,801 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:32:40,801 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:32:40,803 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:32:40,803 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:32:40,806 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:32:40,806 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:32:40,807 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:32:40,808 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-11-11 16:32:54,104 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-11-11 16:32:54,107 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 16:32:54,107 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:32:54,110 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:32:54,110 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:32:54,112 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:32:54,112 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:32:54,113 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:32:54,114 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:32:54,115 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:32:54,115 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-11-11 16:32:54,182 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.generate_summary_document'
2025-11-11 16:33:10,686 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-11-11 16:33:10,690 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 16:33:10,690 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:33:10,695 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:33:10,695 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:33:10,696 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:33:10,697 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:33:10,698 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:33:10,698 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:33:10,700 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:33:10,700 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-11-11 16:33:12,327 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-11-11 16:33:12,329 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 16:33:12,330 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:33:12,331 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:33:12,332 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:33:12,335 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:33:12,336 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:33:12,337 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:33:12,337 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:33:12,338 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:33:12,338 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-11-11 16:33:12,348 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-11-11 16:33:27,991 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-11-11 16:33:27,995 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 16:33:27,995 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:33:27,997 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:33:27,998 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:33:27,999 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:33:27,999 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:33:28,002 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:33:28,002 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:33:28,004 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:33:28,005 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-11-11 16:33:28,046 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: fb67101d-f6c5-4b7a-8113-64327f099b30
2025-11-11 16:33:28,049 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.evaluate_specification'
2025-11-11 16:33:29,035 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-11-11 16:33:29,039 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 16:33:29,039 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:33:29,041 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:33:29,042 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:33:29,044 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:33:29,044 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:33:29,045 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:33:29,046 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:33:29,047 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:33:29,047 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-11-11 16:33:29,086 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: fb67101d-f6c5-4b7a-8113-64327f099b30
2025-11-11 16:33:29,088 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.evaluate_specification'
2025-11-11 16:36:44,414 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-11-11 16:36:44,423 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 16:36:44,423 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:36:44,440 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:36:44,440 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:36:44,449 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:36:44,450 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:36:44,452 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:36:44,452 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:36:44,453 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:36:44,454 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-11-11 16:36:44,504 | INFO | hackthon_support_agent.SummaryService | 既存仕様書を検出。差分ベースで更新します。
2025-11-11 16:36:44,512 | INFO | hackthon_support_agent.SummaryService | 差分検出: 手動編集=False, 新規Q&A=5件
2025-11-11 16:36:44,514 | INFO | hackthon_support_agent.SummaryService | 新規キャッシュを作成: fb67101d-f6c5-4b7a-8113-64327f099b30
2025-11-11 16:36:45,759 | ERROR | hackthon_support_agent.SummaryService | キャッシュ使用中にエラー: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'Cached content is too small. total_token_count=914, min_total_token_count=4096', 'status': 'INVALID_ARGUMENT'}}
2025-11-11 16:36:45,762 | INFO | hackthon_support_agent.SummaryService | フォールバック: キャッシュなしで生成
2025-11-11 16:36:58,810 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: fb67101d-f6c5-4b7a-8113-64327f099b30
2025-11-11 16:36:58,814 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.evaluate_specification'
2025-11-11 16:37:27,216 | INFO | hackthon_support_agent.SummaryService | 不足情報から追加Q&Aを生成: 【ユーザー像】想定ユーザーである高校生が、このサービスを「いつ（例: 学校の放課後、自宅での自習時間...
2025-11-11 16:37:27,219 | INFO | hackthon_support_agent.SummaryService | 不足情報から追加Q&Aを生成: 【技術要件】AIが学生の学力や得意不得意を判断するための初期データとして、どのような情報（例: 過去...
2025-11-11 16:37:27,220 | INFO | hackthon_support_agent.SummaryService | 不足情報から追加Q&Aを生成: 【機能要件】サービスで提供する数学の問題は、どのように作成・調達することを想定していますか？（例: ...
2025-11-11 16:37:27,221 | INFO | hackthon_support_agent.SummaryService | 不足情報から追加Q&Aを生成: 【非機能要件】サービスは24時間365日利用可能であるべきか、特定の時間帯のみの提供で良いか、また、...
2025-11-11 16:37:27,222 | INFO | hackthon_support_agent.SummaryService | 不足情報から追加Q&Aを生成: 【ビジネス要件】このサービスの収益モデルはどのように考えていますか？（例: 月額課金、問題集ごとの販...
2025-11-11 16:37:27,251 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-11-11 16:37:27,254 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 16:37:27,254 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:37:27,266 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:37:27,267 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:37:27,269 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:37:27,269 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:37:27,271 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:37:27,271 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:37:27,273 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:37:27,273 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-11-11 16:37:27,282 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-11-11 16:39:32,302 | DEBUG | hackthon_support_agent.FunctionService | Initializing BaseService (provider=google)
2025-11-11 16:39:32,308 | INFO | hackthon_support_agent.FunctionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 16:39:32,308 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:39:32,319 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:39:32,321 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:39:32,325 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:39:32,327 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:39:32,334 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:39:32,335 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:39:32,341 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:39:32,342 | DEBUG | hackthon_support_agent.FunctionService | LLMs initialized
2025-11-11 16:39:32,344 | DEBUG | hackthon_support_agent.FunctionService | Generating functional requirements for project_id: fb67101d-f6c5-4b7a-8113-64327f099b30
2025-11-11 16:39:32,350 | DEBUG | hackthon_support_agent.FunctionService | Fetching prompt 'function_service.generate_functional_requirements'
2025-11-11 16:40:20,377 | DEBUG | hackthon_support_agent.FunctionService | Generating clarification questions for 1 low-confidence requirements
2025-11-11 16:40:20,379 | DEBUG | hackthon_support_agent.FunctionService | Fetching prompt 'function_service.generate_clarification_questions'
2025-11-11 16:40:34,240 | DEBUG | hackthon_support_agent.FunctionService | Saving functional requirements to project document: fb67101d-f6c5-4b7a-8113-64327f099b30
2025-11-11 16:40:34,255 | DEBUG | hackthon_support_agent.FunctionService | Saving 3 clarification questions to database
2025-11-11 16:41:09,964 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:41:09,972 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 16:41:09,972 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:41:09,981 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:41:09,981 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:41:09,984 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:41:09,985 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:41:09,992 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:41:09,995 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:41:10,002 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:41:10,002 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:41:10,065 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Fetching context for project: fb67101d-f6c5-4b7a-8113-64327f099b30
2025-11-11 16:41:10,070 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Starting workflow for project: fb67101d-f6c5-4b7a-8113-64327f099b30
2025-11-11 16:41:10,075 | INFO | hackthon_support_agent.BaseService | [PLANNING] Starting planning phase
2025-11-11 16:41:10,075 | INFO | hackthon_support_agent.BaseService | [PLANNING] Plan created with 3 focus areas
2025-11-11 16:41:10,078 | INFO | hackthon_support_agent.BaseService | [CACHE] Creating context cache
2025-11-11 16:41:10,324 | ERROR | hackthon_support_agent.BaseService | [CACHE] Cache creation failed: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'Cached content is too small. total_token_count=3306, min_total_token_count=4096', 'status': 'INVALID_ARGUMENT'}}
2025-11-11 16:41:10,327 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Starting parallel extraction
2025-11-11 16:41:10,328 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: データ・モデル
2025-11-11 16:41:13,679 | DEBUG | hackthon_support_agent.FrameworkService | Initializing BaseService (provider=google)
2025-11-11 16:41:13,682 | INFO | hackthon_support_agent.FrameworkService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 16:41:13,683 | DEBUG | hackthon_support_agent.FrameworkService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:41:13,686 | INFO | hackthon_support_agent.FrameworkService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:41:13,687 | DEBUG | hackthon_support_agent.FrameworkService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:41:13,689 | INFO | hackthon_support_agent.FrameworkService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:41:13,689 | DEBUG | hackthon_support_agent.FrameworkService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:41:13,691 | INFO | hackthon_support_agent.FrameworkService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:41:13,692 | DEBUG | hackthon_support_agent.FrameworkService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:41:13,696 | INFO | hackthon_support_agent.FrameworkService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:41:13,696 | DEBUG | hackthon_support_agent.FrameworkService | LLMs initialized
2025-11-11 16:41:13,697 | DEBUG | hackthon_support_agent.FrameworkService | Fetching prompt 'framework_service.generate_simple_recommendations'
2025-11-11 16:41:34,993 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 5 functions using LangChain
2025-11-11 16:41:34,996 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] データ・モデル completed in 24.67s - 5 functions extracted
2025-11-11 16:41:34,996 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: API・バックエンド
2025-11-11 16:42:00,022 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 6 functions using LangChain
2025-11-11 16:42:00,026 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] API・バックエンド completed in 25.03s - 6 functions extracted
2025-11-11 16:42:00,026 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: UI・画面
2025-11-11 16:42:15,710 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 7 functions using LangChain
2025-11-11 16:42:15,712 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] UI・画面 completed in 15.69s - 7 functions extracted
2025-11-11 16:42:15,713 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Completed: 3 areas processed
2025-11-11 16:42:15,719 | INFO | hackthon_support_agent.BaseService | [MERGE] Merging results from all focus areas
2025-11-11 16:42:15,719 | INFO | hackthon_support_agent.BaseService | [MERGE] Merged: 18 unique functions
2025-11-11 16:42:15,721 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURING] Starting parallel structuring
2025-11-11 16:42:35,622 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 18 functions
2025-11-11 16:42:35,624 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 16, 'Should': 1, 'Could': 1}
2025-11-11 16:42:39,828 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 18 functions
2025-11-11 16:42:39,829 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'data': 7, 'auth': 1, 'logic': 2, 'api': 1, 'ui': 7}
2025-11-11 16:42:59,151 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 29 dependencies
2025-11-11 16:42:59,153 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 26, 'relates': 3}
2025-11-11 16:42:59,154 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURING] Completed: 18 functions, 29 dependencies
2025-11-11 16:42:59,157 | INFO | hackthon_support_agent.BaseService | [PERSISTENCE] Saving to database
2025-11-11 16:42:59,193 | INFO | hackthon_support_agent.BaseService | [PERSISTENCE] Saved 18 functions and 29 dependencies to DB
2025-11-11 16:42:59,195 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Workflow completed in 109.13s
2025-11-11 16:43:55,996 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 16:44:12,194 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 16:44:23,589 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 16:44:30,376 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 16:44:44,032 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 16:45:09,934 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 16:45:30,286 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 16:45:42,675 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 16:48:19,581 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 16:48:33,195 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 16:48:44,741 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 16:49:05,272 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 16:49:20,953 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 16:49:40,189 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 16:50:29,068 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 16:50:48,912 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 16:51:01,916 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 16:51:16,340 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 16:51:58,579 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-12 01:52:05,926 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 16:52:20,068 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 16:52:29,194 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 16:53:36,712 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 16:53:37,054 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-11-11 16:53:37,057 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 16:53:37,057 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:53:37,070 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:53:37,070 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:53:37,072 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:53:37,072 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:53:37,073 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:53:37,074 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:53:37,075 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:53:37,075 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-11-11 16:53:37,075 | DEBUG | hackthon_support_agent.QuestionService | Generating questions for project_id: None with idea_prompt: 
        ハッカソン参加者向けのタスク管理・プロジェクト支援アプリを作成したい。
        AIがプロジェクトの計画からタスク分解、進捗管理まで支援する。
        
2025-11-11 16:53:37,076 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-11-11 16:53:49,488 | INFO | hackthon_support_agent.QuestionService | Generated 7 questions for project_id: None
2025-11-11 16:53:49,489 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-11-11 16:53:49,494 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 16:53:49,494 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:53:49,496 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:53:49,496 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:53:49,498 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:53:49,498 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:53:49,500 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:53:49,501 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:53:49,502 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:53:49,502 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-11-11 16:53:49,552 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.generate_summary_document'
2025-11-11 16:54:01,790 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-11-11 16:54:01,795 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 16:54:01,795 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:54:01,798 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:54:01,798 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:54:01,800 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:54:01,800 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:54:01,802 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:54:01,802 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:54:01,804 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:54:01,804 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-11-11 16:54:01,804 | DEBUG | hackthon_support_agent.QuestionService | Generating questions for project_id: None with idea_prompt: 
        ハッカソン参加者向けのタスク管理・プロジェクト支援アプリを作成したい。
        AIがプロジェクトの計画からタスク分解、進捗管理まで支援する。
        
2025-11-11 16:54:01,805 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-11-11 16:54:20,501 | INFO | hackthon_support_agent.QuestionService | Generated 6 questions for project_id: None
2025-11-11 16:54:20,503 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-11-11 16:54:20,508 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 16:54:20,509 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:54:20,511 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:54:20,511 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:54:20,513 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:54:20,513 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:54:20,515 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:54:20,515 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:54:20,516 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:54:20,517 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-11-11 16:54:20,555 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.generate_summary_document'
2025-11-11 16:54:32,856 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-11-11 16:54:32,862 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 16:54:32,862 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:54:32,866 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:54:32,866 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:54:32,867 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:54:32,868 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:54:32,869 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:54:32,869 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:54:32,870 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:54:32,870 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-11-11 16:54:32,871 | DEBUG | hackthon_support_agent.QuestionService | Generating questions for project_id: None with idea_prompt: 
        ハッカソン参加者向けのタスク管理・プロジェクト支援アプリを作成したい。
        AIがプロジェクトの計画からタスク分解、進捗管理まで支援する。
        
2025-11-11 16:54:32,871 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-11-11 16:54:32,874 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-11-11 16:54:32,876 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 16:54:32,877 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:54:32,878 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:54:32,878 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:54:32,880 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:54:32,880 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:54:32,881 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:54:32,881 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:54:32,883 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:54:32,883 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-11-11 16:54:32,923 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.generate_summary_document'
2025-11-11 16:54:48,381 | INFO | hackthon_support_agent.QuestionService | Generated 6 questions for project_id: None
2025-11-11 16:56:25,016 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-11-11 16:56:25,021 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 16:56:25,021 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:56:25,042 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:56:25,042 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:56:25,045 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:56:25,045 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:56:25,046 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:56:25,047 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:56:25,048 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:56:25,048 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-11-11 16:56:25,049 | DEBUG | hackthon_support_agent.QuestionService | Generating questions for project_id: 5119aa4d-7997-4fc8-bb6c-dc0d23f44dc9 with idea_prompt: プロジェクトタイトル: オンライン学習プラットフォーム
プロジェクトアイディア: 学生の学力と得意不得意に合わせたAIを用いた動的な課題作成サービス
期間: 2025-11-11 〜 2025-12-11 01:46
2025-11-11 16:56:25,049 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-11-11 16:56:39,927 | INFO | hackthon_support_agent.QuestionService | Generated 8 questions for project_id: 5119aa4d-7997-4fc8-bb6c-dc0d23f44dc9
2025-11-11 16:56:39,942 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-11-11 16:56:39,944 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 16:56:39,945 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:56:39,950 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:56:39,950 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:56:39,951 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:56:39,951 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:56:39,958 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:56:39,958 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:56:39,960 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:56:39,960 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-11-11 16:56:42,139 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-11-11 16:56:42,143 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 16:56:42,143 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:56:42,147 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:56:42,148 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:56:42,151 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:56:42,151 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:56:42,154 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:56:42,154 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:56:42,156 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:56:42,157 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-11-11 16:56:42,222 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.generate_summary_document'
2025-11-11 16:57:00,552 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-11-11 16:57:00,555 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 16:57:00,556 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:57:00,558 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:57:00,559 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:57:00,560 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:57:00,561 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:57:00,563 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:57:00,563 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:57:00,564 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:57:00,565 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-11-11 16:57:01,349 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-11-11 16:57:01,352 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 16:57:01,352 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:57:01,355 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:57:01,356 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:57:01,362 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:57:01,362 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:57:01,365 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:57:01,365 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:57:01,367 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:57:01,368 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-11-11 16:57:01,381 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-11-11 16:57:18,957 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-11-11 16:57:18,961 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 16:57:18,962 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:57:18,964 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:57:18,964 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:57:18,966 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:57:18,967 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:57:18,970 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:57:18,970 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:57:18,972 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:57:18,972 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-11-11 16:57:19,018 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: 5119aa4d-7997-4fc8-bb6c-dc0d23f44dc9
2025-11-11 16:57:19,021 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.evaluate_specification'
2025-11-11 16:57:20,013 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-11-11 16:57:20,015 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 16:57:20,015 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:57:20,017 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:57:20,018 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:57:20,019 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:57:20,019 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:57:20,020 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:57:20,021 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:57:20,022 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:57:20,022 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-11-11 16:57:20,062 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: 5119aa4d-7997-4fc8-bb6c-dc0d23f44dc9
2025-11-11 16:57:20,064 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.evaluate_specification'
2025-11-11 16:57:35,607 | DEBUG | hackthon_support_agent.FunctionService | Initializing BaseService (provider=google)
2025-11-11 16:57:35,612 | INFO | hackthon_support_agent.FunctionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 16:57:35,613 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:57:35,614 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:57:35,615 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:57:35,616 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:57:35,617 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:57:35,619 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:57:35,620 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:57:35,621 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:57:35,623 | DEBUG | hackthon_support_agent.FunctionService | LLMs initialized
2025-11-11 16:57:35,623 | DEBUG | hackthon_support_agent.FunctionService | Generating functional requirements for project_id: 5119aa4d-7997-4fc8-bb6c-dc0d23f44dc9
2025-11-11 16:57:35,625 | DEBUG | hackthon_support_agent.FunctionService | Fetching prompt 'function_service.generate_functional_requirements'
2025-11-11 16:58:12,365 | DEBUG | hackthon_support_agent.FunctionService | Saving functional requirements to project document: 5119aa4d-7997-4fc8-bb6c-dc0d23f44dc9
2025-11-11 16:58:19,220 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:58:19,224 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 16:58:19,224 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:58:19,233 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:58:19,233 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:58:19,236 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:58:19,236 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:58:19,238 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:58:19,239 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:58:19,241 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:58:19,241 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:58:19,302 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Fetching context for project: 5119aa4d-7997-4fc8-bb6c-dc0d23f44dc9
2025-11-11 16:58:19,307 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Starting workflow for project: 5119aa4d-7997-4fc8-bb6c-dc0d23f44dc9
2025-11-11 16:58:19,311 | INFO | hackthon_support_agent.BaseService | [PLANNING] Starting planning phase
2025-11-11 16:58:19,312 | INFO | hackthon_support_agent.BaseService | [PLANNING] Plan created with 3 focus areas
2025-11-11 16:58:19,315 | INFO | hackthon_support_agent.BaseService | [CACHE] Creating context cache
2025-11-11 16:58:19,563 | ERROR | hackthon_support_agent.BaseService | [CACHE] Cache creation failed: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'Cached content is too small. total_token_count=3955, min_total_token_count=4096', 'status': 'INVALID_ARGUMENT'}}
2025-11-11 16:58:19,566 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Starting parallel extraction
2025-11-11 16:58:19,566 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: データ・モデル
2025-11-11 16:58:24,559 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 16:58:24,562 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 16:58:24,563 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:58:24,567 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:58:24,567 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:58:24,570 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:58:24,571 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:58:24,573 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:58:24,573 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:58:24,574 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:58:24,575 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 16:58:24,620 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Fetching context for project: 5119aa4d-7997-4fc8-bb6c-dc0d23f44dc9
2025-11-11 16:58:24,623 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Starting workflow for project: 5119aa4d-7997-4fc8-bb6c-dc0d23f44dc9
2025-11-11 16:58:24,625 | INFO | hackthon_support_agent.BaseService | [PLANNING] Starting planning phase
2025-11-11 16:58:24,625 | INFO | hackthon_support_agent.BaseService | [PLANNING] Plan created with 3 focus areas
2025-11-11 16:58:24,626 | INFO | hackthon_support_agent.BaseService | [CACHE] Creating context cache
2025-11-11 16:58:24,863 | ERROR | hackthon_support_agent.BaseService | [CACHE] Cache creation failed: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'Cached content is too small. total_token_count=3955, min_total_token_count=4096', 'status': 'INVALID_ARGUMENT'}}
2025-11-11 16:58:24,866 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Starting parallel extraction
2025-11-11 16:58:24,866 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: データ・モデル
2025-11-11 16:58:29,747 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 5 functions using LangChain
2025-11-11 16:58:29,749 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] データ・モデル completed in 10.18s - 5 functions extracted
2025-11-11 16:58:29,749 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: API・バックエンド
2025-11-11 16:58:40,482 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 5 functions using LangChain
2025-11-11 16:58:40,482 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] データ・モデル completed in 15.62s - 5 functions extracted
2025-11-11 16:58:40,483 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: API・バックエンド
2025-11-11 16:58:45,577 | DEBUG | hackthon_support_agent.FrameworkService | Initializing BaseService (provider=google)
2025-11-11 16:58:45,583 | INFO | hackthon_support_agent.FrameworkService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 16:58:45,584 | DEBUG | hackthon_support_agent.FrameworkService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:58:45,601 | INFO | hackthon_support_agent.FrameworkService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:58:45,601 | DEBUG | hackthon_support_agent.FrameworkService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:58:45,603 | INFO | hackthon_support_agent.FrameworkService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:58:45,603 | DEBUG | hackthon_support_agent.FrameworkService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 16:58:45,605 | INFO | hackthon_support_agent.FrameworkService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 16:58:45,606 | DEBUG | hackthon_support_agent.FrameworkService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 16:58:45,607 | INFO | hackthon_support_agent.FrameworkService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 16:58:45,608 | DEBUG | hackthon_support_agent.FrameworkService | LLMs initialized
2025-11-11 16:58:45,608 | DEBUG | hackthon_support_agent.FrameworkService | Fetching prompt 'framework_service.generate_simple_recommendations'
2025-11-11 16:58:49,770 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 6 functions using LangChain
2025-11-11 16:58:49,771 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] API・バックエンド completed in 20.02s - 6 functions extracted
2025-11-11 16:58:49,771 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: UI・画面
2025-11-11 16:59:07,923 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 7 functions using LangChain
2025-11-11 16:59:07,925 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] API・バックエンド completed in 27.44s - 7 functions extracted
2025-11-11 16:59:07,925 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: UI・画面
2025-11-11 16:59:10,054 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 7 functions using LangChain
2025-11-11 16:59:10,054 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] UI・画面 completed in 20.28s - 7 functions extracted
2025-11-11 16:59:10,055 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Completed: 3 areas processed
2025-11-11 16:59:10,062 | INFO | hackthon_support_agent.BaseService | [MERGE] Merging results from all focus areas
2025-11-11 16:59:10,063 | INFO | hackthon_support_agent.BaseService | [MERGE] Merged: 18 unique functions
2025-11-11 16:59:10,064 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURING] Starting parallel structuring
2025-11-11 16:59:10,080 | ERROR | hackthon_support_agent.BaseService | Categorization failed: Event loop is closed
2025-11-11 16:59:10,081 | ERROR | hackthon_support_agent.BaseService | [CATEGORIZE] Returning original functions unchanged
2025-11-11 16:59:10,081 | ERROR | hackthon_support_agent.BaseService | Priority assignment failed: Event loop is closed
2025-11-11 16:59:10,082 | ERROR | hackthon_support_agent.BaseService | Dependency analysis failed: Event loop is closed
2025-11-11 16:59:10,082 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURING] Completed: 18 functions, 0 dependencies
2025-11-11 16:59:10,084 | INFO | hackthon_support_agent.BaseService | [PERSISTENCE] Saving to database
2025-11-11 16:59:10,113 | INFO | hackthon_support_agent.BaseService | [PERSISTENCE] Saved 18 functions and 0 dependencies to DB
2025-11-11 16:59:10,115 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Workflow completed in 50.81s
2025-11-11 16:59:33,822 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 7 functions using LangChain
2025-11-11 16:59:33,825 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] UI・画面 completed in 25.90s - 7 functions extracted
2025-11-11 16:59:33,826 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Completed: 3 areas processed
2025-11-11 16:59:33,830 | INFO | hackthon_support_agent.BaseService | [MERGE] Merging results from all focus areas
2025-11-11 16:59:33,831 | INFO | hackthon_support_agent.BaseService | [MERGE] Merged: 16 unique functions
2025-11-11 16:59:33,834 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURING] Starting parallel structuring
2025-11-11 16:59:33,864 | ERROR | hackthon_support_agent.BaseService | Categorization failed: Event loop is closed
2025-11-11 16:59:33,864 | ERROR | hackthon_support_agent.BaseService | [CATEGORIZE] Returning original functions unchanged
2025-11-11 16:59:33,864 | ERROR | hackthon_support_agent.BaseService | Priority assignment failed: Event loop is closed
2025-11-11 16:59:33,865 | ERROR | hackthon_support_agent.BaseService | Dependency analysis failed: Event loop is closed
2025-11-11 16:59:33,865 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURING] Completed: 16 functions, 0 dependencies
2025-11-11 16:59:33,867 | INFO | hackthon_support_agent.BaseService | [PERSISTENCE] Saving to database
2025-11-11 16:59:33,872 | ERROR | hackthon_support_agent.BaseService | [PERSISTENCE] Persistence failed: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "structured_functions_project_id_function_code_key"
DETAIL:  Key (project_id, function_code)=(5119aa4d-7997-4fc8-bb6c-dc0d23f44dc9, F001) already exists.

[SQL: INSERT INTO structured_functions (function_id, project_id, function_code, function_name, description, category, priority, source_doc_id, extraction_confidence, order_index) VALUES (%(function_id)s::UUID, %(project_id)s::UUID, %(function_code)s, %(function_name)s, %(description)s, %(category)s, %(priority)s, %(source_doc_id)s::UUID, %(extraction_confidence)s, %(order_index)s) RETURNING structured_functions.created_at]
[parameters: {'function_id': UUID('fd84aece-7c01-470a-83b6-b4349bc6202e'), 'project_id': '5119aa4d-7997-4fc8-bb6c-dc0d23f44dc9', 'function_code': 'F001', 'function_name': 'ユーザープロファイルデータ管理', 'description': 'システムに登録されたユーザーの基本情報（ID、パスワードハッシュ、メールアドレスなど）と、AIが動的に構築する学習プロファイル（現在の学力レベル、得意・不得意分野、各単元の理解度、ユーザーからの自己申告情報など）を永続的に保存、更新、取得するためのデータ管理機能。新規ユーザー登録時のプロファイル初期化、学習進捗に応じたリアルタイムなプロファイル更新、AIによる個別最適化課題生成のためのプロファイルデータ効率的取得を可能にするAPIエンドポイント群を提供する。データはセキュアに管理され、個人情報保護に配慮した構造とする。', 'category': 'data', 'priority': 'Should', 'source_doc_id': None, 'extraction_confidence': 0.8, 'order_index': 1}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
2025-11-11 16:59:33,874 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Workflow completed in 69.25s
2025-11-11 17:02:16,069 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 17:02:36,457 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-11 17:03:17,272 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-11-11 17:03:17,277 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 17:03:17,277 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 17:03:17,323 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 17:03:17,324 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 17:03:17,331 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 17:03:17,332 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 17:03:17,337 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 17:03:17,337 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 17:03:17,341 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 17:03:17,342 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-11-11 17:03:17,342 | DEBUG | hackthon_support_agent.QuestionService | Generating questions for project_id: 0f0aa27a-059d-401d-bc63-a1a07002cdf3 with idea_prompt: プロジェクトタイトル: オンライン学習プラットフォーム
プロジェクトアイディア: 学生の学力と得意不得意に合わせたAIを用いた動的な課題作成サービス
期間: 2025-11-11 〜 2025-12-11 02:03
2025-11-11 17:03:17,343 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-11-11 17:03:30,404 | INFO | hackthon_support_agent.QuestionService | Generated 6 questions for project_id: 0f0aa27a-059d-401d-bc63-a1a07002cdf3
2025-11-11 17:03:30,413 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-11-11 17:03:30,415 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 17:03:30,415 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 17:03:30,419 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 17:03:30,420 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 17:03:30,421 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 17:03:30,421 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 17:03:30,424 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 17:03:30,424 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 17:03:30,425 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 17:03:30,425 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-11-11 17:03:38,720 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-11-11 17:03:38,724 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 17:03:38,725 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 17:03:38,729 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 17:03:38,730 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 17:03:38,733 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 17:03:38,734 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 17:03:38,736 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 17:03:38,737 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 17:03:38,739 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 17:03:38,739 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-11-11 17:03:38,807 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.generate_summary_document'
2025-11-11 17:03:52,735 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-11-11 17:03:52,739 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 17:03:52,739 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 17:03:52,746 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 17:03:52,747 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 17:03:52,748 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 17:03:52,749 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 17:03:52,750 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 17:03:52,751 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 17:03:52,752 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 17:03:52,752 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-11-11 17:03:53,563 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-11-11 17:03:53,565 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 17:03:53,566 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 17:03:53,568 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 17:03:53,568 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 17:03:53,570 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 17:03:53,571 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 17:03:53,572 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 17:03:53,572 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 17:03:53,574 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 17:03:53,574 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-11-11 17:03:53,584 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-11-11 17:04:13,711 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-11-11 17:04:13,723 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 17:04:13,724 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 17:04:13,739 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 17:04:13,740 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 17:04:13,765 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 17:04:13,765 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 17:04:13,774 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 17:04:13,776 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 17:04:13,782 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 17:04:13,783 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-11-11 17:04:13,947 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: 0f0aa27a-059d-401d-bc63-a1a07002cdf3
2025-11-11 17:04:13,954 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.evaluate_specification'
2025-11-11 17:04:14,766 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-11-11 17:04:14,770 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 17:04:14,770 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 17:04:14,772 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 17:04:14,773 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 17:04:14,775 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 17:04:14,775 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 17:04:14,778 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 17:04:14,778 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 17:04:14,781 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 17:04:14,781 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-11-11 17:04:14,830 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: 0f0aa27a-059d-401d-bc63-a1a07002cdf3
2025-11-11 17:04:14,834 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.evaluate_specification'
2025-11-11 17:04:26,825 | DEBUG | hackthon_support_agent.FunctionService | Initializing BaseService (provider=google)
2025-11-11 17:04:26,828 | INFO | hackthon_support_agent.FunctionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 17:04:26,828 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 17:04:26,831 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 17:04:26,831 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 17:04:26,833 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 17:04:26,833 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 17:04:26,835 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 17:04:26,836 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 17:04:26,837 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 17:04:26,838 | DEBUG | hackthon_support_agent.FunctionService | LLMs initialized
2025-11-11 17:04:26,838 | DEBUG | hackthon_support_agent.FunctionService | Generating functional requirements for project_id: 0f0aa27a-059d-401d-bc63-a1a07002cdf3
2025-11-11 17:04:26,840 | DEBUG | hackthon_support_agent.FunctionService | Fetching prompt 'function_service.generate_functional_requirements'
2025-11-11 17:05:32,741 | DEBUG | hackthon_support_agent.FunctionService | Generating clarification questions for 2 low-confidence requirements
2025-11-11 17:05:32,744 | DEBUG | hackthon_support_agent.FunctionService | Fetching prompt 'function_service.generate_clarification_questions'
2025-11-11 17:05:50,334 | DEBUG | hackthon_support_agent.FunctionService | Saving functional requirements to project document: 0f0aa27a-059d-401d-bc63-a1a07002cdf3
2025-11-11 17:05:50,361 | DEBUG | hackthon_support_agent.FunctionService | Saving 6 clarification questions to database
2025-11-11 17:05:59,914 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-11 17:05:59,919 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 17:05:59,929 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 17:05:59,940 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 17:05:59,941 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 17:05:59,945 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 17:05:59,946 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 17:05:59,948 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 17:05:59,949 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 17:05:59,951 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 17:05:59,951 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-11 17:06:00,022 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Fetching context for project: 0f0aa27a-059d-401d-bc63-a1a07002cdf3
2025-11-11 17:06:00,026 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Starting workflow for project: 0f0aa27a-059d-401d-bc63-a1a07002cdf3
2025-11-11 17:06:00,047 | INFO | hackthon_support_agent.BaseService | [PLANNING] Starting planning phase
2025-11-11 17:06:00,047 | INFO | hackthon_support_agent.BaseService | [PLANNING] Plan created with 3 focus areas
2025-11-11 17:06:00,067 | INFO | hackthon_support_agent.BaseService | [CACHE] Creating context cache
2025-11-11 17:06:01,713 | INFO | hackthon_support_agent.BaseService | [CACHE] Context cache created: cachedContents/afphq5azdwx7qnzfkpvm3gbrf5akx483w0srsrr3
2025-11-11 17:06:01,716 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Starting parallel extraction
2025-11-11 17:06:01,716 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: データ・モデル
2025-11-11 17:06:01,735 | DEBUG | hackthon_support_agent.FrameworkService | Initializing BaseService (provider=google)
2025-11-11 17:06:01,738 | INFO | hackthon_support_agent.FrameworkService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-11 17:06:01,738 | DEBUG | hackthon_support_agent.FrameworkService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 17:06:01,740 | INFO | hackthon_support_agent.FrameworkService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 17:06:01,741 | DEBUG | hackthon_support_agent.FrameworkService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 17:06:01,742 | INFO | hackthon_support_agent.FrameworkService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 17:06:01,742 | DEBUG | hackthon_support_agent.FrameworkService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-11 17:06:01,744 | INFO | hackthon_support_agent.FrameworkService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-11 17:06:01,744 | DEBUG | hackthon_support_agent.FrameworkService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-11 17:06:01,746 | INFO | hackthon_support_agent.FrameworkService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-11 17:06:01,746 | DEBUG | hackthon_support_agent.FrameworkService | LLMs initialized
2025-11-11 17:06:01,746 | DEBUG | hackthon_support_agent.FrameworkService | Fetching prompt 'framework_service.generate_simple_recommendations'
2025-11-11 17:06:08,505 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 5 functions using Cache
2025-11-11 17:06:08,505 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] データ・モデル completed in 6.79s - 5 functions extracted
2025-11-11 17:06:08,506 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: API・バックエンド
2025-11-11 17:06:16,273 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 8 functions using Cache
2025-11-11 17:06:16,274 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] API・バックエンド completed in 7.77s - 8 functions extracted
2025-11-11 17:06:16,274 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: UI・画面
2025-11-11 17:06:24,878 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 8 functions using Cache
2025-11-11 17:06:24,878 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] UI・画面 completed in 8.60s - 8 functions extracted
2025-11-11 17:06:24,879 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Completed: 3 areas processed
2025-11-11 17:06:24,882 | INFO | hackthon_support_agent.BaseService | [MERGE] Merging results from all focus areas
2025-11-11 17:06:24,882 | INFO | hackthon_support_agent.BaseService | [MERGE] Merged: 21 unique functions
2025-11-11 17:06:24,884 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURING] Starting parallel structuring
2025-11-11 17:06:50,338 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority assignment successful: 21 functions
2025-11-11 17:06:50,339 | INFO | hackthon_support_agent.BaseService | [PRIORITY] Priority distribution: {'Must': 18, 'Could': 2, 'Should': 1}
2025-11-11 17:06:50,938 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Categorization successful: 21 functions
2025-11-11 17:06:50,939 | INFO | hackthon_support_agent.BaseService | [CATEGORIZE] Category distribution: {'data': 6, 'auth': 1, 'logic': 5, 'api': 1, 'ui': 8}
2025-11-11 17:06:54,018 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency analysis successful: 32 dependencies
2025-11-11 17:06:54,018 | INFO | hackthon_support_agent.BaseService | [DEPENDENCY] Dependency type distribution: {'requires': 23, 'blocks': 4, 'relates': 5}
2025-11-11 17:06:54,019 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURING] Completed: 21 functions, 32 dependencies
2025-11-11 17:06:54,022 | INFO | hackthon_support_agent.BaseService | [PERSISTENCE] Saving to database
2025-11-11 17:06:54,040 | INFO | hackthon_support_agent.BaseService | [PERSISTENCE] Cleared existing data for project 0f0aa27a-059d-401d-bc63-a1a07002cdf3
2025-11-11 17:06:54,065 | INFO | hackthon_support_agent.BaseService | [PERSISTENCE] Saved 21 functions and 32 dependencies to DB
2025-11-11 17:06:54,067 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Workflow completed in 54.04s
2025-11-12 01:38:46,474 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-12 01:38:49,080 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-12 01:43:02,983 | DEBUG | hackthon_support_agent.IntegratedTaskService | Initializing BaseService (provider=google)
2025-11-12 01:43:02,988 | INFO | hackthon_support_agent.IntegratedTaskService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-12 01:43:02,988 | DEBUG | hackthon_support_agent.IntegratedTaskService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 01:43:03,072 | INFO | hackthon_support_agent.IntegratedTaskService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 01:43:03,073 | DEBUG | hackthon_support_agent.IntegratedTaskService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 01:43:03,075 | INFO | hackthon_support_agent.IntegratedTaskService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 01:43:03,075 | DEBUG | hackthon_support_agent.IntegratedTaskService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 01:43:03,077 | INFO | hackthon_support_agent.IntegratedTaskService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 01:43:03,077 | DEBUG | hackthon_support_agent.IntegratedTaskService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-12 01:43:03,079 | INFO | hackthon_support_agent.IntegratedTaskService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-12 01:43:03,079 | DEBUG | hackthon_support_agent.IntegratedTaskService | LLMs initialized
2025-11-12 01:43:03,080 | DEBUG | hackthon_support_agent.TaskGenerationService | Initializing BaseService (provider=google)
2025-11-12 01:43:03,082 | INFO | hackthon_support_agent.TaskGenerationService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-12 01:43:03,082 | DEBUG | hackthon_support_agent.TaskGenerationService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 01:43:03,085 | INFO | hackthon_support_agent.TaskGenerationService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 01:43:03,085 | DEBUG | hackthon_support_agent.TaskGenerationService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 01:43:03,088 | INFO | hackthon_support_agent.TaskGenerationService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 01:43:03,088 | DEBUG | hackthon_support_agent.TaskGenerationService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 01:43:03,091 | INFO | hackthon_support_agent.TaskGenerationService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 01:43:03,091 | DEBUG | hackthon_support_agent.TaskGenerationService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-12 01:43:03,093 | INFO | hackthon_support_agent.TaskGenerationService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-12 01:43:03,093 | DEBUG | hackthon_support_agent.TaskGenerationService | LLMs initialized
2025-11-12 01:43:03,094 | DEBUG | hackthon_support_agent.TaskQualityEvaluationService | Initializing BaseService (provider=google)
2025-11-12 01:43:03,096 | INFO | hackthon_support_agent.TaskQualityEvaluationService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-12 01:43:03,096 | DEBUG | hackthon_support_agent.TaskQualityEvaluationService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 01:43:03,098 | INFO | hackthon_support_agent.TaskQualityEvaluationService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 01:43:03,098 | DEBUG | hackthon_support_agent.TaskQualityEvaluationService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 01:43:03,100 | INFO | hackthon_support_agent.TaskQualityEvaluationService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 01:43:03,100 | DEBUG | hackthon_support_agent.TaskQualityEvaluationService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 01:43:03,102 | INFO | hackthon_support_agent.TaskQualityEvaluationService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 01:43:03,102 | DEBUG | hackthon_support_agent.TaskQualityEvaluationService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-12 01:43:03,104 | INFO | hackthon_support_agent.TaskQualityEvaluationService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-12 01:43:03,104 | DEBUG | hackthon_support_agent.TaskQualityEvaluationService | LLMs initialized
2025-11-12 01:43:03,104 | DEBUG | hackthon_support_agent.LayerConsistencyEvaluator | Initializing BaseService (provider=google)
2025-11-12 01:43:03,106 | INFO | hackthon_support_agent.LayerConsistencyEvaluator | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-12 01:43:03,107 | DEBUG | hackthon_support_agent.LayerConsistencyEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 01:43:03,109 | INFO | hackthon_support_agent.LayerConsistencyEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 01:43:03,109 | DEBUG | hackthon_support_agent.LayerConsistencyEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 01:43:03,114 | INFO | hackthon_support_agent.LayerConsistencyEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 01:43:03,114 | DEBUG | hackthon_support_agent.LayerConsistencyEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 01:43:03,116 | INFO | hackthon_support_agent.LayerConsistencyEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 01:43:03,116 | DEBUG | hackthon_support_agent.LayerConsistencyEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-12 01:43:03,257 | INFO | hackthon_support_agent.LayerConsistencyEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-12 01:43:03,257 | DEBUG | hackthon_support_agent.LayerConsistencyEvaluator | LLMs initialized
2025-11-12 01:43:03,257 | DEBUG | hackthon_support_agent.DomainCompletenessEvaluator | Initializing BaseService (provider=google)
2025-11-12 01:43:03,260 | INFO | hackthon_support_agent.DomainCompletenessEvaluator | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-12 01:43:03,260 | DEBUG | hackthon_support_agent.DomainCompletenessEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 01:43:03,262 | INFO | hackthon_support_agent.DomainCompletenessEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 01:43:03,262 | DEBUG | hackthon_support_agent.DomainCompletenessEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 01:43:03,264 | INFO | hackthon_support_agent.DomainCompletenessEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 01:43:03,264 | DEBUG | hackthon_support_agent.DomainCompletenessEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 01:43:03,266 | INFO | hackthon_support_agent.DomainCompletenessEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 01:43:03,266 | DEBUG | hackthon_support_agent.DomainCompletenessEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-12 01:43:03,267 | INFO | hackthon_support_agent.DomainCompletenessEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-12 01:43:03,268 | DEBUG | hackthon_support_agent.DomainCompletenessEvaluator | LLMs initialized
2025-11-12 01:43:03,268 | DEBUG | hackthon_support_agent.TaskDependencyService | Initializing BaseService (provider=google)
2025-11-12 01:43:03,270 | INFO | hackthon_support_agent.TaskDependencyService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-12 01:43:03,271 | DEBUG | hackthon_support_agent.TaskDependencyService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 01:43:03,272 | INFO | hackthon_support_agent.TaskDependencyService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 01:43:03,273 | DEBUG | hackthon_support_agent.TaskDependencyService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 01:43:03,274 | INFO | hackthon_support_agent.TaskDependencyService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 01:43:03,275 | DEBUG | hackthon_support_agent.TaskDependencyService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 01:43:03,276 | INFO | hackthon_support_agent.TaskDependencyService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 01:43:03,277 | DEBUG | hackthon_support_agent.TaskDependencyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-12 01:43:03,278 | INFO | hackthon_support_agent.TaskDependencyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-12 01:43:03,278 | DEBUG | hackthon_support_agent.TaskDependencyService | LLMs initialized
2025-11-12 01:43:03,279 | DEBUG | hackthon_support_agent.TaskPositionService | Initializing BaseService (provider=google)
2025-11-12 01:43:03,281 | INFO | hackthon_support_agent.TaskPositionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-12 01:43:03,281 | DEBUG | hackthon_support_agent.TaskPositionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 01:43:03,283 | INFO | hackthon_support_agent.TaskPositionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 01:43:03,283 | DEBUG | hackthon_support_agent.TaskPositionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 01:43:03,285 | INFO | hackthon_support_agent.TaskPositionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 01:43:03,285 | DEBUG | hackthon_support_agent.TaskPositionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 01:43:03,289 | INFO | hackthon_support_agent.TaskPositionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 01:43:03,289 | DEBUG | hackthon_support_agent.TaskPositionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-12 01:43:03,291 | INFO | hackthon_support_agent.TaskPositionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-12 01:43:03,292 | DEBUG | hackthon_support_agent.TaskPositionService | LLMs initialized
2025-11-12 01:43:53,443 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-12 01:44:04,088 | DEBUG | hackthon_support_agent.IntegratedTaskService | Initializing BaseService (provider=google)
2025-11-12 01:44:04,093 | INFO | hackthon_support_agent.IntegratedTaskService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-12 01:44:04,094 | DEBUG | hackthon_support_agent.IntegratedTaskService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 01:44:04,113 | INFO | hackthon_support_agent.IntegratedTaskService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 01:44:04,113 | DEBUG | hackthon_support_agent.IntegratedTaskService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 01:44:04,115 | INFO | hackthon_support_agent.IntegratedTaskService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 01:44:04,116 | DEBUG | hackthon_support_agent.IntegratedTaskService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 01:44:04,118 | INFO | hackthon_support_agent.IntegratedTaskService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 01:44:04,118 | DEBUG | hackthon_support_agent.IntegratedTaskService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-12 01:44:04,119 | INFO | hackthon_support_agent.IntegratedTaskService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-12 01:44:04,120 | DEBUG | hackthon_support_agent.IntegratedTaskService | LLMs initialized
2025-11-12 01:44:04,121 | DEBUG | hackthon_support_agent.TaskGenerationService | Initializing BaseService (provider=google)
2025-11-12 01:44:04,123 | INFO | hackthon_support_agent.TaskGenerationService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-12 01:44:04,123 | DEBUG | hackthon_support_agent.TaskGenerationService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 01:44:04,125 | INFO | hackthon_support_agent.TaskGenerationService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 01:44:04,125 | DEBUG | hackthon_support_agent.TaskGenerationService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 01:44:04,127 | INFO | hackthon_support_agent.TaskGenerationService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 01:44:04,127 | DEBUG | hackthon_support_agent.TaskGenerationService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 01:44:04,129 | INFO | hackthon_support_agent.TaskGenerationService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 01:44:04,129 | DEBUG | hackthon_support_agent.TaskGenerationService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-12 01:44:04,131 | INFO | hackthon_support_agent.TaskGenerationService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-12 01:44:04,131 | DEBUG | hackthon_support_agent.TaskGenerationService | LLMs initialized
2025-11-12 01:44:04,131 | DEBUG | hackthon_support_agent.TaskQualityEvaluationService | Initializing BaseService (provider=google)
2025-11-12 01:44:04,134 | INFO | hackthon_support_agent.TaskQualityEvaluationService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-12 01:44:04,134 | DEBUG | hackthon_support_agent.TaskQualityEvaluationService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 01:44:04,136 | INFO | hackthon_support_agent.TaskQualityEvaluationService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 01:44:04,136 | DEBUG | hackthon_support_agent.TaskQualityEvaluationService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 01:44:04,138 | INFO | hackthon_support_agent.TaskQualityEvaluationService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 01:44:04,138 | DEBUG | hackthon_support_agent.TaskQualityEvaluationService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 01:44:04,140 | INFO | hackthon_support_agent.TaskQualityEvaluationService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 01:44:04,140 | DEBUG | hackthon_support_agent.TaskQualityEvaluationService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-12 01:44:04,142 | INFO | hackthon_support_agent.TaskQualityEvaluationService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-12 01:44:04,143 | DEBUG | hackthon_support_agent.TaskQualityEvaluationService | LLMs initialized
2025-11-12 01:44:04,143 | DEBUG | hackthon_support_agent.LayerConsistencyEvaluator | Initializing BaseService (provider=google)
2025-11-12 01:44:04,146 | INFO | hackthon_support_agent.LayerConsistencyEvaluator | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-12 01:44:04,146 | DEBUG | hackthon_support_agent.LayerConsistencyEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 01:44:04,148 | INFO | hackthon_support_agent.LayerConsistencyEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 01:44:04,148 | DEBUG | hackthon_support_agent.LayerConsistencyEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 01:44:04,151 | INFO | hackthon_support_agent.LayerConsistencyEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 01:44:04,151 | DEBUG | hackthon_support_agent.LayerConsistencyEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 01:44:04,154 | INFO | hackthon_support_agent.LayerConsistencyEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 01:44:04,154 | DEBUG | hackthon_support_agent.LayerConsistencyEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-12 01:44:04,157 | INFO | hackthon_support_agent.LayerConsistencyEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-12 01:44:04,157 | DEBUG | hackthon_support_agent.LayerConsistencyEvaluator | LLMs initialized
2025-11-12 01:44:04,158 | DEBUG | hackthon_support_agent.DomainCompletenessEvaluator | Initializing BaseService (provider=google)
2025-11-12 01:44:04,261 | INFO | hackthon_support_agent.DomainCompletenessEvaluator | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-12 01:44:04,262 | DEBUG | hackthon_support_agent.DomainCompletenessEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 01:44:04,263 | INFO | hackthon_support_agent.DomainCompletenessEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 01:44:04,264 | DEBUG | hackthon_support_agent.DomainCompletenessEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 01:44:04,265 | INFO | hackthon_support_agent.DomainCompletenessEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 01:44:04,265 | DEBUG | hackthon_support_agent.DomainCompletenessEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 01:44:04,267 | INFO | hackthon_support_agent.DomainCompletenessEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 01:44:04,267 | DEBUG | hackthon_support_agent.DomainCompletenessEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-12 01:44:04,269 | INFO | hackthon_support_agent.DomainCompletenessEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-12 01:44:04,269 | DEBUG | hackthon_support_agent.DomainCompletenessEvaluator | LLMs initialized
2025-11-12 01:44:04,270 | DEBUG | hackthon_support_agent.TaskDependencyService | Initializing BaseService (provider=google)
2025-11-12 01:44:04,272 | INFO | hackthon_support_agent.TaskDependencyService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-12 01:44:04,272 | DEBUG | hackthon_support_agent.TaskDependencyService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 01:44:04,273 | INFO | hackthon_support_agent.TaskDependencyService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 01:44:04,274 | DEBUG | hackthon_support_agent.TaskDependencyService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 01:44:04,275 | INFO | hackthon_support_agent.TaskDependencyService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 01:44:04,276 | DEBUG | hackthon_support_agent.TaskDependencyService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 01:44:04,277 | INFO | hackthon_support_agent.TaskDependencyService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 01:44:04,277 | DEBUG | hackthon_support_agent.TaskDependencyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-12 01:44:04,279 | INFO | hackthon_support_agent.TaskDependencyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-12 01:44:04,280 | DEBUG | hackthon_support_agent.TaskDependencyService | LLMs initialized
2025-11-12 01:44:04,280 | DEBUG | hackthon_support_agent.TaskPositionService | Initializing BaseService (provider=google)
2025-11-12 01:44:04,282 | INFO | hackthon_support_agent.TaskPositionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-12 01:44:04,282 | DEBUG | hackthon_support_agent.TaskPositionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 01:44:04,284 | INFO | hackthon_support_agent.TaskPositionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 01:44:04,285 | DEBUG | hackthon_support_agent.TaskPositionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 01:44:04,286 | INFO | hackthon_support_agent.TaskPositionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 01:44:04,286 | DEBUG | hackthon_support_agent.TaskPositionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 01:44:04,288 | INFO | hackthon_support_agent.TaskPositionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 01:44:04,289 | DEBUG | hackthon_support_agent.TaskPositionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-12 01:44:04,291 | INFO | hackthon_support_agent.TaskPositionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-12 01:44:04,291 | DEBUG | hackthon_support_agent.TaskPositionService | LLMs initialized
2025-11-12 01:44:30,496 | INFO | hackthon_support_agent.TaskGenerationService | ✅ Batch batch_4: All tasks validated successfully on attempt 1
2025-11-12 01:44:30,503 | INFO | hackthon_support_agent.TaskGenerationService | ✅ Batch batch_3: All tasks validated successfully on attempt 1
2025-11-12 01:44:33,730 | INFO | hackthon_support_agent.TaskGenerationService | ✅ Batch batch_2: All tasks validated successfully on attempt 1
2025-11-12 01:44:45,691 | INFO | hackthon_support_agent.TaskGenerationService | ✅ Batch batch_1: All tasks validated successfully on attempt 1
2025-11-12 02:12:50,400 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-12 02:38:06,016 | DEBUG | hackthon_support_agent.IntegratedTaskService | Initializing BaseService (provider=google)
2025-11-12 02:38:06,022 | INFO | hackthon_support_agent.IntegratedTaskService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-12 02:38:06,023 | DEBUG | hackthon_support_agent.IntegratedTaskService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 02:38:06,064 | INFO | hackthon_support_agent.IntegratedTaskService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 02:38:06,064 | DEBUG | hackthon_support_agent.IntegratedTaskService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 02:38:06,067 | INFO | hackthon_support_agent.IntegratedTaskService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 02:38:06,067 | DEBUG | hackthon_support_agent.IntegratedTaskService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 02:38:06,070 | INFO | hackthon_support_agent.IntegratedTaskService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 02:38:06,071 | DEBUG | hackthon_support_agent.IntegratedTaskService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-12 02:38:06,073 | INFO | hackthon_support_agent.IntegratedTaskService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-12 02:38:06,074 | DEBUG | hackthon_support_agent.IntegratedTaskService | LLMs initialized
2025-11-12 02:38:06,075 | DEBUG | hackthon_support_agent.TaskGenerationService | Initializing BaseService (provider=google)
2025-11-12 02:38:06,078 | INFO | hackthon_support_agent.TaskGenerationService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-12 02:38:06,078 | DEBUG | hackthon_support_agent.TaskGenerationService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 02:38:06,081 | INFO | hackthon_support_agent.TaskGenerationService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 02:38:06,081 | DEBUG | hackthon_support_agent.TaskGenerationService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 02:38:06,084 | INFO | hackthon_support_agent.TaskGenerationService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 02:38:06,085 | DEBUG | hackthon_support_agent.TaskGenerationService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 02:38:06,087 | INFO | hackthon_support_agent.TaskGenerationService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 02:38:06,088 | DEBUG | hackthon_support_agent.TaskGenerationService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-12 02:38:06,091 | INFO | hackthon_support_agent.TaskGenerationService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-12 02:38:06,092 | DEBUG | hackthon_support_agent.TaskGenerationService | LLMs initialized
2025-11-12 02:38:06,093 | DEBUG | hackthon_support_agent.TaskQualityEvaluationService | Initializing BaseService (provider=google)
2025-11-12 02:38:06,097 | INFO | hackthon_support_agent.TaskQualityEvaluationService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-12 02:38:06,097 | DEBUG | hackthon_support_agent.TaskQualityEvaluationService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 02:38:06,101 | INFO | hackthon_support_agent.TaskQualityEvaluationService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 02:38:06,102 | DEBUG | hackthon_support_agent.TaskQualityEvaluationService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 02:38:06,106 | INFO | hackthon_support_agent.TaskQualityEvaluationService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 02:38:06,107 | DEBUG | hackthon_support_agent.TaskQualityEvaluationService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 02:38:06,112 | INFO | hackthon_support_agent.TaskQualityEvaluationService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 02:38:06,113 | DEBUG | hackthon_support_agent.TaskQualityEvaluationService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-12 02:38:06,117 | INFO | hackthon_support_agent.TaskQualityEvaluationService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-12 02:38:06,118 | DEBUG | hackthon_support_agent.TaskQualityEvaluationService | LLMs initialized
2025-11-12 02:38:06,118 | DEBUG | hackthon_support_agent.LayerConsistencyEvaluator | Initializing BaseService (provider=google)
2025-11-12 02:38:06,122 | INFO | hackthon_support_agent.LayerConsistencyEvaluator | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-12 02:38:06,122 | DEBUG | hackthon_support_agent.LayerConsistencyEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 02:38:06,124 | INFO | hackthon_support_agent.LayerConsistencyEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 02:38:06,125 | DEBUG | hackthon_support_agent.LayerConsistencyEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 02:38:06,128 | INFO | hackthon_support_agent.LayerConsistencyEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 02:38:06,128 | DEBUG | hackthon_support_agent.LayerConsistencyEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 02:38:06,131 | INFO | hackthon_support_agent.LayerConsistencyEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 02:38:06,131 | DEBUG | hackthon_support_agent.LayerConsistencyEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-12 02:38:06,134 | INFO | hackthon_support_agent.LayerConsistencyEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-12 02:38:06,135 | DEBUG | hackthon_support_agent.LayerConsistencyEvaluator | LLMs initialized
2025-11-12 02:38:06,135 | DEBUG | hackthon_support_agent.DomainCompletenessEvaluator | Initializing BaseService (provider=google)
2025-11-12 02:38:06,290 | INFO | hackthon_support_agent.DomainCompletenessEvaluator | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-12 02:38:06,291 | DEBUG | hackthon_support_agent.DomainCompletenessEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 02:38:06,293 | INFO | hackthon_support_agent.DomainCompletenessEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 02:38:06,294 | DEBUG | hackthon_support_agent.DomainCompletenessEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 02:38:06,296 | INFO | hackthon_support_agent.DomainCompletenessEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 02:38:06,296 | DEBUG | hackthon_support_agent.DomainCompletenessEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 02:38:06,298 | INFO | hackthon_support_agent.DomainCompletenessEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 02:38:06,299 | DEBUG | hackthon_support_agent.DomainCompletenessEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-12 02:38:06,300 | INFO | hackthon_support_agent.DomainCompletenessEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-12 02:38:06,301 | DEBUG | hackthon_support_agent.DomainCompletenessEvaluator | LLMs initialized
2025-11-12 02:38:06,301 | DEBUG | hackthon_support_agent.TaskDependencyService | Initializing BaseService (provider=google)
2025-11-12 02:38:06,304 | INFO | hackthon_support_agent.TaskDependencyService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-12 02:38:06,305 | DEBUG | hackthon_support_agent.TaskDependencyService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 02:38:06,307 | INFO | hackthon_support_agent.TaskDependencyService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 02:38:06,307 | DEBUG | hackthon_support_agent.TaskDependencyService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 02:38:06,309 | INFO | hackthon_support_agent.TaskDependencyService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 02:38:06,310 | DEBUG | hackthon_support_agent.TaskDependencyService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 02:38:06,312 | INFO | hackthon_support_agent.TaskDependencyService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 02:38:06,312 | DEBUG | hackthon_support_agent.TaskDependencyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-12 02:38:06,314 | INFO | hackthon_support_agent.TaskDependencyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-12 02:38:06,314 | DEBUG | hackthon_support_agent.TaskDependencyService | LLMs initialized
2025-11-12 02:38:06,315 | DEBUG | hackthon_support_agent.TaskPositionService | Initializing BaseService (provider=google)
2025-11-12 02:38:06,317 | INFO | hackthon_support_agent.TaskPositionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-12 02:38:06,318 | DEBUG | hackthon_support_agent.TaskPositionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 02:38:06,320 | INFO | hackthon_support_agent.TaskPositionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 02:38:06,320 | DEBUG | hackthon_support_agent.TaskPositionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 02:38:06,323 | INFO | hackthon_support_agent.TaskPositionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 02:38:06,323 | DEBUG | hackthon_support_agent.TaskPositionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 02:38:06,326 | INFO | hackthon_support_agent.TaskPositionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 02:38:06,326 | DEBUG | hackthon_support_agent.TaskPositionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-12 02:38:06,329 | INFO | hackthon_support_agent.TaskPositionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-12 02:38:06,330 | DEBUG | hackthon_support_agent.TaskPositionService | LLMs initialized
2025-11-12 02:38:24,984 | INFO | hackthon_support_agent.TaskGenerationService | ✅ Batch batch_1: All tasks validated successfully on attempt 1
2025-11-12 02:38:33,205 | INFO | hackthon_support_agent.TaskGenerationService | ✅ Batch batch_2: All tasks validated successfully on attempt 1
2025-11-12 02:38:33,882 | INFO | hackthon_support_agent.TaskGenerationService | ✅ Batch batch_3: All tasks validated successfully on attempt 1
2025-11-12 02:38:41,503 | INFO | hackthon_support_agent.TaskGenerationService | ✅ Batch batch_4: All tasks validated successfully on attempt 1
2025-11-12 03:15:30,018 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-12 03:18:33,747 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-12 03:22:38,471 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-12 03:29:07,779 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-12 03:29:27,467 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-12 03:30:22,211 | DEBUG | hackthon_support_agent.IntegratedTaskService | Initializing BaseService (provider=google)
2025-11-12 03:30:22,216 | INFO | hackthon_support_agent.IntegratedTaskService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-12 03:30:22,217 | DEBUG | hackthon_support_agent.IntegratedTaskService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 03:30:22,248 | INFO | hackthon_support_agent.IntegratedTaskService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 03:30:22,248 | DEBUG | hackthon_support_agent.IntegratedTaskService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 03:30:22,251 | INFO | hackthon_support_agent.IntegratedTaskService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 03:30:22,251 | DEBUG | hackthon_support_agent.IntegratedTaskService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 03:30:22,253 | INFO | hackthon_support_agent.IntegratedTaskService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 03:30:22,253 | DEBUG | hackthon_support_agent.IntegratedTaskService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-12 03:30:22,257 | INFO | hackthon_support_agent.IntegratedTaskService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-12 03:30:22,258 | DEBUG | hackthon_support_agent.IntegratedTaskService | LLMs initialized
2025-11-12 03:30:22,259 | DEBUG | hackthon_support_agent.TaskGenerationService | Initializing BaseService (provider=google)
2025-11-12 03:30:22,262 | INFO | hackthon_support_agent.TaskGenerationService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-12 03:30:22,262 | DEBUG | hackthon_support_agent.TaskGenerationService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 03:30:22,265 | INFO | hackthon_support_agent.TaskGenerationService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 03:30:22,265 | DEBUG | hackthon_support_agent.TaskGenerationService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 03:30:22,267 | INFO | hackthon_support_agent.TaskGenerationService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 03:30:22,268 | DEBUG | hackthon_support_agent.TaskGenerationService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 03:30:22,269 | INFO | hackthon_support_agent.TaskGenerationService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 03:30:22,270 | DEBUG | hackthon_support_agent.TaskGenerationService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-12 03:30:22,271 | INFO | hackthon_support_agent.TaskGenerationService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-12 03:30:22,271 | DEBUG | hackthon_support_agent.TaskGenerationService | LLMs initialized
2025-11-12 03:30:22,272 | DEBUG | hackthon_support_agent.TaskQualityEvaluationService | Initializing BaseService (provider=google)
2025-11-12 03:30:22,274 | INFO | hackthon_support_agent.TaskQualityEvaluationService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-12 03:30:22,275 | DEBUG | hackthon_support_agent.TaskQualityEvaluationService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 03:30:22,277 | INFO | hackthon_support_agent.TaskQualityEvaluationService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 03:30:22,277 | DEBUG | hackthon_support_agent.TaskQualityEvaluationService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 03:30:22,279 | INFO | hackthon_support_agent.TaskQualityEvaluationService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 03:30:22,280 | DEBUG | hackthon_support_agent.TaskQualityEvaluationService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 03:30:22,281 | INFO | hackthon_support_agent.TaskQualityEvaluationService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 03:30:22,282 | DEBUG | hackthon_support_agent.TaskQualityEvaluationService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-12 03:30:22,284 | INFO | hackthon_support_agent.TaskQualityEvaluationService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-12 03:30:22,284 | DEBUG | hackthon_support_agent.TaskQualityEvaluationService | LLMs initialized
2025-11-12 03:30:22,284 | DEBUG | hackthon_support_agent.LayerConsistencyEvaluator | Initializing BaseService (provider=google)
2025-11-12 03:30:22,287 | INFO | hackthon_support_agent.LayerConsistencyEvaluator | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-12 03:30:22,287 | DEBUG | hackthon_support_agent.LayerConsistencyEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 03:30:22,289 | INFO | hackthon_support_agent.LayerConsistencyEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 03:30:22,289 | DEBUG | hackthon_support_agent.LayerConsistencyEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 03:30:22,292 | INFO | hackthon_support_agent.LayerConsistencyEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 03:30:22,293 | DEBUG | hackthon_support_agent.LayerConsistencyEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 03:30:22,296 | INFO | hackthon_support_agent.LayerConsistencyEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 03:30:22,296 | DEBUG | hackthon_support_agent.LayerConsistencyEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-12 03:30:22,299 | INFO | hackthon_support_agent.LayerConsistencyEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-12 03:30:22,300 | DEBUG | hackthon_support_agent.LayerConsistencyEvaluator | LLMs initialized
2025-11-12 03:30:22,300 | DEBUG | hackthon_support_agent.DomainCompletenessEvaluator | Initializing BaseService (provider=google)
2025-11-12 03:30:22,533 | INFO | hackthon_support_agent.DomainCompletenessEvaluator | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-12 03:30:22,534 | DEBUG | hackthon_support_agent.DomainCompletenessEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 03:30:22,535 | INFO | hackthon_support_agent.DomainCompletenessEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 03:30:22,536 | DEBUG | hackthon_support_agent.DomainCompletenessEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 03:30:22,537 | INFO | hackthon_support_agent.DomainCompletenessEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 03:30:22,537 | DEBUG | hackthon_support_agent.DomainCompletenessEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 03:30:22,539 | INFO | hackthon_support_agent.DomainCompletenessEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 03:30:22,539 | DEBUG | hackthon_support_agent.DomainCompletenessEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-12 03:30:22,541 | INFO | hackthon_support_agent.DomainCompletenessEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-12 03:30:22,541 | DEBUG | hackthon_support_agent.DomainCompletenessEvaluator | LLMs initialized
2025-11-12 03:30:22,541 | DEBUG | hackthon_support_agent.TaskDependencyService | Initializing BaseService (provider=google)
2025-11-12 03:30:22,543 | INFO | hackthon_support_agent.TaskDependencyService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-12 03:30:22,544 | DEBUG | hackthon_support_agent.TaskDependencyService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 03:30:22,545 | INFO | hackthon_support_agent.TaskDependencyService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 03:30:22,546 | DEBUG | hackthon_support_agent.TaskDependencyService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 03:30:22,548 | INFO | hackthon_support_agent.TaskDependencyService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 03:30:22,548 | DEBUG | hackthon_support_agent.TaskDependencyService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 03:30:22,550 | INFO | hackthon_support_agent.TaskDependencyService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 03:30:22,550 | DEBUG | hackthon_support_agent.TaskDependencyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-12 03:30:22,552 | INFO | hackthon_support_agent.TaskDependencyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-12 03:30:22,552 | DEBUG | hackthon_support_agent.TaskDependencyService | LLMs initialized
2025-11-12 03:30:22,553 | DEBUG | hackthon_support_agent.TaskPositionService | Initializing BaseService (provider=google)
2025-11-12 03:30:22,555 | INFO | hackthon_support_agent.TaskPositionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-12 03:30:22,555 | DEBUG | hackthon_support_agent.TaskPositionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 03:30:22,557 | INFO | hackthon_support_agent.TaskPositionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 03:30:22,557 | DEBUG | hackthon_support_agent.TaskPositionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 03:30:22,559 | INFO | hackthon_support_agent.TaskPositionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 03:30:22,559 | DEBUG | hackthon_support_agent.TaskPositionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 03:30:22,561 | INFO | hackthon_support_agent.TaskPositionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 03:30:22,561 | DEBUG | hackthon_support_agent.TaskPositionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-12 03:30:22,563 | INFO | hackthon_support_agent.TaskPositionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-12 03:30:22,563 | DEBUG | hackthon_support_agent.TaskPositionService | LLMs initialized
2025-11-12 03:31:19,761 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-12 03:31:24,395 | DEBUG | hackthon_support_agent.IntegratedTaskService | Initializing BaseService (provider=google)
2025-11-12 03:31:24,401 | INFO | hackthon_support_agent.IntegratedTaskService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-12 03:31:24,402 | DEBUG | hackthon_support_agent.IntegratedTaskService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 03:31:24,424 | INFO | hackthon_support_agent.IntegratedTaskService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 03:31:24,425 | DEBUG | hackthon_support_agent.IntegratedTaskService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 03:31:24,428 | INFO | hackthon_support_agent.IntegratedTaskService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 03:31:24,429 | DEBUG | hackthon_support_agent.IntegratedTaskService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 03:31:24,431 | INFO | hackthon_support_agent.IntegratedTaskService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 03:31:24,431 | DEBUG | hackthon_support_agent.IntegratedTaskService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-12 03:31:24,433 | INFO | hackthon_support_agent.IntegratedTaskService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-12 03:31:24,434 | DEBUG | hackthon_support_agent.IntegratedTaskService | LLMs initialized
2025-11-12 03:31:24,434 | DEBUG | hackthon_support_agent.TaskGenerationService | Initializing BaseService (provider=google)
2025-11-12 03:31:24,437 | INFO | hackthon_support_agent.TaskGenerationService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-12 03:31:24,438 | DEBUG | hackthon_support_agent.TaskGenerationService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 03:31:24,441 | INFO | hackthon_support_agent.TaskGenerationService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 03:31:24,441 | DEBUG | hackthon_support_agent.TaskGenerationService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 03:31:24,443 | INFO | hackthon_support_agent.TaskGenerationService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 03:31:24,444 | DEBUG | hackthon_support_agent.TaskGenerationService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 03:31:24,447 | INFO | hackthon_support_agent.TaskGenerationService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 03:31:24,448 | DEBUG | hackthon_support_agent.TaskGenerationService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-12 03:31:24,451 | INFO | hackthon_support_agent.TaskGenerationService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-12 03:31:24,451 | DEBUG | hackthon_support_agent.TaskGenerationService | LLMs initialized
2025-11-12 03:31:24,452 | DEBUG | hackthon_support_agent.TaskQualityEvaluationService | Initializing BaseService (provider=google)
2025-11-12 03:31:24,457 | INFO | hackthon_support_agent.TaskQualityEvaluationService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-12 03:31:24,457 | DEBUG | hackthon_support_agent.TaskQualityEvaluationService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 03:31:24,460 | INFO | hackthon_support_agent.TaskQualityEvaluationService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 03:31:24,460 | DEBUG | hackthon_support_agent.TaskQualityEvaluationService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 03:31:24,464 | INFO | hackthon_support_agent.TaskQualityEvaluationService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 03:31:24,465 | DEBUG | hackthon_support_agent.TaskQualityEvaluationService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 03:31:24,468 | INFO | hackthon_support_agent.TaskQualityEvaluationService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 03:31:24,469 | DEBUG | hackthon_support_agent.TaskQualityEvaluationService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-12 03:31:24,472 | INFO | hackthon_support_agent.TaskQualityEvaluationService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-12 03:31:24,473 | DEBUG | hackthon_support_agent.TaskQualityEvaluationService | LLMs initialized
2025-11-12 03:31:24,473 | DEBUG | hackthon_support_agent.LayerConsistencyEvaluator | Initializing BaseService (provider=google)
2025-11-12 03:31:24,477 | INFO | hackthon_support_agent.LayerConsistencyEvaluator | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-12 03:31:24,478 | DEBUG | hackthon_support_agent.LayerConsistencyEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 03:31:24,491 | INFO | hackthon_support_agent.LayerConsistencyEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 03:31:24,492 | DEBUG | hackthon_support_agent.LayerConsistencyEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 03:31:24,495 | INFO | hackthon_support_agent.LayerConsistencyEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 03:31:24,495 | DEBUG | hackthon_support_agent.LayerConsistencyEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 03:31:24,497 | INFO | hackthon_support_agent.LayerConsistencyEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 03:31:24,498 | DEBUG | hackthon_support_agent.LayerConsistencyEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-12 03:31:24,501 | INFO | hackthon_support_agent.LayerConsistencyEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-12 03:31:24,501 | DEBUG | hackthon_support_agent.LayerConsistencyEvaluator | LLMs initialized
2025-11-12 03:31:24,502 | DEBUG | hackthon_support_agent.DomainCompletenessEvaluator | Initializing BaseService (provider=google)
2025-11-12 03:31:24,610 | INFO | hackthon_support_agent.DomainCompletenessEvaluator | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-12 03:31:24,611 | DEBUG | hackthon_support_agent.DomainCompletenessEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 03:31:24,613 | INFO | hackthon_support_agent.DomainCompletenessEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 03:31:24,613 | DEBUG | hackthon_support_agent.DomainCompletenessEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 03:31:24,615 | INFO | hackthon_support_agent.DomainCompletenessEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 03:31:24,615 | DEBUG | hackthon_support_agent.DomainCompletenessEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 03:31:24,617 | INFO | hackthon_support_agent.DomainCompletenessEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 03:31:24,618 | DEBUG | hackthon_support_agent.DomainCompletenessEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-12 03:31:24,620 | INFO | hackthon_support_agent.DomainCompletenessEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-12 03:31:24,620 | DEBUG | hackthon_support_agent.DomainCompletenessEvaluator | LLMs initialized
2025-11-12 03:31:24,620 | DEBUG | hackthon_support_agent.TaskDependencyService | Initializing BaseService (provider=google)
2025-11-12 03:31:24,623 | INFO | hackthon_support_agent.TaskDependencyService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-12 03:31:24,623 | DEBUG | hackthon_support_agent.TaskDependencyService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 03:31:24,626 | INFO | hackthon_support_agent.TaskDependencyService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 03:31:24,626 | DEBUG | hackthon_support_agent.TaskDependencyService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 03:31:24,628 | INFO | hackthon_support_agent.TaskDependencyService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 03:31:24,628 | DEBUG | hackthon_support_agent.TaskDependencyService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 03:31:24,630 | INFO | hackthon_support_agent.TaskDependencyService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 03:31:24,630 | DEBUG | hackthon_support_agent.TaskDependencyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-12 03:31:24,632 | INFO | hackthon_support_agent.TaskDependencyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-12 03:31:24,632 | DEBUG | hackthon_support_agent.TaskDependencyService | LLMs initialized
2025-11-12 03:31:24,633 | DEBUG | hackthon_support_agent.TaskPositionService | Initializing BaseService (provider=google)
2025-11-12 03:31:24,636 | INFO | hackthon_support_agent.TaskPositionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-12 03:31:24,636 | DEBUG | hackthon_support_agent.TaskPositionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 03:31:24,638 | INFO | hackthon_support_agent.TaskPositionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 03:31:24,638 | DEBUG | hackthon_support_agent.TaskPositionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 03:31:24,640 | INFO | hackthon_support_agent.TaskPositionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 03:31:24,640 | DEBUG | hackthon_support_agent.TaskPositionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 03:31:24,642 | INFO | hackthon_support_agent.TaskPositionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 03:31:24,643 | DEBUG | hackthon_support_agent.TaskPositionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-12 03:31:24,645 | INFO | hackthon_support_agent.TaskPositionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-12 03:31:24,645 | DEBUG | hackthon_support_agent.TaskPositionService | LLMs initialized
2025-11-12 03:40:36,803 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-12 03:40:40,379 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-12 03:41:10,297 | DEBUG | hackthon_support_agent.IntegratedTaskService | Initializing BaseService (provider=google)
2025-11-12 03:41:10,301 | INFO | hackthon_support_agent.IntegratedTaskService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-12 03:41:10,301 | DEBUG | hackthon_support_agent.IntegratedTaskService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 03:41:10,335 | INFO | hackthon_support_agent.IntegratedTaskService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 03:41:10,335 | DEBUG | hackthon_support_agent.IntegratedTaskService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 03:41:10,336 | INFO | hackthon_support_agent.IntegratedTaskService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 03:41:10,337 | DEBUG | hackthon_support_agent.IntegratedTaskService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 03:41:10,338 | INFO | hackthon_support_agent.IntegratedTaskService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 03:41:10,338 | DEBUG | hackthon_support_agent.IntegratedTaskService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-12 03:41:10,339 | INFO | hackthon_support_agent.IntegratedTaskService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-12 03:41:10,339 | DEBUG | hackthon_support_agent.IntegratedTaskService | LLMs initialized
2025-11-12 03:41:10,340 | DEBUG | hackthon_support_agent.TaskGenerationService | Initializing BaseService (provider=google)
2025-11-12 03:41:10,342 | INFO | hackthon_support_agent.TaskGenerationService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-12 03:41:10,342 | DEBUG | hackthon_support_agent.TaskGenerationService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 03:41:10,344 | INFO | hackthon_support_agent.TaskGenerationService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 03:41:10,345 | DEBUG | hackthon_support_agent.TaskGenerationService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 03:41:10,349 | INFO | hackthon_support_agent.TaskGenerationService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 03:41:10,349 | DEBUG | hackthon_support_agent.TaskGenerationService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 03:41:10,352 | INFO | hackthon_support_agent.TaskGenerationService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 03:41:10,352 | DEBUG | hackthon_support_agent.TaskGenerationService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-12 03:41:10,356 | INFO | hackthon_support_agent.TaskGenerationService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-12 03:41:10,356 | DEBUG | hackthon_support_agent.TaskGenerationService | LLMs initialized
2025-11-12 03:41:10,357 | DEBUG | hackthon_support_agent.TaskQualityEvaluationService | Initializing BaseService (provider=google)
2025-11-12 03:41:10,359 | INFO | hackthon_support_agent.TaskQualityEvaluationService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-12 03:41:10,360 | DEBUG | hackthon_support_agent.TaskQualityEvaluationService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 03:41:10,362 | INFO | hackthon_support_agent.TaskQualityEvaluationService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 03:41:10,362 | DEBUG | hackthon_support_agent.TaskQualityEvaluationService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 03:41:10,365 | INFO | hackthon_support_agent.TaskQualityEvaluationService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 03:41:10,365 | DEBUG | hackthon_support_agent.TaskQualityEvaluationService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 03:41:10,367 | INFO | hackthon_support_agent.TaskQualityEvaluationService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 03:41:10,367 | DEBUG | hackthon_support_agent.TaskQualityEvaluationService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-12 03:41:10,372 | INFO | hackthon_support_agent.TaskQualityEvaluationService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-12 03:41:10,372 | DEBUG | hackthon_support_agent.TaskQualityEvaluationService | LLMs initialized
2025-11-12 03:41:10,372 | DEBUG | hackthon_support_agent.LayerConsistencyEvaluator | Initializing BaseService (provider=google)
2025-11-12 03:41:10,375 | INFO | hackthon_support_agent.LayerConsistencyEvaluator | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-12 03:41:10,375 | DEBUG | hackthon_support_agent.LayerConsistencyEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 03:41:10,378 | INFO | hackthon_support_agent.LayerConsistencyEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 03:41:10,378 | DEBUG | hackthon_support_agent.LayerConsistencyEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 03:41:10,383 | INFO | hackthon_support_agent.LayerConsistencyEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 03:41:10,384 | DEBUG | hackthon_support_agent.LayerConsistencyEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 03:41:10,387 | INFO | hackthon_support_agent.LayerConsistencyEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 03:41:10,387 | DEBUG | hackthon_support_agent.LayerConsistencyEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-12 03:41:10,390 | INFO | hackthon_support_agent.LayerConsistencyEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-12 03:41:10,390 | DEBUG | hackthon_support_agent.LayerConsistencyEvaluator | LLMs initialized
2025-11-12 03:41:10,390 | DEBUG | hackthon_support_agent.DomainCompletenessEvaluator | Initializing BaseService (provider=google)
2025-11-12 03:41:10,540 | INFO | hackthon_support_agent.DomainCompletenessEvaluator | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-12 03:41:10,541 | DEBUG | hackthon_support_agent.DomainCompletenessEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 03:41:10,544 | INFO | hackthon_support_agent.DomainCompletenessEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 03:41:10,544 | DEBUG | hackthon_support_agent.DomainCompletenessEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 03:41:10,547 | INFO | hackthon_support_agent.DomainCompletenessEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 03:41:10,547 | DEBUG | hackthon_support_agent.DomainCompletenessEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 03:41:10,552 | INFO | hackthon_support_agent.DomainCompletenessEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 03:41:10,552 | DEBUG | hackthon_support_agent.DomainCompletenessEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-12 03:41:10,553 | INFO | hackthon_support_agent.DomainCompletenessEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-12 03:41:10,553 | DEBUG | hackthon_support_agent.DomainCompletenessEvaluator | LLMs initialized
2025-11-12 03:41:10,554 | DEBUG | hackthon_support_agent.TaskDependencyService | Initializing BaseService (provider=google)
2025-11-12 03:41:10,555 | INFO | hackthon_support_agent.TaskDependencyService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-12 03:41:10,555 | DEBUG | hackthon_support_agent.TaskDependencyService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 03:41:10,556 | INFO | hackthon_support_agent.TaskDependencyService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 03:41:10,557 | DEBUG | hackthon_support_agent.TaskDependencyService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 03:41:10,558 | INFO | hackthon_support_agent.TaskDependencyService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 03:41:10,558 | DEBUG | hackthon_support_agent.TaskDependencyService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 03:41:10,560 | INFO | hackthon_support_agent.TaskDependencyService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 03:41:10,560 | DEBUG | hackthon_support_agent.TaskDependencyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-12 03:41:10,562 | INFO | hackthon_support_agent.TaskDependencyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-12 03:41:10,562 | DEBUG | hackthon_support_agent.TaskDependencyService | LLMs initialized
2025-11-12 03:41:10,562 | DEBUG | hackthon_support_agent.TaskPositionService | Initializing BaseService (provider=google)
2025-11-12 03:41:10,564 | INFO | hackthon_support_agent.TaskPositionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-12 03:41:10,564 | DEBUG | hackthon_support_agent.TaskPositionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 03:41:10,567 | INFO | hackthon_support_agent.TaskPositionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 03:41:10,567 | DEBUG | hackthon_support_agent.TaskPositionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 03:41:10,569 | INFO | hackthon_support_agent.TaskPositionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 03:41:10,569 | DEBUG | hackthon_support_agent.TaskPositionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 03:41:10,571 | INFO | hackthon_support_agent.TaskPositionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 03:41:10,571 | DEBUG | hackthon_support_agent.TaskPositionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-12 03:41:10,573 | INFO | hackthon_support_agent.TaskPositionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-12 03:41:10,574 | DEBUG | hackthon_support_agent.TaskPositionService | LLMs initialized
2025-11-12 03:41:26,972 | INFO | hackthon_support_agent.TaskGenerationService | ✅ Domain 問題管理: All tasks validated successfully on attempt 1
2025-11-12 03:41:28,159 | INFO | hackthon_support_agent.TaskGenerationService | ✅ Domain 学習コンテンツ管理: All tasks validated successfully on attempt 1
2025-11-12 03:41:29,015 | INFO | hackthon_support_agent.TaskGenerationService | ✅ Domain 学習履歴管理: All tasks validated successfully on attempt 1
2025-11-12 03:41:29,017 | INFO | hackthon_support_agent.TaskGenerationService | ✅ Domain ユーザー管理: All tasks validated successfully on attempt 1
2025-11-12 03:41:35,603 | INFO | hackthon_support_agent.TaskGenerationService | ✅ Domain 学習UI: All tasks validated successfully on attempt 1
2025-11-12 03:41:36,532 | INFO | hackthon_support_agent.TaskGenerationService | ✅ Domain AIモデル管理: All tasks validated successfully on attempt 1
2025-11-12 05:11:55,517 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-12 05:11:59,742 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-12 05:14:46,696 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-12 05:15:20,297 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-12 05:16:12,412 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-12 05:17:26,199 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-12 05:24:06,917 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-12 05:25:39,039 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-12 05:25:59,466 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-12 05:26:01,627 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-12 05:35:55,659 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-12 05:36:25,273 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-12 05:36:53,620 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-12 05:37:05,399 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-12 05:37:26,436 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-12 05:37:39,625 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-12 05:38:06,345 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-12 05:38:14,496 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-12 05:38:26,086 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-12 05:38:28,310 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-12 05:40:45,418 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-12 05:41:08,026 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-12 05:44:51,385 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-12 05:45:13,348 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-12 05:45:28,995 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-12 05:45:32,219 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-12 05:54:35,396 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-12 05:54:48,548 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-12 05:55:01,972 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-12 05:55:16,027 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-12 05:55:24,685 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-12 05:55:27,336 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-12 06:06:58,364 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-12 06:08:26,064 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-12 06:08:29,030 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-12 06:10:54,968 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-12 06:11:02,807 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-12 06:11:04,969 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-12 06:20:52,594 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-12 06:20:54,882 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-12 06:27:53,424 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-12 06:41:01,221 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-12 06:41:42,416 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-12 06:41:51,894 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-12 06:42:17,280 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-12 06:42:37,296 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-12 06:42:51,579 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-12 06:42:53,781 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-12 06:44:07,402 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-12 06:44:09,941 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-12 07:13:53,706 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-12 07:14:02,360 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-12 07:14:35,821 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-12 07:16:12,483 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-12 07:16:30,394 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-12 07:16:32,748 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-12 07:38:12,990 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-12 07:38:35,818 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-12 07:38:49,165 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-12 08:22:15,904 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-11-12 08:22:15,910 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-12 08:22:15,910 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 08:22:15,937 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 08:22:15,937 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 08:22:15,939 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 08:22:15,939 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 08:22:15,940 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 08:22:15,940 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-12 08:22:15,942 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-12 08:22:15,942 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-11-12 08:22:15,942 | DEBUG | hackthon_support_agent.QuestionService | Generating questions for project_id: ceca519e-a48a-450d-9342-ef8e7e0326b5 with idea_prompt: プロジェクトタイトル: オンライン学習プラットフォーム
プロジェクトアイディア: 学生の学力と得意不得意に合わせたAIを用いた動的な課題作成サービス
期間: 2025-11-12 〜 2025-12-12 17:21
2025-11-12 08:22:15,942 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-11-12 08:22:31,123 | INFO | hackthon_support_agent.QuestionService | Generated 7 questions for project_id: ceca519e-a48a-450d-9342-ef8e7e0326b5
2025-11-12 08:22:31,136 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-11-12 08:22:31,139 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-12 08:22:31,139 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 08:22:31,145 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 08:22:31,145 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 08:22:31,146 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 08:22:31,146 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 08:22:31,149 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 08:22:31,149 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-12 08:22:31,150 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-12 08:22:31,150 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-11-12 08:22:45,410 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-11-12 08:22:45,417 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-12 08:22:45,418 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 08:22:45,428 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 08:22:45,428 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 08:22:45,430 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 08:22:45,430 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 08:22:45,431 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 08:22:45,432 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-12 08:22:45,433 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-12 08:22:45,434 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-11-12 08:22:45,516 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.generate_summary_document'
2025-11-12 08:22:56,827 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-11-12 08:22:56,833 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-12 08:22:56,833 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 08:22:56,838 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 08:22:56,838 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 08:22:56,841 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 08:22:56,841 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 08:22:56,844 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 08:22:56,845 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-12 08:22:56,848 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-12 08:22:56,849 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-11-12 08:23:15,791 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-11-12 08:23:15,795 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-12 08:23:15,796 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 08:23:15,807 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 08:23:15,807 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 08:23:15,811 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 08:23:15,811 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 08:23:15,815 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 08:23:15,815 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-12 08:23:15,818 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-12 08:23:15,819 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-11-12 08:23:15,830 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-11-12 08:23:31,617 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-11-12 08:23:31,629 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-12 08:23:31,630 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 08:23:31,648 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 08:23:31,649 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 08:23:31,653 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 08:23:31,653 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 08:23:31,665 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 08:23:31,667 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-12 08:23:31,675 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-12 08:23:31,676 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-11-12 08:23:31,747 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: ceca519e-a48a-450d-9342-ef8e7e0326b5
2025-11-12 08:23:31,753 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.evaluate_specification'
2025-11-12 08:23:32,644 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-11-12 08:23:32,647 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-12 08:23:32,648 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 08:23:32,650 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 08:23:32,650 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 08:23:32,652 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 08:23:32,653 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 08:23:32,654 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 08:23:32,654 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-12 08:23:32,656 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-12 08:23:32,656 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-11-12 08:23:32,695 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: ceca519e-a48a-450d-9342-ef8e7e0326b5
2025-11-12 08:23:32,697 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.evaluate_specification'
2025-11-12 08:26:19,867 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-11-12 08:26:19,873 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-12 08:26:19,873 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 08:26:19,882 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 08:26:19,883 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 08:26:19,885 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 08:26:19,885 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 08:26:19,889 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 08:26:19,889 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-12 08:26:19,890 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-12 08:26:19,890 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-11-12 08:26:19,945 | INFO | hackthon_support_agent.SummaryService | 既存仕様書を検出。差分ベースで更新します。
2025-11-12 08:26:19,952 | INFO | hackthon_support_agent.SummaryService | 差分検出: 手動編集=False, 新規Q&A=5件
2025-11-12 08:26:19,953 | INFO | hackthon_support_agent.SummaryService | 新規キャッシュを作成: ceca519e-a48a-450d-9342-ef8e7e0326b5
2025-11-12 08:26:20,131 | ERROR | hackthon_support_agent.SummaryService | キャッシュ使用中にエラー: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'Cached content is too small. total_token_count=834, min_total_token_count=4096', 'status': 'INVALID_ARGUMENT'}}
2025-11-12 08:26:20,131 | INFO | hackthon_support_agent.SummaryService | フォールバック: キャッシュなしで生成
2025-11-12 08:26:29,806 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: ceca519e-a48a-450d-9342-ef8e7e0326b5
2025-11-12 08:26:29,809 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.evaluate_specification'
2025-11-12 08:26:49,260 | INFO | hackthon_support_agent.SummaryService | 不足情報から追加Q&Aを生成: 【利用シーン (いつ・頻度)】ユーザーはAI課題サービスを、一日のうちでどの時間帯に、どれくらいの頻...
2025-11-12 08:26:49,263 | INFO | hackthon_support_agent.SummaryService | 不足情報から追加Q&Aを生成: 【利用シーン (具体的な行動 - 解答入力)】ユーザーは「問題を解く」際、具体的にどのような操作で解...
2025-11-12 08:26:49,264 | INFO | hackthon_support_agent.SummaryService | 不足情報から追加Q&Aを生成: 【利用シーン (具体的な行動 - フィードバック)】問題を間違えた場合、正誤判定、解説、類題、ヒント...
2025-11-12 08:26:49,264 | INFO | hackthon_support_agent.SummaryService | 不足情報から追加Q&Aを生成: 【利用シーン (具体的な行動 - 難易度変化)】「正解が続けば徐々に難易度が上がる」とありますが、ユ...
2025-11-12 08:26:49,265 | INFO | hackthon_support_agent.SummaryService | 不足情報から追加Q&Aを生成: 【利用シーン (具体的な行動 - ダッシュボード)】ダッシュボードで「学習状況が可視化される」とあり...
2025-11-12 08:26:49,286 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-11-12 08:26:49,289 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-12 08:26:49,289 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 08:26:49,294 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 08:26:49,295 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 08:26:49,297 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 08:26:49,297 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 08:26:49,299 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 08:26:49,299 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-12 08:26:49,301 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-12 08:26:49,302 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-11-12 08:26:49,310 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-11-12 08:27:53,557 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-11-12 08:27:53,565 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-12 08:27:53,566 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 08:27:53,581 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 08:27:53,582 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 08:27:53,584 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 08:27:53,584 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 08:27:53,586 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 08:27:53,587 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-12 08:27:53,588 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-12 08:27:53,588 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-11-12 08:27:53,642 | INFO | hackthon_support_agent.SummaryService | 既存仕様書を検出。差分ベースで更新します。
2025-11-12 08:27:53,645 | INFO | hackthon_support_agent.SummaryService | 差分検出: 手動編集=False, 新規Q&A=15件
2025-11-12 08:27:53,645 | INFO | hackthon_support_agent.SummaryService | 新規キャッシュを作成: ceca519e-a48a-450d-9342-ef8e7e0326b5
2025-11-12 08:27:53,820 | ERROR | hackthon_support_agent.SummaryService | キャッシュ使用中にエラー: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'Cached content is too small. total_token_count=1232, min_total_token_count=4096', 'status': 'INVALID_ARGUMENT'}}
2025-11-12 08:27:53,820 | INFO | hackthon_support_agent.SummaryService | フォールバック: キャッシュなしで生成
2025-11-12 08:28:04,344 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: ceca519e-a48a-450d-9342-ef8e7e0326b5
2025-11-12 08:28:04,349 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.evaluate_specification'
2025-11-12 08:28:19,489 | INFO | hackthon_support_agent.SummaryService | 不足情報から追加Q&Aを生成: 【利用シーン】ユーザーはAI課題サービスを、一日のうちでどの時間帯に、どれくらいの頻度で、一回あたり...
2025-11-12 08:28:19,492 | INFO | hackthon_support_agent.SummaryService | 不足情報から追加Q&Aを生成: 【ユーザー体験 (UI/UX)】ユーザーは「問題を解く」際、具体的にどのような操作で解答を入力します...
2025-11-12 08:28:19,494 | INFO | hackthon_support_agent.SummaryService | 不足情報から追加Q&Aを生成: 【ユーザー体験 (UI/UX)】問題を間違えた場合、正誤判定、解説、類題、ヒントはそれぞれどのタイミ...
2025-11-12 08:28:19,495 | INFO | hackthon_support_agent.SummaryService | 不足情報から追加Q&Aを生成: 【ユーザー体験 (UI/UX)】「正解が続けば徐々に難易度が上がる」とありますが、ユーザーは難易度が...
2025-11-12 08:28:19,496 | INFO | hackthon_support_agent.SummaryService | 不足情報から追加Q&Aを生成: 【ユーザー体験 (UI/UX)】ダッシュボードで「学習状況が可視化される」とありますが、具体的にどの...
2025-11-12 08:28:19,515 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-11-12 08:28:19,519 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-12 08:28:19,519 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 08:28:19,522 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 08:28:19,522 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 08:28:19,540 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 08:28:19,541 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 08:28:19,555 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 08:28:19,555 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-12 08:28:19,558 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-12 08:28:19,558 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-11-12 08:28:19,564 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-11-12 08:29:19,680 | DEBUG | hackthon_support_agent.FunctionService | Initializing BaseService (provider=google)
2025-11-12 08:29:19,685 | INFO | hackthon_support_agent.FunctionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-12 08:29:19,685 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 08:29:19,704 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 08:29:19,705 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 08:29:19,708 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 08:29:19,708 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 08:29:19,711 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 08:29:19,712 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-12 08:29:19,714 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-12 08:29:19,715 | DEBUG | hackthon_support_agent.FunctionService | LLMs initialized
2025-11-12 08:29:19,715 | DEBUG | hackthon_support_agent.FunctionService | Generating functional requirements for project_id: ceca519e-a48a-450d-9342-ef8e7e0326b5
2025-11-12 08:29:19,720 | DEBUG | hackthon_support_agent.FunctionService | Fetching prompt 'function_service.generate_functional_requirements'
2025-11-12 08:29:55,103 | DEBUG | hackthon_support_agent.FunctionService | Generating clarification questions for 3 low-confidence requirements
2025-11-12 08:29:55,105 | DEBUG | hackthon_support_agent.FunctionService | Fetching prompt 'function_service.generate_clarification_questions'
2025-11-12 08:30:18,311 | DEBUG | hackthon_support_agent.FunctionService | Saving functional requirements to project document: ceca519e-a48a-450d-9342-ef8e7e0326b5
2025-11-12 08:30:18,353 | DEBUG | hackthon_support_agent.FunctionService | Saving 9 clarification questions to database
2025-11-12 08:31:39,139 | DEBUG | hackthon_support_agent.BaseService | Initializing BaseService (provider=google)
2025-11-12 08:31:39,144 | INFO | hackthon_support_agent.BaseService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-12 08:31:39,144 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 08:31:39,155 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 08:31:39,156 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 08:31:39,160 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 08:31:39,161 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 08:31:39,163 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 08:31:39,164 | DEBUG | hackthon_support_agent.BaseService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-12 08:31:39,167 | INFO | hackthon_support_agent.BaseService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-12 08:31:39,167 | DEBUG | hackthon_support_agent.BaseService | LLMs initialized
2025-11-12 08:31:39,234 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Fetching context for project: ceca519e-a48a-450d-9342-ef8e7e0326b5
2025-11-12 08:31:39,237 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Starting workflow for project: ceca519e-a48a-450d-9342-ef8e7e0326b5
2025-11-12 08:31:39,242 | INFO | hackthon_support_agent.BaseService | [PLANNING] Starting planning phase
2025-11-12 08:31:39,242 | INFO | hackthon_support_agent.BaseService | [PLANNING] Plan created with 3 focus areas
2025-11-12 08:31:39,244 | INFO | hackthon_support_agent.BaseService | [CACHE] Creating context cache
2025-11-12 08:31:39,461 | ERROR | hackthon_support_agent.BaseService | [CACHE] Cache creation failed: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'Cached content is too small. total_token_count=3891, min_total_token_count=4096', 'status': 'INVALID_ARGUMENT'}}
2025-11-12 08:31:39,464 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Starting parallel extraction
2025-11-12 08:31:39,464 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: データ・モデル
2025-11-12 08:31:41,039 | DEBUG | hackthon_support_agent.FrameworkService | Initializing BaseService (provider=google)
2025-11-12 08:31:41,042 | INFO | hackthon_support_agent.FrameworkService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-12 08:31:41,043 | DEBUG | hackthon_support_agent.FrameworkService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 08:31:41,047 | INFO | hackthon_support_agent.FrameworkService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 08:31:41,048 | DEBUG | hackthon_support_agent.FrameworkService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 08:31:41,051 | INFO | hackthon_support_agent.FrameworkService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 08:31:41,051 | DEBUG | hackthon_support_agent.FrameworkService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 08:31:41,053 | INFO | hackthon_support_agent.FrameworkService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 08:31:41,053 | DEBUG | hackthon_support_agent.FrameworkService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-12 08:31:41,055 | INFO | hackthon_support_agent.FrameworkService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-12 08:31:41,055 | DEBUG | hackthon_support_agent.FrameworkService | LLMs initialized
2025-11-12 08:31:41,056 | DEBUG | hackthon_support_agent.FrameworkService | Fetching prompt 'framework_service.generate_simple_recommendations'
2025-11-12 08:31:59,233 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 6 functions using LangChain
2025-11-12 08:31:59,235 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] データ・モデル completed in 19.77s - 6 functions extracted
2025-11-12 08:31:59,235 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: API・バックエンド
2025-11-12 08:32:16,913 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 6 functions using LangChain
2025-11-12 08:32:16,915 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] API・バックエンド completed in 17.68s - 6 functions extracted
2025-11-12 08:32:16,916 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Processing focus area: UI・画面
2025-11-12 08:32:33,327 | INFO | hackthon_support_agent.BaseService | [EXTRACT] Extracted 6 functions using LangChain
2025-11-12 08:32:33,329 | INFO | hackthon_support_agent.BaseService | [PROCESS_FOCUS_AREA] UI・画面 completed in 16.41s - 6 functions extracted
2025-11-12 08:32:33,330 | INFO | hackthon_support_agent.BaseService | [PARALLEL_EXTRACT] Completed: 3 areas processed
2025-11-12 08:32:33,335 | INFO | hackthon_support_agent.BaseService | [MERGE] Merging results from all focus areas
2025-11-12 08:32:33,336 | INFO | hackthon_support_agent.BaseService | [MERGE] Merged: 18 unique functions
2025-11-12 08:32:33,338 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURING] Starting parallel structuring
2025-11-12 08:32:33,366 | ERROR | hackthon_support_agent.BaseService | Categorization failed: Event loop is closed
2025-11-12 08:32:33,366 | ERROR | hackthon_support_agent.BaseService | [CATEGORIZE] Returning original functions unchanged
2025-11-12 08:32:33,367 | ERROR | hackthon_support_agent.BaseService | Priority assignment failed: Event loop is closed
2025-11-12 08:32:33,367 | ERROR | hackthon_support_agent.BaseService | Dependency analysis failed: Event loop is closed
2025-11-12 08:32:33,367 | INFO | hackthon_support_agent.BaseService | [PARALLEL_STRUCTURING] Completed: 18 functions, 0 dependencies
2025-11-12 08:32:33,368 | INFO | hackthon_support_agent.BaseService | [PERSISTENCE] Saving to database
2025-11-12 08:32:33,377 | INFO | hackthon_support_agent.BaseService | [PERSISTENCE] Cleared existing data for project ceca519e-a48a-450d-9342-ef8e7e0326b5
2025-11-12 08:32:33,401 | INFO | hackthon_support_agent.BaseService | [PERSISTENCE] Saved 18 functions and 0 dependencies to DB
2025-11-12 08:32:33,404 | INFO | hackthon_support_agent.BaseService | [WORKFLOW] Workflow completed in 54.17s
2025-11-12 08:35:02,907 | DEBUG | hackthon_support_agent.IntegratedTaskService | Initializing BaseService (provider=google)
2025-11-12 08:35:02,912 | INFO | hackthon_support_agent.IntegratedTaskService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-12 08:35:02,912 | DEBUG | hackthon_support_agent.IntegratedTaskService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 08:35:02,923 | INFO | hackthon_support_agent.IntegratedTaskService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 08:35:02,924 | DEBUG | hackthon_support_agent.IntegratedTaskService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 08:35:02,926 | INFO | hackthon_support_agent.IntegratedTaskService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 08:35:02,926 | DEBUG | hackthon_support_agent.IntegratedTaskService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 08:35:02,929 | INFO | hackthon_support_agent.IntegratedTaskService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 08:35:02,929 | DEBUG | hackthon_support_agent.IntegratedTaskService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-12 08:35:02,932 | INFO | hackthon_support_agent.IntegratedTaskService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-12 08:35:02,932 | DEBUG | hackthon_support_agent.IntegratedTaskService | LLMs initialized
2025-11-12 08:35:02,932 | DEBUG | hackthon_support_agent.TaskGenerationService | Initializing BaseService (provider=google)
2025-11-12 08:35:02,936 | INFO | hackthon_support_agent.TaskGenerationService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-12 08:35:02,936 | DEBUG | hackthon_support_agent.TaskGenerationService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 08:35:02,939 | INFO | hackthon_support_agent.TaskGenerationService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 08:35:02,940 | DEBUG | hackthon_support_agent.TaskGenerationService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 08:35:02,942 | INFO | hackthon_support_agent.TaskGenerationService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 08:35:02,942 | DEBUG | hackthon_support_agent.TaskGenerationService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 08:35:02,944 | INFO | hackthon_support_agent.TaskGenerationService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 08:35:02,944 | DEBUG | hackthon_support_agent.TaskGenerationService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-12 08:35:02,946 | INFO | hackthon_support_agent.TaskGenerationService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-12 08:35:02,946 | DEBUG | hackthon_support_agent.TaskGenerationService | LLMs initialized
2025-11-12 08:35:02,947 | DEBUG | hackthon_support_agent.TaskQualityEvaluationService | Initializing BaseService (provider=google)
2025-11-12 08:35:02,950 | INFO | hackthon_support_agent.TaskQualityEvaluationService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-12 08:35:02,950 | DEBUG | hackthon_support_agent.TaskQualityEvaluationService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 08:35:02,952 | INFO | hackthon_support_agent.TaskQualityEvaluationService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 08:35:02,952 | DEBUG | hackthon_support_agent.TaskQualityEvaluationService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 08:35:02,954 | INFO | hackthon_support_agent.TaskQualityEvaluationService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 08:35:02,955 | DEBUG | hackthon_support_agent.TaskQualityEvaluationService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 08:35:02,956 | INFO | hackthon_support_agent.TaskQualityEvaluationService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 08:35:02,957 | DEBUG | hackthon_support_agent.TaskQualityEvaluationService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-12 08:35:02,958 | INFO | hackthon_support_agent.TaskQualityEvaluationService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-12 08:35:02,958 | DEBUG | hackthon_support_agent.TaskQualityEvaluationService | LLMs initialized
2025-11-12 08:35:02,959 | DEBUG | hackthon_support_agent.LayerConsistencyEvaluator | Initializing BaseService (provider=google)
2025-11-12 08:35:02,961 | INFO | hackthon_support_agent.LayerConsistencyEvaluator | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-12 08:35:02,962 | DEBUG | hackthon_support_agent.LayerConsistencyEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 08:35:02,965 | INFO | hackthon_support_agent.LayerConsistencyEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 08:35:02,965 | DEBUG | hackthon_support_agent.LayerConsistencyEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 08:35:02,968 | INFO | hackthon_support_agent.LayerConsistencyEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 08:35:02,968 | DEBUG | hackthon_support_agent.LayerConsistencyEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 08:35:02,970 | INFO | hackthon_support_agent.LayerConsistencyEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 08:35:02,970 | DEBUG | hackthon_support_agent.LayerConsistencyEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-12 08:35:02,971 | INFO | hackthon_support_agent.LayerConsistencyEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-12 08:35:02,972 | DEBUG | hackthon_support_agent.LayerConsistencyEvaluator | LLMs initialized
2025-11-12 08:35:02,972 | DEBUG | hackthon_support_agent.DomainCompletenessEvaluator | Initializing BaseService (provider=google)
2025-11-12 08:35:02,975 | INFO | hackthon_support_agent.DomainCompletenessEvaluator | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-12 08:35:02,975 | DEBUG | hackthon_support_agent.DomainCompletenessEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 08:35:02,991 | INFO | hackthon_support_agent.DomainCompletenessEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 08:35:02,991 | DEBUG | hackthon_support_agent.DomainCompletenessEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 08:35:02,993 | INFO | hackthon_support_agent.DomainCompletenessEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 08:35:02,994 | DEBUG | hackthon_support_agent.DomainCompletenessEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 08:35:02,995 | INFO | hackthon_support_agent.DomainCompletenessEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 08:35:02,996 | DEBUG | hackthon_support_agent.DomainCompletenessEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-12 08:35:02,999 | INFO | hackthon_support_agent.DomainCompletenessEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-12 08:35:02,999 | DEBUG | hackthon_support_agent.DomainCompletenessEvaluator | LLMs initialized
2025-11-12 08:35:03,000 | DEBUG | hackthon_support_agent.TaskDependencyService | Initializing BaseService (provider=google)
2025-11-12 08:35:03,002 | INFO | hackthon_support_agent.TaskDependencyService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-12 08:35:03,002 | DEBUG | hackthon_support_agent.TaskDependencyService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 08:35:03,004 | INFO | hackthon_support_agent.TaskDependencyService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 08:35:03,004 | DEBUG | hackthon_support_agent.TaskDependencyService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 08:35:03,007 | INFO | hackthon_support_agent.TaskDependencyService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 08:35:03,008 | DEBUG | hackthon_support_agent.TaskDependencyService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 08:35:03,009 | INFO | hackthon_support_agent.TaskDependencyService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 08:35:03,010 | DEBUG | hackthon_support_agent.TaskDependencyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-12 08:35:03,012 | INFO | hackthon_support_agent.TaskDependencyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-12 08:35:03,012 | DEBUG | hackthon_support_agent.TaskDependencyService | LLMs initialized
2025-11-12 08:35:03,013 | DEBUG | hackthon_support_agent.TaskPositionService | Initializing BaseService (provider=google)
2025-11-12 08:35:03,017 | INFO | hackthon_support_agent.TaskPositionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-12 08:35:03,018 | DEBUG | hackthon_support_agent.TaskPositionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 08:35:03,020 | INFO | hackthon_support_agent.TaskPositionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 08:35:03,021 | DEBUG | hackthon_support_agent.TaskPositionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 08:35:03,026 | INFO | hackthon_support_agent.TaskPositionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 08:35:03,027 | DEBUG | hackthon_support_agent.TaskPositionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 08:35:03,029 | INFO | hackthon_support_agent.TaskPositionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 08:35:03,032 | DEBUG | hackthon_support_agent.TaskPositionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-12 08:35:03,036 | INFO | hackthon_support_agent.TaskPositionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-12 08:35:03,037 | DEBUG | hackthon_support_agent.TaskPositionService | LLMs initialized
2025-11-12 08:35:18,656 | INFO | hackthon_support_agent.TaskGenerationService | ✅ Domain AIモデル管理: All tasks validated successfully on attempt 1
2025-11-12 08:35:20,556 | INFO | hackthon_support_agent.TaskGenerationService | ✅ Domain ユーザー管理: All tasks validated successfully on attempt 1
2025-11-12 08:35:21,451 | INFO | hackthon_support_agent.TaskGenerationService | ✅ Domain 学習履歴・統計管理: All tasks validated successfully on attempt 1
2025-11-12 08:35:24,331 | INFO | hackthon_support_agent.TaskGenerationService | ✅ Domain 学習コンテンツ管理: All tasks validated successfully on attempt 1
2025-11-12 08:35:24,845 | INFO | hackthon_support_agent.TaskGenerationService | ✅ Domain 学習UI: All tasks validated successfully on attempt 1
2025-11-12 08:35:25,385 | INFO | hackthon_support_agent.TaskGenerationService | ✅ Domain 学力分析: All tasks validated successfully on attempt 1
2025-11-12 08:35:25,799 | INFO | hackthon_support_agent.TaskGenerationService | ✅ Domain 問題解答処理: All tasks validated successfully on attempt 1
2025-11-12 12:45:34,424 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-12 12:45:37,111 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-12 14:43:53,348 | DEBUG | hackthon_support_agent.IntegratedTaskService | Initializing BaseService (provider=google)
2025-11-12 14:43:53,363 | INFO | hackthon_support_agent.IntegratedTaskService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-12 14:43:53,364 | DEBUG | hackthon_support_agent.IntegratedTaskService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 14:43:53,513 | INFO | hackthon_support_agent.IntegratedTaskService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 14:43:53,514 | DEBUG | hackthon_support_agent.IntegratedTaskService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 14:43:53,517 | INFO | hackthon_support_agent.IntegratedTaskService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 14:43:53,522 | DEBUG | hackthon_support_agent.IntegratedTaskService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 14:43:53,525 | INFO | hackthon_support_agent.IntegratedTaskService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 14:43:53,525 | DEBUG | hackthon_support_agent.IntegratedTaskService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-12 14:43:53,528 | INFO | hackthon_support_agent.IntegratedTaskService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-12 14:43:53,528 | DEBUG | hackthon_support_agent.IntegratedTaskService | LLMs initialized
2025-11-12 14:43:53,529 | DEBUG | hackthon_support_agent.TaskGenerationService | Initializing BaseService (provider=google)
2025-11-12 14:43:53,531 | INFO | hackthon_support_agent.TaskGenerationService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-12 14:43:53,532 | DEBUG | hackthon_support_agent.TaskGenerationService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 14:43:53,534 | INFO | hackthon_support_agent.TaskGenerationService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 14:43:53,534 | DEBUG | hackthon_support_agent.TaskGenerationService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 14:43:53,537 | INFO | hackthon_support_agent.TaskGenerationService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 14:43:53,537 | DEBUG | hackthon_support_agent.TaskGenerationService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 14:43:53,539 | INFO | hackthon_support_agent.TaskGenerationService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 14:43:53,540 | DEBUG | hackthon_support_agent.TaskGenerationService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-12 14:43:53,541 | INFO | hackthon_support_agent.TaskGenerationService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-12 14:43:53,542 | DEBUG | hackthon_support_agent.TaskGenerationService | LLMs initialized
2025-11-12 14:43:53,543 | DEBUG | hackthon_support_agent.TaskQualityEvaluationService | Initializing BaseService (provider=google)
2025-11-12 14:43:53,551 | INFO | hackthon_support_agent.TaskQualityEvaluationService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-12 14:43:53,552 | DEBUG | hackthon_support_agent.TaskQualityEvaluationService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 14:43:53,555 | INFO | hackthon_support_agent.TaskQualityEvaluationService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 14:43:53,556 | DEBUG | hackthon_support_agent.TaskQualityEvaluationService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 14:43:53,558 | INFO | hackthon_support_agent.TaskQualityEvaluationService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 14:43:53,559 | DEBUG | hackthon_support_agent.TaskQualityEvaluationService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 14:43:53,562 | INFO | hackthon_support_agent.TaskQualityEvaluationService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 14:43:53,563 | DEBUG | hackthon_support_agent.TaskQualityEvaluationService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-12 14:43:53,567 | INFO | hackthon_support_agent.TaskQualityEvaluationService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-12 14:43:53,567 | DEBUG | hackthon_support_agent.TaskQualityEvaluationService | LLMs initialized
2025-11-12 14:43:53,568 | DEBUG | hackthon_support_agent.LayerConsistencyEvaluator | Initializing BaseService (provider=google)
2025-11-12 14:43:53,574 | INFO | hackthon_support_agent.LayerConsistencyEvaluator | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-12 14:43:53,574 | DEBUG | hackthon_support_agent.LayerConsistencyEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 14:43:53,575 | INFO | hackthon_support_agent.LayerConsistencyEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 14:43:53,576 | DEBUG | hackthon_support_agent.LayerConsistencyEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 14:43:53,581 | INFO | hackthon_support_agent.LayerConsistencyEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 14:43:53,582 | DEBUG | hackthon_support_agent.LayerConsistencyEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 14:43:53,584 | INFO | hackthon_support_agent.LayerConsistencyEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 14:43:53,584 | DEBUG | hackthon_support_agent.LayerConsistencyEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-12 14:43:53,586 | INFO | hackthon_support_agent.LayerConsistencyEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-12 14:43:53,587 | DEBUG | hackthon_support_agent.LayerConsistencyEvaluator | LLMs initialized
2025-11-12 14:43:53,587 | DEBUG | hackthon_support_agent.DomainCompletenessEvaluator | Initializing BaseService (provider=google)
2025-11-12 14:43:53,590 | INFO | hackthon_support_agent.DomainCompletenessEvaluator | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-12 14:43:53,590 | DEBUG | hackthon_support_agent.DomainCompletenessEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 14:43:53,592 | INFO | hackthon_support_agent.DomainCompletenessEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 14:43:53,593 | DEBUG | hackthon_support_agent.DomainCompletenessEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 14:43:53,595 | INFO | hackthon_support_agent.DomainCompletenessEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 14:43:53,595 | DEBUG | hackthon_support_agent.DomainCompletenessEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 14:43:53,597 | INFO | hackthon_support_agent.DomainCompletenessEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 14:43:53,598 | DEBUG | hackthon_support_agent.DomainCompletenessEvaluator | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-12 14:43:53,599 | INFO | hackthon_support_agent.DomainCompletenessEvaluator | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-12 14:43:53,600 | DEBUG | hackthon_support_agent.DomainCompletenessEvaluator | LLMs initialized
2025-11-12 14:43:53,600 | DEBUG | hackthon_support_agent.TaskDependencyService | Initializing BaseService (provider=google)
2025-11-12 14:43:53,605 | INFO | hackthon_support_agent.TaskDependencyService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-12 14:43:53,606 | DEBUG | hackthon_support_agent.TaskDependencyService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 14:43:53,609 | INFO | hackthon_support_agent.TaskDependencyService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 14:43:53,610 | DEBUG | hackthon_support_agent.TaskDependencyService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 14:43:53,613 | INFO | hackthon_support_agent.TaskDependencyService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 14:43:53,614 | DEBUG | hackthon_support_agent.TaskDependencyService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 14:43:53,617 | INFO | hackthon_support_agent.TaskDependencyService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 14:43:53,617 | DEBUG | hackthon_support_agent.TaskDependencyService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-12 14:43:53,622 | INFO | hackthon_support_agent.TaskDependencyService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-12 14:43:53,623 | DEBUG | hackthon_support_agent.TaskDependencyService | LLMs initialized
2025-11-12 14:43:53,624 | DEBUG | hackthon_support_agent.TaskPositionService | Initializing BaseService (provider=google)
2025-11-12 14:43:53,626 | INFO | hackthon_support_agent.TaskPositionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-12 14:43:53,628 | DEBUG | hackthon_support_agent.TaskPositionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 14:43:53,631 | INFO | hackthon_support_agent.TaskPositionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 14:43:53,632 | DEBUG | hackthon_support_agent.TaskPositionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 14:43:53,633 | INFO | hackthon_support_agent.TaskPositionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 14:43:53,633 | DEBUG | hackthon_support_agent.TaskPositionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-12 14:43:53,634 | INFO | hackthon_support_agent.TaskPositionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-12 14:43:53,636 | DEBUG | hackthon_support_agent.TaskPositionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-12 14:43:53,638 | INFO | hackthon_support_agent.TaskPositionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-12 14:43:53,638 | DEBUG | hackthon_support_agent.TaskPositionService | LLMs initialized
2025-11-12 14:44:12,181 | INFO | hackthon_support_agent.TaskGenerationService | ✅ Domain 学習履歴・課題管理: All tasks validated successfully on attempt 1
2025-11-12 14:44:12,321 | INFO | hackthon_support_agent.TaskGenerationService | ✅ Domain AI学習支援: All tasks validated successfully on attempt 1
2025-11-12 14:44:12,529 | INFO | hackthon_support_agent.TaskGenerationService | ✅ Domain データ管理API: All tasks validated successfully on attempt 1
2025-11-12 14:44:13,239 | INFO | hackthon_support_agent.TaskGenerationService | ✅ Domain ユーザー管理: All tasks validated successfully on attempt 1
2025-11-12 14:44:13,579 | INFO | hackthon_support_agent.TaskGenerationService | ✅ Domain 診断テスト: All tasks validated successfully on attempt 1
2025-11-13 00:19:16,279 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-11-13 00:19:16,290 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-13 00:19:16,290 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-13 00:19:16,337 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-13 00:19:16,338 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-13 00:19:16,343 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-13 00:19:16,343 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-13 00:19:16,346 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-13 00:19:16,347 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-13 00:19:16,351 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-13 00:19:16,351 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-11-13 00:19:16,351 | DEBUG | hackthon_support_agent.QuestionService | Generating questions for project_id: 6f57ded8-b6f3-4682-8a3b-08509bb208a5 with idea_prompt: プロジェクトタイトル: 自分の投稿が全く見えないSNSアプリ
プロジェクトアイディア: 承認欲求から抜け出そう！自分の投稿した内容はタイムライン上に流れず、他人が投稿したものしか見れないSNS。投稿した内容に対しては、リアクションだけできて、最後にされたリアクションの内容だけが投稿者には伝達される。
期間: 2025-11-12 〜 2025-11-30 01:17
2025-11-13 00:19:16,352 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-11-13 00:21:08,905 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-13 00:21:13,249 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-13 04:00:41,874 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-13 04:00:46,551 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-14 08:14:49,373 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-14 08:15:50,069 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-14 08:17:26,716 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-14 08:52:14,525 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-14 08:53:08,619 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-14 08:53:11,505 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-14 08:53:15,873 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-11-14 08:53:15,878 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-14 08:53:15,879 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-14 08:53:15,973 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-14 08:53:15,973 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-14 08:53:15,981 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-14 08:53:15,981 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-14 08:53:15,987 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-14 08:53:15,987 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-14 08:53:15,995 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-14 08:53:15,996 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-11-14 08:53:15,996 | DEBUG | hackthon_support_agent.QuestionService | Generating questions for project_id: 0a048c19-9818-4c20-9eaa-067e2eafbccf with idea_prompt: プロジェクトタイトル: オンライン学習プラットフォーム
プロジェクトアイディア: 学生の学力と得意不得意に合わせたAIを用いた動的な課題作成サービス
期間: 2025-11-14 〜 2025-11-14 17:30
2025-11-14 08:53:15,997 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-11-14 08:53:29,240 | INFO | hackthon_support_agent.QuestionService | Generated 5 questions for project_id: 0a048c19-9818-4c20-9eaa-067e2eafbccf
2025-11-14 08:53:29,252 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-11-14 08:53:29,256 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-14 08:53:29,256 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-14 08:53:29,264 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-14 08:53:29,265 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-14 08:53:29,269 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-14 08:53:29,269 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-14 08:53:29,274 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-14 08:53:29,275 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-14 08:53:29,279 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-14 08:53:29,279 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-11-14 08:53:35,493 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-11-14 08:53:35,499 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-14 08:53:35,499 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-14 08:53:35,508 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-14 08:53:35,509 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-14 08:53:35,515 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-14 08:53:35,516 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-14 08:53:35,521 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-14 08:53:35,522 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-14 08:53:35,525 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-14 08:53:35,526 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-11-14 08:53:35,688 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.generate_summary_document'
2025-11-14 08:53:47,473 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-11-14 08:53:47,478 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-14 08:53:47,478 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-14 08:53:47,497 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-14 08:53:47,498 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-14 08:53:47,501 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-14 08:53:47,502 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-14 08:53:47,512 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-14 08:53:47,513 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-14 08:53:47,523 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-14 08:53:47,523 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-11-14 08:54:06,373 | DEBUG | hackthon_support_agent.MVPJudgeService | Initializing BaseService (provider=google)
2025-11-14 08:54:06,377 | INFO | hackthon_support_agent.MVPJudgeService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-14 08:54:06,378 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-14 08:54:06,388 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-14 08:54:06,389 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-14 08:54:06,393 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-14 08:54:06,394 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-14 08:54:06,398 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-14 08:54:06,399 | DEBUG | hackthon_support_agent.MVPJudgeService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-14 08:54:06,401 | INFO | hackthon_support_agent.MVPJudgeService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-14 08:54:06,401 | DEBUG | hackthon_support_agent.MVPJudgeService | LLMs initialized
2025-11-14 08:54:06,411 | DEBUG | hackthon_support_agent.MVPJudgeService | Fetching prompt 'mvp_service.judge_mvp'
2025-11-14 08:54:23,976 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-14 08:54:25,201 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-11-14 08:54:25,203 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-14 08:54:25,204 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-14 08:54:25,236 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-14 08:54:25,237 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-14 08:54:25,239 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-14 08:54:25,239 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-14 08:54:25,241 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-14 08:54:25,242 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-14 08:54:25,244 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-14 08:54:25,244 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-11-14 08:54:25,354 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: 0a048c19-9818-4c20-9eaa-067e2eafbccf
2025-11-14 08:54:25,378 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.evaluate_specification'
2025-11-14 08:54:25,419 | DEBUG | hackthon_support_agent.SummaryService | Initializing BaseService (provider=google)
2025-11-14 08:54:25,421 | INFO | hackthon_support_agent.SummaryService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-14 08:54:25,422 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-14 08:54:25,424 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-14 08:54:25,424 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-14 08:54:25,428 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-14 08:54:25,428 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-14 08:54:25,431 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-14 08:54:25,432 | DEBUG | hackthon_support_agent.SummaryService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-14 08:54:25,435 | INFO | hackthon_support_agent.SummaryService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-14 08:54:25,435 | DEBUG | hackthon_support_agent.SummaryService | LLMs initialized
2025-11-14 08:54:25,485 | DEBUG | hackthon_support_agent.SummaryService | Generating confidence feedback for project_id: 0a048c19-9818-4c20-9eaa-067e2eafbccf
2025-11-14 08:54:25,489 | DEBUG | hackthon_support_agent.SummaryService | Fetching prompt 'summary_service.evaluate_specification'
2025-11-14 08:54:32,479 | DEBUG | hackthon_support_agent.FunctionService | Initializing BaseService (provider=google)
2025-11-14 08:54:32,483 | INFO | hackthon_support_agent.FunctionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-11-14 08:54:32,483 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-14 08:54:32,493 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-14 08:54:32,493 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-14 08:54:32,495 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-14 08:54:32,496 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-11-14 08:54:32,497 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-11-14 08:54:32,498 | DEBUG | hackthon_support_agent.FunctionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-11-14 08:54:32,500 | INFO | hackthon_support_agent.FunctionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-11-14 08:54:32,500 | DEBUG | hackthon_support_agent.FunctionService | LLMs initialized
2025-11-14 08:54:32,501 | DEBUG | hackthon_support_agent.FunctionService | Generating functional requirements for project_id: 0a048c19-9818-4c20-9eaa-067e2eafbccf
2025-11-14 08:54:32,504 | DEBUG | hackthon_support_agent.FunctionService | Fetching prompt 'function_service.generate_functional_requirements'
2025-11-14 08:55:04,343 | DEBUG | hackthon_support_agent.FunctionService | Saving functional requirements to project document: 0a048c19-9818-4c20-9eaa-067e2eafbccf
2025-11-19 05:29:26,349 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-11-19 05:29:30,725 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-12-25 22:04:12,539 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-12-25 22:05:17,129 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-12-25 22:05:21,251 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-12-25 22:05:56,444 | INFO | hackthon_support_agent | Loaded environment variables from /workspaces/hackthon_support_agent/back/.env.local
2025-12-25 22:06:46,925 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-12-25 22:06:46,931 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-12-25 22:06:46,932 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-12-25 22:06:46,994 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-12-25 22:06:46,994 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-12-25 22:06:46,999 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-12-25 22:06:47,000 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-12-25 22:06:47,003 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
2025-12-25 22:06:47,004 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash-lite, temp=0.50)
2025-12-25 22:06:47,007 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash-lite, key_present=True)
2025-12-25 22:06:47,008 | DEBUG | hackthon_support_agent.QuestionService | LLMs initialized
2025-12-25 22:06:47,008 | DEBUG | hackthon_support_agent.QuestionService | Generating questions for project_id: be3cf06f-0d9f-4ec3-be8c-1af43d2bff82 with idea_prompt: プロジェクトタイトル: AIを使用した動的教材作成アプリ
プロジェクトアイディア: 生徒の学力に合わせて問題集の内容を動的に変える数学特化問題アプリ
期間: 2025-12-25 〜 2026-01-08 07:05
2025-12-25 22:06:47,009 | DEBUG | hackthon_support_agent.QuestionService | Fetching prompt 'question_service.generate_question'
2025-12-25 22:06:56,347 | INFO | hackthon_support_agent.QuestionService | Generated 5 questions for project_id: be3cf06f-0d9f-4ec3-be8c-1af43d2bff82
2025-12-25 22:06:56,446 | DEBUG | hackthon_support_agent.QuestionService | Initializing BaseService (provider=google)
2025-12-25 22:06:56,936 | INFO | hackthon_support_agent.QuestionService | Prompts loaded from /workspaces/hackathon_support_agent/back/services/prompts.toml
2025-12-25 22:06:57,020 | DEBUG | hackthon_support_agent.QuestionService | Loading LLM (provider=google, model=gemini-2.5-flash, temp=0.50)
2025-12-25 22:06:57,050 | INFO | hackthon_support_agent.QuestionService | LLM loaded (provider=google, model=gemini-2.5-flash, key_present=True)
